{"cells":[{"cell_type":"markdown","metadata":{"id":"BErSeefeQwQi"},"source":["### Setup packages "]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":22805,"status":"ok","timestamp":1653304554948,"user":{"displayName":"Hans Roggeman","userId":"10574434403170915342"},"user_tz":-60},"id":"L8DGCgVxR2AB","outputId":"78af7951-1ec1-4ad7-cba1-84326103e62d"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11007,"status":"ok","timestamp":1653304565951,"user":{"displayName":"Hans Roggeman","userId":"10574434403170915342"},"user_tz":-60},"id":"3xIx5C6UQn4u","outputId":"6bb0e95c-91ea-43de-caf9-802537081e30"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting progressbar\n","  Downloading progressbar-2.5.tar.gz (10 kB)\n","Building wheels for collected packages: progressbar\n","  Building wheel for progressbar (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for progressbar: filename=progressbar-2.5-py3-none-any.whl size=12082 sha256=ef069446e460ec38e186113fd2e41189d574288064b6398405ced1e27a099a61\n","  Stored in directory: /root/.cache/pip/wheels/f0/fd/1f/3e35ed57e94cd8ced38dd46771f1f0f94f65fec548659ed855\n","Successfully built progressbar\n","Installing collected packages: progressbar\n","Successfully installed progressbar-2.5\n","Requirement already satisfied: plotnine in /usr/local/lib/python3.7/dist-packages (0.6.0)\n","Requirement already satisfied: mizani>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from plotnine) (0.6.0)\n","Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from plotnine) (1.21.6)\n","Requirement already satisfied: patsy>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from plotnine) (0.5.2)\n","Requirement already satisfied: statsmodels>=0.9.0 in /usr/local/lib/python3.7/dist-packages (from plotnine) (0.10.2)\n","Requirement already satisfied: scipy>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from plotnine) (1.4.1)\n","Requirement already satisfied: descartes>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from plotnine) (1.1.0)\n","Requirement already satisfied: pandas>=0.25.0 in /usr/local/lib/python3.7/dist-packages (from plotnine) (1.3.5)\n","Requirement already satisfied: matplotlib>=3.1.1 in /usr/local/lib/python3.7/dist-packages (from plotnine) (3.2.2)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.1.1->plotnine) (1.4.2)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.1.1->plotnine) (3.0.9)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.1.1->plotnine) (0.11.0)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.1.1->plotnine) (2.8.2)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib>=3.1.1->plotnine) (4.2.0)\n","Requirement already satisfied: palettable in /usr/local/lib/python3.7/dist-packages (from mizani>=0.6.0->plotnine) (3.3.0)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.25.0->plotnine) (2022.1)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from patsy>=0.4.1->plotnine) (1.15.0)\n","Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (1.11.0+cu113)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch) (4.2.0)\n","Collecting ipython-autotime\n","  Downloading ipython_autotime-0.3.1-py2.py3-none-any.whl (6.8 kB)\n","Requirement already satisfied: ipython in /usr/local/lib/python3.7/dist-packages (from ipython-autotime) (5.5.0)\n","Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from ipython->ipython-autotime) (4.8.0)\n","Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython->ipython-autotime) (2.6.1)\n","Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython->ipython-autotime) (0.7.5)\n","Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.7/dist-packages (from ipython->ipython-autotime) (5.1.1)\n","Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython->ipython-autotime) (4.4.2)\n","Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from ipython->ipython-autotime) (1.0.18)\n","Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from ipython->ipython-autotime) (57.4.0)\n","Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from ipython->ipython-autotime) (0.8.1)\n","Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython->ipython-autotime) (0.2.5)\n","Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython->ipython-autotime) (1.15.0)\n","Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect->ipython->ipython-autotime) (0.7.0)\n","Installing collected packages: ipython-autotime\n","Successfully installed ipython-autotime-0.3.1\n","time: 130 µs (started: 2022-05-23 11:16:05 +00:00)\n"]}],"source":["%pip install progressbar\n","%pip install plotnine\n","%pip install torch\n","%pip install ipython-autotime\n","%load_ext autotime"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1720,"status":"ok","timestamp":1653304567667,"user":{"displayName":"Hans Roggeman","userId":"10574434403170915342"},"user_tz":-60},"id":"EfIU_eNp3Zio","outputId":"b5c97e94-2601-47f4-fee4-c9c93850893c"},"outputs":[{"output_type":"stream","name":"stdout","text":["time: 1.65 s (started: 2022-05-23 11:16:05 +00:00)\n"]}],"source":["from plotnine import *\n","from plotnine.themes import *"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2852,"status":"ok","timestamp":1653304570516,"user":{"displayName":"Hans Roggeman","userId":"10574434403170915342"},"user_tz":-60},"id":"ZmUjYbArAuQT","outputId":"26a75a3b-1d89-47a6-afc8-51401b197ef8"},"outputs":[{"output_type":"stream","name":"stdout","text":["time: 2.65 s (started: 2022-05-23 11:16:07 +00:00)\n"]}],"source":["import tensorflow as tf\n","from scipy.io import loadmat\n","import random\n","import math\n","import tensorflow_probability as tfp"]},{"cell_type":"markdown","metadata":{"id":"PieVKPfHHYQ6"},"source":["_paper_name_ establishes the reusable name of the paper, it represents the directory under data_papers on the google drive"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1653304570516,"user":{"displayName":"Hans Roggeman","userId":"10574434403170915342"},"user_tz":-60},"id":"BI4p7ZKb0Qz2","outputId":"3f518b5e-e72d-4796-8297-f4653a358e51"},"outputs":[{"output_type":"stream","name":"stdout","text":["time: 1.08 ms (started: 2022-05-23 11:16:10 +00:00)\n"]}],"source":["paper_name = \"dgm_hjb\""]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":577,"status":"ok","timestamp":1653304571088,"user":{"displayName":"Hans Roggeman","userId":"10574434403170915342"},"user_tz":-60},"id":"433z6V3T2rB2","outputId":"116e958a-fc28-4429-f413-320fe598b3a7"},"outputs":[{"output_type":"stream","name":"stdout","text":["time: 611 ms (started: 2022-05-23 11:16:10 +00:00)\n"]}],"source":["import os, sys\n","import errno\n","\n","# make a directory if it does not exist\n","def make_dir_if_not_exist(used_path):\n","    if not os.path.isdir(used_path):\n","        try:\n","            os.mkdir(used_path)\n","        except OSError as exc:\n","            if exc.errno != errno.EEXIST:\n","                raise exc\n","            else:\n","                raise ValueError(f'{used_path} directoy cannot be created because its parent directory does not exist.')\n","\n","# make directories if they do not exist\n","\n","make_dir_if_not_exist(\"/content/drive/MyDrive/data_papers/\")\n","make_dir_if_not_exist(f\"/content/drive/MyDrive/data_papers/{paper_name}\")\n","make_dir_if_not_exist(f\"/content/drive/MyDrive/data_papers/{paper_name}/model_features/\")\n","make_dir_if_not_exist(f\"/content/drive/MyDrive/data_papers/{paper_name}/model_checkpoints/\")\n","make_dir_if_not_exist(f\"/content/drive/MyDrive/data_papers/{paper_name}/model_history/\")\n","make_dir_if_not_exist(f\"/content/drive/MyDrive/data_papers/{paper_name}/model_finals/\")\n","make_dir_if_not_exist(f\"/content/drive/MyDrive/data_papers/{paper_name}/model_predictions/\")\n","make_dir_if_not_exist(f\"/content/drive/MyDrive/data_papers/{paper_name}/model_ccs/\")\n","make_dir_if_not_exist(f\"/content/drive/MyDrive/data_papers/{paper_name}/summary_results/\")\n","make_dir_if_not_exist(f\"/content/drive/MyDrive/data_papers/{paper_name}/summary_results/temp/\")"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1653304571089,"user":{"displayName":"Hans Roggeman","userId":"10574434403170915342"},"user_tz":-60},"id":"uat0pG8aR3Rh","outputId":"9a0e754f-fb35-4399-e9ac-e2635944a0e2"},"outputs":[{"output_type":"stream","name":"stdout","text":["time: 7.3 ms (started: 2022-05-23 11:16:10 +00:00)\n"]}],"source":["# Set up the imports\n","from sklearn.model_selection import train_test_split\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","import pandas as pd\n","import numpy as np\n","\n","import site\n","import os\n","import tensorflow as tf\n","import pandas as pd\n","import h5py as h5\n","import matplotlib.pyplot as plt\n","import errno\n","import numpy as np\n","import itertools\n","import multiprocessing\n","import json\n","import datetime\n","import random\n","from collections import defaultdict\n","from sklearn.model_selection import train_test_split\n","\n","pd.set_option('display.width', 400)\n","pd.set_option('display.max_columns', 40)\n"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3096,"status":"ok","timestamp":1653304574182,"user":{"displayName":"Hans Roggeman","userId":"10574434403170915342"},"user_tz":-60},"id":"KpFjo3MkLus9","outputId":"b9fbfe6e-a02e-48fb-92e0-f0ea520fea5a"},"outputs":[{"output_type":"stream","name":"stdout","text":["time: 2.73 s (started: 2022-05-23 11:16:10 +00:00)\n"]}],"source":["import torch \n","import matplotlib.pyplot as plt\n","import numpy as np\n","from torch.autograd import Variable\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","import matplotlib.pyplot as plt\n","from mpl_toolkits.mplot3d import Axes3D\n","from scipy.stats import norm\n","from matplotlib import cm\n","import pdb\n"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1606,"status":"ok","timestamp":1653304575781,"user":{"displayName":"Hans Roggeman","userId":"10574434403170915342"},"user_tz":-60},"id":"CbfN42gpGZhC","outputId":"a768cc9e-94d5-497c-ecfc-5a1d4d0b6799"},"outputs":[{"output_type":"stream","name":"stdout","text":["time: 1.91 s (started: 2022-05-23 11:16:13 +00:00)\n"]}],"source":["import plotly.graph_objects as go\n","import plotly.express as px\n","from pprint import pprint as pp"]},{"cell_type":"markdown","metadata":{"id":"bvy0WvxDGCxk"},"source":["### Shared functions across models"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":17,"status":"ok","timestamp":1653304575782,"user":{"displayName":"Hans Roggeman","userId":"10574434403170915342"},"user_tz":-60},"id":"cpVaz5dwXZNq","outputId":"8ef9f8ee-6cf4-4065-d44b-da6f180d1331"},"outputs":[{"output_type":"stream","name":"stdout","text":["time: 22.5 ms (started: 2022-05-23 11:16:15 +00:00)\n"]}],"source":["import pandas as pd\n","\n","def plot_report(train_instance):\n","        \n","    history_tl_cpu = [ x for x in train_instance.history_tl ]\n","    history_internal_cpu = [ x.cpu().detach().numpy() for x in train_instance.history_internal_cpu ]\n","    history_terminal_cpu = [ x.cpu().detach().numpy() for x in train_instance.history_terminal ]\n","    history_initial_cpu = [ x.cpu().detach().numpy() for x in train_instance.history_initial ]\n","\n","    obs_data = pd.DataFrame({\"Epochs\" : [ (x+1)*train_instance.hook_interval for x in range(len(history_initial_cpu))], \n","                             \"AvgLogLoss\": np.log(history_tl_cpu), \n","                             \"TerminalLogLoss\" :  np.log(history_terminal_cpu),\n","                             \"InternalLogLoss\" :  np.log(history_internal_cpu),\n","                             \"InitialLogLoss\" : np.log(history_initial_cpu)\n","                             })\n","\n","    return (ggplot(obs_data, aes(\"Epochs\",\"AvgLogLoss\")) + geom_line() + geom_point(),\n","            ggplot(obs_data, aes(\"Epochs\",\"TerminalLogLoss\")) + geom_line() + geom_point(),\n","            ggplot(obs_data, aes(\"Epochs\",\"InternalLogLoss\")) + geom_line() + geom_point(),\n","            ggplot(obs_data, aes(\"Epochs\",\"InitialLogLoss\")) + geom_line() + geom_point()\n","            )\n","\n","def plot_activation_mean(train_instance):\n","    \n","    # pdb.set_trace()\n","\n","    if train_instance.debug == False:\n","        print( 'error: debug is off , turn it on and train again ' )\n","    else:\n","        history = np.array(train_instance.history_mean_hooks)\n","        jet= plt.get_cmap('jet')\n","        colors = iter(jet(np.linspace(0,1,10)))\n","        fig, ax = plt.subplots()\n","        for i in range(history.shape[1]):\n","            ax.plot(history[:,i], '--r', label= i , color=next(colors) )\n","        fig.suptitle('Layers activation mean value', fontsize=10)\n","        leg = ax.legend();\n"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":16,"status":"ok","timestamp":1653304575783,"user":{"displayName":"Hans Roggeman","userId":"10574434403170915342"},"user_tz":-60},"id":"QMAuMqdgU9kL","outputId":"ce361753-575d-482f-801a-cb109a7bcd7a"},"outputs":[{"output_type":"stream","name":"stdout","text":["time: 512 µs (started: 2022-05-23 11:16:15 +00:00)\n"]}],"source":["# plot_report(train)\n","# plot_activation_mean(train)"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":15,"status":"ok","timestamp":1653304575783,"user":{"displayName":"Hans Roggeman","userId":"10574434403170915342"},"user_tz":-60},"id":"sCV-yFDXUV4J","outputId":"98ba48c5-8fd6-4dab-9bea-e1c4e83e8964"},"outputs":[{"output_type":"stream","name":"stdout","text":["time: 766 µs (started: 2022-05-23 11:16:15 +00:00)\n"]}],"source":["# print( 'Value at 0' , net( torch.tensor( [ 0. , 1. , 1. , 1. ] ).cuda() ) )\n","# #%% save\n","# torch.save(net.state_dict(), './model3Assets')\n","# #%%\n","# net = TheModelClass(*args, **kwargs)\n","# net.load_state_dict(torch.load('./modelmodel3Assets'))\n","# net.eval()"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":15,"status":"ok","timestamp":1653304575784,"user":{"displayName":"Hans Roggeman","userId":"10574434403170915342"},"user_tz":-60},"id":"ONB5NopRa3fD","outputId":"9917f87e-1279-4a18-a1cb-a10bd1c934cc"},"outputs":[{"output_type":"stream","name":"stdout","text":["time: 27.8 ms (started: 2022-05-23 11:16:15 +00:00)\n"]}],"source":["# a set up that just maximizes the loss s.t. loss < eps (maximizeloss_weights_st) using the weights on the losses\n","from scipy.optimize import LinearConstraint, NonlinearConstraint\n","from scipy.optimize import Bounds\n","from functools import partial\n","from scipy.optimize import minimize\n","from functools import wraps\n","\n","def negative(f):\n","    @wraps(f)\n","    def g(*args,**kwargs):\n","        return - f(*args,**kwargs)\n","    # g.__name__ = f'negative({f.__name__})'\n","    return g\n","# kl_loss = nn.KLDivLoss(size_average=None, reduction=\"batchmean\")\n","\n","# we can add more minimization functions here later (e.g. SS diff)\n","def KLDiffHere( varX, loss_terms, log_target = False, reduction = \"mean\"):  \n","  target = torch.tensor([1./len(loss_terms)]*len(loss_terms))*torch.tensor(loss_terms)\n","  input = torch.tensor(varX*loss_terms)\n","  loss_pointwise = target * (torch.log(target) - torch.log(input))\n","  if reduction == \"mean\":  # default\n","      loss = loss_pointwise.mean()\n","  elif reduction == \"batchmean\":  # mathematically correct\n","      loss = loss_pointwise.sum() / input.size(0)\n","  elif reduction == \"sum\":\n","      loss = loss_pointwise.sum()\n","  else:  # reduction == \"none\"\n","      loss = loss_pointwise  \n","  return loss\n","\n","  # return torch.nn.KLDivLoss(varX*loss_terms,np.array([1./len(loss_terms)]*len(loss_terms))*loss_terms)\n","\n","def minimize_weights_st(loss_terms, loss_func):\n","  bounds = Bounds([0]*len(loss_terms), [1.0]*len(loss_terms))\n","  linear_constraint = LinearConstraint([[1]*len(loss_terms)], [1.0], [1.0])\n","  x0 = [0.25]*len(loss_terms)\n","  res = minimize( partial(loss_func, loss_terms=loss_terms), \n","                  x0, \n","                  method='trust-constr', \n","                  constraints=[linear_constraint],\n","                  options={'verbose': 0}, \n","                  bounds=bounds )\n","  return res\n","\n","def maximizeloss_weights_st(loss_terms, loss_func, eps):\n","  bounds = Bounds([0]*len(loss_terms), [1.0]*len(loss_terms))\n","  linear_constraint = LinearConstraint([[1]*len(loss_terms)], [1.0], [1.0])\n","  nonlinear_constraint  = NonlinearConstraint(negative(partial(loss_func, loss_terms=loss_terms)),1E-12,eps)\n","  # even though zero is the KL minimum it helps to put a negative number here to explore\n","\n","  x0 = [1.0/len(loss_terms)]*len(loss_terms)\n","  res = minimize( negative(partial(loss_func, loss_terms=loss_terms)), \n","                  x0, \n","                  method='trust-constr', \n","                  constraints=[linear_constraint, nonlinear_constraint],\n","                  options={'verbose': 0}, \n","                  bounds=bounds )\n","  return res\n"]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":14,"status":"ok","timestamp":1653304575785,"user":{"displayName":"Hans Roggeman","userId":"10574434403170915342"},"user_tz":-60},"id":"RM0IVdZ_TXW3","outputId":"282fe2c3-d6b7-4032-9e3d-39d2020614c5"},"outputs":[{"output_type":"stream","name":"stdout","text":["[0.33334757 0.33333761 0.33331482]\n","time: 74.7 ms (started: 2022-05-23 11:16:15 +00:00)\n"]}],"source":["r1 = maximizeloss_weights_st( [ 34.25, 100.12, 23.45] , KLDiffHere, 1E9)\n","print(r1.x)"]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":13,"status":"ok","timestamp":1653304575785,"user":{"displayName":"Hans Roggeman","userId":"10574434403170915342"},"user_tz":-60},"id":"ewko67bDIcz9","outputId":"44013889-5fe3-4e31-f77b-9452c99b2c83"},"outputs":[{"output_type":"stream","name":"stdout","text":["time: 4.88 ms (started: 2022-05-23 11:16:15 +00:00)\n"]}],"source":["### There is an issue getting this to work because of nonlinear_constraint  = NonlinearConstraint(negative(partial(loss_func, loss_terms=loss_terms)),1E-9,eps)\n","\n","    # def calculateLossAdaptWeights(self , size = 2**8 , train = True, min_max = True):\n","    #     '''\n","    #     Helper function that Sample and Calculate loss,\n","    #     This is adapted in that it changes the weights on the losses to maximize the loss provided\n","    #     the KL distance of the new weighting is within self.eps of the previous distribution (starting at equally weighted)\n","    #     '''        \n","    #     x , x_terminal , x_boundary = self.sample(size)\n","    #     x = Variable( x , requires_grad=True)\n","    #     Ls = self.criterion( x , x_terminal , x_boundary )\n","    #     DO , TC , BC = Ls\n","    #     DOm = torch.mean(DO).detach().cpu().float().item()\n","    #     TCm = torch.mean(TC).detach().cpu().float().item()\n","    #     BCm = torch.mean(BC).detach().cpu().float().item()\n","\n","    #     losses_for_reweighting = [ torch.mean(lv).detach().cpu().float().item() for lv in Ls if list(lv.size())] \n","    #     mask_for_available_losses = [ True if list(lv.size()) else False for lv in Ls ]\n","\n","    #     # print([ DOm, TCm, BCm])\n","    #     # if is.nan(DOm):\n","    #     #   print(DO)\n","\n","    #     if self.weights is None:\n","    #       self.weights = torch.ones(1,len(Ls))/len(Ls)\n","\n","    #     # pdb.set_trace()\n","\n","    #     if min_max:\n","    #         r1 = maximizeloss_weights_st( losses_for_reweighting , KLDiffHere, self.eps)\n","    #         candidate_weigths = torch.zeros_like(self.weights).to(torch.device(\"cuda:0\"))\n","    #         candidate_weigths[0][mask_for_available_losses] = torch.tensor(r1.x).to(torch.device(\"cuda:0\")).float()\n","    #         self.weights = candidate_weigths.to(torch.device(\"cuda:0\"))\n","    #         self.weights_tbl.append(self.weights.detach().cpu().numpy())\n","\n","    #     numActive = np.sum([1 if list(lv.size()) else 0 for lv in Ls ])\n","    #     if train == True:\n","    #         return  (self.weights[0,0]*torch.mean(DO) + \n","    #                  self.weights[0,1]*torch.mean(TC) + \n","    #                  self.weights[0,2]*torch.mean(BC)) , \\\n","    #                  self.weights[0,0]*torch.mean(DO) , \\\n","    #                  self.weights[0,1]*torch.mean(TC) , \\\n","    #                  self.weights[0,2]*torch.mean(BC) , \\\n","    #                  (1./numActive*torch.mean(DO) + \n","    #                  1./numActive*torch.mean(TC) + \n","    #                  1./numActive*torch.mean(BC))             \n","    #     else:\n","    #         return  DO , TC , BC\n"]},{"cell_type":"code","execution_count":16,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":13,"status":"ok","timestamp":1653304575786,"user":{"displayName":"Hans Roggeman","userId":"10574434403170915342"},"user_tz":-60},"id":"iyacROFeXgNp","outputId":"b5fd3603-b90c-4cb5-c8b5-068897067e43"},"outputs":[{"output_type":"stream","name":"stdout","text":["time: 12.3 ms (started: 2022-05-23 11:16:15 +00:00)\n"]}],"source":["import torch\n","from torch.distributions import Normal\n","\n","std_norm_cdf = Normal(0, 1).cdf\n","std_norm_pdf = lambda x: torch.exp(Normal(0, 1).log_prob(x))\n","\n","def bs_price(right, K, S, T, sigma, r):\n","    d_1 = (1 / (sigma * torch.sqrt(T))) * (torch.log(S / K) + (r + (torch.square(sigma) / 2)) * T)\n","    d_2 = d_1 - sigma * torch.sqrt(T)\n","    \n","    if right == \"C\":\n","        C = std_norm_cdf(d_1) * S - std_norm_cdf(d_2) * K * torch.exp(-r * T)\n","        return C\n","        \n","    elif right == \"P\":\n","        P = std_norm_cdf(-d_2) * K * torch.exp(-r * T) - std_norm_cdf(-d_1) * S\n","        return P"]},{"cell_type":"code","execution_count":17,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12,"status":"ok","timestamp":1653304575786,"user":{"displayName":"Hans Roggeman","userId":"10574434403170915342"},"user_tz":-60},"id":"sLsA5AvqpMM7","outputId":"8d925ac4-e688-41b6-eba9-e499cfc045b0"},"outputs":[{"output_type":"stream","name":"stdout","text":["time: 1.82 ms (started: 2022-05-23 11:16:15 +00:00)\n"]}],"source":["import torch\n","\n","def to_cpu_detach(x):\n","  if isinstance(x, list):\n","    return [ y.detach().cpu().item() for y in x ]\n","  else:\n","    return x.detach().cpu().item()"]},{"cell_type":"code","execution_count":18,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11,"status":"ok","timestamp":1653304575786,"user":{"displayName":"Hans Roggeman","userId":"10574434403170915342"},"user_tz":-60},"id":"PC-E2SeX46A9","outputId":"af2dcaa7-0013-4db7-9a3e-9aec3face280"},"outputs":[{"output_type":"stream","name":"stdout","text":["time: 1.46 ms (started: 2022-05-23 11:16:15 +00:00)\n"]}],"source":["def huber_loss_zero_target(x, delta = 1.0):\n","  loss_function = torch.nn.HuberLoss(delta=delta)\n","  return loss_function(x, torch.zeros_like(x))\n"]},{"cell_type":"code","execution_count":19,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11,"status":"ok","timestamp":1653304575787,"user":{"displayName":"Hans Roggeman","userId":"10574434403170915342"},"user_tz":-60},"id":"MNYJyHWpeL66","outputId":"aa77478d-de23-4a3c-cdb0-8b1b3970f1da"},"outputs":[{"output_type":"stream","name":"stdout","text":["time: 24 ms (started: 2022-05-23 11:16:15 +00:00)\n"]}],"source":["def save_model_train(lr, net,  eqLossFn, sample_method, trainObj, eqType, eqObject = None ):\n","\n","  model_id_str =  f\"{eqType}_{datetime.datetime.now():%Y%m%d%H%M%S}_{eqLossFn}_{sample_method}_{trainObj.stop_epoch}_{str(lr).replace('.','p')}_{net.NL}_{net.NN}\"\n","  \n","  if eqObject is not None:\n","    try:\n","        beta = getattr(eqObject,\"beta\")\n","        beta_str = str(beta).replace('.','p')\n","        model_id_str = model_id_str + f\"_beta{beta_str}\"\n","    except AttributeError:\n","        pass\n","    try:\n","        wgamma = getattr(eqObject,\"wgamma\")\n","        wgamma_str = str(wgamma).replace('.','p')\n","        model_id_str = model_id_str + f\"_wgamma{wgamma_str}\"\n","    except AttributeError:\n","        pass\n","  \n","  torch.save(net.state_dict(), f\"/content/drive/MyDrive/data_papers/{paper_name}/model_finals/{model_id_str}\")\n","  df_at_hookintervals = None\n","  train_losses = None\n","  validation_losses = None\n","  try:\n","      df_at_hookintervals = getattr(trainObj, \"history_surfaces_hooks\")\n","      if df_at_hookintervals is not None:\n","        df_at_hookintervals.to_csv(f\"/content/drive/MyDrive/data_papers/{paper_name}/model_checkpoints/validationHook_{trainObj.hook_interval}_{model_id_str}.csv\", index=False)\n","  except AttributeError:\n","      print(\"Class `{}` does not have `{}`\".format(trainObj.__class__.__name__, \"history_surfaces_hooks\"))\n","\n","  try:\n","      train_losses = getattr(trainObj,\"train_losses\")\n","      if train_losses is not None:\n","        train_losses.tofile(f\"/content/drive/MyDrive/data_papers/{paper_name}/model_checkpoints/trainlosses_{model_id_str}.csv\", sep = ',')    \n","  except AttributeError:\n","      print(\"Class `{}` does not have `{}`\".format(trainObj.__class__.__name__, \"train_losses\"))\n","      # raise NotImplementedError(\"Class `{}` does not have `{}`\".format(trainObj.__class__.__name__, \"train_losses\"))\n","\n","  try:\n","      validation_losses = getattr(trainObj,\"validation_losses\")\n","      if validation_losses is not None:\n","        validation_losses.tofile(f\"/content/drive/MyDrive/data_papers/{paper_name}/model_checkpoints/validationlosses_{model_id_str}.csv\", sep = ',')    \n","  except AttributeError:\n","      print(\"Class `{}` does not have `{}`\".format(trainObj.__class__.__name__, \"validation_losses\"))"]},{"cell_type":"code","execution_count":20,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":340,"status":"ok","timestamp":1653304576117,"user":{"displayName":"Hans Roggeman","userId":"10574434403170915342"},"user_tz":-60},"id":"ipogSsVTbv0k","outputId":"8f326c5d-6c2d-4eff-cc5e-0fc688116f8d"},"outputs":[{"output_type":"stream","name":"stdout","text":["time: 25.6 ms (started: 2022-05-23 11:16:15 +00:00)\n"]}],"source":["def save_model_train_stratified(lr, net,  eqLossFn, sample_method, trainObj, eqType, eqObject = None ):\n","\n","  model_id_str =  f\"{eqType}_{datetime.datetime.now():%Y%m%d%H%M%S}_{eqLossFn}_{sample_method}_{trainObj.stop_epoch}_{str(lr).replace('.','p')}_{net.NL}_{net.NN}\"\n","  \n","  if eqObject is not None:\n","    try:\n","        beta = getattr(eqObject,\"beta\")\n","        beta_str = str(beta).replace('.','p')\n","        model_id_str = model_id_str + f\"_beta{beta_str}\"\n","    except AttributeError:\n","        pass\n","    try:\n","        wgamma = getattr(eqObject,\"wgamma\")\n","        wgamma_str = str(wgamma).replace('.','p')\n","        model_id_str = model_id_str + f\"_gamma{wgamma_str}\"\n","    except AttributeError:\n","        pass\n","    try:\n","        xbreaks = getattr(eqObject,\"xbreaks\")\n","        xbreaks_str = str(len(xbreaks))\n","        model_id_str = model_id_str + f\"_StSaXbrks{xbreaks_str}\"\n","    except AttributeError:\n","        pass\n","    try:\n","        tbreaks = getattr(eqObject,\"tbreaks\")\n","        tbreaks_str = str(len(tbreaks))\n","        model_id_str = model_id_str + f\"_StSaTbrks{tbreaks_str}\"\n","    except AttributeError:\n","        pass\n","  \n","  torch.save(net.state_dict(), f\"/content/drive/MyDrive/data_papers/{paper_name}/model_finals/{model_id_str}\")\n","  df_at_hookintervals = None\n","  train_losses = None\n","  validation_losses = None\n","  try:\n","      df_at_hookintervals = getattr(trainObj, \"history_surfaces_hooks\")\n","      if df_at_hookintervals is not None:\n","        df_at_hookintervals.to_csv(f\"/content/drive/MyDrive/data_papers/{paper_name}/model_checkpoints/validationHook_{trainObj.hook_interval}_{model_id_str}.csv\", index=False)\n","  except AttributeError:\n","      print(\"Class `{}` does not have `{}`\".format(trainObj.__class__.__name__, \"history_surfaces_hooks\"))\n","\n","  try:\n","      train_losses = getattr(trainObj,\"train_losses\")\n","      if train_losses is not None:\n","        train_losses.tofile(f\"/content/drive/MyDrive/data_papers/{paper_name}/model_checkpoints/trainlosses_{model_id_str}.csv\", sep = ',')    \n","  except AttributeError:\n","      print(\"Class `{}` does not have `{}`\".format(trainObj.__class__.__name__, \"train_losses\"))\n","      # raise NotImplementedError(\"Class `{}` does not have `{}`\".format(trainObj.__class__.__name__, \"train_losses\"))\n","\n","  try:\n","      validation_losses = getattr(trainObj,\"validation_losses\")\n","      if validation_losses is not None:\n","        validation_losses.tofile(f\"/content/drive/MyDrive/data_papers/{paper_name}/model_checkpoints/validationlosses_{model_id_str}.csv\", sep = ',')    \n","  except AttributeError:\n","      print(\"Class `{}` does not have `{}`\".format(trainObj.__class__.__name__, \"validation_losses\"))"]},{"cell_type":"markdown","metadata":{"id":"Tz5tUJuYaXKu"},"source":["### Merton Invest-Consumption Problem - Equation HJB optimization\n","\n","[Extensions of the Deep Galerkin Method](https://arxiv.org/pdf/1912.01455v3.pdf)"]},{"cell_type":"markdown","metadata":{"id":"N-GO35FcJPP6"},"source":["##### Closed form terminal utility functions"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0cWoRXs02PoF"},"outputs":[],"source":["def expTerminalUtilityOfWealth(x, gamma_discount = 1.0):\n","  return(-torch.exp(-gamma_discount*x))\n","\n","def expTerminalUtilityOfWealth_np(x, gamma_discount = 1.0):\n","  return(-np.exp(-gamma_discount*x))\n","\n","# closed form value function\n","def Htx(x):\n","  return -torch.exp(-x[:,1].reshape(-1,1)*1.0*torch.exp(x[:,3].reshape(-1,1)*(1.0-x[:,0].reshape(-1,1))) - \n","                    0.5*(1.0-x[:,0].reshape(-1,1))*((x[:,2].reshape(-1,1)-x[:,3].reshape(-1,1))/(x[:,4].reshape(-1,1)))**2  )\n","\n","from functools import partial\n","\n","# should give a closed form solution for the control => PI(x,t) = [(mu-r)/(gamma*sigma^2)]*exp(-r*(T-t))"]},{"cell_type":"markdown","metadata":{"id":"HrivvbmubiiY"},"source":["#### MertonUtilityNet"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JRraqOG4aXKx"},"outputs":[],"source":["class MertonUtilityNet(nn.Module):\n","    def __init__(self , NL  , NN, activation = torch.tanh  ):\n","        super(MertonUtilityNet, self).__init__()\n","        self.NL = NL\n","        self.NN = NN\n","        self.Input = 5 + 1  # wealth, time, mu, r, sigma, pi\n","        self.fc_input = nn.Linear(self.Input,self.NN)\n","        torch.nn.init.xavier_uniform_(self.fc_input.weight)\n","        self.linears = nn.ModuleList([nn.Linear(self.NN, self.NN) for i in range(self.NL)])\n","        for i, l in enumerate(self.linears):    \n","            torch.nn.init.xavier_uniform_(l.weight)\n","        self.fc_output = nn.Linear(self.NN,1)\n","        torch.nn.init.xavier_uniform_(self.fc_output.weight)\n","        self.act = activation\n","        \n","    def forward(self, x):\n","        h = self.act( self.fc_input(x)  )\n","        for i, l in enumerate(self.linears):\n","            h = self.act( l(h) )\n","        out = self.fc_output(h)\n","        return out "]},{"cell_type":"markdown","metadata":{"id":"fyFbPZr7I5RE"},"source":["#### MertonPiNet"]},{"cell_type":"code","execution_count":111,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":276,"status":"ok","timestamp":1653315279340,"user":{"displayName":"Hans Roggeman","userId":"10574434403170915342"},"user_tz":-60},"id":"PR7PHL4KI1S9","outputId":"1f681de7-62f9-4334-c45f-a2cc9916fd82"},"outputs":[{"output_type":"stream","name":"stdout","text":["time: 16.7 ms (started: 2022-05-23 14:14:39 +00:00)\n"]}],"source":["import torch.nn.functional as F\n","\n","class MertonPiNet(nn.Module):\n","    def __init__(self , NL  , NN, activation = torch.tanh  ):\n","        super(MertonPiNet, self).__init__()\n","        self.NL = NL\n","        self.NN = NN\n","        self.Input = 5   # wealth, time, mu, r, sigma\n","        self.fc_input = nn.Linear(self.Input,self.NN)\n","        torch.nn.init.xavier_uniform_(self.fc_input.weight)\n","        self.linears = nn.ModuleList([nn.Linear(self.NN, self.NN) for i in range(self.NL)])\n","        for i, l in enumerate(self.linears):    \n","            torch.nn.init.xavier_uniform_(l.weight)            \n","        # self.fc_output_d = nn.Linear(self.NN, 2)\n","        # torch.nn.init.xavier_uniform_(self.fc_output_d.weight)\n","        # self.fc_output = torch.nn.Softmax(dim=1)\n","        self.fc_output = nn.Linear(self.NN, 1)\n","        torch.nn.init.xavier_uniform_(self.fc_output.weight)\n","        self.act = activation\n","        \n","    def forward(self, x):\n","        h = self.act( self.fc_input(x)  )\n","        for i, l in enumerate(self.linears):\n","            h = self.act( l(h) )\n","        # out = self.fc_output_d(h)\n","        out = self.fc_output(h)\n","        # torch.max(torch.tensor([1.0,1.3,1.5]), torch.tensor(1.32).expand_as(torch.tensor([1.0,1.3,1.5])))\n","        out = torch.min(torch.max(out, torch.tensor(0.0).expand_as(out).to(out.device)),torch.tensor(10.0).expand_as(out).to(out.device))\n","        return out \n","        "]},{"cell_type":"markdown","metadata":{"id":"RNhAbZ727RC_"},"source":["#### MertonAlternativePiNet\n","\n","[implement from github](https://github.com/Plemeur/DGM/blob/master/first_net.py)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_c-dZ5b37NwV"},"outputs":[],"source":["class LinearWithXavier(nn.Module):\n","    \"\"\" Copy of linear module from Pytorch, modified to have a Xavier init,\n","        TODO : figure out what to do with the bias\"\"\"\n","    def __init__(self, in_features, out_features, bias=True):\n","        super(LinearWithXavier, self).__init__()\n","        self.in_features = in_features\n","        self.out_features = out_features\n","        self.weight = torch.nn.Parameter(torch.Tensor(out_features, in_features))\n","        if bias:\n","            self.bias = torch.nn.Parameter(torch.Tensor(out_features))\n","        else:\n","            self.register_parameter('bias', None)\n","        self.reset_parameters()\n","    def reset_parameters(self):\n","        torch.nn.init.xavier_uniform_(self.weight)\n","        if self.bias is not None:\n","            torch.nn.init.uniform_(self.bias, -1, 1) #boundary matter?\n","    def forward(self, input):\n","        return torch.nn.functional.linear(input, self.weight, self.bias)\n","    def extra_repr(self):\n","        return 'in_features={}, out_features={}, bias={}'.format(\n","            self.in_features, self.out_features, self.bias is not None\n","        )\n","\n","\n","class DGM_layer(nn.Module):\n","    \"\"\" See readme for paper source\"\"\"\n","    def __init__(self, in_features, out_feature, residual=False):\n","        super(DGM_layer, self).__init__()\n","        self.residual = residual\n","\n","        self.Z = LinearWithXavier(out_feature, out_feature)\n","        self.UZ = LinearWithXavier(in_features, out_feature, bias=False)\n","        self.G = LinearWithXavier(out_feature, out_feature)\n","        self.UG = LinearWithXavier(in_features, out_feature, bias=False)\n","        self.R = LinearWithXavier(out_feature, out_feature)\n","        self.UR = LinearWithXavier(in_features, out_feature, bias=False)\n","        self.H = LinearWithXavier(out_feature, out_feature)\n","        self.UH = LinearWithXavier(in_features, out_feature, bias=False)\n","\n","    def forward(self, x, s):\n","        z = torch.tanh(self.UZ(x) + self.Z(s))\n","        g = torch.tanh(self.UG(x) + self.G(s))\n","        r = torch.tanh(self.UR(x) + self.R(s))\n","        h = torch.tanh(self.UH(x) + self.H(s * r))\n","        return (1 - g) * h + z * s\n","\n","\n","class MertonAlternativePiNet(nn.Module):\n","\n","    def __init__(self, in_size, out_size, neurons, depth):\n","        super(MertonAlternativePiNet, self).__init__()\n","        self.dim = in_size\n","        self.input_layer = LinearWithXavier(in_size, neurons)\n","        self.middle_layer = nn.ModuleList([DGM_layer(in_size, neurons) for i in range(depth)])\n","        self.final_layer = LinearWithXavier(neurons, out_size)\n","\n","    def forward(self, X):\n","        s = torch.tanh(self.input_layer(X))\n","        for i, layer in enumerate(self.middle_layer):\n","            s = torch.tanh(layer(X, s))\n","\n","        return self.final_layer(s)\n"]},{"cell_type":"markdown","metadata":{"id":"leiCOWL89Mr5"},"source":["#### MertonAlternativeUtilityNet"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sD3ZL1NY9TMF"},"outputs":[],"source":["# class MertonAlternativeUtilityNet(MertonAlternativePiNet):\n","#     def __init__(self, in_size, out_size, neurons, depth):\n","#         super(MertonAlternativeUtilityNet, self).__init__(in_size, out_size, neurons, depth)\n","\n"]},{"cell_type":"markdown","metadata":{"id":"CNsqOm1ithSG"},"source":["#### MertonMatchPiNet\n","\n","[Matching Paper by hand](https://arxiv.org/abs/1912.01455v3)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"REWml4aYthSH"},"outputs":[],"source":["class DGMLayerPaper(nn.Module):\n","\n","    def __init__(self, in_features, out_feature, activation=torch.relu, residual=False):\n","        \n","        super(DGMLayerPaper, self).__init__()\n","        self.residual = residual\n","        self.activation = activation\n","\n","        self.Z = LinearWithXavier(out_feature, out_feature) # w.S\n","        self.UZ = LinearWithXavier(in_features, out_feature, bias=True) # u.x\n","        self.G = LinearWithXavier(out_feature, out_feature)\n","        self.UG = LinearWithXavier(in_features, out_feature, bias=True)\n","        self.R = LinearWithXavier(out_feature, out_feature)\n","        self.UR = LinearWithXavier(in_features, out_feature, bias=True)\n","        self.H = LinearWithXavier(out_feature, out_feature) # w.(S(o)R)\n","        self.UH = LinearWithXavier(in_features, out_feature, bias=True)\n","\n","    def forward(self, x, s):\n","        z = self.activation(self.UZ(x) + self.Z(s))\n","        g = self.activation(self.UG(x) + self.G(s))\n","        r = self.activation(self.UR(x) + self.R(s))\n","        h = self.activation(self.UH(x) + self.H(s * r))\n","        return (1 - g) * h + z * s\n","\n","\n","class MertonMatchPiNet(nn.Module):\n","\n","    def __init__(self, in_size, out_size, neurons, depth):\n","        super(MertonMatchPiNet, self).__init__()\n","        self.dim = in_size\n","        self.input_layer = LinearWithXavier(in_size, neurons)\n","        self.middle_layer = nn.ModuleList([DGMLayerPaper(in_size, neurons) for i in range(depth)])\n","        self.final_layer = LinearWithXavier(neurons, out_size)\n","\n","    def forward(self, X):\n","        s = torch.tanh(self.input_layer(X))\n","        for i, layer in enumerate(self.middle_layer):\n","            s = torch.tanh(layer(X, s))\n","\n","        return self.final_layer(s)\n"]},{"cell_type":"markdown","metadata":{"id":"wClW1g9rbm8o"},"source":["#### PiEquation"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2ivFXAdDYERq"},"outputs":[],"source":["# torch.max(torch.tensor([1.0,1.3,1.5]), torch.tensor(1.32).expand_as(torch.tensor([1.0,1.3,1.5])))"]},{"cell_type":"code","execution_count":109,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":398,"status":"ok","timestamp":1653315239614,"user":{"displayName":"Hans Roggeman","userId":"10574434403170915342"},"user_tz":-60},"id":"uQTTkUhWuiJi","outputId":"5a770c08-d36c-426b-a88c-7bc7172c1bbb"},"outputs":[{"output_type":"stream","name":"stdout","text":["time: 21.9 ms (started: 2022-05-23 14:13:59 +00:00)\n"]}],"source":["class PiEquation():\n","\n","    def __init__(self , pi_net, du_dx, d2u_dx2):\n","        self.pi_net = pi_net\n","        self.wgamma = 0.0001\n","        self.du_dx = du_dx  # (torch.sign(du_dx).to(du_dx.device)*torch.max(torch.abs(du_dx).to(du_dx.device), torch.tensor(1e-12).expand_as(du_dx).to(du_dx.device))).to(du_dx.device)\n","        self.d2u_dx2 = d2u_dx2 # (torch.sign(d2u_dx2).to(du_dx.device)*torch.max(torch.abs(d2u_dx2).to(du_dx.device), torch.tensor(1e-14).expand_as(d2u_dx2).to(d2u_dx2.device))).to(d2u_dx2.device)\n","\n","    def criterion(self, x_internal):\n","      #  time, wealth, mu, r, sigma\n","      pi_net_preds = self.pi_net(x_internal)\n","      # pi_net_preds = pi_net_preds[:,0].reshape(-1,1)\n","      pi_net_preds = pi_net_preds.reshape(-1,1)\n","\n","      # dpi = torch.autograd.grad( pi_net_preds, \n","      #                           x_internal, \n","      #                           grad_outputs=torch.ones_like(pi_net_preds) ,\n","      #                           create_graph=True,\n","      #                           retain_graph=True)\n","      # dpi_dt = dpi[0][:,0].reshape(-1,1)\n","      # dpi_dx = dpi[0][:,1].reshape(-1,1)\n","\n","      # d2pi_dx2 = torch.autograd.grad( dpi_dx, \n","      #                                 x_internal , \n","      #                                 grad_outputs=torch.ones_like(dpi_dx) ,\n","      #                                 create_graph = True,\n","      #                                 retain_graph=True)[0][:,1].reshape(-1,1)\n","      intC = None\n","      # pdb.set_trace()\n","      if len(x_internal) == 0:\n","        intC_loss = torch.tensor(0).cuda().float()  \n","      else:\n","        # pdb.set_trace()\n","        intC_loss = -(pi_net_preds*(x_internal[:,2].reshape(-1,1)-x_internal[:,3].reshape(-1,1)) + x_internal[:,3].reshape(-1,1)*x_internal[:,1].reshape(-1,1))*self.du_dx - \\\n","                                    0.5*(x_internal[:,4].reshape(-1,1)**2)*(pi_net_preds**2)*self.d2u_dx2\n","\n","        # print(f\"Pi Loss {torch.mean(intC_loss).item()} {x_internal.shape[0]} {torch.mean(self.du_dx)}\")          \n","\n","        # intC_loss = (pi_net_preds*(x_internal[:,2].reshape(-1,1)-x_internal[:,3].reshape(-1,1)) + x_internal[:,3].reshape(-1,1)*x_internal[:,1].reshape(-1,1))*self.du_dx + \\\n","        #                             0.5*(x_internal[:,4].reshape(-1,1)**2)*(pi_net_preds**2)*self.d2u_dx2\n","\n","      return  1.0*intC_loss\n","\n","    def calculatePiLoss(self, x_internal, keep_batch = False):\n","        '''\n","        Helper function that Sample and Calculate loss,\n","        '''        \n","        x_internal = Variable( x_internal , requires_grad=True)\n","        Ls = self.criterion( x_internal )\n","        \n","        return_losses = []\n","        if not keep_batch:\n","          loss_pi = torch.mean(Ls)           \n","          return loss_pi          \n","        else:\n","          return Ls\n"]},{"cell_type":"markdown","metadata":{"id":"8RRoBgFQINMv"},"source":["#### TrainInternalPiWithDGM\n"]},{"cell_type":"code","execution_count":47,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":322,"status":"ok","timestamp":1653307284271,"user":{"displayName":"Hans Roggeman","userId":"10574434403170915342"},"user_tz":-60},"id":"VREn3fanpP1b","outputId":"b8343015-b63d-4255-dbe7-3e41df81b9e4"},"outputs":[{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["time: 104 ms (started: 2022-05-23 12:01:10 +00:00)\n"]}],"source":["class TrainInternalPiWithDGM():\n","    \n","    def __init__(self , u_equation, pi_equation, BATCH_SIZE , epoch, lr, debug = False, loss_multiply = 1.0):\n","        self.BATCH_SIZE = BATCH_SIZE\n","        self.u_model = u_equation        \n","        self.pi_model = pi_equation\n","        self.debug = debug  \n","        self.hook_interval = 20      \n","        if self.debug == True:\n","            self.hooks = {}            \n","            self.get_all_layers(self.pi_model.pi_net)\n","\n","        self.optimizer_used = optim.Adam\n","\n","        self.use_early_stop = False\n","        self.early_stop_patience = 10\n","        self.early_stop_delta = 0.0        \n","        self.best_loss = np.Inf\n","        self.early_stop_counter = 0\n","\n","        self.stop_epoch = 0\n","\n","        self.validation_sample = None\n","        self.validation_losses = None\n","        self.train_losses = None        \n","\n","        self.epoch = epoch\n","        self.lr = lr\n","\n","        self.loss_multiply = loss_multiply\n","\n","    def get_num_epochs_to_train(self, current_u_epoch = None):\n","      if current_u_epoch is None:\n","        return self.epoch\n","      else:\n","        if current_u_epoch < 5000:\n","          return self.epoch\n","        elif current_u_epoch < 30000:\n","          return 2000\n","        elif current_u_epoch < 100000:\n","          return 4000\n","        else:\n","          return 200\n","\n","        \n","    def train(self , epoch_trained = None, eqLossFn = 'calculatePiLoss', sample_method_X = \"U\"):\n","        \n","        num_epochs_here = self.get_num_epochs_to_train(epoch_trained)\n","\n","        if self.validation_sample is not None:\n","          self.validation_losses = np.ones((num_epochs_here, 3 ), dtype='float32') * np.nan\n","        self.train_losses = np.ones((num_epochs_here, 1 ), dtype='float32') * np.nan\n","\n","        optimizer = self.optimizer_used(self.pi_model.pi_net.parameters(), self.lr)\n","        # optimizer = self.optimizer_used(self.u_model.pi_net.parameters(), self.lr)\n","        # optimizer = optim.SGD(self.net.parameters(), lr)\n","        \n","        loss_avg = 0.0\n","        # pdb.set_trace()\n","        loss_calc_method = None\n","        try:\n","            loss_calc_method = getattr(self.pi_model, eqLossFn)\n","        except AttributeError:\n","            raise NotImplementedError(\"Class `{}` does not implement `{}`\".format(self.pi_model.__class__.__name__, eqLossFn))\n","        \n","        for e in range(num_epochs_here):\n","\n","            optimizer.zero_grad()            \n","\n","            sample_batch = self.u_model.sample(sample_method_X = sample_method_X, size=self.BATCH_SIZE)\n","\n","            loss_avg = 0.0\n","            # pdb.set_trace()\n","            loss  = loss_calc_method( sample_batch[0], keep_batch = False )            \n","            # print(f\"Pi Net Epoch {e} Loss {round(loss.item(),5)}\")\n","\n","            self.train_losses[e,:] = [ to_cpu_detach(loss) ]\n","\n","            if self.debug == True and (self.validation_sample is not None):\n","              losses_L2_validation, losses_ABS_validation, losses_Huber_valiation = loss_calc_method( self.validation_sample, \n","                                                                                                     loss_transforms = [ torch.square, torch.abs, partial(huber_loss_zero_target, delta=huber_delta) ], \n","                                                                                                     keep_batch = False )\n","              validation_loss_list = [*to_cpu_detach(losses_L2_validation),\n","                                      *to_cpu_detach(losses_ABS_validation),\n","                                      *to_cpu_detach(losses_Huber_valiation)]\n","              self.validation_losses[e,:] = validation_loss_list\n","            \n","            if self.use_early_stop:\n","              loss_to_check = loss\n","              if loss_to_check < (self.best_loss-self.early_stop_delta):\n","                self.best_loss = loss_to_check\n","                self.early_stop_counter = 0\n","              else:\n","                self.early_stop_counter += 1\n","              if self.early_stop_counter>=self.early_stop_patience:\n","                # print(f\"Pi Early Stop at epoch {e}: {loss_to_check} with patience {self.early_stop_patience}\")\n","                break\n","            \n","            loss_avg = loss_avg + float(loss.item())\n","            loss.backward(retain_graph=True)\n","\n","            optimizer.step()\n","            if (e % self.hook_interval == (self.hook_interval-1)) or e == 0:\n","                loss_avg = loss_avg/self.hook_interval\n","                # print(\"Pi Epoch {} - lr {} -  key loss: {}\".format(e , self.lr , loss))\n","\n","        self.stop_epoch = e\n","\n","    def hook_fn(self, m, i, o):\n","              self.hooks[m] = o.detach()\n","            \n","    def get_all_layers(self, net):\n","      for name, layer in net._modules.items():\n","          if isinstance(layer, nn.ModuleList):\n","              for n , l in layer.named_children():\n","                l.register_forward_hook(self.hook_fn)\n","          else:\n","              # it's a non sequential. Register a hook\n","              layer.register_forward_hook(self.hook_fn)\n"]},{"cell_type":"markdown","metadata":{"id":"hp4BG1ewKF6o"},"source":["#### MertonEquation"]},{"cell_type":"code","execution_count":100,"metadata":{"cellView":"code","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1452,"status":"ok","timestamp":1653313317806,"user":{"displayName":"Hans Roggeman","userId":"10574434403170915342"},"user_tz":-60},"id":"LBMZYQSPaXKy","outputId":"94d20d51-0fd5-4d06-8385-8dde477ae82a"},"outputs":[{"output_type":"stream","name":"stdout","text":["time: 956 ms (started: 2022-05-23 13:41:56 +00:00)\n"]}],"source":["import math\n","\n","class MertonEquation():\n","    \n","    def __init__(self , u_net, pi_net, pi_net_epoch, pi_net_lr, term_utility_function = partial(expTerminalUtilityOfWealth,gamma_discount=0.1) ):\n","\n","        self.u_net = u_net\n","        self.pi_net = pi_net\n","        self.wgamma = 0.0001\n","        self.term_utility_func = term_utility_function\n","        self.xbreaks = None\n","        self.tbreaks = None\n","\n","        self.MAX_X = 1.0\n","        self.T = 1.0\n","        self.MAX_MU = 0.2\n","        self.MAX_SIGMA = 1.0\n","\n","        self.MIN_PI = 0.0\n","        self.MAX_PI = 10.0\n","\n","        self.pi_net_epoch = pi_net_epoch\n","        self.pi_net_lr = pi_net_lr\n","        self.loss_multiply = 1.0\n","\n","        self.FORCE_MU = None\n","        self.FORCE_R = None\n","        self.FORCE_SIGMA = None\n","\n","        self.weights=None\n","        self.gamma = 1E-3\n","        self.beta = 1E-3\n","\n","    def g(self,x):\n","        # Time, Wealth, Mu, R, Sigma\n","        return self.term_utility_func(x[:,1].reshape(-1,1))\n","\n","    @staticmethod\n","    def to_device(x, to_cpu):\n","      if to_cpu:\n","        return x.cpu()\n","      else:\n","        return x.cuda()\n","\n","    def mu_r_sample(self, size, range_multiplier = 1.0):\n","      mu_candidate = -self.MAX_MU*range_multiplier*torch.rand([size, 1])+self.MAX_MU*range_multiplier\n","      r_candidate = -self.MAX_MU*range_multiplier*torch.rand([size, 1])+self.MAX_MU*range_multiplier\n","      r_sample = torch.where(r_candidate < mu_candidate, r_candidate, mu_candidate)\n","      mu_sample = torch.where(r_candidate > mu_candidate, r_candidate, mu_candidate)\n","      return (mu_sample, r_sample)\n","\n","    def apply_forced_mu_r_sigma(self, mu_sample, r_sample, sigma_sample):\n","      if self.FORCE_MU is not None:\n","         mu_sample = self.FORCE_MU*torch.ones_like(mu_sample)            \n","      if self.FORCE_R is not None:\n","        r_sample = self.FORCE_R*torch.ones_like(r_sample)\n","      if self.FORCE_SIGMA is not None:\n","        sigma_sample = self.FORCE_SIGMA*torch.ones_like(sigma_sample)\n","      return mu_sample, r_sample, sigma_sample\n","\n","\n","    def sample(self , sample_method_X = \"U\", size = 2**8, to_cpu = False ):\n","        '''\n","        Sampling function\n","        '''\n","        if sample_method_X in [\"U\"]:\n","            range_multiplier = 1.0\n","            \n","            ### internal samples of Time, Wealth, Mu, R, Sigma\n","            mu_sample_internal, r_sample_internal = self.mu_r_sample(size, range_multiplier)\n","            sigma_sample_internal = -self.MAX_SIGMA*range_multiplier*torch.rand([size, 1])+self.MAX_SIGMA*range_multiplier\n","            mu_sample_internal, r_sample_internal, sigma_sample_internal = self.apply_forced_mu_r_sigma(mu_sample_internal, r_sample_internal, sigma_sample_internal)\n","            x_internal = self.to_device(torch.cat(( torch.rand([size,1])*self.T , # Time\n","                                                   -self.MAX_X*range_multiplier*torch.rand([size, 1])+self.MAX_X*range_multiplier, # Wealth\n","                                                    mu_sample_internal, # mu\n","                                                    r_sample_internal, # R\n","                                                    sigma_sample_internal # Sigma\n","                                                   ) , dim = 1 ),to_cpu)\n","            ### Terminal time samples\n","            mu_sample_terminal, r_sample_terminal = self.mu_r_sample(size, range_multiplier)\n","            sigma_sample_terminal = -self.MAX_SIGMA*range_multiplier*torch.rand([size, 1])+self.MAX_SIGMA*range_multiplier\n","            mu_sample_terminal, r_sample_terminal, sigma_sample_terminal = self.apply_forced_mu_r_sigma(mu_sample_terminal, r_sample_terminal, sigma_sample_terminal)\n","            x_terminal = self.to_device(torch.cat(( torch.zeros(size, 1) + self.T , # Time\n","                                                   -self.MAX_X*range_multiplier*torch.rand([size, 1])+self.MAX_X*range_multiplier, # Wealth\n","                                                    mu_sample_terminal, # mu\n","                                                    r_sample_terminal, # R\n","                                                    sigma_sample_terminal # Sigma\n","                                                   ) , dim = 1 ),to_cpu)\n","            \n","            # x_initial = torch.cat( ( torch.zeros(size, 1), -self.MAX_X*range_multiplier*torch.rand([size, 1])+self.MAX_X*range_multiplier) , dim = 1 ).cuda()\n","            return x_internal , x_terminal\n","\n","        raise ValueError(f\"{sample_method_X} is not a supported sampling method\")\n","        \n","    def sample_stratified(self , sample_method_X = \"U\", size = 2**8, to_cpu = False ):\n","\n","      if self.xbreaks is None and self.tbreaks is None:\n","        return self.sample(sample_method_X, size, to_cpu)\n","\n","      internal_strata_xts = []\n","      terminal_strata_xts = []\n","      \n","      if sample_method_X in [\"U\"]:\n","          range_multiplier = 1.0\n","          xbreaks_used = self.xbreaks[:] if self.xbreaks is not None else [0,range_multiplier*self.MAX_X]\n","          tbreaks_used = self.tbreaks[:] if self.tbreaks is not None else [0,self.T]\n","          if xbreaks_used[-1] < range_multiplier*self.MAX_X:\n","            xbreaks_used.append(range_multiplier*self.MAX_X)\n","          while xbreaks_used[0] < 0.0:\n","            xbreaks_used.pop(0)\n","          if not xbreaks_used:\n","            xbreaks_used = [0,range_multiplier*self.MAX_X]\n","          if xbreaks_used[0] > 0.0:            \n","            xbreaks_used.insert(0, 0.0)\n","\n","          if tbreaks_used[-1] < self.T:\n","            tbreaks_used.append(self.T)\n","          xbreaks_range = xbreaks_used[-1]-xbreaks_used[0]\n","          tbreaks_range = tbreaks_used[-1]-tbreaks_used[0]\n","\n","          total_strat_processed = 0\n","\n","          # internal samples\n","          for stratum_x_count in range(len(xbreaks_used)-1):\n","              \n","            num_samples_in_stratum = 0\n","            if len(xbreaks_used) > 2:  # x division takes priority so assign it if there is no T division\n","              range_ratio_x_stratum = (xbreaks_used[stratum_x_count+1]-xbreaks_used[stratum_x_count])/xbreaks_range\n","              num_samples_in_stratum = math.ceil(range_ratio_x_stratum*size)\n","\n","            for stratum_t_count in range(len(self.tbreaks)-1):\n","\n","              if num_samples_in_stratum == 0: # there is only a T division, so use it\n","                range_ratio_t_stratum = (tbreaks_used[stratum_t_count+1]-tbreaks_used[stratum_t_count])/tbreaks_range\n","                num_samples_in_stratum = math.ceil(range_ratio_t_stratum*size)\n","              else:\n","                # there is both an X and a T division, assign the number of samples uniformly, assuming same scale of X and T\n","                stratum_coverage_on_unit_square = \\\n","                  ((xbreaks_used[stratum_x_count+1]-xbreaks_used[stratum_x_count])/xbreaks_range)*\\\n","                  ((tbreaks_used[stratum_t_count+1]-tbreaks_used[stratum_t_count])/tbreaks_range)\n","                num_samples_in_stratum = math.ceil(stratum_coverage_on_unit_square * size)\n","\n","              range_multiplier = 1.0\n","\n","              ### internal samples of Time, Wealth, Mu, R, Sigma\n","              internal_stratum_t_sample = tbreaks_used[stratum_t_count] + torch.rand([num_samples_in_stratum,1])*(tbreaks_used[stratum_t_count+1]-tbreaks_used[stratum_t_count])\n","              internal_stratum_x_sample = xbreaks_used[stratum_x_count] + torch.rand([num_samples_in_stratum,1])*(xbreaks_used[stratum_x_count+1]-xbreaks_used[stratum_x_count])\n","              stratum_mu_sample_internal, stratum_r_sample_internal = self.mu_r_sample(num_samples_in_stratum, range_multiplier)\n","              stratum_sigma_sample_internal = -self.MAX_SIGMA*range_multiplier*torch.rand([num_samples_in_stratum, 1])+self.MAX_SIGMA*range_multiplier\n","              stratum_mu_sample_internal, stratum_r_sample_internal, stratum_sigma_sample_internal = \\\n","                self.apply_forced_mu_r_sigma(stratum_mu_sample_internal, stratum_r_sample_internal, stratum_sigma_sample_internal)\n","              x_internal_stratum = self.to_device(torch.cat(( internal_stratum_t_sample , # Time\n","                                                              internal_stratum_x_sample, # Wealth\n","                                                              stratum_mu_sample_internal, # mu\n","                                                              stratum_r_sample_internal, # R\n","                                                               # Sigma\n","                                                            ) , dim = 1 ),to_cpu)\n","              if not internal_strata_xts: \n","                internal_strata_xts = [ x_internal_stratum ] \n","              else:\n","                internal_strata_xts.append(x_internal_stratum) \n","\n","              ### Terminal time samples\n","              terminal_stratum_x_sample = xbreaks_used[stratum_x_count] + torch.rand([num_samples_in_stratum,1])*(xbreaks_used[stratum_x_count+1]-xbreaks_used[stratum_x_count])\n","              stratum_mu_sample_terminal, stratum_r_sample_terminal = self.mu_r_sample(num_samples_in_stratum, range_multiplier)\n","              stratum_sigma_sample_terminal = -self.MAX_SIGMA*range_multiplier*torch.rand([num_samples_in_stratum, 1])+self.MAX_SIGMA*range_multiplier\n","              stratum_mu_sample_terminal, stratum_r_sample_terminal, stratum_sigma_sample_terminal = \\\n","                self.apply_forced_mu_r_sigma(stratum_mu_sample_terminal, stratum_r_sample_terminal, stratum_sigma_sample_terminal)\n","              x_terminal_stratum = self.to_device(torch.cat(( torch.zeros(num_samples_in_stratum, 1) + self.T , # Time\n","                                                      terminal_stratum_x_sample, # Wealth\n","                                                      stratum_mu_sample_terminal, # mu\n","                                                      stratum_r_sample_terminal, # R\n","                                                      stratum_sigma_sample_terminal # Sigma\n","                                                    ) , dim = 1 ),to_cpu)\n","              if not terminal_strata_xts:\n","                terminal_strata_xts = [ x_terminal_stratum ] # terminal_stratum_xt[None,:,:]\n","              else:\n","                terminal_strata_xts.append(x_terminal_stratum) # torch.vstack((terminal_strata_xts,terminal_stratum_xt[None,:,: ]))\n","\n","              total_strat_processed += 1 \n","              # print((len(internal_strata_xts),xbreaks_used[stratum_x_count],tbreaks_used[stratum_t_count]))\n","\n","          # pdb.set_trace()\n","          # x_initial = torch.cat( ( torch.zeros(size, 1), -self.MAX_X*range_multiplier*torch.rand([size, 1])+self.MAX_X*range_multiplier) , dim = 1 ).cuda()\n","          return internal_strata_xts , terminal_strata_xts\n","    \n","      raise ValueError(f\"{sample_method_X} is not a supported sampling method\")\n","\n","    def pi_net_epoch_from_epoch(self, e):\n","      return self.pi_net_epoch\n","\n","    def criterion(self, x_internal , x_terminal, train_epoch, loss_transforms = [torch.square]):\n","        '''\n","        Loss function that helps network find solution to equation\n","        '''   \n","        # Time / Wealth / Mu / r / Sigma (sample data order)\n","        # pdb.set_trace()\n","\n","        # replace with closed form just to check\n","        # self.pi_net = lambda x: (((x[:,2]-x[:,3])/(1.0*(x[:,4]**2)))*torch.exp(-x[:,3]*(1.0-x[:,0])))\n","\n","        # pdb.set_trace()\n","        pi_used = self.pi_net(x_internal)  \n","        pi_used.detach_()\n","        # let's assign the first column as the allocation\n","        # pdb.set_trace()     \n","        pi_used = pi_used[:,0].reshape(-1,1)\n","        pi_used = pi_used.reshape(-1,1)\n","\n","        # pi_used = torch.tensor(self.MIN_PI + torch.rand([x_internal.shape[0],1])*(self.MAX_PI - self.MIN_PI), device = x_internal.device)\n","        # pdb.set_trace()\n","\n","        x_internal_before = x_internal.detach().clone()\n","        x_internal =  Variable(torch.cat((x_internal, pi_used), dim=1),requires_grad=True)\n","\n","        du = torch.autograd.grad( self.u_net(x_internal), \n","                                  x_internal, \n","                                  grad_outputs=torch.ones_like(self.u_net(x_internal)) ,\n","                                  create_graph=True,\n","                                  retain_graph=True )\n","        \n","        du_dt = du[0][:,0].reshape(-1,1)\n","        du_dx = du[0][:,1].reshape(-1,1)     \n","\n","        d2u_dx2 = torch.autograd.grad(  du_dx, \n","                                        x_internal , \n","                                        grad_outputs=torch.ones_like(du_dx) ,\n","                                        create_graph = True,\n","                                        retain_graph = True)[0][:,1].reshape(-1,1)\n","    \n","        # def pi_net_fn(x,du_dx = du_dx,d2u_dx2 = d2u_dx2): \n","        #   return (-(((x[:,2]-x[:,3])/(1.0*(x[:,4]**2)))*torch.div(du_dx,d2u_dx2).reshape(-1)))\n","        # pi_net_fn2 = lambda x: (((x[:,2]-x[:,3])/(1.0*(x[:,4]**2)))*torch.exp(-x[:,3]*(1.0-x[:,0])))\n","\n","        pi_model = PiEquation(self.pi_net, du_dx, d2u_dx2)                \n","        pi_trainer = TrainInternalPiWithDGM(self, pi_model, x_internal.shape[0], \n","                                            self.pi_net_epoch, self.pi_net_lr, \n","                                            debug=True, loss_multiply=1.0)\n","        pi_trainer.use_early_stop = True\n","        pi_trainer.early_stop_patience = min(200,math.ceil(self.pi_net_epoch/10.0))\n","        pi_trainer.train()\n","        \n","        # self.pi_net =  pi_net_fn\n","        # self.pi_net =  pi_net_fn2\n","        \n","        if loss_transforms is None:\n","          loss_transforms = [torch.square]\n","\n","        intC = None\n","        terC = None\n","\n","        if len(x_internal) == 0:\n","          intC = [ torch.tensor(0).cuda().float() for loss_transform in loss_transforms ] \n","        else:\n","          # Time, Wealth, Mu, R, Sigma\n","          # pdb.set_trace()\n","          pi_net_preds = self.pi_net(x_internal_before)\n","          pi_net_preds.detach_()\n","          # pi_net_preds = pi_net_preds[:,0].reshape(-1,1)\n","          pi_net_preds = pi_net_preds.reshape(-1,1)\n","          intC_loss = du_dt + (pi_net_preds*(x_internal[:,2].reshape(-1,1)-x_internal[:,3].reshape(-1,1))+x_internal[:,3].reshape(-1,1)*x_internal[:,1].reshape(-1,1))*du_dx + 0.5*(x_internal[:,4].reshape(-1,1)**2)*(pi_net_preds**2)*d2u_dx2\n","          intC = [ loss_transform(intC_loss) for loss_transform in loss_transforms ] \n","\n","        # Terminal Condition - should be equal (both in- and out of the money)\n","        x_terminal_before = x_terminal.detach().clone()\n","        pi_net_preds_terminal = self.pi_net(x_terminal_before)\n","        pi_net_preds_terminal.detach_()\n","        # pi_net_preds_terminal = pi_net_preds_terminal[:,0].reshape(-1,1)\n","        pi_net_preds_terminal = pi_net_preds_terminal.reshape(-1,1)\n","        x_terminal =  Variable(torch.cat((x_terminal, pi_net_preds_terminal), dim=1),requires_grad=True)\n","\n","        terC = [ loss_transform( self.u_net(x_terminal) - self.g(x_terminal)   ) for loss_transform in loss_transforms ]\n","\n","        return  intC , terC\n","\n","    def calculateLoss(self, batch_x, train_epoch, loss_transforms = [ torch.square ], keep_batch = False):\n","        '''\n","        Helper function that Sample and Calculate loss,\n","        '''        \n","        # pdb.set_trace()\n","        x_internal , x_terminal = batch_x\n","        x_internal = Variable( x_internal , requires_grad=True)\n","        Ls = self.criterion( x_internal , x_terminal, train_epoch, loss_transforms = loss_transforms )\n","        intC , terC  = Ls\n","\n","        return_losses = []\n","        for lc in range(len(loss_transforms)):\n","          if not keep_batch:\n","            loss_equalWeightedByType = 0.5*torch.mean(intC[lc]) + 0.5*torch.mean(terC[lc])\n","            return_losses.append( [ loss_equalWeightedByType , \n","                                    0.5*torch.mean(intC[lc]) , 0.5*torch.mean(terC[lc]), \n","                                    loss_equalWeightedByType ] )            \n","          else:\n","            return_losses.append( [intC.numpy(), terC.numpy()] )\n","        return return_losses\n","\n","    def calculateLossUsingKLMinMax(self , batch_x , train_epoch, loss_transforms = [ torch.square ], keep_batch = False):\n","        '''\n","        Helper function that Samples and Calculate loss,\n","        This is adapted in that it changes the weights on the losses\n","        and the distribution of sampling to maximize the loss provided \n","        the KL distance of the loss is within positive constraints\n","        beta represents the constraints on the weights\n","        gamma represents the constraints on the sampling distribution\n","        (each representing an upper bound the KL distribution)\n","        '''        \n","        # x , x_terminal , x_initial = self.sample(sample_method_X, size)\n","        x , x_terminal = batch_x\n","        x = Variable( x, requires_grad=True)\n","        Ls = self.criterion( x , x_terminal , train_epoch, loss_transforms = loss_transforms)\n","        intC , terC = Ls\n","\n","        if self.weights is None:\n","          self.weights = torch.ones(1,len(Ls)).to(intC[0].device)/len(Ls)\n","        \n","        return_losses = []\n","        for lc in range(len(loss_transforms)):\n","          if not keep_batch:\n","            intCt = self.weights[0,0] * torch.pow((1.0/intC[lc].numel() if intC[lc].numel() > 0 else 0.0) * torch.sum( torch.exp(self.beta * intC[lc])), self.gamma/self.beta) \n","            terCt = self.weights[0,1] * torch.pow((1.0/terC[lc].numel() if terC[lc].numel() > 0 else 0.0) * torch.sum( torch.exp(self.beta * terC[lc])), self.gamma/self.beta) \n","            loss_equalWeightedByType = 0.5*torch.mean(intC[lc]) + 0.5*torch.mean(terC[lc]) \n","            transformed_loss = 1.0/self.gamma * torch.log(intCt + terCt)\n","            return_losses.append( [ transformed_loss , \n","                                    0.5*torch.mean(intC[lc]) , 0.5*torch.mean(terC[lc]),\n","                                    loss_equalWeightedByType ] )            \n","          else:\n","            return_losses.append( [intC[lc].numpy(), terC[lc].numpy()] )\n","        return return_losses\n","\n","\n","    def calculateLossKLMinMaxGamma(self , batch_x , train_epoch, loss_transforms = [ torch.square ], keep_batch = False):\n","        '''\n","        Helper function that Samples and Calculate loss,\n","        This is adapted in that it changes the weights on the losses\n","        and the distribution of sampling to maximize the loss provided \n","        the KL distance of the loss is within positive constraints\n","        beta represents the constraints on the weights\n","        gamma represents the constraints on the sampling distribution\n","        (each representing an upper bound the KL distribution)\n","        '''        \n","        # x , x_terminal , x_initial = self.sample(sample_method_X, size)\n","        x , x_terminal  = batch_x\n","        x = Variable( x, requires_grad=True)\n","        Ls = self.criterion( x , x_terminal, train_epoch, loss_transforms = loss_transforms)\n","        intC , terC  = Ls\n","\n","        if self.weights is None:\n","          self.weights = torch.ones(1,len(Ls)).to(intC[0].device)/len(Ls)\n","        \n","        return_losses = []\n","        for lc in range(len(loss_transforms)):\n","          if not keep_batch:\n","            intCt = self.weights[0,0] * (1.0/intC[lc].numel() if intC[lc].numel() > 0 else 0.0) * torch.sum( torch.exp(self.gamma * intC[lc])) \n","            terCt = self.weights[0,1] * (1.0/terC[lc].numel() if terC[lc].numel() > 0 else 0.0) * torch.sum( torch.exp(self.gamma * terC[lc])) \n","            loss_equalWeightedByType = 0.5*torch.mean(intC[lc]) + 0.5*torch.mean(terC[lc]) \n","            transformed_loss = 1.0/self.gamma * torch.log(intCt + terCt )\n","            return_losses.append( [ transformed_loss , \n","                                    0.5*torch.mean(intC[lc]) , 0.5*torch.mean(terC[lc]),\n","                                    loss_equalWeightedByType ] )            \n","          else:\n","            return_losses.append( [intC[lc].numpy(), terC[lc].numpy()] )\n","        return return_losses\n","\n","    "]},{"cell_type":"markdown","metadata":{"id":"65nooklCbsdy"},"source":["#### TrainHJBMertonWithDGM"]},{"cell_type":"code","execution_count":49,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":0,"status":"ok","timestamp":1653307284280,"user":{"displayName":"Hans Roggeman","userId":"10574434403170915342"},"user_tz":-60},"id":"74jqGI3o2GlN","outputId":"2c4ad01a-6223-482c-e513-f28ba69eedd1"},"outputs":[{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["time: 2.6 ms (started: 2022-05-23 12:01:13 +00:00)\n"]}],"source":["def attach_pi_used(x, pi_net, requires_grad=True):\n","  pi_used = pi_net(x)  \n","  pi_used.detach_()\n","  # pi_used = pi_used[:,0].reshape(-1,1)\n","  pi_used = pi_used.reshape(-1,1)\n","  \n","  before_x = x.detach().clone()\n","  new_x =  Variable(torch.cat((x, pi_used), dim=1),requires_grad=requires_grad)\n","  return before_x, new_x"]},{"cell_type":"code","execution_count":50,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":0,"status":"ok","timestamp":1653307284282,"user":{"displayName":"Hans Roggeman","userId":"10574434403170915342"},"user_tz":-60},"id":"OtO8fV7oaXK2","outputId":"44ed2ba0-0c03-4864-bd34-b8ee37b0aed2"},"outputs":[{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["time: 697 ms (started: 2022-05-23 12:01:13 +00:00)\n"]}],"source":["class TrainHJBMertonWithDGM():\n","    \n","    def __init__(self , net , equation , BATCH_SIZE , debug = False):\n","        self.history_mean_hooks = [] \n","        self.history_surfaces_hooks = None       \n","        self.history_tl = []\n","        self.history_internal = []\n","        self.history_terminal = []\n","        self.history_initial = []              \n","        self.history_nonzero = []\n","        self.BATCH_SIZE = BATCH_SIZE\n","        self.net = net\n","        self.model = equation        \n","        self.debug = debug  \n","        self.hook_interval = 20      \n","        if self.debug == True:\n","            self.hooks = {}            \n","            self.get_all_layers(self.net)\n","\n","        self.optimizer_used = optim.Adam\n","\n","        self.use_early_stop = False\n","        self.early_stop_patience = 10\n","        self.early_stop_delta = 0.0        \n","        self.best_loss = np.Inf\n","        self.monitored_loss_type = \"Train_L2\"\n","        self.early_stop_counter = 0\n","        \n","        self.pi_lr_mulitplier = 1.01\n","        self.last_loss = np.Inf\n","\n","        self.stop_epoch = 0\n","\n","        self.validation_sample = None\n","        self.validation_losses = None\n","        self.train_losses = None   \n","\n","        self.min_epoch_for_min_loss = 100     \n","        \n","\n","    def train(self , epoch , lr, eqLossFn = 'calculateLoss', sample_method_X = \"U\", key_loss_func = torch.square, huber_delta = 0.5, save_name_best = None):\n","        \n","        if self.validation_sample is not None:\n","          self.validation_losses = np.ones((epoch, 3*4 ), dtype='float32') * np.nan\n","        self.train_losses = np.ones((epoch, 3*2 + 1 ), dtype='float32') * np.nan\n","\n","        optimizer = self.optimizer_used(self.net.parameters(), lr)\n","        # scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min')\n","        \n","        loss_avg = 0.0\n","        loss_calc_method = None\n","        try:\n","            loss_calc_method = getattr(self.model, eqLossFn)\n","        except AttributeError:\n","            raise NotImplementedError(\"Class `{}` does not implement `{}`\".format(self.model.__class__.__name__, eqLossFn))\n","        \n","        for e in range(epoch):\n","\n","            optimizer.zero_grad()\n","            \n","            # pdb.set_trace()\n","            sample_batch = self.model.sample(sample_method_X = sample_method_X, size=self.BATCH_SIZE)\n","\n","            losses_L2, losses_ABS = loss_calc_method( sample_batch, e, loss_transforms = [ key_loss_func, torch.abs ], keep_batch = False )\n","            # pdb.set_trace()\n","            loss , internal , terminal , losses_equalWeightedByType = losses_L2\n","            loss_abs , internal_abs , terminal_abs , losses_equalWeightedByType_abs = losses_ABS\n","            max_loss_L2 = torch.max(torch.tensor([internal , terminal ]))\n","\n","            self.train_losses[e,:] = [ to_cpu_detach(loss) , to_cpu_detach(internal) , to_cpu_detach(terminal) , \n","                                       to_cpu_detach(loss_abs) , to_cpu_detach(internal_abs) , to_cpu_detach(terminal_abs), \n","                                       to_cpu_detach(losses_equalWeightedByType_abs)]\n","\n","            if self.debug == True and (self.validation_sample is not None):\n","              losses_L2_validation, losses_ABS_validation, losses_Huber_valiation = loss_calc_method( self.validation_sample, \n","                                                                                                     loss_transforms = [ torch.square, torch.abs, partial(huber_loss_zero_target, delta=huber_delta) ], \n","                                                                                                     keep_batch = False )\n","              validation_loss_list = [*to_cpu_detach(losses_L2_validation),\n","                                      *to_cpu_detach(losses_ABS_validation),\n","                                      *to_cpu_detach(losses_Huber_valiation)]\n","              # validation_loss_list = validation_loss_list.pop(5) # the L2 loss is duplicated at index 1\n","              self.validation_losses[e,:] = validation_loss_list\n","              # pdb.set_trace()\n","              # print(f\"Epoch {e} - Pi Pred (0.47) {self.model.pi_net(self.validation_sample[0]).item()}\")\n","\n","            \n","            if self.use_early_stop or (save_name_best is not None):\n","              loss_to_check = losses_equalWeightedByType\n","              if self.monitored_loss_type == \"Train_L2\":\n","                pass\n","              elif self.monitored_loss_type == \"Train_L1\":             \n","                loss_to_check = losses_equalWeightedByType_abs\n","              elif self.monitored_loss_type == \"Train_MAXL2\":             \n","                loss_to_check = max_loss_L2\n","\n","              if loss_to_check < (self.best_loss-self.early_stop_delta):\n","                self.best_loss = loss_to_check\n","                if (e > self.min_epoch_for_min_loss) and (save_name_best is not None):\n","                  torch.save(self.net.state_dict(), f\"/content/drive/MyDrive/data_papers/{paper_name}/model_checkpoints/Unet_{save_name_best}_{self.net.__class__.__name__}_{self.model.__class__.__name__}\")\n","                  torch.save(self.model.pi_net.state_dict(), f\"/content/drive/MyDrive/data_papers/{paper_name}/model_checkpoints/Pinet_{save_name_best}_{self.model.pi_net.__class__.__name__}_{self.model.__class__.__name__}\")\n","                self.early_stop_counter = 0\n","                # print(f\"New Loss to beat for early Stop at epoch {e}, original loss: {losses_equalWeightedByType} with patience {self.early_stop_patience}\")\n","              else:\n","                self.early_stop_counter += 1\n","              if self.use_early_stop and (self.early_stop_counter>=self.early_stop_patience):\n","                print(f\"Early Stop at epoch {e}, {self.monitored_loss_type}: {loss_to_check} with patience {self.early_stop_patience}\")\n","                break\n","\n","              if self.pi_lr_mulitplier is not None:\n","                self.last_loss = loss.item()\n","                if loss.item() < self.last_loss:\n","                  self.model.pi_net_lr = min(self.model.pi_net_lr  * self.pi_lr_mulitplier, 1.0)\n","                else:\n","                  self.model.pi_net_lr = max(self.model.pi_net_lr  / self.pi_lr_mulitplier, 1e-14)\n","\n","                  \n","\n","            # self.min_epoch_for_min_loss\n","\n","            loss_avg = loss_avg + float(loss.item())\n","            loss.backward()\n","\n","\n","            optimizer.step()\n","\n","            if (e % self.hook_interval == (self.hook_interval-1)) or e == 0:\n","                # scheduler.step(loss.item())\n","                loss_avg = loss_avg/self.hook_interval\n","                # pdb.set_trace()\n","                # print(f\"Epoch {e} - lr {lr} - Pi Weight {self.model.pi_net.fc_output.weight[0][0]} - key loss: {round(loss.item(),5)} - eqWeighted loss: {round(losses_equalWeightedByType.item(),5)} - L1 loss {round(loss_abs.item(),5)} - Max Loss {round(max_loss_L2.item(),5)}\")\n","                # print(f\"Epoch {e} - lr {lr} - Pi Weight {self.model.pi_net.fc_output.weight[0][0]} - key loss: {round(loss.item(),5)} - eqWeighted loss: {round(losses_equalWeightedByType.item(),5)} - L1 loss {round(loss_abs.item(),5)} - Max Loss {round(max_loss_L2.item(),5)}\")\n","                print(f\"Epoch {e} - lr {lr} - key loss: {round(loss.item(),5)} - eqWeighted loss: {round(losses_equalWeightedByType.item(),5)} - L1 loss {round(loss_abs.item(),5)} - Max Loss {round(max_loss_L2.item(),5)}\")\n","                # loss_avg = 0\n","                ## report detailed loss ## ## puting inside no grad??? for memory optimization!\n","                # tl , dl , il , bl, _ = self.model.calculateLoss( 2**6 )  # note that this is the standard loss!!\n","\n","                self.history_tl.append( loss_avg )\n","                self.history_internal.append( internal )\n","                self.history_terminal.append( terminal )\n","                \n","                if self.debug == True and (self.validation_sample is not None):\n","                    mean = []\n","                    for l in self.hooks:\n","                        mean.append(torch.mean( self.hooks[l] ).item())\n","                    self.history_mean_hooks.append( mean )\n","                    xinternal, xterminal = self.validation_sample\n","                    xinternal_before, xinternal_expanded = attach_pi_used(xinternal, self.model.pi_net, requires_grad=False)\n","                    xterminal_before, xterminal_expanded = attach_pi_used(xterminal, self.model.pi_net, requires_grad=False)\n","\n","                    xinternal_res = self.model.u_net(xinternal_expanded).detach()\n","                    xterminal_res = self.model.u_net(xterminal_expanded).detach()\n","\n","                    # pdb.set_trace()\n","                    df_internal = self.create_result_df(e, xinternal, xinternal_res, \"INTERNAL\")\n","                    df_terminal = self.create_result_df(e, xterminal, xterminal_res, \"TERMINAL\")\n","                    \n","                    if self.history_surfaces_hooks is None:\n","                      self.history_surfaces_hooks = pd.concat([df_internal, df_terminal],axis=0)\n","                    else:\n","                      self.history_surfaces_hooks = pd.concat([self.history_surfaces_hooks,pd.concat([df_internal, df_terminal],axis=0) ], axis=0)\n","\n","        self.stop_epoch = e\n","\n","    def hook_fn(self, m, i, o):\n","              self.hooks[m] = o.detach()\n","            \n","    def get_all_layers(self, net):\n","      for name, layer in net._modules.items():\n","          if isinstance(layer, nn.ModuleList):\n","              for n , l in layer.named_children():\n","                l.register_forward_hook(self.hook_fn)\n","          else:\n","              # it's a non sequential. Register a hook\n","              layer.register_forward_hook(self.hook_fn)\n","    \n","    def create_result_df(self, e, xsample, xsample_res, sample_type):\n","      df_xsample = pd.DataFrame(xsample.cpu().numpy(), columns = [\"Time\", \"S1\", \"Mu\", \"R\", \"Sigma\"])\n","      df_xsample[\"Epoch\"] = e\n","      df_xsample[\"Sample\"] = sample_type\n","      df_xsample[\"Result\"] = xsample_res.cpu().numpy()\n","      return df_xsample\n","\n","    def train_stratified(self , epoch , lr, \n","                         eqLossFn = 'calculateLoss', \n","                         sample_method_X = \"U\", \n","                         key_loss_func = torch.square, \n","                         huber_delta = 0.5,\n","                         save_name_best = None\n","                         ):\n","        \n","        self.validation_losses = np.ones((epoch, 3*3 ), dtype='float32') * np.nan\n","        self.train_losses = np.ones((epoch, 3*2 + 1), dtype='float32') * np.nan\n","        optimizer = self.optimizer_used(self.net.parameters(), lr)\n","        # optimizer = optim.SGD(self.net.parameters(), lr)\n","        loss_avg = 0.0\n","        loss_calc_method = None\n","        try:\n","            loss_calc_method = getattr(self.model, eqLossFn)\n","        except AttributeError:\n","            raise NotImplementedError(\"Class `{}` does not implement `{}`\".format(self.model.__class__.__name__, eqLossFn))\n","        \n","        for e in range(epoch):\n","            optimizer.zero_grad()\n","            # pdb.set_trace()\n","            internal_xts_bts, terminal_xts_bts = self.model.sample_stratified(sample_method_X = sample_method_X, size=self.BATCH_SIZE)\n","            validation_stratum_losses = None #np.array([])#.reshape(1,self.validation_losses.shape[1])\n","            training_stratum_losses = None # np.array([])#.reshape(1,self.train_losses.shape[1])  \n","            training_value_to_optimize = torch.tensor(0.0,requires_grad=True)           \n","            \n","            # pdb.set_trace()\n","            for stratum_count in range(len(internal_xts_bts)):              \n","              sample_batch = (internal_xts_bts[stratum_count], \n","                              terminal_xts_bts[stratum_count])  \n","\n","              # pdb.set_trace()\n","              stratum_losses_L2, stratum_losses_ABS = loss_calc_method(sample_batch, \n","                                                                       loss_transforms = [ key_loss_func, torch.abs ], \n","                                                                       keep_batch = False )\n","              # if np.isnan(stratum_losses_L2[0].detach().cpu().item()):\n","              #   pdb.set_trace()\n","              #   pass\n","            \n","              if training_stratum_losses is not None:\n","                training_stratum_losses = torch.vstack([training_stratum_losses, torch.tensor([*to_cpu_detach(stratum_losses_L2), *to_cpu_detach(stratum_losses_ABS)]) ]) \n","              else:\n","                training_stratum_losses = torch.tensor([*stratum_losses_L2, *stratum_losses_ABS], requires_grad=False) \n","\n","              # pdb.set_trace()  \n","              training_value_to_optimize = training_value_to_optimize + stratum_losses_L2[0]\n","\n","            # pdb.set_trace()              \n","            training_loss_for_epoch = torch.sum(training_stratum_losses,0)\n","            loss = training_value_to_optimize\n","\n","            loss_optimized , internal , terminal, losses_equalWeightedByType, \\\n","            loss_abs , internal_abs , terminal_abs ,losses_equalWeightedByType_abs = training_loss_for_epoch            \n","            max_loss_L2 = torch.max(torch.tensor([internal , terminal ]))\n","\n","            self.train_losses[e,:] = training_loss_for_epoch.detach().numpy()\n","\n","            if self.debug == True and (self.validation_sample is not None):\n","              losses_L2_validation, losses_ABS_validation, losses_Huber_valiation = \\\n","                loss_calc_method( self.validation_sample, \n","                                  loss_transforms = [ torch.square, torch.abs, partial(huber_loss_zero_target, delta=huber_delta) ], \n","                                  keep_batch = False )\n","              validation_loss = [*to_cpu_detach(losses_L2_validation),\n","                                              *to_cpu_detach(losses_ABS_validation),\n","                                              *to_cpu_detach(losses_Huber_valiation)]\n","              # validation_loss = validation_loss.pop(5) # the L2 loss is duplicated at index 1                \n","              self.validation_losses[e,:] = validation_loss\n","\n","            if self.use_early_stop or (save_name_best is not None):\n","              loss_to_check = losses_equalWeightedByType\n","              if self.monitored_loss_type == \"Train_L2\":\n","                pass\n","              elif self.monitored_loss_type == \"Train_L1\":             \n","                loss_to_check = losses_equalWeightedByType_abs\n","              elif self.monitored_loss_type == \"Train_MAXL2\":             \n","                loss_to_check = max_loss_L2\n","              if loss_to_check < (self.best_loss-self.early_stop_delta):\n","                self.best_loss = loss_to_check\n","                if (e > self.min_epoch_for_min_loss) and (save_name_best is not None):\n","                  torch.save(self.net.state_dict(), f\"/content/drive/MyDrive/data_papers/{paper_name}/model_checkpoints/Unet_{save_name_best}_{self.net.__class__.__name__}_{self.model.__class__.__name__}\")\n","                  torch.save(self.model.pi_net.state_dict(), f\"/content/drive/MyDrive/data_papers/{paper_name}/model_checkpoints/Pinet_{save_name_best}_{self.model.pi_net.__class__.__name__}_{self.model.__class__.__name__}\")\n","                self.early_stop_counter = 0\n","                # print(f\"New Loss to beat for early Stop at epoch {e}, original loss: {losses_equalWeightedByType} with patience {self.early_stop_patience}\")\n","              else:\n","                self.early_stop_counter += 1\n","              if self.use_early_stop and (self.early_stop_counter>=self.early_stop_patience):\n","                print(f\"Early Stop at epoch {e}, {self.monitored_loss_type}: {loss_to_check} with patience {self.early_stop_patience}\")\n","                break\n","\n","            loss_avg = loss_avg + float(loss.item())\n","            loss.backward()\n","\n","            optimizer.step()\n","            if (e % self.hook_interval == (self.hook_interval-1)) or e == 0:\n","                loss_avg = loss_avg/self.hook_interval\n","                print(\"Epoch {} - lr {} -  key loss: {} - eqWeighted loss: {} - L1 loss {} - Max Loss {}\".format(e , lr , loss, losses_equalWeightedByType, loss_abs, max_loss_L2 ))\n","                # loss_avg = 0\n","                ## report detailed loss ## ## puting inside no grad??? for memory optimization!\n","                # tl , dl , il , bl, _ = self.model.calculateLoss( 2**6 )  # note that this is the standard loss!!\n","                self.history_tl.append( loss_avg )\n","                self.history_internal.append( internal )\n","                self.history_terminal.append( terminal )\n","                if self.debug == True and (self.validation_sample is not None):\n","                    mean = []\n","                    for l in self.hooks:\n","                        mean.append(torch.mean( self.hooks[l] ).item())\n","                    self.history_mean_hooks.append( mean )\n","                    xinternal, xterminal, xinitial, xnonzero = self.validation_sample\n","                    xinternal_res = self.model.net(xinternal).detach()\n","                    xterminal_res = self.model.net(xterminal).detach()\n","\n","                    # pdb.set_trace()\n","                    df_internal = self.create_result_df(e, xinternal, xinternal_res, \"INTERNAL\")\n","                    df_terminal = self.create_result_df(e, xterminal, xterminal_res, \"TERMINAL\")\n","                    \n","                    if self.history_surfaces_hooks is None:\n","                      self.history_surfaces_hooks = pd.concat([df_internal, df_terminal],axis=0)\n","                    else:\n","                      self.history_surfaces_hooks = pd.concat([self.history_surfaces_hooks,pd.concat([df_internal, df_terminal],axis=0) ], axis=0)\n","\n","        self.stop_epoch = e\n"," "]},{"cell_type":"markdown","metadata":{"id":"oy05I1QFh7EM"},"source":["### Test Case"]},{"cell_type":"markdown","metadata":{"id":"U7zqglm1ewTL"},"source":["#### Test Case NO Stratification"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":296,"status":"ok","timestamp":1653173056732,"user":{"displayName":"Hans Roggeman","userId":"10574434403170915342"},"user_tz":-60},"id":"-yLM2WbUoymO","outputId":"f77edcc5-4bfc-4f7c-9074-cd5f132c9d7d"},"outputs":[{"name":"stdout","output_type":"stream","text":["time: 12.2 ms (started: 2022-05-21 22:44:18 +00:00)\n"]}],"source":["# mequation = MertonEquation(MertonUtilityNet( NL = 1 , NN = 3 ), MertonAlternativePiNet( in_size = 5 , out_size = 1, neurons = 100, depth=5 ), 1, 10000.0)\n","# # val_sample_to_use = tuple([ x.cpu().detach() for x in mequation.sample(sample_method_X=\"U\", size=1) ] )\n","# val_sample_to_use = mequation.sample(sample_method_X=\"U\", size=1) \n","# # # gamma = 1.0 # time = 0.0 # mu = 0.05 # r = 0.02 # sigma = 0.25   \n","# val_sample_to_use[0][0,0] = 0.0\n","# val_sample_to_use[0][0,2] = 0.05\n","# val_sample_to_use[0][0,3] = 0.02\n","# val_sample_to_use[0][0,4] = 0.25"]},{"cell_type":"code","execution_count":112,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IUNDoPJRe6dL","executionInfo":{"status":"ok","timestamp":1653315773258,"user_tz":-60,"elapsed":489706,"user":{"displayName":"Hans Roggeman","userId":"10574434403170915342"}},"outputId":"bb1d53b9-eab6-4bcd-a8c3-c94f6334e879"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 0 - lr 0.1 - key loss: 0.09179 - eqWeighted loss: 0.09179 - L1 loss 0.23488 - Max Loss 0.08475\n","Epoch 99 - lr 0.1 - key loss: 0.00078 - eqWeighted loss: 0.00078 - L1 loss 0.02071 - Max Loss 0.00063\n","Epoch 199 - lr 0.1 - key loss: 0.0033 - eqWeighted loss: 0.0033 - L1 loss 0.0443 - Max Loss 0.0031\n","Epoch 299 - lr 0.1 - key loss: 0.00043 - eqWeighted loss: 0.00043 - L1 loss 0.01235 - Max Loss 0.00043\n","Epoch 399 - lr 0.1 - key loss: 0.00086 - eqWeighted loss: 0.00086 - L1 loss 0.01764 - Max Loss 0.00086\n","Epoch 499 - lr 0.1 - key loss: 0.00043 - eqWeighted loss: 0.00043 - L1 loss 0.01283 - Max Loss 0.00043\n","Epoch 599 - lr 0.1 - key loss: 0.00033 - eqWeighted loss: 0.00033 - L1 loss 0.01092 - Max Loss 0.00033\n","Epoch 699 - lr 0.1 - key loss: 0.00113 - eqWeighted loss: 0.00113 - L1 loss 0.0194 - Max Loss 0.00113\n","Epoch 799 - lr 0.1 - key loss: 0.00084 - eqWeighted loss: 0.00084 - L1 loss 0.0169 - Max Loss 0.00084\n","Epoch 899 - lr 0.1 - key loss: 0.00049 - eqWeighted loss: 0.00049 - L1 loss 0.01993 - Max Loss 0.00035\n","Epoch 999 - lr 0.1 - key loss: 0.00696 - eqWeighted loss: 0.00696 - L1 loss 0.06951 - Max Loss 0.00419\n","Epoch 1099 - lr 0.1 - key loss: 0.0019 - eqWeighted loss: 0.0019 - L1 loss 0.0277 - Max Loss 0.0019\n","Epoch 1199 - lr 0.1 - key loss: 0.00146 - eqWeighted loss: 0.00146 - L1 loss 0.02338 - Max Loss 0.00146\n","Epoch 1299 - lr 0.1 - key loss: 0.00036 - eqWeighted loss: 0.00036 - L1 loss 0.01163 - Max Loss 0.00036\n","Epoch 1399 - lr 0.1 - key loss: 0.15143 - eqWeighted loss: 0.15143 - L1 loss 0.27482 - Max Loss 0.15143\n","Epoch 1499 - lr 0.1 - key loss: 0.00056 - eqWeighted loss: 0.00056 - L1 loss 0.01379 - Max Loss 0.00056\n","Epoch 1599 - lr 0.1 - key loss: 0.00038 - eqWeighted loss: 0.00038 - L1 loss 0.01176 - Max Loss 0.00038\n","Epoch 1699 - lr 0.1 - key loss: 0.00038 - eqWeighted loss: 0.00038 - L1 loss 0.01416 - Max Loss 0.00033\n","Epoch 1799 - lr 0.1 - key loss: 0.00041 - eqWeighted loss: 0.00041 - L1 loss 0.01277 - Max Loss 0.00041\n","Epoch 1899 - lr 0.1 - key loss: 0.00042 - eqWeighted loss: 0.00042 - L1 loss 0.0121 - Max Loss 0.00042\n","Epoch 1999 - lr 0.1 - key loss: 0.00067 - eqWeighted loss: 0.00067 - L1 loss 0.01431 - Max Loss 0.00067\n","Epoch 2099 - lr 0.1 - key loss: 0.00033 - eqWeighted loss: 0.00033 - L1 loss 0.0109 - Max Loss 0.00033\n","Epoch 2199 - lr 0.1 - key loss: 0.00079 - eqWeighted loss: 0.00079 - L1 loss 0.01538 - Max Loss 0.00079\n","Epoch 2299 - lr 0.1 - key loss: 0.00055 - eqWeighted loss: 0.00055 - L1 loss 0.0141 - Max Loss 0.00055\n","Epoch 2399 - lr 0.1 - key loss: 0.0009 - eqWeighted loss: 0.0009 - L1 loss 0.01767 - Max Loss 0.0009\n","Epoch 2499 - lr 0.1 - key loss: 0.01374 - eqWeighted loss: 0.01374 - L1 loss 0.0817 - Max Loss 0.01374\n","Early Stop at epoch 2515, Train_L2: 0.00037386445910669863 with patience 2500\n","time: 8min 9s (started: 2022-05-23 14:14:43 +00:00)\n"]}],"source":["torch.cuda.empty_cache()\n","seed = 123\n","torch.manual_seed(seed)\n","torch.cuda.manual_seed(seed)\n","torch.cuda.manual_seed_all(seed)\n","np.random.seed(seed)\n","random.seed(seed)\n","torch.backends.cudnn.benchmark = False\n","torch.backends.cudnn.deterministic = True\n","\n","# u_net, pi_net, pi_net_epoch, pi_net_lr\n","eqLossFn= 'calculateLoss' # 'calculateLossUsingKLMinMax' #'calculateLoss'\n","sample_method= \"U\"\n","lr = 0.1\n","lr_for_pi = 0.00001\n","max_pi_epochs = 1 # has to be low!!!\n","save_name_best = None\n","# save_name_best = f\"{datetime.datetime.now():%Y%m%d%H%M%S}\"\n","\n","# u_net = MertonUtilityNet(NL = 3, NN =100) \n","u_net = MertonAlternativePiNet( in_size = 6 , out_size = 1, neurons = 64, depth= 10 )\n","u_net.to(torch.device(\"cuda:0\")) \n","pi_net = MertonPiNet(NL=3, NN=100)  \n","# pi_net = MertonAlternativePiNet( in_size = 5 , out_size = 1, neurons = 64, depth= 3 )\n","pi_net.to(torch.device(\"cuda:0\")) \n","## providing sampler with net so it can accept/reject based on net and other criterions\n","mequation = MertonEquation(u_net, pi_net, max_pi_epochs, lr_for_pi)\n","# mequation.FORCE_MU = 0.05\n","# mequation.FORCE_R = 0.02\n","# mequation.FORCE_SIGMA = 0.25\n","trainMertonAlloc = TrainHJBMertonWithDGM(u_net, mequation, BATCH_SIZE = 2**7 , debug = True )\n","trainMertonAlloc.hook_interval = 100\n","trainMertonAlloc.use_early_stop = True\n","trainMertonAlloc.early_stop_patience = 2500\n","trainMertonAlloc.min_epoch_for_min_loss = 50\n","trainMertonAlloc.pi_lr_mulitplier = 1.0\n","# trainMertonAlloc.validation_sample = val_sample_to_use\n","# trainMertonAlloc.train(epoch = 100000 , lr = lr, eqLossFn = eqLossFn , sample_method_X = sample_method, save_name_best = save_name_best)\n","trainMertonAlloc.train(epoch = 100000 , lr = lr, eqLossFn = eqLossFn , sample_method_X = sample_method,  key_loss_func = torch.square, save_name_best = save_name_best)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":305,"status":"ok","timestamp":1653262707180,"user":{"displayName":"Hans Roggeman","userId":"10574434403170915342"},"user_tz":-60},"id":"SoD7h8iiu-Il","outputId":"88374342-2b36-4ff4-cd7d-4a80b979ca54"},"outputs":[{"data":{"text/plain":["['Unet_20220521192206_MertonUtilityNet_MertonEquation',\n"," 'Pinet_20220521192206_MertonAlternativePiNet_MertonEquation',\n"," 'Pinet_20220521192328_MertonAlternativePiNet_MertonEquation',\n"," 'Unet_20220521192328_MertonUtilityNet_MertonEquation',\n"," 'Unet_20220521203949_MertonUtilityNet_MertonEquation',\n"," 'Pinet_20220521203949_MertonAlternativePiNet_MertonEquation',\n"," 'Unet_20220521222352_MertonUtilityNet_MertonEquation',\n"," 'Pinet_20220521222352_MertonAlternativePiNet_MertonEquation',\n"," 'Unet_20220521223154_MertonUtilityNet_MertonEquation',\n"," 'Pinet_20220521223154_MertonAlternativePiNet_MertonEquation',\n"," 'Unet_20220521224523_MertonUtilityNet_MertonEquation',\n"," 'Pinet_20220521224523_MertonAlternativePiNet_MertonEquation',\n"," 'Pinet_20220521230208_MertonAlternativePiNet_MertonEquation',\n"," 'Unet_20220521230208_MertonUtilityNet_MertonEquation',\n"," 'Unet_20220521231548_MertonUtilityNet_MertonEquation',\n"," 'Pinet_20220521231548_MertonAlternativePiNet_MertonEquation',\n"," 'Unet_20220522174720_MertonAlternativePiNet_MertonEquation',\n"," 'Pinet_20220522174720_MertonPiNet_MertonEquation',\n"," 'Unet_20220522175154_MertonAlternativePiNet_MertonEquation',\n"," 'Pinet_20220522175154_MertonPiNet_MertonEquation',\n"," 'Unet_20220522185852_MertonAlternativePiNet_MertonEquation',\n"," 'Pinet_20220522185852_MertonPiNet_MertonEquation',\n"," 'Unet_20220522190044_MertonAlternativePiNet_MertonEquation',\n"," 'Pinet_20220522190044_MertonPiNet_MertonEquation',\n"," 'Unet_20220522214455_MertonAlternativePiNet_MertonEquation',\n"," 'Pinet_20220522214455_MertonAlternativePiNet_MertonEquation']"]},"execution_count":263,"metadata":{},"output_type":"execute_result"},{"name":"stdout","output_type":"stream","text":["time: 3.97 ms (started: 2022-05-22 23:38:28 +00:00)\n"]}],"source":["os.listdir(f\"/content/drive/MyDrive/data_papers/dgm_hjb/model_checkpoints\")\n","# {datetime.datetime.now():%Y%m%d%H%M%S}"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_JT0dEt4iwAd"},"outputs":[],"source":["# # u_net = MertonUtilityNet(NL=3, NN=100)\n","# u_net = MertonAlternativePiNet( in_size = 6 , out_size = 1, neurons = 64, depth= 6 )\n","# u_net.load_state_dict(torch.load(f\"/content/drive/MyDrive/data_papers/dgm_hjb/model_checkpoints/Unet_20220522214455_MertonAlternativePiNet_MertonEquation\"))\n","# u_net.to(torch.device(\"cuda:0\")) \n","# u_net.eval()\n","# pi_net = MertonAlternativePiNet( in_size = 5 , out_size = 1, neurons = 64, depth= 3 )\n","# # pi_net = MertonPiNet(NL=3, NN=100)  #\n","# pi_net.load_state_dict(torch.load(f\"/content/drive/MyDrive/data_papers/dgm_hjb/model_checkpoints/Pinet_20220522214455_MertonAlternativePiNet_MertonEquation\"))\n","# pi_net.to(torch.device(\"cuda:0\")) \n","# pi_net.eval()\n","\n","# # eqLossFn= 'calculateLoss' \n","# # sample_method= \"U\"\n","# # lr = 0.000001\n","# lr_for_pi = 0.000001\n","# # max_pi_epochs = 1 # has to be low!!!\n","# mequation = MertonEquation(u_net, pi_net, 1, lr_for_pi)\n"]},{"cell_type":"code","execution_count":113,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"u35g5sAPbsG_","executionInfo":{"status":"ok","timestamp":1653315820105,"user_tz":-60,"elapsed":315,"user":{"displayName":"Hans Roggeman","userId":"10574434403170915342"}},"outputId":"eef5ec79-ca3e-46c4-c6a6-0f4a44ff9b4c"},"outputs":[{"output_type":"stream","name":"stdout","text":["time: 12.9 ms (started: 2022-05-23 14:23:40 +00:00)\n"]}],"source":["# check control for closed form:\n","# PI(x,t) = [(mu-r)/(gamma*sigma^2)]*exp(-r*(T-t))\n","# ((mu-r)/(gamma*(sigma**2)))*np.exp(-r*(1.0-time))\n","# gamma = 1.0 # time = 0.0 # mu = 0.05 # r = 0.02 # sigma = 0.25   # PI\n","\n","gamma = 1.0\n","internal_sample, terminal_sample = mequation.sample(size=100, to_cpu=False)\n","mask = (internal_sample[:,0] > 0.1) & (internal_sample[:,4] > 0.1)\n","internal_sample = internal_sample[mask.reshape(-1),:]\n","# time, wealth, mu, r, sigma\n","time = internal_sample[:,0].cpu().detach()\n","wealth = internal_sample[:,1].cpu().detach()\n","mu = internal_sample[:,2].cpu().detach()\n","r = internal_sample[:,3].cpu().detach()\n","sigma = internal_sample[:,4].cpu().detach()\n","\n","# mequation.pi_net(internal_sample)[:,0]"]},{"cell_type":"code","execution_count":114,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":466},"id":"Woj8BoAK5OLC","executionInfo":{"status":"ok","timestamp":1653315820777,"user_tz":-60,"elapsed":8,"user":{"displayName":"Hans Roggeman","userId":"10574434403170915342"}},"outputId":"6325ca29-e509-4260-dc67-d71b0dac73f2"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 640x480 with 1 Axes>"],"image/png":"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\n"},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":["<ggplot: (8755135256941)>"]},"metadata":{},"execution_count":114},{"output_type":"stream","name":"stdout","text":["time: 241 ms (started: 2022-05-23 14:23:40 +00:00)\n"]}],"source":["# plot the fitted value function vs the closed form (ideally straight line...)\n","u_net.eval()\n","u_internal_sample = torch.cat((internal_sample, mequation.pi_net(internal_sample).reshape(-1,1)), dim=1)\n","u_net_results = u_net(u_internal_sample).detach().cpu().numpy().reshape(-1).tolist()\n","htx_results = Htx(u_internal_sample).cpu().detach().numpy().reshape(-1).tolist()\n","dataf2 = pd.DataFrame( { 'u_net': u_net_results, 'closed_form': htx_results } )\n","ggplot(dataf2, aes(x='u_net', y='closed_form')) + geom_point()"]},{"cell_type":"code","execution_count":115,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":466},"id":"GHfTC6GljYnd","executionInfo":{"status":"ok","timestamp":1653315825026,"user_tz":-60,"elapsed":331,"user":{"displayName":"Hans Roggeman","userId":"10574434403170915342"}},"outputId":"69fc6a55-eed3-4d80-a4fa-5b87c72c2ad7"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 640x480 with 1 Axes>"],"image/png":"iVBORw0KGgoAAAANSUhEUgAAAigAAAGvCAYAAABxUC54AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAAPYQAAD2EBqD+naQAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOzdeXhMZ/8G8PucWbKKRCOxRQSJLWpfithpq33VGrXHUorQWora3rcaxdtai6LVtLXVz1JUURq1BC1FrWmsETshhMgyy/n9oZm3I4vMZCbnZOb+XFcvzZmZM9/km8nc85znPEeQJEkCERERkYKIchdARERE9DwGFCIiIlIcBhQiIiJSHAYUIiIiUhwGFCIiIlIcBhQiIiJSHAYUIiIiUhwGFCIiIlIctdwFFERSUpLN9ykIAtzc3JCWlgZHXsNOq9UiMzNT7jLshn10DOyjY3CGPrKHlvH19X3hfTiC8hxRFOHu7g5RdOwfjYuLi9wl2BX76BjYR8fgDH1kD+3wnIX2TERERET5pKhDPIcOHcKaNWtw584deHl5YdCgQWjSpIncZREREVEhU0xAOXnyJL766iuMGzcOVatWRUpKCtLT0+Uui4iIiGSgmICyZs0a9OjRA9WrVwcAeHt7y1wRERERyUURAcVgMODChQto2LAh3n33XaSnp6NOnToYPHgwPDw85C6PiIiICpkiAsrDhw+h1+uxf/9+REVFwdXVFXPmzMFXX32F9957z3S/pKQks1OLRVFEyZIlbVqLSqUy+9dRCYLg0N8j++gY2EfH4Ax9ZA9tTxEBJev0rDfeeMN0bnT37t3xySefmN1v48aN+PLLL01fR0REIDIy0i41eXl52WW/SqLVauUuwe7YR8fAPjoGR+8je2hbiggonp6e8PX1hSAIed6va9euaNGihelrURSRnJxs01pUKhW8vLyQkpICg8Fg030riYeHB1JTU+Uuw27YR8fAPjoGZ+gje2gZHx+fF95HEQEFANq3b4+ffvoJ9evXh4uLCzZu3IiGDRua3cfX19ds9bmkpCS7/bIbDAaHfSEBgCRJDv39ZWEfHQP76BgcuY/soe0pJqB0794dKSkpGDFiBFQqFerXr4/BgwfLXRYRERHJQDEBRaVSYciQIRgyZIjcpRAREZHMuNQ9ERERmRgMBkUslMqAQkRERDAYDPj3v/+NcuXKISAgAK1bt0ZiYqJs9TCgEBEREebPn4/ly5dDr9cDAOLi4tC1a1dkZGTIUg8DChEREeH77783hRMA0Ov1SEhIwLlz52SphwGFiIiIFIcBhYiIiNC9e3eo1f87uVelUiEgIADVqlWTpR4GFCIiIsKYMWMQEREBUXwWDYKDg7Fx40a4urrKUo9i1kEhIiIi+ajVasycORPTp09HRkYGPD095a1H1mcnIiIiRdFoNNBoNHKXwUM8REREpDwMKERERKQ4DChERESkOAwoREREpDgMKERERKQ4DChERESkOAwoREREpDgMKERERKQ4DChERESkOAwoREREpDgMKERERKQ4DChERESkOAwoREREpDgMKERERKQ4DChERESkOAwoREREpDgMKERERKQ4DChERESkOAwoREREpDgMKERERKQ4DChERESkOAwoREREpDgMKERERKQ4DChERESkOAwoREREpDgMKERERKQ4DChERESkOAwoREREpDgMKERERKQ4DChERESkOAwoREREpDgMKERERKQ4DChERESkOAwoREREpDgMKERERKQ4DChEREQOQJIkfPnll6hVqxZCQkIwePBgPHz4UO6yrKaWuwAiIiIquOjoaEydOhUGgwEAsH37dly/fh3bt2+HKBa98YiiVzERERFls3TpUlM4AQCdTodjx44hPj5exqqsx4BCRETkANLT0y3arnQMKERERA6gbdu20Gg0pq9FUcRLL72EkJAQGauyHgMKERGRA/j4448RFhZm+rpEiRJYt24dPDw8ZKzKepwkS0RE5AA8PDzw/fffIzExEU+fPkVQUBBcXV3lLstqDChEREQOQhAEBAYGyl2GTfAQDxERESmOIEmSJHcR1kpJSYGLi4tN9ykIArRaLTIzM1GEfzQvpFarodfr5S7DbthHx8A+OgZn6CN7aJn8vHcX6UM8mZmZyMzMtOk+VSoVtFotUlNTzc4ndzTFihXD48eP5S7DbthHx8A+OgZn6CN7aJn8BBQe4iEiIiLFYUAhIiIixWFAISIiIsVhQCEiIiLFYUAhIiIixWFAISIiIsVhQCEiIiLFYUAhIiIixWFAISIiIsVhQCEiIiLFYUAhIiIikxMnTqBjx46oX78+IiIicOvWLVnqKNLX4iEiIiLbOXfuHN58803o9XoYjUbcuHEDx48fx6FDh+Dj41OotXAEhYiIiAAAX3/9NQwGA4xGIwBAr9fj/v37+Omnnwq9FgYUIiIiAgA8fPgw29WKRVFESkpKodfCgEJEREQAgKZNm0KtNp/9kZGRgYYNGxZ6LQwoREREBADo378/unfvDgAQBAGiKGLWrFmoW7duodfCSbJEREQE4NnhnIULF2LEiBG4ffs2KlWqhHLlyslSCwMKERERmalSpQqqVKkiaw08xENERESKw4BCREREisOAQkRERIrDgEJERESKw4BCREREisOAQkRERIrDgEJERESKw4BCREREisOAQkRERIrDgEJERESKw4BCREREisOAQkRERIrDgEJERESKw4BCREREisOAQkRERIrDgEJERESKw4BCREREisOAQkRERIrDgEJERESKw4BCREREisOAQkRERIrDgEJERESKw4BCREREiqOWuwAiIiIquJiYGMTGxsLd3R3du3dHhQoV5C6pQBhQiIiIiriFCxciKioKarUagiDg888/x7Zt2/Dyyy/LXZrVeIiHiIioCLtz5w6ioqIgSRJ0Oh0yMzORmZmJ8ePHy11agTCgEBERFWHXrl2DJElm2wwGA65evSpTRbbBgEJERFSEBQQEQBAEs20qlarIz0FhQCEiIirC/P39MW3aNAiCAI1GA61WCxcXF3z66adyl1YgnCRLRERUxEVGRqJGjRo4cOAAPDw80K1bNwQGBspdVoEwoBARETmAVq1aoVWrVnKXYTM8xENERESKo7iAkpKSgt69e2PcuHFyl0JEREQyUVxAiY6ORkBAgNxlEBERkYwUFVDOnDmDmzdvom3btnKXQkRERDJSTEDR6XRYtmwZ3n333WzncxMREZFzUcxZPBs3bkStWrUQFBSEy5cv53ifpKQkJCUlmb4WRRElS5a0aR0qlcrsX0clCIJDf4/so2NgHx2DM/SRPbQ9RQSUmzdvIiYmBgsWLMjzfhs3bsSXX35p+joiIgKRkZF2qcnLy8su+1USrVYrdwl2xz46BvbRMTh6H9lD2xKk5xfwl0FMTAy++OILuLu7A4DpQkeenp5YunSpaXthjaB4eXkhJSUFBoPBpvtWEg8PD6Smpspdht2wj46BfXQMztBH9tAyPj4+L7yPIkZQmjVrhrp165q+PnDgAH799VdMmzYNbm5upu2+vr7w9fU1fZ2UlGS3X3aDweCwLyQAkCTJob+/LOyjY2AfHYMj95E9tD1FBBQXFxe4uLiYvvbw8IBKpcpXwiIiIiLHo4iA8rw2bdqgTZs2cpdBREREMlHMacZEREREWRhQiIiISHEYUIiIiEhxGFCIiIhIcRhQiIiISHEYUIiIiEhxGFCIiIhIcRhQiIiISHEYUIiIiEhxGFCIiIhIcRhQiIiISHEYUIiIiEhxrL5Y4NOnTxETE4Nr164hPT3d7DZBEDB69OgCF0dERETOyaqAsm/fPnTt2hUPHjzI8XYGFCIiIioIqw7xjBgxAi+//DJOnz6NjIwMGI1Gs/8MBoOt6yQiIiInYtUIytWrVzF//nzUqFHD1vUQERERWTeC0rRpU8THx9u6FiIiIiIAVo6gLFu2DN27d4dWq0WbNm3g7e2d7T4lSpQocHFERETknKwKKN7e3ggMDMTQoUMhCEKO9+E8FCIiIrKWVQGlb9++iI2NxdixYxESEgKtVmvruoiIiMiJWRVQYmJisGzZMvTp08fW9RARERFZN0m2bNmyKF68uK1rISIiIgJgZUCZPn06Zs6cieTkZFvXQ0RERGTdIZ7Vq1cjMTERgYGBqF27drazeARBwJYtW2xSIBERETkfqwLK48ePERwcbPY1ERERka1YHFAkScKmTZvg7u4OV1dXe9RERERETs7iOSg6nQ5+fn6IiYmxRz1ERERElo+gaLValCtXjguxERERFZInT55gw4YNuHv3LqpXr4433ngj14VSHYVVc1BGjBiBuXPnon379jzMQ0REZEePHj3Cq6++isTERIiiCL1ej/DwcCxYsMChQ4pVASUxMRHnz59H+fLl0bJlS/j7+5v9kARBwIIFC2xWJBERkbOaN28eEhMTodPpTNvWrVuHbt26oXnz5jJWZl9WBZRt27bBxcUFLi4uOHr0aLbbGVCIiIhs46+//jILJ8Cz6RaXLl1iQHnelStXbF0HERER5aBChQrQaDRmIUWn06Fs2bIyVmV/Vq0kS0RERIVj9OjR8Pb2hlarhSiK0Gg0aNWqFdq2bSt3aXZl1QgKANy4cQPz589HbGwsHjx4gBIlSiAsLAzvvfeew6c6IiKiwuLv74/9+/djxYoVprN4+vfvD1F07DEGqwLKmTNn0Lx5c+h0OrRr1w61a9fGnTt3sHTpUqxYsQL79+9HjRo1bF0rERGRU/L19cWECRPkLqNQWRVQxo0bh0qVKmHXrl3w8fExbU9OTkb79u0xbtw47Nixw2ZFEhERkXOxanwoNjYWU6ZMMQsnAODj44PJkycjNjbWJsURERGRc7IqoKjVamRkZOR4W0ZGBlQqVYGKIiIiIudmVUBp27YtJk+ejPPnz5ttv3DhAqZOnYp27drZpDgiIiJyTlYFlLlz50Kv16N69eqoXbs2Xn31VdSpUwfVqlWDXq/H3LlzbV0nERERORGrAkr58uVx+vRpzJ07FyEhITAajQgJCcG8efNw6tQpBAQE2LpOIiIiciL5PounS5cu+O9//4vKlSvju+++wxtvvIFRo0Zh1KhR9qyPiIiInFC+R1C2bt2K+/fvAwAGDBiAS5cu2a0oIiIicm75HkEpW7YsfvzxR/j7+0OSJNy+fRuJiYm53r98+fI2KZCIiIicT74Dyvvvv49x48Zh5syZEAQBnTt3zvF+kiRBEAQYDAabFUlERETOJd8BZfTo0fjXv/6Fv/76Cx07dsTs2bMREhJiz9qIiIjISVm01H3lypVRuXJl9O/fH926dUNQUFC+HpeYmIgyZcpArbb62oRERETkRKw6zTg6Ojrf4cRgMCAoKAinTp2y5qmIiIjICRXKtZolSSqMpyEiIiIHUSgBhYiIiMgSDChERESkOAwoREREpDgMKERERKQ4Rfq8X61WCxcXF5vuUxAEAICHh4dDT+5Vq9UoVqyY3GXYDfvoGNhHx+AMfWQPbc/uAUUQBLRo0cIujcvMzERmZqZN96lSqaDVapGamurQq+EWK1YMjx8/lrsMu2EfHQP76BicoY/soWXyM7hg94AiiiJ+/fVXez8NEREROZB8BxRRFE1DPPnhqCmZiIiI7C/fAWXu3LmmgKLX6zF//nxotVp06tQJ/v7+uH37NjZv3gydTofRo0fbrWAiIiJyfBZdzTjLhAkTUKdOHWzevBmi+L8TgT777DO89dZbuHXrlm2rJCIiIqdi1WnG33zzDYYPH24WToBnh4GGDx+Ob7/91ibFERERkXOyKqCkpaUhISEhx9sSEhKQnp5ekJqIiIjIyVl1Fk+nTp0wYcIEuLm5oVOnTihevDgePXqEH374AR9++CE6depk6zqJiIjIiVgVUBYvXoynT59i4MCBGDhwIDQaDXQ6HSRJQufOnbFo0SJb10lEREROxKqAUqxYMWzYsAFxcXE4cuQIbt++jdKlS6NBgwaoVq2arWskIiIiJ1OghdqqVavGQEJEREQ2Z/XFAnU6HZYuXYpBgwahffv2uHDhAgBg3bp1iIuLs1mBRERE5HysGkG5fPky2rZti6SkJNSpUwexsbGmaxDs378fO3fuRHR0tE0LJSIiIudh1QjKqFGjULJkSVy+fBkxMTFmVzZs0aIF9u/fb7MCiYiIyPlYNYKyd+9erF27Fr6+vtmuuVOqVCmuJEtEREQFYtUIilqtNhs1+ac7d+7A09OzQEURERGRc7MqoLRo0QJz5syBTqczbRMEAZIkYfny5WjTpo3NCiQiIiLnY9UhntmzZ6NJkyaoXr06OnbsCEEQsHjxYpw5cwYXLlzAkSNHbF0nERERORGrRlCqVq2KY8eOoUmTJli7di1UKhW2bduGypUr48iRI6hUqZKt6yQiIiInYvVCbUFBQbxqMREREdmF1Qu1PS8hIQG//PILHjx4YKtdEhERkZOyKqCMHTsW77//vunrH374AVWqVEH79u0RHByMY8eO2axAIiIicj5WBZQffvgB9evXN309adIkdOjQAadOnULDhg0xZcoUmxVIREREzseqgHLr1i2UL18eAHDp0iXEx8djypQpCA0NxciRI/HHH3/YtEgiIiJyLlYFlOLFi+Pu3bsAgN27d6NEiRKoV68eAMDFxQVpaWm2q5CIiEhGT58+xciRIxEUFIRKlSph8uTJyMzMlLssh2fVWTzNmzfHtGnTcOfOHXz22Wfo1KmT6bb4+HjT6AoREVFRN3z4cOzatcu0OGl0dDT0ej1mz54tc2WOzaoRlHnz5qFUqVKYOHEiypcvjxkzZphuW7lyJcLCwmxWIBERka1IkoTk5GTo9fp83f/Jkyf46aefzFZO1+l0WLVqVa6XfCHbsGoEpWzZstizZ0+Ot/38889wdXUtUFFERES2duTIEQwYMAB3796FWq3GlClTMGLEiDwfk9uhHIPBAEmSIAiCPUolFHAdFEmSEB8fj8OHDyM+Ph6SJMHLywtardZW9RERERXYrVu3EB4ejnv37gEA9Ho9pk+fjo0bN+b5OB8fH9SsWRNq9f8+z2s0GrRo0QKiaLOlxCgHVv90lyxZgtKlS6N69epo1qwZqlevjjJlyuCLL76wZX1EREQFduDAAeh0OrPDMkajEZs2bcrzcYIgYNWqVQgODjZtq1OnDt/rCoFVh3iWL1+OyMhI9OzZEz169IC/vz/u3LmDdevWITIyEhqNBoMHD7Z1rURERFbJbbQjP6MgZcqUwd69e3Hjxg2oVCqULl2ah3YKgVUBZd68eRg1ahTmz59vtr1jx44oWbIkPvvsMwYUIiJSjLCwMLi6ukKv18NoNAJ4Fk7Cw8Pz9XhRFBEQEGDPEuk5Vh3iuXLlCt58880cb3vjjTeQkJBQkJqIiIhsyt/fH5s2bTKFDHd3d8yaNQv/+te/ZK6McmPVCErp0qVx+PBhtG3bNtttv/32G0qXLl3gwoiIiGypVq1a+OOPP5CRkQGtVsvDNApnVUAZNGgQpk+fjoyMDHTr1g3+/v64e/cu1q9fj08//RTTpk2zdZ1EREQ24eLiIncJlA9WBZTJkycjOTkZn376KWbOnPm/nanVGDlyJCZPnmyzAomIiMj5WBVQBEHAnDlzMGnSJPz+++9ITk5GiRIl0LBhQ7z00ku2rpGIiIicjFUBJctLL72EDh062KoWIiIiIgAWBJQXLWbzvC5dulhcDBERERFgQUDp1q1bvncqCAIMBoNVBRERERHlO6BcuXLFnnUQERERmeQ7oAQGBpr+PyYmBomJiRgwYEC2+33zzTcIDAw0uz8RERGRJaxaSXbKlCm4c+dOjrfdu3cPU6ZMKVBRRERE5NysCihnz55F/fr1c7ytbt26OHv2bIGKIiIiIudmVUARBAGPHj3K8bbk5GROkCUiIqICsSqgNGrUCIsXL4YkSWbbJUnCkiVL0KhRI5sUR0RERM7JqoXaPvroI7Rq1Qovv/wyIiIiULp0ady8eRPfffcdzp8/j71799q4TCIiInImVgWUV155BTExMRg/fjwmTJgAo9EIURRN2xs3bmzrOomIiMiJWL3UfdOmTXHw4EGkpaUhOTkZ3t7ecHd3t2VtRERE5KQKdC0eAHBzc4Obm5staiEiIiICYOUkWSIiIiJ7KvAIii3odDosXboUJ0+exOPHj+Hr64vw8HC0aNFC7tKIiIhIBooIKAaDASVKlEBUVBT8/f0RFxeH6dOnw9/fH1WrVpW7PCIiIipkijjE4+rqit69e6NUqVIQBAHVq1dHtWrVEBcXJ3dpREREJANFBJTnpaen4+LFi7zgIBERkZNSxCGefzIajZg/fz6Cg4NRp04ds9uSkpKQlJRk+loURZQsWdKmz69Sqcz+dVSCIDj098g+Ogb20TE4Qx/ZQ9sTpOfXq5eRJElYvHgxEhMT8dFHH2U7fXnZsmX48ssvTV9HREQgMjKysMskIiIiO1NMQJEkCUuXLsXFixfx8ccf57joW2GNoHh5eSElJcWhL3ro4eGB1NRUucuwG/bRMbCPjsEZ+sgeWsbHx+eF91HMIZ5ly5YhPj4eUVFRua5I6+vrC19fX9PXSUlJdvtlNxgMDvtCAp4FQkf+/rKwj46BfXQMjtxH9tD2FBFQ7t69i+3bt0Oj0WDgwIGm7d26dUN4eLiMlREREZEcFBFQ/Pz8sHXrVrnLICIiIoVQ5GnGRERE5NwYUIiIiEhxGFCIiIhIcRhQiIiISHEYUIiIiEhxGFCIiIhIcRhQiIiISHEYUIiIiEhxGFCIiIhIcRhQiIiISHEYUIiIiEhxGFCIiIhIcRhQiIiISHEYUIiIiEhx1HIXQERE5IgePXqEgwcPQq/Xo3HjxvDz85O7pCKFAYWIiMjGLl68iI4dOyI5ORmCIMDFxQXr1q1Dw4YN5S6tyOAhHiIiIht755138ODBA+j1euh0OqSmpqJ///4wGAxyl1ZkMKAQERHZkCRJOHfunFkYkSQJSUlJuHv3royVFS0MKERERDYkCAKKFSuW4/bixYvLUFHRxIBCREQ2odPpcOTIEezfvx/JyclylyOrKVOmQBT/9xarUqkwcuRIuLu7y1hV0cJJskREZBVJknDq1Cncvn0bvr6+GDNmDM6dOwdBEODp6Yk1a9agcePGcpcpi4iICBQvXhyrVq2CXq/HW2+9hQEDBshdVpHCgEJERBYzGAx49913sXnzZqjVauj1etOIgSRJePLkCfr06YNTp07leLjDGXTu3BmdO3eWu4wii4d4iIjIYitWrMC2bdsAAHq9HgBgNBpNt0uShEePHuHKlSuy1EdFHwMKERFZ7PfffzcFk7x4eXkVQjXkiHiIh4iILObj4wOVSpXruh4ajQbt2rVDuXLlCrkychQcQSEiIou98847UKvVpnknGo0GJUqUQGhoKIKDgzFkyBAsX74cgiDIXCkVVRxBISIii1WpUgU7duxAVFQUbty4gdDQUEyfPp3XmyGbYUAhIiKr1KxZE+vWrZO7DHJQPMRDREREisOAQkRERIrDgEJERESKw4BCREREisOAQkRERIrDs3iIiJzM2bNnceDAAWi1WnTo0AGlSpWSuySibBhQiIicyObNm/Huu+9CrVZDkiTMmDEDP/74I6pXry53aURmeIiHiMhJpKamIjIyEgaDARkZGcjMzERqaipGjhwpd2lE2TCgEBE5iZs3byIjI8Nsm8FgwMWLF2WqiCh3DChERE6iZMmSOV4bh8vTkxIxoBAROQlvb29MmDABoihCEASIoghRFDFz5ky5SyPKhpNkiYicyNixY1GxYkXExMTAxcUFPXv2RP369eUuiygbBhQiIifTuXNndO7cWe4yiPLEQzxERESkOAwoRERUpMTExOCNN95A06ZNMX78eDx58kTuksgOeIiHiIiKjD179qBXr14wGo0AgCtXruDs2bPYunUrVCqVzNWRLXEEhYiIioy5c+eawgkA6HQ6HDlyBMePH5exKrIHBhQiIioyHj58mG2bSqXCo0ePZKiG7IkBhYiIioymTZtCo9GYbVOpVAgNDZWpIrIXBhQiIioypk2bhrp16wJ4Fky0Wi2WL1/OKzI7IE6SJSKiIsPDwwNbtmzB8ePH8ejRI4SGhjKcOCgGFCIiKlJUKhUaNGggdxlkZzzEQ0RERIrDgEJERESKw4BCREREiiNIkiTJXYS1UlJS4OLiYtN9CoIArVaLzMxMFOEfzQup1Wro9Xq5y7Ab9tExsI+OwRn6yB5aJj/v3UV6kmxmZiYyMzNtus+s09ZSU1NhMBhsum8lKVasGB4/fix3GXbDPjoG9tExOEMf2UPL5Ceg8BAPERERKQ4DChERESlOkT7EQ0REypWSkoLLly/Dz88PPj4+cpdDRQxHUIiIyOZ27tyJGjVqoF27dqhVqxYiIiIcdv4J2QcDChER2VRiYiIGDhyI9PR007Y1a9Zg8eLFMlZFRQ0DChER2dTRo0chCILZNp1Oh19++UWmiqgoYkAhIiKbcnd3h9FozLbdw8NDhmqoqGJAISIim2revDnKlCkDjUZj2iYIAt555x0Zq6KihgGFiIhsysPDA9u2bUNYWBhKlCiB4OBg/PDDD2jdurXcpRUKSZKQnJwMg8EAo9GIY8eOYffu3bh586bcpRUpPM2YiIhsLi0tDR07dkR4eDjatWuHihUrIjk5We6y7G7//v0YPHgwkpOTodFoEBgYiIsXL0KlUkEQBCxatAhdu3aVu8wigQGFiIhsaufOnRg4cCBEUYTRaIS3tzcOHTqEl156Se7S7Ory5cvo2bOn6RIsOp0OFy9eBADTKdYjRoxAvXr1UKFCBbnKLDJ4iIeIiGwmNTUVQ4YMgU6nQ0ZGBnQ6HZKTk9G/f3+5S7O7X3/9NdvZS88TRRGnTp0qpIqKNgYUIiKymWvXriEtLc1sm16vx+nTp2WqqPCI4ovfUg0GA4oXL14I1RR9DChERGQzvr6+OW4vWbJkIVdS+Nq2bQtRFLMFlaxRFY1Ggxo1auCVV16Ro7wihwGFiIhsxtfXF8OGDYNKpQLw7M1ZEATMmTNH5srsLyAgABs2bEDp0qUBAMWKFcOoUaPQuHFjhISEoEePHti8eTO0Wm3nATsAACAASURBVG2+9pecnIwzZ844xeTinHCSLBER2dRHH32EypUrY9euXXB1dcWAAQPw1ltvOcUbbcOGDfHnn38iIyMDWq32hXNScvPVV19h8uTJMBqNEEUR06dPx9ChQ21crbIxoBCRokmShA0bNuDgwYMoVqwY+vTpg0qVKsldFuVBEAT069cP/fr1AwDTaIozcXFxsfqxBw4cwKRJkyBJEgDAaDRi6tSpqFKlClq2bGmjCpWPAYWIFG3s2LFYuHAhJEmCSqXCV199hR07diA0NFTu0ojsYt++fVCr1dDpdKZtarUa+/btc6qAwjkoRKRYly5dwrx580wrcup0Ouh0OkyePFnu0mRjNBqxdetWzJ8/Hxs3bjR7EyPH4Orqmu3QkCAIBRqVKYo4gkJEinX9+nUIgmAa6gaenaZ57do1uz6vJEl4/PgxihUrZvUcAnswGo2IiIjA7t27oVKpYDAYEB0djU2bNuV74iUpX5cuXbBgwQLTQneiKEIQBHTv3l3u0goVR1CISLEqVqyYbZtarUZISIjdnnPdunUIDAxEpUqVUKVKFfz66692ey5Lbd68Gbt374Zer0dGRgb0ej2OHz+O6OhoAM/C29GjR7Fr1y5e96UIq1ixIrZu3Yrq1avDy8sL1apVw5YtW5xu7hVHUIhIsQICAjB79mxMmDABWq0WkiTB09MTs2bNssvzHThwACNHjjSN2CQnJ6N3797Yt28fgoOD7fKcljh//jxUKhX0er1pm8FgwMWLF/H06VP07NkThw4dMl33ZcmSJejcubOMFZO16tSpo6hwLAcGFCKym6tXr+L69euoUKECypYta9U+PvjgA1StWhWHDh2Cp6cnunTpYrdFv3788UeIomi6bgrwbHXQ3bt3KyKglClTBkaj0WybWq1G6dKlMXPmTBw9ehTA/677Mnz4cNSvXx8BAQGFXitRQfEQD5GTi4+PR7t27VC+fHnUq1cPO3fuLPA+JUnCxx9/jPr166NTp06oU6cOFi1aZPX+mjVrhrFjx2Lo0KGmcPLkyRPcu3fPbH6Kkhw6dAj//e9/sXDhQpvNmQkPD0dISAg0Gg0AQKvVolSpUhg8eDAOHjyY44RZZ1hinhwTAwqRE7t37x7+9a9/4fTp00hLS0NiYiL69++PQ4cOFWi/W7duNQskkiRh+vTpOHDgQEFLhk6nw6hRoxAUFITq1aujUaNGuHDhQoH3CwAdO3bMNkJhNBrRvn17i/azYsUKdOrUCQsWLMDs2bMRFhaGs2fPFrg+V1dXbN++HePGjUOPHj0wcuRI7NmzB15eXvD29s42oZfXfaGijAGFyInt2rULqampZoc0JEnC6tWrC7TfQ4cOZXuz1Gq1OHz4cIH2CwCffPIJNmzYYPo6MTER3bp1y3aBOms0a9YMS5YsgaenJ4Bny7Z///33qFy5cr73cf/+fdMiW5mZmcjMzER6ejrGjBlT4PoAwN3dHWPGjMGiRYswceJEUwAZM2aMaVl54Nl1X+rUqYNGjRrZ5HmJChsDCpETy8zMzBYkJElCenp6gfbr6emZ7YJpWRNcC2rLli1mhzIMBgNu3ryJ+Pj4Au8bALp164bLly8jISEBcXFxaN68uUWPv3btWrZRGIPBgCtXrtikvtw0a9YMGzZsQOPGjVG1alX06tULGzduhFrNqYZUNPE3l8iJNWvWzGz0BHi2LLmlhzSe16tXLyxfvhxGoxEGgwFqtRru7u7o0qVLgfabVV9O8nOp+/wSBAEeHh5WPbZMmTLZ1m4RRRHlypWzVXm5CgsLQ1hYmN2fh6gwcASFyIkFBwdjxYoVcHNzA/Dsjfm9995DeHh4gfZbqVIlbN++HfXr10eZMmXQpEkT7Ny5E6VKlSpwzX369DEbFchaF6VatWoF3rct+Pn5YdKkSRAEAWq1GhqNBmq1Gp9++qncpZGdbd68GR07dsRrr72GhQsXZgv/ZBmOoBA5uQ4dOuCvv/7CjRs3ULJkSXh7e9tkvzVr1sS2bdtssq9/GjlyJNLS0vDFF18gIyMD9evXx/Lly01ntijB+++/j2rVqmHfvn1wc3NDjx497Lq4HMnvm2++wfDhw02H906ePInExER89tlnMldWdAmSUs/Ry4ekpCSb71OlUsHHxwfJyckOnX6LFSuGx48fy12G3bCPjiGvPkqSBEmSbHpoRy757aPRaMTnn3+O1atXQ5IkdOvWDWPHjlX8PBNneD2Ghobizp072bbHx8ejRIkSMlRkW7buoa+v7wvvo+zfaiKiXPzzjBVnMWPGDCxZssS0kuyCBQvw4MEDzJ49W+bKKCUlJcftycnJDhFQ5FD0P3pQkXHv3j38/PPP2Lt3L54+fSp3OURFitFoxNKlS82WudfpdIiOjkZGRoaMlREA1K1b12wkSxAEeHt7cxXfAuAIChWKgwcPonfv3sjIyIDRaERgYCC2bNmC0qVLy10aUZGg1+tzXCk267RwFxcXGaqiLF9//TXatGmDW7duQRAEuLi44LvvvuNVpguAAYXsLj09Hf3798fTp09Np15eu3YNERERGD9+PKpWrWr1dVqInIVWq0WtWrVw5swZ0yiKSqVCUFAQV4tVgMDAQMTGxuLw4cPQ6XSoV68e/Pz85C6rSOMhHrK7xMREPHr0yGxdiKzLxPfq1Qv169fHunXrbPJcBoMhx0+ZRI7g66+/NltPpVSpUli1apWMFdE/eXh4oG3btnj99dcZTmyAIyhkd3l9ujMajTAajRg1ahTq1atnWlL85MmT2L59OwDg9ddfR+3atfN8jszMTEyaNAmrV6+GwWDAK6+8gk2bNnF4lWwiMTERd+7cQcWKFfHSSy/JVkdAQABiY2Nx7tw5GI1GVK9e3bSGDZGj4QgK2Z2/vz/efvvtPE+FVKvVOHHiBADg559/xquvvopFixZh0aJFePXVV01hJTcfffQR1qxZA71eD0mScPToUXTo0CHbkuNEljAajRg3bhzq1auHDh06IDQ0FOvXr5e1JhcXF9SpUwf16tWzeziRJAk///wzli5dih07dvD1RIWKIyhUKObNm4cKFSpgx44dSExMRHJystntBoMBXl5ekCQJkZGRMBgMZufaR0ZG4tKlS7meVrp+/XqzQzs6nQ7Hjx/HtWvXCmWJcXJM3377rdmFE/V6PSIjIxEaGqqYlWvtxWg0YtCgQdixYwc0Gg10Oh1at26NlStX5nq5ASJb4ggKFQq1Wo2xY8fil19+werVq6FSqcyuulqpUiW0aNECT58+xcOHD7M9/vHjx3kuZJXbJztn/sSXkJCAhQsXYs6cOTh27Jjc5RQ6SZJw7969HH+f8mvfvn1mp/UCzyar/v777wUtT/E2btyInTt3wmAwID09HQaDAXv37sWaNWvkLo2cBAMKFboGDRpg06ZNaNSoESpWrIjXXnsNW7duhaurK9zd3XNcar1YsWIoVqxYrvvs1KmT2VLnarUaoaGhKF++vF2+B6U7ceIEwsLCMHv2bMybNw+vv/66zSYiFwZJknDw4EGsXbsWhw8ftvjxt27dQps2bVC9enUEBwejR48eVq24m9NVmQ0GA9zd3S3eV1ETFxeX4xWp4+LiZKqInA0DCsmiSZMm6NGjB27cuIEff/wRDRo0wK5duyAIAhYuXAhRFKHRaKDRaCCKIhYuXJjnqqFRUVHo1KmT6T6BgYH4+uuvnXYoeuTIkcjMzERmZiYyMjIgSRJGjx6NJ0+eyF3aCxmNRgwePBhdunTBmDFj0LRpU3zwwQfI71U5JElCr169zN5IDxw4gNGjR1tcy4ABA8xWrFWr1ShRokSBr/ZcFPj7+2fbJopijtuJ7IEBhWSxd+9ejBkzxrQC5uPHj9G3b18sXLgQK1euRIMGDdCmTRsMHz4cO3bswJtvvpnn/lxdXbFgwQK8+uqrAIArV66gSZMm+P777+3+vShRQkJCtsNbOp0Ot2/flqmi/Fu9ejW2b98Oo9FoClfR0dH4+eef8/X4u3fvmq0VAjz73nfu3JnvkJOlXr16WL9+PWrUqIGSJUuiWbNm2LFjh80uqKhkvXv3RtmyZU0jkxqNBn5+foiIiJC3MHIanCRLssjprByj0YiPP/7Y9LUoimjatCnq1q2br30uXrwYMTExpn0ZjUZERkaidu3aCA4OLnDN165dw/vvv4+zZ8+iZMmSmD59Olq1aoUnT57Azc3NbqM1O3bswPLly5GWlob27dtj1KhRL7w4XJkyZZCQkGD2hlxUPv2eOnUqW7jSaDQ4deoUXnvttTwfazAYMGfOnBxvs/aigmFhYfj111+temxR5unpid27d2PhwoW4dOkSgoKCMGrUKC4KR4WGAYXsLqerzoqi+MJPs0ajEVFRURgyZEi+3lwOHDiQbZE2jUaDY8eOFTigPHr0CB06dEBSUhL0ej3u37+PHj16oFSpUrh16xbUajXef/99jB8/3qYXsPvhhx8wdOhQ08/q1KlTuHjxIpYsWZLn4+bMmYPw8HAIggBJkmAwGDB9+vQ85/EoxUsvvQSVSmUWUiRJytf6I/PmzcPKlSuzbVer1ejZs6dTXFwwMTERq1evRkpKCho2bGh26NNSxYsXx9SpU21coePR6/VYuXIlzp07h4CAAISHh/PSAzbAgPKcjIwMJCYmQqvVmj6lrl+/HitWrEBGRgY6dOiA0aNHK/7y5rkxGo24fPkyVCoVSpcuDVdXV7s9V2ZmJqZMmYLVq1fDaDSiVatWWLx4MU6cOIF9+/blax8ZGRlIS0uDJEk4efIkVCoVatWqleP6D97e3qY35CwGg8Emb8q7d+/G/fv3zQ4bSJKEW7duAXj2B2revHnw9fXFoEGDCvx8WWbMmGH2/eh0Oqxfvx6TJ0/O8/IAYWFh2L17NzZu3IiMjAy0adMGbdq0sei5Hzx4gJEjRyI2Nhaurq4YMWIERo4cafc3+YiICERHRyMlJQV6vR4ajQb+/v7o3r37Cx+7du3abGfdAECHDh3MRucc1fnz5/Hqq6+arnkVHR2NY8eOISoqSu7SHJbBYMDbb7+NQ4cOmf7+rFy50jTxn6xXNN9l7WT27Nn47LPPTF9PmTIF3t7eGD9+vOnTXHx8PBITE/H555/LVabVHj16hF69euHIkSMAnk2CW7duHWrUqPHCx27cuBE//fQTNBoNevbsiZYtW+Z4P6PRiJiYGCQmJmLv3r345ZdfTG8Ye/fuRadOnfDXX3/l6/RfURRRpkwZJCYmomvXrkhKSgIAlC9fHps2bcp2hs6wYcPw008/wWg0QpIkaLVaBAQEoFWrVi98rhdJS0t74SiOwWDA//3f/+U7oFy8eBFDhw7FuXPnULx4cUybNg29evUyu8+jR49yfGxycvILr18UGhqK0NDQfNXyPIPBgPDwcJw7dw46nQ5Pnz7FJ598Aq1Wi3fffdeqfeZXqVKlsGfPHsyaNQsJCQmoVasWxo4dCy8vrxc+Nrffq1GjRjnFqsLTpk1DWlqa2RpCy5YtQ79+/RASEiJjZY5rw4YNOHjwoFkwPnPmDKKjozFs2DAZKyv6BMnSWWMKkvWGZQvr1q1DZGRktu1eXl5ISUnJtj0uLg6+vr42e/68PHr0CEePHgUANGzY0PSH+vTp04iLi4O/vz+aNWv2wjkQgwcPxvbt202HQURRhJ+fH44dO5bnH+958+Zh1qxZMBqNpk/Py5YtQ+fOnc3uZzAYMGDAAOzatQsajQbp6ek57u/5UQ4AphEpjUZjeqG7ublhw4YNGDx4MG7cuGH6o6tSqfDyyy9j165d2fZ96NAhfPLJJ7h79y78/f1RuXJllC5dGv369UOpUqXy/Pnk5fz582jevLnZH/6c1KtXDzt37nzh/h4+fIhXXnkFycnJpn0KgoDo6Gi88cYbpvuFh4cjNjbW7NCVp6cnzpw5Aw8PDxQrVsyq02dfJC4uDs2bN8+2PTAwEH/88YfNny83KpUKPj4+Zj+nvERFRWHJkiWmn5dKpULZsmVx6NAhRQ+526qPjRo1wuXLl822iaKINWvWWDyCZkuW9rEomTlzJhYtWoTMzEzTNlEU0a9fP3z66acyVmZbtu5hft4/eRbP32bNmpXj9tz+aOT2ydbWzp49i0aNGqFPnz7o06cPGjdujPj4eMyZMwdt2rTBmDFjEB4eju7du5u9QHLy66+/mr3RGY1G3L59G1evXs31MampqaZwAvxvPsmkSZOy3XfNmjXYvXu3aWGn3DwfTlQqlemN+OjRo6Yl7g8fPoyAgAAkJiaavSAMBgNOnDiR41B+kyZN8OOPP6JRo0b4448/sHbtWsyfPx9hYWG4du1a7j+cFwgJCcl29oKLi4tZKFSpVOjRo0e+9nfgwAE8fPjQ7PvKGhoGgNjYWLzyyis4fPgwBEEwnXbt6uqK6OhoeHh4WP295Eduv0sv+h2T24QJE8zmmlSuXBkbNmwA8GzEqiicxZTFYDBg7ty5aN68OVq3bo1vv/32hfO2QkJCsh1+NhqNqFChgh0rdW4BAQE5fuAKCAiQqSLHwYDyt6zTXZ+XtRZHFkEQ4OPj88Jfvqw3/wcPHhSorv79+5veyAwGAx48eIC3334bs2fPhiRJpmPNv/32GxYtWpTnvnI7HprX9TySk5NzHDZ/8OBBthfluXPn8vwDqlar4evra/bzBJ79TMeMGYNKlSrB398fXbp0QZcuXeDn55fnG3Fu10Q5duwY1q1bB71eb7q68ZMnTwp0HH7Hjh34+uuvzb4XHx8fBAYGAnj2ezJu3Lh8n4Kp1+tznMuh0+lw+vRpdO/eHZcuXUJ6erppHsasWbNw9OjRXA+vAc8CxK5du/D999/j3LlzFn2P/xQSEgI/Pz+zAKbRaEyncSuVRqPBnDlzcO3aNVy6dAmxsbF48OABatWqhVdeeQU1a9bEO++8o/igBQAffvghPv30U8TFxeH06dOYMGECFi9enOdjoqKi4OXlBa1WCxcXF4iiiA8++ACVKlUqpKqdT3h4OGrWrAmtVguVSgWtVovAwEAMHDhQ7tKKPAaUvzVs2DDH7W3atEG5cuUgCAJUKhU8PT2xatWqPA+JJCQkoGnTpqhZsyaqVKmCvn37IjU11eKaUlJScPXq1WyjB9evX8/2/FnXnsnLsGHDsr3htGrVKs+5DP7+/tkmmapUKgQHB2d7g33+DQ2A2X2qVauGnTt3mg01q9VqLFiwwPRG/zw3NzeEhYXleNu2bdty3H7t2rVsIUiv1yMhISHH++fHihUrzMKXXq/HvXv3EBUVhatXr+L69esYN25cvieQNm7cGGq12uz+KpUKb775pmnF16zny5pTk5qamudhqidPnuD1119Hv379MG7cOLRs2RJffvmlNd8u3NzcsH79erNLxrdp0wbTp0+3an+FzcXFBV5eXnj06BF69Ohh9kHhp59+ynXEVCmePHmC6Ohos1HCrBGVvAQGBuLAgQOYPHkyIiMjsWbNGowfP97e5To1rVaLLVu2YMaMGejXrx8mTJiAXbt2wdPTU+7SijzFBJQnT55g9uzZ6NGjByIiIrBly5ZCff4mTZrkuP38+fNYtGgR3nnnHQwbNgx79+7NNcwAz964wsPDceXKFdO2mJgYTJw40eKa3N3dc5xXolarsx0DVKlUZm8mORkxYgSmTZuGsmXLws/PD926dcPXX3+d55uqRqPBV199ZfpEptVq4enpiaVLl2a7b0REhNkIiUajQfny5XHy5EnEx8cjJiYGgYGBWLZsGRo1agTg2c9r4sSJOHjwYK419OzZM8cJqs+HkCwVK1bM9glZo9FYfarxqVOncOnSpWzbRVFERkYG3N3dLV5jQxRFDBw40DSqJQgChg8fjoiICGRmZmYbtRIEIddRviyffPIJ4uLiYDAYTAucTZkyBefPn7eotizVq1fHsWPH8Pvvv+P06dNYuXKl3a+ea2unTp1CSkpKtjOhVq9eLctcCEmSkJKS8sLnzm3F39TU1BdOMPfz88Pw4cMxceJEWeedOBNXV1eMHDkS//3vfzFq1CiGExtRTEBZtmwZdDodoqOj8Z///AcbNmwo1Auc5bR2AgBcunQJb775Jr777jssW7YMHTt2zPM49tWrV3HlyhWzP0A6nQ47duywuCa1Wo333nsv2zyH0aNHIyQkxPQGnTWsOGLEiDz3l/Um+OeffyIxMRELFy7M1wupdevWiI2NxcyZM/Hpp5/i4MGDOZ4d4uPjg5iYGAwcOBDt2rXDO++8g19++QVlypRBiRIlTEHo448/Nhvtefz4MXr37p3tCsdZWrVqBS8vL7OfgyAI2c54yVKrVi0MHTrU9HPRarV46aWXMGXKlBd+r8/bunUr2rVrZzqd+J9UKhXq169v8T7j4uLQtGlTfPnllzAajVCr1Vi+fDmmTZsGQRDQunXrbI/R6XRo0aJFnvs9duxYtnVg1Go1zp49a3GNWTQaDSpWrFigCcZycnFxyfGw44MHD9C7d2+LV5YtiJMnT6JOnTqoVKkSypUrh/nz5+f6/H5+fihdurRZ8FWr1ahTp47VC84RFTWKOIsnPT0dvXr1wrx580xD/StXrsSNGzfyHHmw5Vk8FStWzNcseo1Gg/bt2+Obb77J8farV6/m+KZVokQJxMfHW1yXJElYsWIF1q9fD0EQ8Pbbb6N///6mEac///wTZcqUwQcffGDRCIG9zv7Ij5zONBAEAZs2bUKzZs1yfExcXByGDBmC8+fPw9vbGx999BHefvvtXJ9DFEXExsZi//798Pb2Ro8ePeDj42NRnZmZmahcuTLS0tKy3ebp6YlvvvnmhaEhJ61atTKNdGRxd3dHfHy8aUTl888/x8cffwxJkqDRaDBv3rwcJ+D+s499+/bFrl27zD5hi6KIDRs25HqYTOkKeuZAZmYmqlatmuPvuiAI+L//+7885/TYSlJSEho1aoQnT56Y+iOKIubNm4devXrl+Ho8ffo0unXrZgruAQEB+OGHH4rkBTAd+SyeLHL+TS0McpzFo4h1UG7cuAFJkszmIQQFBWW7imlSUpJZKBFFESVLliy0OoH/TWLM7ZTeoKAgNGjQAH/++afp06xGo0FERITVS6EPHToUQ4cONdvm7e2NmTNnWrU/AKY5NXLIadRGkiR4enrmWlNoaCgOHToESZLyNc9DpVKhY8eOaNmypdUvpvv37+cYTkRRRFxcnNVn0ly4cCFbTU+fPsWdO3dQsWJFAMD777+PiIgI3L59G2XLls11sbl/9vHDDz/Enj17TBOqNRoNGjRogLCwsCJ70cSsuq2t383NDQ0bNjRdAuH5fd+8ebNQfja//fYb0tLSzMKj0WjEpk2b0Ldv3xxfj7Vr18bx48dx4sQJqNVq1K1bt8gdYstS0D4WBXL+TS0McvRQEQElPT092+XLPTw8sr05bNy40WzSX0RERI5rl1ijQoUKOH369AvvJwgCypUrl+en8R07diAiIgK7d++GRqPBsGHDMHPmTMX98sq1cNXEiRPRp08f0x9rrVaLmjVromXLljZfoTc/i3vlxs3NDRqNJtthk9KlS6NcuXJW79fPzy/bKc+CICA4ONisXh8fHwQFBb1wf1l9bN68OY4cOYKZM2fizp07aNq0KaZMmeIQq1kWpI+9evXCnj17sh1OMRgMqF27tsUja9bILWBqNBrT8+f0evznmWKOoCB9LAqcYTHAwuyhIgKKq6trtjDy9OnTbJ8WunbtajakLopirvMWLDVmzBgMGDAg2/ZmzZrht99+g16vhyiKEEURU6dOzfN5RVHEd999Z7Ytp8Xe5OTh4WHVmUW28Nprr2Hx4sWYM2cOUlJS0LRpU8yZM8emw6Mqlcq0yF5BhiNnzpyJDz74AKIoQhAEGI1GzJkzp0C/dzNmzEBERITZNYomTJgAg8Fg8X6f72P58uXxxRdfmL5OS0vLcRSoqLBFHzt16oSjR4+aTewWRRF9+/ZFzZo1bfY3JC+1atWCh4cHHj9+bPo+RFFE165dkZycLOvrsTDY6vWoZOyhZfLzwUBRc1Dmz59vOr66atUqXL9+vdDmoADPjvtHRUXBaDRCFEVERUVh0KBBWLFiBQ4ePAgvLy8MGjQItWrVsunzyoHHS/Nvz549+Pnnn6FWq9G1a9d8X105LwcPHsSaNWuQkZGB1157DV27drXqGjfsY/5dv34dq1atgsFgQN26dfHaa68V6sUDz5w5gwEDBiAhIQEuLi6YPHmyaSl09rHoYw8tk585KIoIKMCzq6+mp6dj9OjRuHfvHqZOnYr33nsP9erVy/Uxtg4owLNPNSqVCgaDIV/Xiymq+GJyDOxj0ZOWlgZXV1ezcMQ+Fn3soWWK1FL3WaeFRkREYNq0aejatWue4cReBEFA8eLFneKy7ERU+Nzc3Pj3hSgfFDEHBXh2Zoc1i5kRERGR41HMCAoRERFRFgYUIiIiUhwGFCIiIlIcBhQiIiJSHAYUIiIiUhwGFCIiIlIcBhQiIiJSHAYUIiIiUhwGFCIiIlIcBhQiIiJSHAYUIiIiUhzFXM1YKZKSkrBx40Z07do1X1dbJGViHx0D++gY2MeiT44ecgTlOUlJSfjyyy+RlJQkdylUAOyjY2AfHQP7WPTJ0UMGFCIiIlIcBhQiIiJSHNV//vOf/8hdhNK4ubmhfv36cHd3l7sUKgD20TGwj46BfSz6CruHnCRLREREisNDPERERKQ4DChERESkOGq5C1CSJ0+eYPHixTh+/Djc3NzQuXNnvPXWW3KXRbnIb7/++usvrF27FhcvXgQAVKlSBYMHD0aZMmUKu2TKgTWvu5iYGCxYsADDhg3D66+/XkiVUl4s6WNmZia+/fZb7N+/H5mZmShTpgxmzJjB+Skys6SHsbGxWLt2LZKSkuDt7Y2uXbuiffv2Nq2HAeUfli1bBp1Oh+joaNy9exdTp05FuXLlUK9ePblLoxzkt1+pqalo27Ytxo8fD61W1NRJYAAAB/dJREFUi9WrVyMqKgpLliyRqXL6J0tfdykpKdiwYQPKly9fyJVSXizp45IlS5Ceno6FCxeiePHiuHr1KjQajQxV0z/lt4f37t3D3LlzMXHiRDRo0ADx8fGYNm0aKlWqhEqVKtmsHh7i+Vt6ejoOHjyIvn37wt3dHRUqVED79u2xe/duuUujHFjSr3r16iEsLAweHh7QaDTo1KkTrl+/jpSUFBkqp3+y5nUXHR2Nt956C15eXoVYKeXFkj5ev34dhw8fRmRkJHx8fCCKIoKCghhQZGZJD+/duwcPDw80bNgQgiCgatWqKFeuHBITE21aEwPK327cuAFJkhAYGGjaFhQUZPMfONlGQfp15swZ+Pj48A1OASzt45kzZ3Dt2jWbDyVTwVjSxwsXLsDPzw/r1q1Dnz59MHz4cOzataswy6UcWNLDKlWqoGzZsjh8+DCMRiPOnTuHO3fuoEaNGjatiYd4/paenp7t+KeHhwfS0tJkqojyYm2/bt++jWXLlmHIkCH2LI/yyZI+6nQ6LF26FKNHj4Yo8rOVkljSx3v37uHq1ato2LAhoqOjkZCQgGnTpqFMmTIIDQ0trJLpOZb0UKVSoXXr1pg/fz4yMjIgCAKGDRsGPz8/m9bEgPI3V1fXbI14+vQp3NzcZKqI8mJNv+7du4epU6eia9euCAsLs3eJlA+W9HHTpk0IDQ216TFusg1L+uji4gJRFPH2229Do9EgODgYTZs2xdGjRxlQZGRJD0+cOIHo6Gh89NFHCAkJwfXr1zF9+nT4+PigQYMGNquJAeVvZcuWBQAkJiaaJt9duXKFE/EUytJ+JSUlYcqUKXj11VfRqVOnQquT8mZJH0+ePImrV6/i0KFDAJ6dcXD58mWcP38e7733XuEVTdlY0scKFSoUZmmUT5b0MCEhAdWqVUPVqlUBAOXLl0f9+vVx7NgxmwYUjpP+zdXVFU2bNsXKlSvx9OlTXL16Fbt27UK7du3kLo1yYEm/7t+/j8mTJ6Nly5bo1q2bDNVSbizp44cffohFixZhwYIFWLBgASpXrozu3btj0KBBMlRO/2RJH0NDQ1GqVCmsX78eBoMBly5dwsGDB236xkaWs6SHwcHB+Ouvv3DhwgUAzyY+//HHHwgKCrJpTVzq/h+ePHmCRYsWmc4B79KlC9dBUbC8+hUeHo5///vfqFGjBtauXYu1a9fC1dXV7PGLFy9GyZIl5Sid/iG/fXzepEmTEBYWxnVQFMKSPl6/fh2LFi3CpUuXUKJECXTv3h1t27aVs3yCZT3csWMHtmzZguTkZHh4eKBly5bo06ePTeeHMaAQERGR4vAQDxERESkOAwoREREpDgMKERERKQ4DChERESkOAwoREREpDgMKERERKQ4DChERESkOAwoREREpDgMKERERKQ4DChEVWIUKFRAZGSnLc8+fPx/bt2+X5bmJyH641D0RFdiJEyfg4+Mjy5VqK1SogDfffBOLFi0q9OcmIvtRy10AERV9derUkbsEInIwPMRDRHmK+P927h4ktTCMA/j/IGkhkal1UiqQIDAciogaokNmJTRWW4PRVkMZRFsUQYkEDdlekA190NAQfSBtHvuiIWhoMRCijMohMBC6w+UKEiXXm3bk/n/b+3He53m3h/d9OS4XbDYb9vb2YLPZUFhYiMbGRsiynJzzt1c8giDA6/VienoaoijCaDRicHAQr6+vKfMikQgGBgZgNBpRVFSEtrY2nJ+fp8S9vb3F8vIyBEGAIAhYWVn55z0T0c9jgUJEad3d3WF4eBgTExPY2NiARqNBd3c3Hh4eMl7T5/Ph5uYGq6urmJqawvr6OmZnZ5Pjz8/PaG1txeXlJZaWlrC9vQ2tVgu73Z6Mu7Ozg4qKCvT19SEYDCIYDKKnp+ef90tEP49XPESU1tPTEzY3N2G32wEAkiShqqoKi4uLmJ+fz2hNk8kEv98PAHA6nbi4uMDW1hY8Hg+A349fX15ecHJygvLycgBAR0cHamtrsbCwAK/Xi4aGBmg0GoiiiJaWlm/YKREpBU9QiCitkpKSZHHyp+1wOBAKhTJes7OzM6VdV1eHSCSSbB8cHKC9vR16vR6JRAKJRAIqlQqSJOH09DTjuESUH3iCQkRplZWVfegTRRHX19cZr6nT6VLaarUab29vyfbj4yNkWUZBQcGHb2tqajKOS0T5gQUKEaUVjUY/9N3f38NkMmUtpl6vh9PpTHmX8odGo8laXCJSBhYoRJRWLBZDIBBIXvPEYjEcHR1hZGQkazEdDgfW1tZgtVqh1Wo/nadWqxGPx7OWBxH9DBYoRJSWXq/H0NAQZmZmoNPp4PF48P7+jrGxsazFHB8fh9/vhyRJGB0dRXV1NaLRKEKhEMxmM9xuNwDAarUiEAjg8PAQpaWlsFgsMBgMWcuLiHKDj2SJKC2TyQSfzwePx4P+/n7E43Hs7+9DFMWsxTQYDJBlGfX19ZicnERXVxfcbjfC4TCam5uT8+bm5lBZWYne3l40NTVhd3c3azkRUe7wV/dE9CWXy4WzszNcXV39dCpE9B/hCQoREREpDt+gENG3SiQSn44JggCVSpXDbIgoX/GKh4i+TTgchsVi+XRckiQcHx/nLiEiyls8QSGib2M2m7/8y2txcXEOsyGifMYTFCIiIlIcPpIlIiIixWGBQkRERIrDAoWIiIgUhwUKERERKQ4LFCIiIlIcFihERESkOCxQiIiISHF+AR7JDb6vSREOAAAAAElFTkSuQmCC\n"},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":["<ggplot: (8755291685417)>"]},"metadata":{},"execution_count":115},{"output_type":"stream","name":"stdout","text":["time: 223 ms (started: 2022-05-23 14:23:44 +00:00)\n"]}],"source":["# plot the control function vs the closed form (ideally straight line...)\n","mequation.pi_net.eval()\n","dataf = pd.DataFrame( { 'pi_net': mequation.pi_net(internal_sample).cpu().detach().numpy().reshape(-1).tolist(), \n","                       'closed_form': (((mu-r)/(gamma*(sigma**2)))*np.exp(-r*(1.0-time))).numpy().tolist() } )\n","ggplot(dataf, aes(x='pi_net', y='closed_form')) + geom_point()\n"]},{"cell_type":"code","execution_count":116,"metadata":{"id":"f85Kg2zvhMdM","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1653315847884,"user_tz":-60,"elapsed":281,"user":{"displayName":"Hans Roggeman","userId":"10574434403170915342"}},"outputId":"e2707cb2-9866-43a8-9fef-4cbd6cdd2211"},"outputs":[{"output_type":"stream","name":"stdout","text":["time: 2.85 ms (started: 2022-05-23 14:24:07 +00:00)\n"]}],"source":["idx_larger1_control = np.where((((mu-r)/(gamma*(sigma**2)))*np.exp(-r*(1.0-time))).numpy()>1.0)[0].tolist()"]},{"cell_type":"code","source":["pp(mu[idx_larger1_control])\n","pp(r[idx_larger1_control])\n","pp(sigma[idx_larger1_control])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iGXz_y0rIAn4","executionInfo":{"status":"ok","timestamp":1653315851785,"user_tz":-60,"elapsed":303,"user":{"displayName":"Hans Roggeman","userId":"10574434403170915342"}},"outputId":"d17f88a5-f95e-485a-960c-305c661f246f"},"execution_count":117,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([0.1835, 0.1920, 0.1508, 0.1515, 0.0745, 0.1357, 0.1305, 0.1764, 0.1735,\n","        0.1315, 0.1559, 0.1452])\n","tensor([0.1046, 0.0115, 0.0683, 0.0277, 0.0295, 0.0121, 0.0480, 0.0599, 0.1056,\n","        0.0353, 0.0587, 0.0107])\n","tensor([0.2113, 0.3447, 0.1266, 0.2224, 0.1145, 0.2849, 0.1299, 0.2141, 0.1036,\n","        0.1508, 0.2865, 0.3240])\n","time: 4.6 ms (started: 2022-05-23 14:24:11 +00:00)\n"]}]},{"cell_type":"code","source":["((mu-r)/(gamma*(sigma**2)))[idx_larger1_control]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"M6sB28tQIUe3","executionInfo":{"status":"ok","timestamp":1653315862776,"user_tz":-60,"elapsed":312,"user":{"displayName":"Hans Roggeman","userId":"10574434403170915342"}},"outputId":"d7f51448-b240-4f5d-a98c-2e58d22a7062"},"execution_count":118,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([1.7655, 1.5190, 5.1510, 2.5033, 3.4353, 1.5230, 4.8927, 2.5401, 6.3231,\n","        4.2336, 1.1838, 1.2808])"]},"metadata":{},"execution_count":118},{"output_type":"stream","name":"stdout","text":["time: 4.04 ms (started: 2022-05-23 14:24:22 +00:00)\n"]}]},{"cell_type":"code","source":[""],"metadata":{"id":"WIjQMdbnIjT-"},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":["BErSeefeQwQi","N-GO35FcJPP6","HrivvbmubiiY","RNhAbZ727RC_","leiCOWL89Mr5","CNsqOm1ithSG","wClW1g9rbm8o","8RRoBgFQINMv","hp4BG1ewKF6o","65nooklCbsdy"],"machine_shape":"hm","name":"DGM_HBJNNx_Par.ipynb","provenance":[{"file_id":"12X2KXaaeispO6TznFB-M85IhV1NDIolN","timestamp":1653171573057}],"authorship_tag":"ABX9TyPBIH+VbCzPJswr3KkQAK4d"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}