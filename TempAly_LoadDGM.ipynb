{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"TempAly_LoadDGM.ipynb","provenance":[],"collapsed_sections":["BErSeefeQwQi","Wmq1oI-yiTyF","N-GO35FcJPP6","HrivvbmubiiY","fyFbPZr7I5RE","RNhAbZ727RC_","leiCOWL89Mr5","CNsqOm1ithSG","wClW1g9rbm8o","hp4BG1ewKF6o","7zhOYawdgRKW","Ok58PL-Eif4f","LQuS9M6yif4g","3cFXznN2if4k"],"machine_shape":"hm","authorship_tag":"ABX9TyPiQt3Q8zwjK5OUmaH9ZQOj"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["### Setup packages "],"metadata":{"id":"BErSeefeQwQi"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"L8DGCgVxR2AB","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1653166482432,"user_tz":-60,"elapsed":20927,"user":{"displayName":"Hans Roggeman","userId":"10574434403170915342"}},"outputId":"8742acba-6fea-48c4-a2eb-ac5358a39dfa"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","time: 20.7 s (started: 2022-05-21 20:54:22 +00:00)\n"]}]},{"cell_type":"code","execution_count":3,"metadata":{"id":"3xIx5C6UQn4u","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1653166461510,"user_tz":-60,"elapsed":12382,"user":{"displayName":"Hans Roggeman","userId":"10574434403170915342"}},"outputId":"2edb6cef-1542-4dc2-d6f8-94968266f147"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting progressbar\n","  Downloading progressbar-2.5.tar.gz (10 kB)\n","Building wheels for collected packages: progressbar\n","  Building wheel for progressbar (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for progressbar: filename=progressbar-2.5-py3-none-any.whl size=12082 sha256=db19ebebc7a9061689aae4a3a8ad0e246ea647631aa6ac4980e77412c4d1e7ec\n","  Stored in directory: /root/.cache/pip/wheels/f0/fd/1f/3e35ed57e94cd8ced38dd46771f1f0f94f65fec548659ed855\n","Successfully built progressbar\n","Installing collected packages: progressbar\n","Successfully installed progressbar-2.5\n","Requirement already satisfied: plotnine in /usr/local/lib/python3.7/dist-packages (0.6.0)\n","Requirement already satisfied: mizani>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from plotnine) (0.6.0)\n","Requirement already satisfied: matplotlib>=3.1.1 in /usr/local/lib/python3.7/dist-packages (from plotnine) (3.2.2)\n","Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from plotnine) (1.21.6)\n","Requirement already satisfied: statsmodels>=0.9.0 in /usr/local/lib/python3.7/dist-packages (from plotnine) (0.10.2)\n","Requirement already satisfied: pandas>=0.25.0 in /usr/local/lib/python3.7/dist-packages (from plotnine) (1.3.5)\n","Requirement already satisfied: patsy>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from plotnine) (0.5.2)\n","Requirement already satisfied: scipy>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from plotnine) (1.4.1)\n","Requirement already satisfied: descartes>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from plotnine) (1.1.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.1.1->plotnine) (1.4.2)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.1.1->plotnine) (0.11.0)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.1.1->plotnine) (3.0.9)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.1.1->plotnine) (2.8.2)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib>=3.1.1->plotnine) (4.2.0)\n","Requirement already satisfied: palettable in /usr/local/lib/python3.7/dist-packages (from mizani>=0.6.0->plotnine) (3.3.0)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.25.0->plotnine) (2022.1)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from patsy>=0.4.1->plotnine) (1.15.0)\n","Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (1.11.0+cu113)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch) (4.2.0)\n","Collecting ipython-autotime\n","  Downloading ipython_autotime-0.3.1-py2.py3-none-any.whl (6.8 kB)\n","Requirement already satisfied: ipython in /usr/local/lib/python3.7/dist-packages (from ipython-autotime) (5.5.0)\n","Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython->ipython-autotime) (4.4.2)\n","Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.7/dist-packages (from ipython->ipython-autotime) (5.1.1)\n","Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython->ipython-autotime) (2.6.1)\n","Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from ipython->ipython-autotime) (0.8.1)\n","Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from ipython->ipython-autotime) (1.0.18)\n","Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython->ipython-autotime) (0.7.5)\n","Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from ipython->ipython-autotime) (4.8.0)\n","Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from ipython->ipython-autotime) (57.4.0)\n","Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython->ipython-autotime) (1.15.0)\n","Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython->ipython-autotime) (0.2.5)\n","Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect->ipython->ipython-autotime) (0.7.0)\n","Installing collected packages: ipython-autotime\n","Successfully installed ipython-autotime-0.3.1\n","time: 147 µs (started: 2022-05-21 20:54:22 +00:00)\n"]}],"source":["%pip install progressbar\n","%pip install plotnine\n","%pip install torch\n","%pip install ipython-autotime\n","%load_ext autotime"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"EfIU_eNp3Zio","executionInfo":{"status":"ok","timestamp":1653167878207,"user_tz":-60,"elapsed":2027,"user":{"displayName":"Hans Roggeman","userId":"10574434403170915342"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"e8681f2f-3ca5-4698-a414-215d4016cd5e"},"outputs":[{"output_type":"stream","name":"stdout","text":["time: 1.74 s (started: 2022-05-21 21:17:57 +00:00)\n"]}],"source":["from plotnine import *\n","from plotnine.themes import *"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"ZmUjYbArAuQT","executionInfo":{"status":"ok","timestamp":1653167880764,"user_tz":-60,"elapsed":2560,"user":{"displayName":"Hans Roggeman","userId":"10574434403170915342"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"8ef7ec73-bf5d-49e4-8dc0-ea40d7861800"},"outputs":[{"output_type":"stream","name":"stdout","text":["time: 2.59 s (started: 2022-05-21 21:17:59 +00:00)\n"]}],"source":["import tensorflow as tf\n","from scipy.io import loadmat\n","import random\n","import math\n","import tensorflow_probability as tfp"]},{"cell_type":"markdown","metadata":{"id":"PieVKPfHHYQ6"},"source":["_paper_name_ establishes the reusable name of the paper, it represents the directory under data_papers on the google drive"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"BI4p7ZKb0Qz2","executionInfo":{"status":"ok","timestamp":1653167892551,"user_tz":-60,"elapsed":361,"user":{"displayName":"Hans Roggeman","userId":"10574434403170915342"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"44ab9773-ecb7-4cad-90a2-a32b15f53835"},"outputs":[{"output_type":"stream","name":"stdout","text":["time: 979 µs (started: 2022-05-21 21:18:13 +00:00)\n"]}],"source":["paper_name = \"dgm_hjb\""]},{"cell_type":"code","execution_count":8,"metadata":{"id":"433z6V3T2rB2","executionInfo":{"status":"ok","timestamp":1653167895205,"user_tz":-60,"elapsed":923,"user":{"displayName":"Hans Roggeman","userId":"10574434403170915342"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"a71619d6-591e-427c-bf29-9a0c45170c5d"},"outputs":[{"output_type":"stream","name":"stdout","text":["time: 799 ms (started: 2022-05-21 21:18:15 +00:00)\n"]}],"source":["import os, sys\n","import errno\n","\n","# make a directory if it does not exist\n","def make_dir_if_not_exist(used_path):\n","    if not os.path.isdir(used_path):\n","        try:\n","            os.mkdir(used_path)\n","        except OSError as exc:\n","            if exc.errno != errno.EEXIST:\n","                raise exc\n","            else:\n","                raise ValueError(f'{used_path} directoy cannot be created because its parent directory does not exist.')\n","\n","# make directories if they do not exist\n","\n","make_dir_if_not_exist(\"/content/drive/MyDrive/data_papers/\")\n","make_dir_if_not_exist(f\"/content/drive/MyDrive/data_papers/{paper_name}\")\n","make_dir_if_not_exist(f\"/content/drive/MyDrive/data_papers/{paper_name}/model_features/\")\n","make_dir_if_not_exist(f\"/content/drive/MyDrive/data_papers/{paper_name}/model_checkpoints/\")\n","make_dir_if_not_exist(f\"/content/drive/MyDrive/data_papers/{paper_name}/model_history/\")\n","make_dir_if_not_exist(f\"/content/drive/MyDrive/data_papers/{paper_name}/model_finals/\")\n","make_dir_if_not_exist(f\"/content/drive/MyDrive/data_papers/{paper_name}/model_predictions/\")\n","make_dir_if_not_exist(f\"/content/drive/MyDrive/data_papers/{paper_name}/model_ccs/\")\n","make_dir_if_not_exist(f\"/content/drive/MyDrive/data_papers/{paper_name}/summary_results/\")\n","make_dir_if_not_exist(f\"/content/drive/MyDrive/data_papers/{paper_name}/summary_results/temp/\")"]},{"cell_type":"code","source":["# Set up the imports\n","from sklearn.model_selection import train_test_split\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","import pandas as pd\n","import numpy as np\n","\n","import site\n","import os\n","import tensorflow as tf\n","import pandas as pd\n","import h5py as h5\n","import matplotlib.pyplot as plt\n","import errno\n","import numpy as np\n","import itertools\n","import multiprocessing\n","import json\n","import datetime\n","import random\n","from collections import defaultdict\n","from sklearn.model_selection import train_test_split\n","\n","pd.set_option('display.width', 400)\n","pd.set_option('display.max_columns', 40)\n"],"metadata":{"id":"uat0pG8aR3Rh","executionInfo":{"status":"ok","timestamp":1653167897259,"user_tz":-60,"elapsed":2,"user":{"displayName":"Hans Roggeman","userId":"10574434403170915342"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"34199d1c-3793-497a-9fbd-0b10a6765910"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["time: 8.5 ms (started: 2022-05-21 21:18:18 +00:00)\n"]}]},{"cell_type":"code","source":["import torch \n","import matplotlib.pyplot as plt\n","import numpy as np\n","from torch.autograd import Variable\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","import matplotlib.pyplot as plt\n","from mpl_toolkits.mplot3d import Axes3D\n","from scipy.stats import norm\n","from matplotlib import cm\n","import pdb\n"],"metadata":{"id":"KpFjo3MkLus9","executionInfo":{"status":"ok","timestamp":1653167901668,"user_tz":-60,"elapsed":3122,"user":{"displayName":"Hans Roggeman","userId":"10574434403170915342"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"ef43159f-daff-4608-a736-176d6eef1eb3"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["time: 3 s (started: 2022-05-21 21:18:20 +00:00)\n"]}]},{"cell_type":"code","source":["import plotly.graph_objects as go\n","import plotly.express as px\n"],"metadata":{"id":"CbfN42gpGZhC","executionInfo":{"status":"ok","timestamp":1653167903496,"user_tz":-60,"elapsed":1830,"user":{"displayName":"Hans Roggeman","userId":"10574434403170915342"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"28ee78d4-d3cc-40e8-da26-0f947974cf37"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["time: 1.8 s (started: 2022-05-21 21:18:23 +00:00)\n"]}]},{"cell_type":"markdown","metadata":{"id":"Wmq1oI-yiTyF"},"source":["### Shared functions across models"]},{"cell_type":"code","execution_count":40,"metadata":{"executionInfo":{"status":"ok","timestamp":1653170466069,"user_tz":-60,"elapsed":5,"user":{"displayName":"Hans Roggeman","userId":"10574434403170915342"}},"id":"FN790TIziTyG","colab":{"base_uri":"https://localhost:8080/"},"outputId":"0890569f-7ad9-4596-bd31-d4259209b4a6"},"outputs":[{"output_type":"stream","name":"stdout","text":["time: 22.3 ms (started: 2022-05-21 22:01:07 +00:00)\n"]}],"source":["import pandas as pd\n","from pprint import pprint as pp\n","\n","def plot_report(train_instance):\n","        \n","    history_tl_cpu = [ x for x in train_instance.history_tl ]\n","    history_internal_cpu = [ x.cpu().detach().numpy() for x in train_instance.history_internal_cpu ]\n","    history_terminal_cpu = [ x.cpu().detach().numpy() for x in train_instance.history_terminal ]\n","    history_initial_cpu = [ x.cpu().detach().numpy() for x in train_instance.history_initial ]\n","    history_nonzero_cpu = [ x.cpu().detach().numpy() for x in train_instance.history_nonzero ]\n","\n","    obs_data = pd.DataFrame({\"Epochs\" : [ (x+1)*train_instance.hook_interval for x in range(len(history_initial_cpu))], \n","                             \"AvgLogLoss\": np.log(history_tl_cpu), \n","                             \"TerminalLogLoss\" :  np.log(history_terminal_cpu),\n","                             \"InternalLogLoss\" :  np.log(history_internal_cpu),\n","                             \"InitialLogLoss\" : np.log(history_initial_cpu),\n","                             \"NonZeroLogLoss\" : np.log(history_nonzero_cpu),\n","                             })\n","\n","    return (ggplot(obs_data, aes(\"Epochs\",\"AvgLogLoss\")) + geom_line() + geom_point(),\n","            ggplot(obs_data, aes(\"Epochs\",\"TerminalLogLoss\")) + geom_line() + geom_point(),\n","            ggplot(obs_data, aes(\"Epochs\",\"InternalLogLoss\")) + geom_line() + geom_point(),\n","            ggplot(obs_data, aes(\"Epochs\",\"InitialLogLoss\")) + geom_line() + geom_point(),\n","            ggplot(obs_data, aes(\"Epochs\",\"NonZeroLogLoss\")) + geom_line() + geom_point(),\n","            )\n","\n","def plot_activation_mean(train_instance):\n","    \n","    # pdb.set_trace()\n","\n","    if train_instance.debug == False:\n","        print( 'error: debug is off , turn it on and train again ' )\n","    else:\n","        history = np.array(train_instance.history_mean_hooks)\n","        jet= plt.get_cmap('jet')\n","        colors = iter(jet(np.linspace(0,1,10)))\n","        fig, ax = plt.subplots()\n","        for i in range(history.shape[1]):\n","            ax.plot(history[:,i], '--r', label= i , color=next(colors) )\n","        fig.suptitle('Layers activation mean value', fontsize=10)\n","        leg = ax.legend();\n"]},{"cell_type":"code","execution_count":13,"metadata":{"executionInfo":{"status":"ok","timestamp":1653167912303,"user_tz":-60,"elapsed":7,"user":{"displayName":"Hans Roggeman","userId":"10574434403170915342"}},"id":"XK2FoEUciTyG","colab":{"base_uri":"https://localhost:8080/"},"outputId":"dbf095a5-a962-4073-fb3b-46657ed29c0f"},"outputs":[{"output_type":"stream","name":"stdout","text":["time: 630 µs (started: 2022-05-21 21:18:33 +00:00)\n"]}],"source":["# plot_report(train)\n","# plot_activation_mean(train)\n"]},{"cell_type":"code","execution_count":14,"metadata":{"executionInfo":{"status":"ok","timestamp":1653167912303,"user_tz":-60,"elapsed":6,"user":{"displayName":"Hans Roggeman","userId":"10574434403170915342"}},"id":"k-vqgbT8iTyH","colab":{"base_uri":"https://localhost:8080/"},"outputId":"a5ebf8e8-23ab-4771-cd5a-64e5ea5ce38b"},"outputs":[{"output_type":"stream","name":"stdout","text":["time: 1.26 ms (started: 2022-05-21 21:18:33 +00:00)\n"]}],"source":["# print( 'Value at 0' , net( torch.tensor( [ 0. , 1. , 1. , 1. ] ).cuda() ) )\n","# #%% save\n","# torch.save(net.state_dict(), './model3Assets')\n","# #%%\n","# net = TheModelClass(*args, **kwargs)\n","# net.load_state_dict(torch.load('./modelmodel3Assets'))\n","# net.eval()\n"]},{"cell_type":"code","execution_count":15,"metadata":{"executionInfo":{"status":"ok","timestamp":1653167912304,"user_tz":-60,"elapsed":7,"user":{"displayName":"Hans Roggeman","userId":"10574434403170915342"}},"id":"vibC4jAEiTyH","colab":{"base_uri":"https://localhost:8080/"},"outputId":"63a34225-1ea9-4dfe-f265-b3405c660d33"},"outputs":[{"output_type":"stream","name":"stdout","text":["time: 29.6 ms (started: 2022-05-21 21:18:33 +00:00)\n"]}],"source":["# a set up that just maximizes the loss s.t. loss < eps (maximizeloss_weights_st) using the weights on the losses\n","from scipy.optimize import LinearConstraint, NonlinearConstraint\n","from scipy.optimize import Bounds\n","from functools import partial\n","from scipy.optimize import minimize\n","from functools import wraps\n","\n","def negative(f):\n","    @wraps(f)\n","    def g(*args,**kwargs):\n","        return - f(*args,**kwargs)\n","    # g.__name__ = f'negative({f.__name__})'\n","    return g\n","# kl_loss = nn.KLDivLoss(size_average=None, reduction=\"batchmean\")\n","\n","# we can add more minimization functions here later (e.g. SS diff)\n","def KLDiffHere( varX, loss_terms, log_target = False, reduction = \"mean\"):  \n","  target = torch.tensor([1./len(loss_terms)]*len(loss_terms))*torch.tensor(loss_terms)\n","  input = torch.tensor(varX*loss_terms)\n","  loss_pointwise = target * (torch.log(target) - torch.log(input))\n","  if reduction == \"mean\":  # default\n","      loss = loss_pointwise.mean()\n","  elif reduction == \"batchmean\":  # mathematically correct\n","      loss = loss_pointwise.sum() / input.size(0)\n","  elif reduction == \"sum\":\n","      loss = loss_pointwise.sum()\n","  else:  # reduction == \"none\"\n","      loss = loss_pointwise  \n","  return loss\n","\n","  # return torch.nn.KLDivLoss(varX*loss_terms,np.array([1./len(loss_terms)]*len(loss_terms))*loss_terms)\n","\n","def minimize_weights_st(loss_terms, loss_func):\n","  bounds = Bounds([0]*len(loss_terms), [1.0]*len(loss_terms))\n","  linear_constraint = LinearConstraint([[1]*len(loss_terms)], [1.0], [1.0])\n","  x0 = [0.25]*len(loss_terms)\n","  res = minimize( partial(loss_func, loss_terms=loss_terms), \n","                  x0, \n","                  method='trust-constr', \n","                  constraints=[linear_constraint],\n","                  options={'verbose': 0}, \n","                  bounds=bounds )\n","  return res\n","\n","def maximizeloss_weights_st(loss_terms, loss_func, eps):\n","  bounds = Bounds([0]*len(loss_terms), [1.0]*len(loss_terms))\n","  linear_constraint = LinearConstraint([[1]*len(loss_terms)], [1.0], [1.0])\n","  nonlinear_constraint  = NonlinearConstraint(negative(partial(loss_func, loss_terms=loss_terms)),1E-9,eps)\n","  # even though zero is the KL minimum it helps to put a negative number here to explore\n","\n","  x0 = [1.0/len(loss_terms)]*len(loss_terms)\n","  res = minimize( negative(partial(loss_func, loss_terms=loss_terms)), \n","                  x0, \n","                  method='trust-constr', \n","                  constraints=[linear_constraint, nonlinear_constraint],\n","                  options={'verbose': 0}, \n","                  bounds=bounds )\n","  return res\n"]},{"cell_type":"code","execution_count":16,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1653167912304,"user":{"displayName":"Hans Roggeman","userId":"10574434403170915342"},"user_tz":-60},"outputId":"1a767a74-df5b-48b9-9fd5-32c4995b7190","id":"n9J6J1QRiTyI"},"outputs":[{"output_type":"stream","name":"stdout","text":["[0.33334757 0.33333761 0.33331482]\n","time: 78.6 ms (started: 2022-05-21 21:18:33 +00:00)\n"]}],"source":["r1 = maximizeloss_weights_st( [ 34.25, 100.12, 23.45] , KLDiffHere, 1E9)\n","print(r1.x)"]},{"cell_type":"code","execution_count":17,"metadata":{"executionInfo":{"status":"ok","timestamp":1653167912304,"user_tz":-60,"elapsed":6,"user":{"displayName":"Hans Roggeman","userId":"10574434403170915342"}},"id":"hOKx5NzSiTyN","colab":{"base_uri":"https://localhost:8080/"},"outputId":"25f546f5-8d9d-4c4c-9700-634bd5bea7c7"},"outputs":[{"output_type":"stream","name":"stdout","text":["time: 4.13 ms (started: 2022-05-21 21:18:33 +00:00)\n"]}],"source":["### There is an issue getting this to work because of nonlinear_constraint  = NonlinearConstraint(negative(partial(loss_func, loss_terms=loss_terms)),1E-9,eps)\n","\n","    # def calculateLossAdaptWeights(self , size = 2**8 , train = True, min_max = True):\n","    #     '''\n","    #     Helper function that Sample and Calculate loss,\n","    #     This is adapted in that it changes the weights on the losses to maximize the loss provided\n","    #     the KL distance of the new weighting is within self.eps of the previous distribution (starting at equally weighted)\n","    #     '''        \n","    #     x , x_terminal , x_boundary = self.sample(size)\n","    #     x = Variable( x , requires_grad=True)\n","    #     Ls = self.criterion( x , x_terminal , x_boundary )\n","    #     DO , TC , BC = Ls\n","    #     DOm = torch.mean(DO).detach().cpu().float().item()\n","    #     TCm = torch.mean(TC).detach().cpu().float().item()\n","    #     BCm = torch.mean(BC).detach().cpu().float().item()\n","\n","    #     losses_for_reweighting = [ torch.mean(lv).detach().cpu().float().item() for lv in Ls if list(lv.size())] \n","    #     mask_for_available_losses = [ True if list(lv.size()) else False for lv in Ls ]\n","\n","    #     # print([ DOm, TCm, BCm])\n","    #     # if is.nan(DOm):\n","    #     #   print(DO)\n","\n","    #     if self.weights is None:\n","    #       self.weights = torch.ones(1,len(Ls))/len(Ls)\n","\n","    #     # pdb.set_trace()\n","\n","    #     if min_max:\n","    #         r1 = maximizeloss_weights_st( losses_for_reweighting , KLDiffHere, self.eps)\n","    #         candidate_weigths = torch.zeros_like(self.weights).to(torch.device(\"cuda:0\"))\n","    #         candidate_weigths[0][mask_for_available_losses] = torch.tensor(r1.x).to(torch.device(\"cuda:0\")).float()\n","    #         self.weights = candidate_weigths.to(torch.device(\"cuda:0\"))\n","    #         self.weights_tbl.append(self.weights.detach().cpu().numpy())\n","\n","    #     numActive = np.sum([1 if list(lv.size()) else 0 for lv in Ls ])\n","    #     if train == True:\n","    #         return  (self.weights[0,0]*torch.mean(DO) + \n","    #                  self.weights[0,1]*torch.mean(TC) + \n","    #                  self.weights[0,2]*torch.mean(BC)) , \\\n","    #                  self.weights[0,0]*torch.mean(DO) , \\\n","    #                  self.weights[0,1]*torch.mean(TC) , \\\n","    #                  self.weights[0,2]*torch.mean(BC) , \\\n","    #                  (1./numActive*torch.mean(DO) + \n","    #                  1./numActive*torch.mean(TC) + \n","    #                  1./numActive*torch.mean(BC))             \n","    #     else:\n","    #         return  DO , TC , BC\n"]},{"cell_type":"code","execution_count":18,"metadata":{"executionInfo":{"status":"ok","timestamp":1653167912305,"user_tz":-60,"elapsed":7,"user":{"displayName":"Hans Roggeman","userId":"10574434403170915342"}},"id":"9isahKzRiTyN","colab":{"base_uri":"https://localhost:8080/"},"outputId":"fb1e85a3-dc61-4cea-851e-70b5eac10460"},"outputs":[{"output_type":"stream","name":"stdout","text":["time: 7.74 ms (started: 2022-05-21 21:18:33 +00:00)\n"]}],"source":["import torch\n","from torch.distributions import Normal\n","\n","std_norm_cdf = Normal(0, 1).cdf\n","std_norm_pdf = lambda x: torch.exp(Normal(0, 1).log_prob(x))\n","\n","def bs_price(right, K, S, T, sigma, r):\n","    d_1 = (1 / (sigma * torch.sqrt(T))) * (torch.log(S / K) + (r + (torch.square(sigma) / 2)) * T)\n","    d_2 = d_1 - sigma * torch.sqrt(T)\n","    \n","    if right == \"C\":\n","        C = std_norm_cdf(d_1) * S - std_norm_cdf(d_2) * K * torch.exp(-r * T)\n","        return C\n","        \n","    elif right == \"P\":\n","        P = std_norm_cdf(-d_2) * K * torch.exp(-r * T) - std_norm_cdf(-d_1) * S\n","        return P"]},{"cell_type":"code","execution_count":19,"metadata":{"executionInfo":{"status":"ok","timestamp":1653167912305,"user_tz":-60,"elapsed":6,"user":{"displayName":"Hans Roggeman","userId":"10574434403170915342"}},"id":"Y2mEPNEWiTyN","colab":{"base_uri":"https://localhost:8080/"},"outputId":"ac0f38fa-f393-4caf-e15d-3d930013611a"},"outputs":[{"output_type":"stream","name":"stdout","text":["time: 1.98 ms (started: 2022-05-21 21:18:33 +00:00)\n"]}],"source":["import torch\n","\n","def to_cpu_detach(x):\n","  if isinstance(x, list):\n","    return [ y.detach().cpu().item() for y in x ]\n","  else:\n","    return x.detach().cpu().item()"]},{"cell_type":"code","execution_count":20,"metadata":{"executionInfo":{"status":"ok","timestamp":1653167912305,"user_tz":-60,"elapsed":6,"user":{"displayName":"Hans Roggeman","userId":"10574434403170915342"}},"id":"-sqdzF7ciTyO","colab":{"base_uri":"https://localhost:8080/"},"outputId":"754b028e-36d3-45cd-80ce-34a977559671"},"outputs":[{"output_type":"stream","name":"stdout","text":["time: 1.26 ms (started: 2022-05-21 21:18:33 +00:00)\n"]}],"source":["def huber_loss_zero_target(x, delta = 1.0):\n","  loss_function = torch.nn.HuberLoss(delta=delta)\n","  return loss_function(x, torch.zeros_like(x))\n"]},{"cell_type":"code","execution_count":21,"metadata":{"executionInfo":{"status":"ok","timestamp":1653167912636,"user_tz":-60,"elapsed":5,"user":{"displayName":"Hans Roggeman","userId":"10574434403170915342"}},"id":"_Ow2igAxiTyP","colab":{"base_uri":"https://localhost:8080/"},"outputId":"ebd58536-41fa-4601-981d-acdcadfd67b8"},"outputs":[{"output_type":"stream","name":"stdout","text":["time: 19.8 ms (started: 2022-05-21 21:18:33 +00:00)\n"]}],"source":["def save_model_train(lr, net,  eqLossFn, sample_method, trainObj, eqType, eqObject = None ):\n","\n","  model_id_str =  f\"{eqType}_{datetime.datetime.now():%Y%m%d%H%M%S}_{eqLossFn}_{sample_method}_{trainObj.stop_epoch}_{str(lr).replace('.','p')}_{net.NL}_{net.NN}\"\n","  \n","  if eqObject is not None:\n","    try:\n","        beta = getattr(eqObject,\"beta\")\n","        beta_str = str(beta).replace('.','p')\n","        model_id_str = model_id_str + f\"_beta{beta_str}\"\n","    except AttributeError:\n","        pass\n","    try:\n","        gamma = getattr(eqObject,\"gamma\")\n","        gamma_str = str(gamma).replace('.','p')\n","        model_id_str = model_id_str + f\"_gamma{gamma_str}\"\n","    except AttributeError:\n","        pass\n","  \n","  torch.save(net.state_dict(), f\"/content/drive/MyDrive/data_papers/{paper_name}/model_finals/{model_id_str}\")\n","  df_at_hookintervals = None\n","  train_losses = None\n","  validation_losses = None\n","  try:\n","      df_at_hookintervals = getattr(trainObj, \"history_surfaces_hooks\")\n","      if df_at_hookintervals is not None:\n","        df_at_hookintervals.to_csv(f\"/content/drive/MyDrive/data_papers/{paper_name}/model_checkpoints/validationHook_{trainObj.hook_interval}_{model_id_str}.csv\", index=False)\n","  except AttributeError:\n","      print(\"Class `{}` does not have `{}`\".format(trainObj.__class__.__name__, \"history_surfaces_hooks\"))\n","\n","  try:\n","      train_losses = getattr(trainObj,\"train_losses\")\n","      if train_losses is not None:\n","        train_losses.tofile(f\"/content/drive/MyDrive/data_papers/{paper_name}/model_checkpoints/trainlosses_{model_id_str}.csv\", sep = ',')    \n","  except AttributeError:\n","      print(\"Class `{}` does not have `{}`\".format(trainObj.__class__.__name__, \"train_losses\"))\n","      # raise NotImplementedError(\"Class `{}` does not have `{}`\".format(trainObj.__class__.__name__, \"train_losses\"))\n","\n","  try:\n","      validation_losses = getattr(trainObj,\"validation_losses\")\n","      if validation_losses is not None:\n","        validation_losses.tofile(f\"/content/drive/MyDrive/data_papers/{paper_name}/model_checkpoints/validationlosses_{model_id_str}.csv\", sep = ',')    \n","  except AttributeError:\n","      print(\"Class `{}` does not have `{}`\".format(trainObj.__class__.__name__, \"validation_losses\"))"]},{"cell_type":"code","source":["def save_model_train_stratified(lr, net,  eqLossFn, sample_method, trainObj, eqType, eqObject = None ):\n","\n","  model_id_str =  f\"{eqType}_{datetime.datetime.now():%Y%m%d%H%M%S}_{eqLossFn}_{sample_method}_{trainObj.stop_epoch}_{str(lr).replace('.','p')}_{net.NL}_{net.NN}\"\n","  \n","  if eqObject is not None:\n","    try:\n","        beta = getattr(eqObject,\"beta\")\n","        beta_str = str(beta).replace('.','p')\n","        model_id_str = model_id_str + f\"_beta{beta_str}\"\n","    except AttributeError:\n","        pass\n","    try:\n","        gamma = getattr(eqObject,\"gamma\")\n","        gamma_str = str(gamma).replace('.','p')\n","        model_id_str = model_id_str + f\"_gamma{gamma_str}\"\n","    except AttributeError:\n","        pass\n","    try:\n","        xbreaks = getattr(eqObject,\"xbreaks\")\n","        xbreaks_str = str(len(xbreaks))\n","        model_id_str = model_id_str + f\"_StSaXbrks{xbreaks_str}\"\n","    except AttributeError:\n","        pass\n","    try:\n","        tbreaks = getattr(eqObject,\"tbreaks\")\n","        tbreaks_str = str(len(tbreaks))\n","        model_id_str = model_id_str + f\"_StSaTbrks{tbreaks_str}\"\n","    except AttributeError:\n","        pass\n","  \n","  torch.save(net.state_dict(), f\"/content/drive/MyDrive/data_papers/{paper_name}/model_finals/{model_id_str}\")\n","  df_at_hookintervals = None\n","  train_losses = None\n","  validation_losses = None\n","  try:\n","      df_at_hookintervals = getattr(trainObj, \"history_surfaces_hooks\")\n","      if df_at_hookintervals is not None:\n","        df_at_hookintervals.to_csv(f\"/content/drive/MyDrive/data_papers/{paper_name}/model_checkpoints/validationHook_{trainObj.hook_interval}_{model_id_str}.csv\", index=False)\n","  except AttributeError:\n","      print(\"Class `{}` does not have `{}`\".format(trainObj.__class__.__name__, \"history_surfaces_hooks\"))\n","\n","  try:\n","      train_losses = getattr(trainObj,\"train_losses\")\n","      if train_losses is not None:\n","        train_losses.tofile(f\"/content/drive/MyDrive/data_papers/{paper_name}/model_checkpoints/trainlosses_{model_id_str}.csv\", sep = ',')    \n","  except AttributeError:\n","      print(\"Class `{}` does not have `{}`\".format(trainObj.__class__.__name__, \"train_losses\"))\n","      # raise NotImplementedError(\"Class `{}` does not have `{}`\".format(trainObj.__class__.__name__, \"train_losses\"))\n","\n","  try:\n","      validation_losses = getattr(trainObj,\"validation_losses\")\n","      if validation_losses is not None:\n","        validation_losses.tofile(f\"/content/drive/MyDrive/data_papers/{paper_name}/model_checkpoints/validationlosses_{model_id_str}.csv\", sep = ',')    \n","  except AttributeError:\n","      print(\"Class `{}` does not have `{}`\".format(trainObj.__class__.__name__, \"validation_losses\"))"],"metadata":{"id":"ipogSsVTbv0k","executionInfo":{"status":"ok","timestamp":1653167912636,"user_tz":-60,"elapsed":3,"user":{"displayName":"Hans Roggeman","userId":"10574434403170915342"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"3a93d61c-db99-4fd1-959e-58ef3e9347dd"},"execution_count":22,"outputs":[{"output_type":"stream","name":"stdout","text":["time: 25.7 ms (started: 2022-05-21 21:18:33 +00:00)\n"]}]},{"cell_type":"code","source":[""],"metadata":{"id":"lZMofvFeifhQ","executionInfo":{"status":"ok","timestamp":1653167912636,"user_tz":-60,"elapsed":2,"user":{"displayName":"Hans Roggeman","userId":"10574434403170915342"}}},"execution_count":22,"outputs":[]},{"cell_type":"markdown","source":["## Merton Allocation Reads"],"metadata":{"id":"WWSOXVBSgWVe"}},{"cell_type":"markdown","metadata":{"id":"n22_bWyloTAa"},"source":["### Merton Invest-Consumption Problem - Equation HJB optimization\n","\n","[Extensions of the Deep Galerkin Method](https://arxiv.org/pdf/1912.01455v3.pdf)"]},{"cell_type":"markdown","source":["##### Closed form terminal utility functions & Value functions"],"metadata":{"id":"N-GO35FcJPP6"}},{"cell_type":"code","source":["def expTerminalUtilityOfWealth(x, gamma_discount = 1.0):\n","  return(-torch.exp(-gamma_discount*x))\n","\n","def expTerminalUtilityOfWealth_np(x, gamma_discount = 1.0):\n","  return(-np.exp(-gamma_discount*x))\n","\n","# closed form value function\n","def Htx(x):\n","  return -torch.exp(-x[:,1].reshape(-1,1)*1.0*torch.exp(x[:,3].reshape(-1,1)*(1.0-x[:,0].reshape(-1,1))) - \n","                    0.5*(1.0-x[:,0].reshape(-1,1))*((x[:,2].reshape(-1,1)-x[:,3].reshape(-1,1))/(x[:,4].reshape(-1,1)))**2  )\n","\n","# closed form pi functions\n","\n","# pi_net_fn2 = lambda x: (((x[:,2]-x[:,3])/(1.0*(x[:,4]**2)))*torch.exp(-x[:,3]*(1.0-x[:,0])))\n","# def pi_net_fn(x,du_dx = du_dx,d2u_dx2 = d2u_dx2): \n","    #   return (-(((x[:,2]-x[:,3])/(1.0*(x[:,4]**2)))*torch.div(du_dx,d2u_dx2).reshape(-1)))\n","\n","\n","\n","from functools import partial\n","\n","# should give a closed form solution for the control => PI(x,t) = [(mu-r)/(gamma*sigma^2)]*exp(-r*(T-t))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0cWoRXs02PoF","executionInfo":{"status":"ok","timestamp":1653171147896,"user_tz":-60,"elapsed":444,"user":{"displayName":"Hans Roggeman","userId":"10574434403170915342"}},"outputId":"4f1b197c-a010-4aac-9a47-887e1e8ab65c"},"execution_count":51,"outputs":[{"output_type":"stream","name":"stdout","text":["time: 8.4 ms (started: 2022-05-21 22:12:28 +00:00)\n"]}]},{"cell_type":"markdown","metadata":{"id":"HrivvbmubiiY"},"source":["#### MertonUtilityNet"]},{"cell_type":"code","execution_count":27,"metadata":{"id":"JRraqOG4aXKx","executionInfo":{"status":"ok","timestamp":1653170337064,"user_tz":-60,"elapsed":4,"user":{"displayName":"Hans Roggeman","userId":"10574434403170915342"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"95a11457-6e9f-462e-e5f0-dd9fce3dfdca"},"outputs":[{"output_type":"stream","name":"stdout","text":["time: 11 ms (started: 2022-05-21 21:58:58 +00:00)\n"]}],"source":["class MertonUtilityNet(nn.Module):\n","    def __init__(self , NL  , NN, activation = torch.tanh  ):\n","        super(MertonUtilityNet, self).__init__()\n","        self.NL = NL\n","        self.NN = NN\n","        self.Input = 5 + 1  # wealth, time, mu, r, sigma, pi\n","        self.fc_input = nn.Linear(self.Input,self.NN)\n","        torch.nn.init.xavier_uniform_(self.fc_input.weight)\n","        self.linears = nn.ModuleList([nn.Linear(self.NN, self.NN) for i in range(self.NL)])\n","        for i, l in enumerate(self.linears):    \n","            torch.nn.init.xavier_uniform_(l.weight)\n","        self.fc_output = nn.Linear(self.NN,1)\n","        torch.nn.init.xavier_uniform_(self.fc_output.weight)\n","        self.act = activation\n","        \n","    def forward(self, x):\n","        h = self.act( self.fc_input(x)  )\n","        for i, l in enumerate(self.linears):\n","            h = self.act( l(h) )\n","        out = self.fc_output(h)\n","        return out "]},{"cell_type":"markdown","source":["#### MertonPiNet"],"metadata":{"id":"fyFbPZr7I5RE"}},{"cell_type":"code","source":["import torch.nn.functional as F\n","\n","class MertonPiNet(nn.Module):\n","    def __init__(self , NL  , NN, activation = torch.relu  ):\n","        super(MertonPiNet, self).__init__()\n","        self.NL = NL\n","        self.NN = NN\n","        self.Input = 5   # wealth, time, mu, r, sigma\n","        self.fc_input = nn.Linear(self.Input,self.NN)\n","        torch.nn.init.xavier_uniform_(self.fc_input.weight)\n","        self.linears = nn.ModuleList([nn.Linear(self.NN, self.NN) for i in range(self.NL)])\n","        for i, l in enumerate(self.linears):    \n","            torch.nn.init.xavier_uniform_(l.weight)            \n","        # self.fc_output_d = nn.Linear(self.NN, 2)\n","        # self.fc_output = torch.nn.Softmax(dim=1)\n","        self.fc_output = nn.Linear(self.NN, 1)\n","        torch.nn.init.xavier_uniform_(self.fc_output.weight)\n","        self.act = activation\n","        \n","    def forward(self, x):\n","        h = self.act( self.fc_input(x)  )\n","        for i, l in enumerate(self.linears):\n","            h = self.act( l(h) )\n","        # out = self.fc_output_d(h)\n","        out = self.fc_output(h)\n","        return out \n","        "],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PR7PHL4KI1S9","executionInfo":{"status":"ok","timestamp":1653170338671,"user_tz":-60,"elapsed":2,"user":{"displayName":"Hans Roggeman","userId":"10574434403170915342"}},"outputId":"c114e947-c61e-436b-f26d-f95aba3cd3ac"},"execution_count":28,"outputs":[{"output_type":"stream","name":"stdout","text":["time: 16.9 ms (started: 2022-05-21 21:59:00 +00:00)\n"]}]},{"cell_type":"markdown","source":["#### MertonAlternativePiNet\n","\n","[implement from github](https://github.com/Plemeur/DGM/blob/master/first_net.py)"],"metadata":{"id":"RNhAbZ727RC_"}},{"cell_type":"code","source":["class LinearWithXavier(nn.Module):\n","    \"\"\" Copy of linear module from Pytorch, modified to have a Xavier init,\n","        TODO : figure out what to do with the bias\"\"\"\n","    def __init__(self, in_features, out_features, bias=True):\n","        super(LinearWithXavier, self).__init__()\n","        self.in_features = in_features\n","        self.out_features = out_features\n","        self.weight = torch.nn.Parameter(torch.Tensor(out_features, in_features))\n","        if bias:\n","            self.bias = torch.nn.Parameter(torch.Tensor(out_features))\n","        else:\n","            self.register_parameter('bias', None)\n","        self.reset_parameters()\n","    def reset_parameters(self):\n","        torch.nn.init.xavier_uniform_(self.weight)\n","        if self.bias is not None:\n","            torch.nn.init.uniform_(self.bias, -1, 1) #boundary matter?\n","    def forward(self, input):\n","        return torch.nn.functional.linear(input, self.weight, self.bias)\n","    def extra_repr(self):\n","        return 'in_features={}, out_features={}, bias={}'.format(\n","            self.in_features, self.out_features, self.bias is not None\n","        )\n","\n","\n","class DGM_layer(nn.Module):\n","    \"\"\" See readme for paper source\"\"\"\n","    def __init__(self, in_features, out_feature, residual=False):\n","        super(DGM_layer, self).__init__()\n","        self.residual = residual\n","\n","        self.Z = LinearWithXavier(out_feature, out_feature)\n","        self.UZ = LinearWithXavier(in_features, out_feature, bias=False)\n","        self.G = LinearWithXavier(out_feature, out_feature)\n","        self.UG = LinearWithXavier(in_features, out_feature, bias=False)\n","        self.R = LinearWithXavier(out_feature, out_feature)\n","        self.UR = LinearWithXavier(in_features, out_feature, bias=False)\n","        self.H = LinearWithXavier(out_feature, out_feature)\n","        self.UH = LinearWithXavier(in_features, out_feature, bias=False)\n","\n","    def forward(self, x, s):\n","        z = torch.tanh(self.UZ(x) + self.Z(s))\n","        g = torch.tanh(self.UG(x) + self.G(s))\n","        r = torch.tanh(self.UR(x) + self.R(s))\n","        h = torch.tanh(self.UH(x) + self.H(s * r))\n","        return (1 - g) * h + z * s\n","\n","\n","class MertonAlternativePiNet(nn.Module):\n","\n","    def __init__(self, in_size, out_size, neurons, depth):\n","        super(MertonAlternativePiNet, self).__init__()\n","        self.dim = in_size\n","        self.input_layer = LinearWithXavier(in_size, neurons)\n","        self.middle_layer = nn.ModuleList([DGM_layer(in_size, neurons) for i in range(depth)])\n","        self.final_layer = LinearWithXavier(neurons, out_size)\n","\n","    def forward(self, X):\n","        s = torch.tanh(self.input_layer(X))\n","        for i, layer in enumerate(self.middle_layer):\n","            s = torch.tanh(layer(X, s))\n","\n","        return self.final_layer(s)\n"],"metadata":{"id":"_c-dZ5b37NwV","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1653170341122,"user_tz":-60,"elapsed":369,"user":{"displayName":"Hans Roggeman","userId":"10574434403170915342"}},"outputId":"9d2c2e7f-ce09-409e-a100-42923846966b"},"execution_count":29,"outputs":[{"output_type":"stream","name":"stdout","text":["time: 59.8 ms (started: 2022-05-21 21:59:02 +00:00)\n"]}]},{"cell_type":"markdown","source":["#### MertonAlternativeUtilityNet"],"metadata":{"id":"leiCOWL89Mr5"}},{"cell_type":"code","source":["class MertonAlternativeUtilityNet(MertonAlternativePiNet):\n","    def __init__(self, in_size, out_size, neurons, depth):\n","        super(MertonAlternativeUtilityNet, self).__init__(in_size, out_size, neurons, depth)\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sD3ZL1NY9TMF","executionInfo":{"status":"ok","timestamp":1653170342830,"user_tz":-60,"elapsed":2,"user":{"displayName":"Hans Roggeman","userId":"10574434403170915342"}},"outputId":"2d116e3b-7253-41cc-85ef-cd5e217f2e0f"},"execution_count":30,"outputs":[{"output_type":"stream","name":"stdout","text":["time: 1.56 ms (started: 2022-05-21 21:59:04 +00:00)\n"]}]},{"cell_type":"markdown","source":["#### MertonMatchPiNet\n","\n","[Matching Paper by hand](https://arxiv.org/abs/1912.01455v3)"],"metadata":{"id":"CNsqOm1ithSG"}},{"cell_type":"code","source":["class DGMLayerPaper(nn.Module):\n","\n","    def __init__(self, in_features, out_feature, activation=torch.relu, residual=False):\n","        \n","        super(DGMLayerPaper, self).__init__()\n","        self.residual = residual\n","        self.activation = activation\n","\n","        self.Z = LinearWithXavier(out_feature, out_feature) # w.S\n","        self.UZ = LinearWithXavier(in_features, out_feature, bias=True) # u.x\n","        self.G = LinearWithXavier(out_feature, out_feature)\n","        self.UG = LinearWithXavier(in_features, out_feature, bias=True)\n","        self.R = LinearWithXavier(out_feature, out_feature)\n","        self.UR = LinearWithXavier(in_features, out_feature, bias=True)\n","        self.H = LinearWithXavier(out_feature, out_feature) # w.(S(o)R)\n","        self.UH = LinearWithXavier(in_features, out_feature, bias=True)\n","\n","    def forward(self, x, s):\n","        z = self.activation(self.UZ(x) + self.Z(s))\n","        g = self.activation(self.UG(x) + self.G(s))\n","        r = self.activation(self.UR(x) + self.R(s))\n","        h = self.activation(self.UH(x) + self.H(s * r))\n","        return (1 - g) * h + z * s\n","\n","\n","class MertonMatchPiNet(nn.Module):\n","\n","    def __init__(self, in_size, out_size, neurons, depth):\n","        super(MertonMatchPiNet, self).__init__()\n","        self.dim = in_size\n","        self.input_layer = LinearWithXavier(in_size, neurons)\n","        self.middle_layer = nn.ModuleList([DGMLayerPaper(in_size, neurons) for i in range(depth)])\n","        self.final_layer = LinearWithXavier(neurons, out_size)\n","\n","    def forward(self, X):\n","        s = torch.tanh(self.input_layer(X))\n","        for i, layer in enumerate(self.middle_layer):\n","            s = torch.tanh(layer(X, s))\n","\n","        return self.final_layer(s)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1653170345969,"user_tz":-60,"elapsed":5,"user":{"displayName":"Hans Roggeman","userId":"10574434403170915342"}},"outputId":"61acf915-51f4-4173-95ec-27f0cabdefd5","id":"REWml4aYthSH"},"execution_count":31,"outputs":[{"output_type":"stream","name":"stdout","text":["time: 23.3 ms (started: 2022-05-21 21:59:07 +00:00)\n"]}]},{"cell_type":"markdown","metadata":{"id":"wClW1g9rbm8o"},"source":["#### PiEquation"]},{"cell_type":"code","source":["# torch.max(torch.tensor([1.0,1.3,1.5]), torch.tensor(1.32).expand_as(torch.tensor([1.0,1.3,1.5])))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2ivFXAdDYERq","executionInfo":{"status":"ok","timestamp":1653170349131,"user_tz":-60,"elapsed":347,"user":{"displayName":"Hans Roggeman","userId":"10574434403170915342"}},"outputId":"36491ca0-a0b8-4fe1-c446-be894784280c"},"execution_count":32,"outputs":[{"output_type":"stream","name":"stdout","text":["time: 807 µs (started: 2022-05-21 21:59:10 +00:00)\n"]}]},{"cell_type":"code","source":["class PiEquation():\n","\n","    def __init__(self , pi_net, du_dx, d2u_dx2):\n","        self.pi_net = pi_net\n","        self.wgamma = 0.0001\n","        self.du_dx = (torch.sign(du_dx).to(du_dx.device)*torch.max(torch.abs(du_dx).to(du_dx.device), torch.tensor(1e-12).expand_as(du_dx).to(du_dx.device))).to(du_dx.device)\n","        self.d2u_dx2 = (torch.sign(d2u_dx2).to(du_dx.device)*torch.max(torch.abs(d2u_dx2).to(du_dx.device), torch.tensor(1e-12).expand_as(d2u_dx2).to(d2u_dx2.device))).to(d2u_dx2.device)\n","\n","    def criterion(self, x_internal):\n","      #  time, wealth, mu, r, sigma\n","      pi_net_preds = self.pi_net(x_internal)\n","      # pi_net_preds = pi_net_preds[:,0].reshape(-1,1)\n","      pi_net_preds = pi_net_preds.reshape(-1,1)\n","\n","      dpi = torch.autograd.grad( pi_net_preds, \n","                                x_internal, \n","                                grad_outputs=torch.ones_like(pi_net_preds) ,\n","                                create_graph=True,\n","                                retain_graph=True)\n","      dpi_dt = dpi[0][:,0].reshape(-1,1)\n","      dpi_dx = dpi[0][:,1].reshape(-1,1)\n","\n","      d2pi_dx2 = torch.autograd.grad( dpi_dx, \n","                                      x_internal , \n","                                      grad_outputs=torch.ones_like(dpi_dx) ,\n","                                      create_graph = True,\n","                                      retain_graph=True)[0][:,1].reshape(-1,1)\n","      intC = None\n","      # pdb.set_trace()\n","      if len(x_internal) == 0:\n","        intC_loss = torch.tensor(0).cuda().float()  \n","      else:\n","        # pdb.set_trace()\n","        intC_loss = -(pi_net_preds*(x_internal[:,2].reshape(-1,1)-x_internal[:,3].reshape(-1,1)) + x_internal[:,3].reshape(-1,1)*x_internal[:,1].reshape(-1,1))*self.du_dx - \\\n","                                    0.5*(x_internal[:,4].reshape(-1,1)**2)*(pi_net_preds**2)*self.d2u_dx2\n","\n","        # print(f\"Pi Loss {torch.mean(intC_loss).item()} {x_internal.shape[0]} {torch.mean(self.du_dx)}\")          \n","\n","        # intC_loss = (pi_net_preds*(x_internal[:,2].reshape(-1,1)-x_internal[:,3].reshape(-1,1)) + x_internal[:,3].reshape(-1,1)*x_internal[:,1].reshape(-1,1))*self.du_dx + \\\n","        #                             0.5*(x_internal[:,4].reshape(-1,1)**2)*(pi_net_preds**2)*self.d2u_dx2\n","\n","      return  1.0*intC_loss\n","\n","    def calculatePiLoss(self, x_internal, keep_batch = False):\n","        '''\n","        Helper function that Sample and Calculate loss,\n","        '''        \n","        x_internal = Variable( x_internal , requires_grad=True)\n","        Ls = self.criterion( x_internal )\n","        \n","        return_losses = []\n","        if not keep_batch:\n","          loss_pi = torch.mean(Ls)           \n","          return loss_pi          \n","        else:\n","          return Ls\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uQTTkUhWuiJi","executionInfo":{"status":"ok","timestamp":1653170349513,"user_tz":-60,"elapsed":4,"user":{"displayName":"Hans Roggeman","userId":"10574434403170915342"}},"outputId":"26e89159-6e2d-439e-f4ac-9534178e20f7"},"execution_count":33,"outputs":[{"output_type":"stream","name":"stdout","text":["time: 35.6 ms (started: 2022-05-21 21:59:10 +00:00)\n"]}]},{"cell_type":"markdown","source":["#### MertonEquation"],"metadata":{"id":"hp4BG1ewKF6o"}},{"cell_type":"code","execution_count":34,"metadata":{"cellView":"code","id":"LBMZYQSPaXKy","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1653170357893,"user_tz":-60,"elapsed":1379,"user":{"displayName":"Hans Roggeman","userId":"10574434403170915342"}},"outputId":"fd02272f-9ac6-4a8c-ab9e-ddc132d58fa6"},"outputs":[{"output_type":"stream","name":"stdout","text":["time: 896 ms (started: 2022-05-21 21:59:18 +00:00)\n"]}],"source":["import math\n","\n","class MertonEquation():\n","    \n","    def __init__(self , u_net, pi_net, pi_net_epoch, pi_net_lr, term_utility_function = partial(expTerminalUtilityOfWealth,gamma_discount=0.1) ):\n","\n","        self.u_net = u_net\n","        self.pi_net = pi_net\n","        self.wgamma = 0.0001\n","        self.term_utility_func = term_utility_function\n","        self.xbreaks = None\n","        self.tbreaks = None\n","\n","        self.MAX_X = 1.0\n","        self.T = 1.0\n","        self.MAX_MU = 0.2\n","        self.MAX_SIGMA = 1.0\n","\n","        self.pi_net_epoch = pi_net_epoch\n","        self.pi_net_lr = pi_net_lr\n","        self.loss_multiply = 1.0\n","\n","        self.FORCE_MU = None\n","        self.FORCE_R = None\n","        self.FORCE_SIGMA = None\n","\n","        self.weights=None\n","        self.gamma = 1.0\n","\n","    def g(self,x):\n","        # Time, Wealth, Mu, R, Sigma\n","        return self.term_utility_func(x[:,1].reshape(-1,1))\n","\n","    @staticmethod\n","    def to_device(x, to_cpu):\n","      if to_cpu:\n","        return x.cpu()\n","      else:\n","        return x.cuda()\n","\n","    def mu_r_sample(self, size, range_multiplier = 1.0):\n","      mu_candidate = -self.MAX_MU*range_multiplier*torch.rand([size, 1])+self.MAX_MU*range_multiplier\n","      r_candidate = -self.MAX_MU*range_multiplier*torch.rand([size, 1])+self.MAX_MU*range_multiplier\n","      r_sample = torch.where(r_candidate < mu_candidate, r_candidate, mu_candidate)\n","      mu_sample = torch.where(r_candidate > mu_candidate, r_candidate, mu_candidate)\n","      return (mu_sample, r_sample)\n","\n","    def apply_forced_mu_r_sigma(self, mu_sample, r_sample, sigma_sample):\n","      if self.FORCE_MU is not None:\n","         mu_sample = self.FORCE_MU*torch.ones_like(mu_sample)            \n","      if self.FORCE_R is not None:\n","        r_sample = self.FORCE_R*torch.ones_like(r_sample)\n","      if self.FORCE_SIGMA is not None:\n","        sigma_sample = self.FORCE_SIGMA*torch.ones_like(sigma_sample)\n","      return mu_sample, r_sample, sigma_sample\n","\n","\n","    def sample(self , sample_method_X = \"U\", size = 2**8, to_cpu = False ):\n","        '''\n","        Sampling function\n","        '''\n","        if sample_method_X in [\"U\"]:\n","            range_multiplier = 1.0\n","            \n","            ### internal samples of Time, Wealth, Mu, R, Sigma\n","            mu_sample_internal, r_sample_internal = self.mu_r_sample(size, range_multiplier)\n","            sigma_sample_internal = -self.MAX_SIGMA*range_multiplier*torch.rand([size, 1])+self.MAX_SIGMA*range_multiplier\n","            mu_sample_internal, r_sample_internal, sigma_sample_internal = self.apply_forced_mu_r_sigma(mu_sample_internal, r_sample_internal, sigma_sample_internal)\n","            x_internal = self.to_device(torch.cat(( torch.rand([size,1])*self.T , # Time\n","                                                   -self.MAX_X*range_multiplier*torch.rand([size, 1])+self.MAX_X*range_multiplier, # Wealth\n","                                                    mu_sample_internal, # mu\n","                                                    r_sample_internal, # R\n","                                                    sigma_sample_internal # Sigma\n","                                                   ) , dim = 1 ),to_cpu)\n","            ### Terminal time samples\n","            mu_sample_terminal, r_sample_terminal = self.mu_r_sample(size, range_multiplier)\n","            sigma_sample_terminal = -self.MAX_SIGMA*range_multiplier*torch.rand([size, 1])+self.MAX_SIGMA*range_multiplier\n","            mu_sample_terminal, r_sample_terminal, sigma_sample_terminal = self.apply_forced_mu_r_sigma(mu_sample_terminal, r_sample_terminal, sigma_sample_terminal)\n","            x_terminal = self.to_device(torch.cat(( torch.zeros(size, 1) + self.T , # Time\n","                                                   -self.MAX_X*range_multiplier*torch.rand([size, 1])+self.MAX_X*range_multiplier, # Wealth\n","                                                    mu_sample_terminal, # mu\n","                                                    r_sample_terminal, # R\n","                                                    sigma_sample_terminal # Sigma\n","                                                   ) , dim = 1 ),to_cpu)\n","            \n","            # x_initial = torch.cat( ( torch.zeros(size, 1), -self.MAX_X*range_multiplier*torch.rand([size, 1])+self.MAX_X*range_multiplier) , dim = 1 ).cuda()\n","            return x_internal , x_terminal\n","\n","        raise ValueError(f\"{sample_method_X} is not a supported sampling method\")\n","        \n","    def sample_stratified(self , sample_method_X = \"U\", size = 2**8, to_cpu = False ):\n","\n","      if self.xbreaks is None and self.tbreaks is None:\n","        return self.sample(sample_method_X, size, to_cpu)\n","\n","      internal_strata_xts = []\n","      terminal_strata_xts = []\n","      \n","      if sample_method_X in [\"U\"]:\n","          range_multiplier = 1.0\n","          xbreaks_used = self.xbreaks[:] if self.xbreaks is not None else [0,range_multiplier*self.MAX_X]\n","          tbreaks_used = self.tbreaks[:] if self.tbreaks is not None else [0,self.T]\n","          if xbreaks_used[-1] < range_multiplier*self.MAX_X:\n","            xbreaks_used.append(range_multiplier*self.MAX_X)\n","          while xbreaks_used[0] < 0.0:\n","            xbreaks_used.pop(0)\n","          if not xbreaks_used:\n","            xbreaks_used = [0,range_multiplier*self.MAX_X]\n","          if xbreaks_used[0] > 0.0:            \n","            xbreaks_used.insert(0, 0.0)\n","\n","          if tbreaks_used[-1] < self.T:\n","            tbreaks_used.append(self.T)\n","          xbreaks_range = xbreaks_used[-1]-xbreaks_used[0]\n","          tbreaks_range = tbreaks_used[-1]-tbreaks_used[0]\n","\n","          total_strat_processed = 0\n","\n","          # internal samples\n","          for stratum_x_count in range(len(xbreaks_used)-1):\n","              \n","            num_samples_in_stratum = 0\n","            if len(xbreaks_used) > 2:  # x division takes priority so assign it if there is no T division\n","              range_ratio_x_stratum = (xbreaks_used[stratum_x_count+1]-xbreaks_used[stratum_x_count])/xbreaks_range\n","              num_samples_in_stratum = math.ceil(range_ratio_x_stratum*size)\n","\n","            for stratum_t_count in range(len(self.tbreaks)-1):\n","\n","              if num_samples_in_stratum == 0: # there is only a T division, so use it\n","                range_ratio_t_stratum = (tbreaks_used[stratum_t_count+1]-tbreaks_used[stratum_t_count])/tbreaks_range\n","                num_samples_in_stratum = math.ceil(range_ratio_t_stratum*size)\n","              else:\n","                # there is both an X and a T division, assign the number of samples uniformly, assuming same scale of X and T\n","                stratum_coverage_on_unit_square = \\\n","                  ((xbreaks_used[stratum_x_count+1]-xbreaks_used[stratum_x_count])/xbreaks_range)*\\\n","                  ((tbreaks_used[stratum_t_count+1]-tbreaks_used[stratum_t_count])/tbreaks_range)\n","                num_samples_in_stratum = math.ceil(stratum_coverage_on_unit_square * size)\n","\n","              range_multiplier = 1.0\n","\n","              ### internal samples of Time, Wealth, Mu, R, Sigma\n","              internal_stratum_t_sample = tbreaks_used[stratum_t_count] + torch.rand([num_samples_in_stratum,1])*(tbreaks_used[stratum_t_count+1]-tbreaks_used[stratum_t_count])\n","              internal_stratum_x_sample = xbreaks_used[stratum_x_count] + torch.rand([num_samples_in_stratum,1])*(xbreaks_used[stratum_x_count+1]-xbreaks_used[stratum_x_count])\n","              stratum_mu_sample_internal, stratum_r_sample_internal = self.mu_r_sample(num_samples_in_stratum, range_multiplier)\n","              stratum_sigma_sample_internal = -self.MAX_SIGMA*range_multiplier*torch.rand([num_samples_in_stratum, 1])+self.MAX_SIGMA*range_multiplier\n","              stratum_mu_sample_internal, stratum_r_sample_internal, stratum_sigma_sample_internal = \\\n","                self.apply_forced_mu_r_sigma(stratum_mu_sample_internal, stratum_r_sample_internal, stratum_sigma_sample_internal)\n","              x_internal_stratum = self.to_device(torch.cat(( internal_stratum_t_sample , # Time\n","                                                              internal_stratum_x_sample, # Wealth\n","                                                              stratum_mu_sample_internal, # mu\n","                                                              stratum_r_sample_internal, # R\n","                                                               # Sigma\n","                                                            ) , dim = 1 ),to_cpu)\n","              if not internal_strata_xts: \n","                internal_strata_xts = [ x_internal_stratum ] \n","              else:\n","                internal_strata_xts.append(x_internal_stratum) \n","\n","              ### Terminal time samples\n","              terminal_stratum_x_sample = xbreaks_used[stratum_x_count] + torch.rand([num_samples_in_stratum,1])*(xbreaks_used[stratum_x_count+1]-xbreaks_used[stratum_x_count])\n","              stratum_mu_sample_terminal, stratum_r_sample_terminal = self.mu_r_sample(num_samples_in_stratum, range_multiplier)\n","              stratum_sigma_sample_terminal = -self.MAX_SIGMA*range_multiplier*torch.rand([num_samples_in_stratum, 1])+self.MAX_SIGMA*range_multiplier\n","              stratum_mu_sample_terminal, stratum_r_sample_terminal, stratum_sigma_sample_terminal = \\\n","                self.apply_forced_mu_r_sigma(stratum_mu_sample_terminal, stratum_r_sample_terminal, stratum_sigma_sample_terminal)\n","              x_terminal_stratum = self.to_device(torch.cat(( torch.zeros(num_samples_in_stratum, 1) + self.T , # Time\n","                                                      terminal_stratum_x_sample, # Wealth\n","                                                      stratum_mu_sample_terminal, # mu\n","                                                      stratum_r_sample_terminal, # R\n","                                                      stratum_sigma_sample_terminal # Sigma\n","                                                    ) , dim = 1 ),to_cpu)\n","              if not terminal_strata_xts:\n","                terminal_strata_xts = [ x_terminal_stratum ] # terminal_stratum_xt[None,:,:]\n","              else:\n","                terminal_strata_xts.append(x_terminal_stratum) # torch.vstack((terminal_strata_xts,terminal_stratum_xt[None,:,: ]))\n","\n","              total_strat_processed += 1 \n","              # print((len(internal_strata_xts),xbreaks_used[stratum_x_count],tbreaks_used[stratum_t_count]))\n","\n","          # pdb.set_trace()\n","          # x_initial = torch.cat( ( torch.zeros(size, 1), -self.MAX_X*range_multiplier*torch.rand([size, 1])+self.MAX_X*range_multiplier) , dim = 1 ).cuda()\n","          return internal_strata_xts , terminal_strata_xts\n","    \n","      raise ValueError(f\"{sample_method_X} is not a supported sampling method\")\n","\n","    def criterion(self, x_internal , x_terminal, loss_transforms = [torch.square]):\n","        '''\n","        Loss function that helps network find solution to equation\n","        '''   \n","        # Time / Wealth / Mu / r / Sigma (sample data order)\n","        # pdb.set_trace()\n","\n","        # replace with closed form just to check\n","        # self.pi_net = lambda x: (((x[:,2]-x[:,3])/(1.0*(x[:,4]**2)))*torch.exp(-x[:,3]*(1.0-x[:,0])))\n","\n","        # pdb.set_trace()\n","        pi_used = self.pi_net(x_internal)  \n","        pi_used.detach_()\n","        # let's assign the first column as the allocation\n","        # pdb.set_trace()     \n","        # pi_used = pi_used[:,0].reshape(-1,1)\n","        pi_used = pi_used.reshape(-1,1)\n","        x_internal_before = x_internal.detach().clone()\n","        x_internal =  Variable(torch.cat((x_internal, pi_used), dim=1),requires_grad=True)\n","\n","        du = torch.autograd.grad( self.u_net(x_internal), \n","                                  x_internal, \n","                                  grad_outputs=torch.ones_like(self.u_net(x_internal)) ,\n","                                  create_graph=True,\n","                                  retain_graph=True )\n","        \n","        du_dt = du[0][:,0].reshape(-1,1)\n","        du_dx = du[0][:,1].reshape(-1,1)     \n","\n","        d2u_dx2 = torch.autograd.grad(  du_dx, \n","                                        x_internal , \n","                                        grad_outputs=torch.ones_like(du_dx) ,\n","                                        create_graph = True,\n","                                        retain_graph = True)[0][:,1].reshape(-1,1)\n","    \n","        # def pi_net_fn(x,du_dx = du_dx,d2u_dx2 = d2u_dx2): \n","        #   return (-(((x[:,2]-x[:,3])/(1.0*(x[:,4]**2)))*torch.div(du_dx,d2u_dx2).reshape(-1)))\n","\n","        # pi_net_fn2 = lambda x: (((x[:,2]-x[:,3])/(1.0*(x[:,4]**2)))*torch.exp(-x[:,3]*(1.0-x[:,0])))\n","\n","        pi_model = PiEquation(self.pi_net, du_dx, d2u_dx2)                \n","        pi_trainer = TrainInternalPiWithDGM(self, pi_model, x_internal.shape[0], \n","                                            self.pi_net_epoch, self.pi_net_lr, \n","                                            debug=True, loss_multiply=1.0)\n","        pi_trainer.use_early_stop = True\n","        pi_trainer.early_stop_patience = min(200,math.ceil(self.pi_net_epoch/10.0))\n","        pi_trainer.train()\n","        \n","        # self.pi_net =  pi_net_fn\n","        # self.pi_net =  pi_net_fn2\n","        if loss_transforms is None:\n","          loss_transforms = [torch.square]\n","\n","        intC = None\n","        terC = None\n","\n","        if len(x_internal) == 0:\n","          intC = [ torch.tensor(0).cuda().float() for loss_transform in loss_transforms ] \n","        else:\n","          # Time, Wealth, Mu, R, Sigma\n","          # pdb.set_trace()\n","          pi_net_preds = self.pi_net(x_internal_before)\n","          pi_net_preds.detach_()\n","          # pi_net_preds = pi_net_preds[:,0].reshape(-1,1)\n","          pi_net_preds = pi_net_preds.reshape(-1,1)\n","          intC_loss = du_dt + (pi_net_preds*(x_internal[:,2].reshape(-1,1)-x_internal[:,3].reshape(-1,1))+x_internal[:,3].reshape(-1,1)*x_internal[:,1].reshape(-1,1))*du_dx + 0.5*(x_internal[:,4].reshape(-1,1)**2)*(pi_net_preds**2)*d2u_dx2\n","          intC = [ loss_transform(intC_loss) for loss_transform in loss_transforms ] \n","\n","        # Terminal Condition - should be equal (both in- and out of the money)\n","        x_terminal_before = x_terminal.detach().clone()\n","        pi_net_preds_terminal = self.pi_net(x_terminal_before)\n","        pi_net_preds_terminal.detach_()\n","        # pi_net_preds_terminal = pi_net_preds_terminal[:,0].reshape(-1,1)\n","        pi_net_preds_terminal = pi_net_preds_terminal.reshape(-1,1)\n","        x_terminal =  Variable(torch.cat((x_terminal, pi_net_preds_terminal), dim=1),requires_grad=True)\n","\n","        terC = [ loss_transform( self.u_net(x_terminal) - self.g(x_terminal)   ) for loss_transform in loss_transforms ]\n","\n","        return  intC , terC\n","\n","    def calculateLoss(self, batch_x, train = True, loss_transforms = [ torch.square ], keep_batch = False):\n","        '''\n","        Helper function that Sample and Calculate loss,\n","        '''        \n","        # pdb.set_trace()\n","        x_internal , x_terminal = batch_x\n","        x_internal = Variable( x_internal , requires_grad=True)\n","        Ls = self.criterion( x_internal , x_terminal, loss_transforms = loss_transforms )\n","        intC , terC  = Ls\n","\n","        return_losses = []\n","        for lc in range(len(loss_transforms)):\n","          if not keep_batch:\n","            loss_equalWeightedByType = 0.5*torch.mean(intC[lc]) + 0.5*torch.mean(terC[lc])\n","            return_losses.append( [ loss_equalWeightedByType , \n","                                    0.5*torch.mean(intC[lc]) , 0.5*torch.mean(terC[lc]), \n","                                    loss_equalWeightedByType ] )            \n","          else:\n","            return_losses.append( [intC.numpy(), terC.numpy()] )\n","        return return_losses\n","\n","    def calculateLossUsingKLMinMax(self , batch_x , train = True, loss_transforms = [ torch.square ], keep_batch = False):\n","        '''\n","        Helper function that Samples and Calculate loss,\n","        This is adapted in that it changes the weights on the losses\n","        and the distribution of sampling to maximize the loss provided \n","        the KL distance of the loss is within positive constraints\n","        beta represents the constraints on the weights\n","        gamma represents the constraints on the sampling distribution\n","        (each representing an upper bound the KL distribution)\n","        '''        \n","        # x , x_terminal , x_initial = self.sample(sample_method_X, size)\n","        x , x_terminal = batch_x\n","        x = Variable( x, requires_grad=True)\n","        Ls = self.criterion( x , x_terminal , loss_transforms = loss_transforms)\n","        intC , terC = Ls\n","\n","        if self.weights is None:\n","          self.weights = torch.ones(1,len(Ls)).to(intC[0].device)/len(Ls)\n","        \n","        return_losses = []\n","        for lc in range(len(loss_transforms)):\n","          if not keep_batch:\n","            intCt = self.weights[0,0] * torch.pow((1.0/intC[lc].numel() if intC[lc].numel() > 0 else 0.0) * torch.sum( torch.exp(self.beta * intC[lc])), self.gamma/self.beta) \n","            terCt = self.weights[0,1] * torch.pow((1.0/terC[lc].numel() if terC[lc].numel() > 0 else 0.0) * torch.sum( torch.exp(self.beta * terC[lc])), self.gamma/self.beta) \n","            loss_equalWeightedByType = 0.5*torch.mean(intC[lc]) + 0.5*torch.mean(terC[lc]) \n","            transformed_loss = 1.0/self.gamma * torch.log(intCt + terCt)\n","            return_losses.append( [ transformed_loss , \n","                                    0.5*torch.mean(intC[lc]) , 0.5*torch.mean(terC[lc]),\n","                                    loss_equalWeightedByType ] )            \n","          else:\n","            return_losses.append( [intC[lc].numpy(), terC[lc].numpy()] )\n","        return return_losses\n","\n","\n","    def calculateLossKLMinMaxGamma(self , batch_x , train = True, loss_transforms = [ torch.square ], keep_batch = False):\n","        '''\n","        Helper function that Samples and Calculate loss,\n","        This is adapted in that it changes the weights on the losses\n","        and the distribution of sampling to maximize the loss provided \n","        the KL distance of the loss is within positive constraints\n","        beta represents the constraints on the weights\n","        gamma represents the constraints on the sampling distribution\n","        (each representing an upper bound the KL distribution)\n","        '''        \n","        # x , x_terminal , x_initial = self.sample(sample_method_X, size)\n","        x , x_terminal  = batch_x\n","        x = Variable( x, requires_grad=True)\n","        Ls = self.criterion( x , x_terminal, loss_transforms = loss_transforms)\n","        intC , terC  = Ls\n","\n","        if self.weights is None:\n","          self.weights = torch.ones(1,len(Ls)).to(intC[0].device)/len(Ls)\n","        \n","        return_losses = []\n","        for lc in range(len(loss_transforms)):\n","          if not keep_batch:\n","            intCt = self.weights[0,0] * (1.0/intC[lc].numel() if intC[lc].numel() > 0 else 0.0) * torch.sum( torch.exp(self.gamma * intC[lc])) \n","            terCt = self.weights[0,1] * (1.0/terC[lc].numel() if terC[lc].numel() > 0 else 0.0) * torch.sum( torch.exp(self.gamma * terC[lc])) \n","            loss_equalWeightedByType = 0.5*torch.mean(intC[lc]) + 0.5*torch.mean(terC[lc]) \n","            transformed_loss = 1.0/self.gamma * torch.log(intCt + terCt )\n","            return_losses.append( [ transformed_loss , \n","                                    0.5*torch.mean(intC[lc]) , 0.5*torch.mean(terC[lc]),\n","                                    loss_equalWeightedByType ] )            \n","          else:\n","            return_losses.append( [intC[lc].numpy(), terC[lc].numpy()] )\n","        return return_losses\n","\n","    "]},{"cell_type":"markdown","source":["## Merton NN/Model reads"],"metadata":{"id":"22F_aySqogZo"}},{"cell_type":"code","source":["import os\n","os.listdir(f\"/content/drive/MyDrive/data_papers/dgm_hjb/model_checkpoints/\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"APm7yD_IgePX","executionInfo":{"status":"ok","timestamp":1653170357893,"user_tz":-60,"elapsed":10,"user":{"displayName":"Hans Roggeman","userId":"10574434403170915342"}},"outputId":"d032152b-62a3-4c02-cc89-6571798df7e2"},"execution_count":35,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['Unet_20220521192206_MertonUtilityNet_MertonEquation',\n"," 'Pinet_20220521192206_MertonAlternativePiNet_MertonEquation',\n"," 'Pinet_20220521192328_MertonAlternativePiNet_MertonEquation',\n"," 'Unet_20220521192328_MertonUtilityNet_MertonEquation',\n"," 'Unet_20220521203949_MertonUtilityNet_MertonEquation',\n"," 'Pinet_20220521203949_MertonAlternativePiNet_MertonEquation']"]},"metadata":{},"execution_count":35},{"output_type":"stream","name":"stdout","text":["time: 3.76 ms (started: 2022-05-21 21:59:19 +00:00)\n"]}]},{"cell_type":"code","source":["pp(u_net.keys())\n","u_net['linears.0.weight'].shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oz1zxL_NotxA","executionInfo":{"status":"ok","timestamp":1653170972234,"user_tz":-60,"elapsed":316,"user":{"displayName":"Hans Roggeman","userId":"10574434403170915342"}},"outputId":"7650db3a-5c59-418d-e662-4c124599810c"},"execution_count":48,"outputs":[{"output_type":"stream","name":"stdout","text":["odict_keys(['fc_input.weight', 'fc_input.bias', 'linears.0.weight', 'linears.0.bias', 'linears.1.weight', 'linears.1.bias', 'linears.2.weight', 'linears.2.bias', 'fc_output.weight', 'fc_output.bias'])\n"]},{"output_type":"execute_result","data":{"text/plain":["torch.Size([100, 100])"]},"metadata":{},"execution_count":48},{"output_type":"stream","name":"stdout","text":["time: 3.76 ms (started: 2022-05-21 22:09:33 +00:00)\n"]}]},{"cell_type":"code","source":["u_net = MertonUtilityNet(NL=3, NN=100)\n","u_net.load_state_dict(torch.load(f\"/content/drive/MyDrive/data_papers/dgm_hjb/model_checkpoints/Unet_20220521203949_MertonUtilityNet_MertonEquation\"))\n","u_net.to(torch.device(\"cuda:0\")) \n","u_net.eval()\n","pi_net = MertonAlternativePiNet( in_size = 5 , out_size = 1, neurons = 64, depth= 3 )\n","pi_net.load_state_dict(torch.load(f\"/content/drive/MyDrive/data_papers/dgm_hjb/model_checkpoints/Pinet_20220521203949_MertonAlternativePiNet_MertonEquation\"))\n","pi_net.to(torch.device(\"cuda:0\")) \n","pi_net.eval()\n","\n","# eqLossFn= 'calculateLoss' \n","# sample_method= \"U\"\n","# lr = 0.000001\n","# lr_for_pi = 0.000001\n","# max_pi_epochs = 1 # has to be low!!!\n","\n","mequation = MertonEquation(u_net, pi_net, 1, lr_for_pi)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_JT0dEt4iwAd","executionInfo":{"status":"ok","timestamp":1653171235981,"user_tz":-60,"elapsed":330,"user":{"displayName":"Hans Roggeman","userId":"10574434403170915342"}},"outputId":"ba36bdf3-fdc6-4c44-8638-4eb3d70a8489"},"execution_count":52,"outputs":[{"output_type":"stream","name":"stdout","text":["time: 28 ms (started: 2022-05-21 22:13:57 +00:00)\n"]}]},{"cell_type":"code","source":["# check control for closed form:\n","# PI(x,t) = [(mu-r)/(gamma*sigma^2)]*exp(-r*(T-t))\n","# ((mu-r)/(gamma*(sigma**2)))*np.exp(-r*(1.0-time))\n","# gamma = 1.0 # time = 0.0 # mu = 0.05 # r = 0.02 # sigma = 0.25   # PI\n","\n","gamma = 1.0\n","internal_sample, terminal_sample = mequation.sample(size=100, to_cpu=False)\n","mask = (internal_sample[:,0] > 0.1) & (internal_sample[:,4] > 0.1)\n","internal_sample = internal_sample[mask.reshape(-1),:]\n","# time, wealth, mu, r, sigma\n","time = internal_sample[:,0].cpu().detach()\n","wealth = internal_sample[:,1].cpu().detach()\n","mu = internal_sample[:,2].cpu().detach()\n","r = internal_sample[:,3].cpu().detach()\n","sigma = internal_sample[:,4].cpu().detach()\n","\n","# mequation.pi_net(internal_sample)[:,0]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"u35g5sAPbsG_","executionInfo":{"status":"ok","timestamp":1653171278118,"user_tz":-60,"elapsed":347,"user":{"displayName":"Hans Roggeman","userId":"10574434403170915342"}},"outputId":"09a98f33-a52f-4216-94c7-39bb1c81a1e7"},"execution_count":53,"outputs":[{"output_type":"stream","name":"stdout","text":["time: 35.2 ms (started: 2022-05-21 22:14:39 +00:00)\n"]}]},{"cell_type":"code","source":["# plot the fitted value function vs the closed form (ideally straight line...)\n","u_internal_sample = torch.cat((internal_sample, mequation.pi_net(internal_sample).reshape(-1,1)), dim=1)\n","u_net_results = u_net(u_internal_sample).detach().cpu().numpy().reshape(-1).tolist()\n","htx_results = Htx(u_internal_sample).cpu().detach().numpy().reshape(-1).tolist()\n","dataf2 = pd.DataFrame( { 'u_net': u_net_results, 'closed_form': htx_results } )\n","ggplot(dataf2, aes(x='u_net', y='closed_form')) + geom_point()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":466},"id":"Woj8BoAK5OLC","executionInfo":{"status":"ok","timestamp":1653171281597,"user_tz":-60,"elapsed":660,"user":{"displayName":"Hans Roggeman","userId":"10574434403170915342"}},"outputId":"f0cdfb4c-3acf-4eba-9883-370e0746bd61"},"execution_count":54,"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 640x480 with 1 Axes>"],"image/png":"iVBORw0KGgoAAAANSUhEUgAAAj4AAAGvCAYAAABb4N/XAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAAPYQAAD2EBqD+naQAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOzdeXhM598G8PvMlk0iiSWJkCC2pkUtLS2qGrval6pa86OorV60imr5aa2xb6WtLbG0tUXsYq8lltpLqGhoEUtIkGTOzJz3D695O52EmO3MZO7Pdbkuc+bknNsjzDfPeRZBkiQJRERERG5AIXcAIiIiIkdh4UNERERug4UPERERuQ0WPkREROQ2WPgQERGR22DhQ0RERG6DhQ8RERG5DRY+RERE5DZY+BAREZHbUMkdwBndvXvX6msIggAvLy9kZWXBlRbH1mg00Gq1csfIN7azY7CdHcNV2xlgWzsK2/n5ihYt+sJz2ONjJwqFAt7e3lAoXKuJPTw85I7wUtjOjsF2dgxXbWeAbe0obGfrOU8SIiIiIjtj4UNERERug4UPERERuQ0WPkREROQ2WPgQERGR22DhQ0RERG6DhQ8RERG5DRY+RERE5DZY+BAREZHbYOFDREREboOFDxEREbkNblJKRBbT6/X46aefkJycjODgYHTt2hU+Pj5yxyIiyhMLHyKyiMFgQLdu3bBnzx4IggBBELB06VLs3LkThQoVkjseEVGu+KiLiCySkJCAPXv2QKfTQRRFaLVapKamYt68eXJHIyLKEwsfIrLItWvXoFKZdhprtVqkpKTIlIiI6MVY+BCRRcLCwqDT6UyOaTQalC5dWp5ARET5wMKHiCzSsmVL1K1bF2q1GiqVChqNBqGhofjkk0/kjkZElCcObiYiiyiVSqxatQorV65EcnIyQkJC0KNHDw5sJiKnxsKHiCymUqnQvXt3uWMQEeUbH3URERGR22DhQ0RERG6DhQ8RERG5DRY+RERE5DZY+BAREZHbYOFDREREboOFDxEREbkNFj5ERETkNgRJkiS5QzibjIwMeHh4WHUNQRCg0Wig1WrhSk2sUqnM9l9yZmxnx2A7O4artjPAtnYUtvPz5eezmys350Kr1UKr1Vp1DaVSCY1Gg8ePH0Ov19somf35+voiMzNT7hj5xnZ2DLazY7hqOwNsa0dhOz9ffgofPuoiIiIit8HCh4iIiNwGCx8iIiJyGyx8iIiIyG2w8CEiIiK3wcKHiIiI3AYLHyIiInIbLHyIiIjIbbDwISIiIrfBwoeIiIjcBgsfIiIichssfIiIiMhtsPAhIiIit8HCh4iIiNwGCx8iIiJyGyx8iIiIyG2w8CEiIiK3wcKHiIiI3AYLHyIiInIbLHyIiIjIbbDwISKrrFu3DrVq1UKlSpXQvXt33LlzR+5IRER5YuFDRBZLSEhAv379cPXqVdy7dw+7du1CmzZtkJOTI3c0IqJcsfAp4B4/fgydTid3DCqgFixYAEmSjK9FUcTly5dx/PhxGVMREeWNhU8BlZKSgnfeeQelS5dGyZIlMWbMGOj1erljUQHz5MkTs2MKhSLX40REzoCFj4OcOnUKvXv3Rrt27RATEwOtVmu3e2VnZ6N9+/ZITk4GAOj1evzwww+YMWOG3e5J7qlRo0ZQq9UmxzQaDapWrSpTIiKi52Ph4wDHjh1Ds2bNsGnTJhw4cAAxMTHo2bOnySMCW7pw4QKuX79u0sOj0+nw008/2eV+5L6GDx+OJk2aGF8XKlQIsbGxKF68uIypiIjyppI7gDv49ttvYTAYYDAYADwdB7Fz50789ttvqF69uszpiCyn0Wjw448/IjU1FQ8ePEBERAQKFSokdywiojyx8HGAtLQ0Y9HzjFKpxN27d+1yv8jISISFheHvv/82DmxWqVTo3LmzXe6XH4mJiTh8+DB8fX3RqVMnhISEyJaFbEsQBISHhyM8PFzuKEREL8TCxwGqV6+OlJQUiKJoPCZJEipVqmSX+3l6emLt2rXo2bMnzp8/D5VKhT59+mDIkCF2ud+LTJs2DVOnToVK9fTbbfbs2di+fTvKlStndq5Op8P69evx559/onTp0mjTpo3x6xzh5s2biIuLw8OHD/HGG2+gZcuWEATBYfcnIiL7YuHjAOPHj8fJkyfxxx9/QKVSQRRFTJs2DWFhYXa7Z+nSpbF37148efIEHh4eUCqVdrvX86SmpmLy5MkAYBzQrdfrMXLkSPzyyy8m54qiiI4dO+Lo0aNQKpXQ6/VYuXIlfvrpJ4cUP1evXkXjxo2RlZUFg8GAxYsXo3fv3pgwYYLd701ERI7BwscBAgICkJiYiD179uDhw4eoVq0aKlas6JB7e3t7O+Q+efnzzz8hCILJQG69Xo+rV6+anRsXF4ekpCTodDrjI7ojR45g1apV6Natm92zfvXVV2brHn333Xf46KOP8Morr9j9/pQ/169fx9WrVxESEoIKFSrIHYeIXAxndTmAwWDArl27kJKSgsKFC6N8+fJyR3KYUqVKmc1eUyqVKF26tNm5V65cyXWm2x9//GGveCauXr1qttijSqXC9evXHXJ/erGFCxeiRo0a6NixI+rUqYPhw4fbbXYkERVMLHzsTKfT4cMPP0SfPn0wceJE9OrVCz179jQb7FxQlS5dGkOHDoVCoYBKpYJGo4GXlxe+/fZbs3NLliyZ63iaEiVKOCIqypUrZ/ZITafTcdCuk0hKSsLYsWMhSZKx2ImNjcXKlStlTkZEroSFj53FxsbiwIED0Ol0yM7Ohl6vx86dO83GtxRko0aNwpIlS4wDrPft25frwO5u3bqhTJky0Gg0EAQBGo0GERER6Nq1q0Nyjh8/Hr6+vtBoNNBoNFAoFBg4cKBDHktKkoT09HSkp6ezByMPSUlJ0Gg0JscMBgMOHz4sUyIickUc42Nnly5dMvsgEwQBFy9elCmRPJo3b47mzZs/9xwfHx9s374dixcvxp9//onw8HB8/PHHDhunFB4ejgMHDmD16tXGWV3NmjWz+33v37+PHj164MiRIwCA2rVrY+nSpShSpIjd7+1KfH19c31s6ufnJ1MiInJFLHzsLCQkBAqFaceaIAgIDg6WKZFzK1SoEIYOHSrb/YOCghw+7b937944ceKE8fWJEyfQp08frFu3zqE5nF2rVq0wZcoU3L9/HzqdDkqlEkqlEj179pQ7GhG5ED7qsrOePXsiODjYuJ+RWq1GqVKl0KVLF5mTkTPIzs7GgQMHTNZ4EkURBw4cQHZ2tozJnE9AQAB27NiBRo0aITw8HLVr18bmzZs5s4uIXgp7fOzMz88PiYmJmDNnDq5du4aIiAgMGjTIJsv663Q6TJkyBWvWrMH9+/chSRKKFy+OUaNGoUOHDjZIT/amUCjMpvsDT3sF/91TSEBoaCiWL18udwwicmEsfBzA398fX375pc2v+8UXXyA2NtZkCvb169fxySefQKPRoFWrVja/J9nWs7+nLVu2GHt91Go1mjdvbjaQl4iIrMcfKV2UVqvFsmXLzNadAZ7OEFq0aJEMqcgSs2bNQuvWrY2zyVq3bo1Zs2bJHYuIqEByuR6f2NhYbNu2DTqdDnXq1EG/fv2M42fycuPGDQwZMgS1a9fGiBEjHJTUvnJycp477fnJkycOTEPW8PHxwYIFCzB//nwA4N5gRER25FI9Pjt27MC+ffswbdo0LFq0CDdu3EBcXNwLv27BggUFbrVkX19fVKxYMdc9uNRqNRo3bixDKrKGIAgseoiI7MylCp9du3ahdevWCA4Ohp+fHzp37ozExMTnfk1iYiL8/f1RpUoVB6V0nBUrVuS6qnGLFi0wbNgwGRI99ddff2HUqFHo1asXpk+fbjI7SavVYtSoUShfvjzKlSuHzz77jLOXiIjIYVzqUVdqairKli1rfF22bFk8fPgQ6enpCAgIMDs/IyMDa9aswaRJk7Bt2zZHRnWIMmXK4NChQ7h48SJycnKg0WhQrFgxlCxZUrZMN27cQIMGDfDo0SPodDps374du3fvxoYNG6BSqTBy5EisXr3aOJA3NjYWjx8/xrx582TLTERE7sOlCp/s7Gz4+PgYXz/7fVZWVq6Fz5IlS/D+++8jMDDwude9e/cu7t69a3ytUChQrFgxq7I+ewSV26MoW/Lx8UGNGjVsdj1BEKzKPHv2bGPRAzxdk+bEiRPYtWsXmjZtipUrV0Kv1xvPF0URP//8M2bNmgUPD4+Xvp+j2tnWrG1nR2M7O4artjPAtnYUtrP1nKbwmTRpEg4dOpTn+/Hx8fD09MTjx4+Nx54N4PXy8jI7//z587h69SoGDhz4wnuvXbsWixcvNr7u2bNnvr4uP1xxOX1rplGnpaXlusN5RkYGfH19c92cVZIkFCpUyKq1jdytneXCdnYMV2xngG3tKGxn6zhN4TNy5MgXnhMWFoaUlBRERkYCAK5evYrChQvn2ttz+vRp3Lp1C7169QLwtLfIYDCgf//+WLBggcm57du3R/369Y2vFQoF0tPTrfnjGPcQysjIMOnhcHY+Pj4mxeXLqlSpEnbs2GGyErFWq0V4eDiePHmC2rVr4/jx48b3VSoVqlSpAlEULWpzd21nR2M7O4artjPAtnYUtvPz5VYP/JvTFD75ERUVhbVr16JGjRrw8fHB6tWrERUVleu5bdu2Ndlgcv369bh58yYGDBhgdm7RokVRtGhR4+u7d+/a7C9Ir9e71D8qSZKsyjto0CDs3LkTFy5cgEqlglarRZ8+fVCrVi3s3bsXZcqUQXJyMu7duwcAKF++PJYuXWp1G7lbO8uF7ewYrtbOANvaUdjO1nOpwqdx48a4c+cOhg0bBr1ej7fffhsfffSR8f2vv/4akZGR6NSpE7y8vEwegXl6ekKj0cDf31+O6G7Dx8cHW7duxebNm3H79m28+uqrqFevHlatWoUhQ4YYt2gQBAGTJk1Cjx49nOrZLxERFWyC9LxV8NzUPwc6W0qpVCIgIADp6elOU+Xmh6+vLzIzM216Tb1ej/DwcOTk5JgcDwwMxKVLl6y6NtvZMdjOjuGq7QywrR2F7fx8/3x6kxeX6vEh15Senm5W9ADA/fv3odVqXXKgHtmfJEnYsGEDLl68iKCgIHzwwQcmszqJiCzBwsfFnDhxAidOnIC/vz8aNWqEJUuWYMuWLVAqlejYsSOio6OdblfvwMBAs59SBEFAUFAQix7KlSRJ+Pjjj7Fp0yYolUpIkoTFixdj+/btTjU7hIhcDwsfFzJ//nx8/fXX8PDwgF6vh0KhMOlJOXnyJBITE7Fy5Uqn2vpAoVBg/vz56NmzJ1QqlXGPsWd7U72ITqfDrVu34O/vb9WU95e1b98+bNy4EQDQsmVLNGjQwGH3dne7du3Cpk2bTAZE/vnnn5g9ezbGjBkjczoicmUsfFzEH3/8ga+//hqSJD13i4fExETs2LEDTZo0cWC6F2vatCkSExOxc+dOKBQKNGvWLF/7px09ehTdu3fH/fv3IQgC+vXrh3Hjxtm9sFuzZg0GDRpkvE9sbCxmzpyJLl26mJ27bds2LFu2DFqtFu+//z569uzpVIWnK7p69SrUarXZYpfJyckypiKigoCFj4tITk6GUqk0Wxzw3wRBQEpKioNSvZxXX30Vr776ar7Pv337Nj744APjQpWSJGHRokUoVaoU+vTpY6+YkCQJn3/+OSRJwj/H/o8cORIffvihSVHz008/YeDAgcbzfv31V1y7dg3jxo2zWz53EBYWZrIWFPB0890yZcrIlIiICgrnGgxCeQoKCnph0QM8/dAuVapUnu8fOXIETZs2xeuvv46uXbvi5s2bVuW6cuUKEhMTceXKFauuk5ukpCRotVqT4kOv12PTpk02v9c/PXnyJNcFwrKysvDo0SOTY8964f6Zb8GCBcjIyLBrxoKuSZMmqF+/PtRqNZRKpXEfusGDB8sdjYhcHHt8XES1atXQsmVLbN26FTqdzjjg899bQNSrV89k4cZ/On36NNq2bQu9Xg9JknD79m00a9YMBw4cgK+v70tnmjBhAmbNmgWFQgGDwYBPP/0Uo0ePtujPlxu1Wo3cVltQqez7bevj44NixYrh7t27JvcvUqSI2Rijhw8fmn29JEm4f/8+B+FaQaFQIC4uDitWrMDvv/+OoKAgREdH52tVViKi52Hh4yIEQcDixYvx/fff4+jRowgMDMTHH3+MS5cuITY2FjqdDk2bNkWvXr2gUCggSRLi4+ORlJSEwoULo0uXLvj+++9hMBiMH+Y6nQ5paWnYvn07OnTo8FJ5tm7dijlz5gCAsfiaPXs2qlevnmfh9bLefvttFClSBPfu3TP2dikUCnTv3t0m13+eRYsWoXPnzsbXzx6z/XvsTmRkJM6dO2fSG+fn54cSJUrYPWNBp1KpjFvOEBHZCgsfF6JUKtG3b1/07dvXeKxChQpo2bKl2bljx47F4sWLIQgCFAoFFi5ciGrVqpn1ECkUCrPHN/mRlJQEpVJpcj2lUomkpCSbFT5+fn6Ij4/Hxx9/jPPnz8PPzw+jR49GmzZtbHL956lbty7279+PnTt3AgAaNmyIiIgIs/MWLlyIli1bIj093bhr8tKlSx06Tf9Z751CoUCxYsU4sJqI6DlY+BRAycnJWLhwockxvV6P27dvQ6VSmfROiKKIN95446Xv4evra/YBKwiCRY/Mnqds2bLYtWuXTa/5Mvf+Z5GZm4iICBw+fBj79++HTqdDrVq1HNrbc+vWLXz00Uc4c+YMAKB27dpYvnw5HwkREeWBg5sLoNTUVLP9r/R6PURRND7SetY7MWPGjJeaafXMhx9+CE9PT+N4G5VKBU9PT3z44YfW/wGcTHp6Og4dOoSzZ8+a9ZgBQOHChdGyZUu0bdvW4Y+4evTogQsXLhhfnzhxAv3793doBiIiV8IenwKoTJkyZnuiqFQqlC9fHnPmzMHgwYORlpaGiIgIBAcHW3SPkJAQ7NixA2PGjMEff/yBiIgITJgwASEhIbb4IziNffv2oXv37sjKyoIkSahTpw7i4uKcYuuEhw8f4uTJkybHRFHEnj17oNPp7D4InIjIFfF/xgIoIiIC//M//4OZM2caP/x8fHwwYcIEAED58uXztXhgfu6zatUqq6/jrO7fv4/u3bsb1xECno5tGjt2LGJiYmRM9lRehY1CoXC6bUuIiJwFCx8nJIoivvnmG6xcuRJ6vR7NmzfH5MmT4e3tne9rfPHFF6hZsyaSkpLg5+eHTp06ISgoyI6pC54LFy4gKyvL5Jgoiti/f79MiUz5+PigefPm2Llzp3GxP7VajU6dOrHwISLKAwsfJ/T1119jyZIlxg+ztWvXIjMzE0uXLn2p6zRq1AiNGjWyQ0L3UKhQoVzXEbL1AG5rzJ8/H8OHD0dCQgIUCgU6duyIb775Ru5YREROi4WPk5EkCcuXLzdZrl8URWzevBkZGRlcFM+BKleujDfffBO//fab8e9DEAQMGTJE5mT/z8fHBwsWLMCCBQvkjkJE5BJY+DgBvV6PuXPnYuvWrfD09IRWq831vH/uxE72p1QqsWbNGowePRoHDx5EoUKFMHToULRu3VruaEREZCEWPk5g+PDhWL16tcn6Okql0jgz69mMrKJFi8oV0W0VKlQIs2bNkjsGERHZCAsfmd25cwexsbFmxxUKhbHwKVOmDOLi4rgiLxERkZVY+MgsPT091+MajQZJSUnQ6XQoVaqU2YKERERE9PJY+MgsLCwMfn5+yMjIMB5TqVSoVq0aSpYsKWOyvEmSxN4nIiJySVzsQ2aenp5Yvnw5vL29oVKpoFQqERISgrlz59rk+mlpaTh16hTu3btn9bWOHTuGN954A8HBwahcuTJ27Nhhg4RERESOwx4fJ1CnTh0cPXoUJ0+ehEajwVtvvWWTLRFmzpyJb7/9FpIkQaFQYOLEiYiOjrboWikpKWjXrh1ycnIgSRJu3bqFbt26YcuWLahRo4bVWYmIiByBPT5OIjg4GM2bN0fDhg1tUvRs27bNWPQAgMFgwMiRI3Ho0CGLrrd161ZIkmSyoJ8gCFi7dq3VWYmIiByFhU8BtX//frNtCzQaDQ4ePGjR9f65oOI//XMKPhERkbNj4VNAeXp6mhU+kiTBy8vLouu99957ZkWOwWBAkyZNLM5IRETkaCx8CqjOnTtDEARj8aNUKqFWq9G2bVuLrle5cmUsWrTIWDipVCpMmjQJUVFRNstMRERkbyx8CqgKFSpg48aNePXVVxEQEICqVati8+bNVk2Rb9WqFa5cuYLffvsNKSkpFg+UJiIikgtndTmJmzdv4uLFiwgMDETlypXNHlNZombNmti9e7cN0v0/jUbjtOsLERERvQgLHyewdu1aDBw4EAaDAQaDAQ0bNsTSpUvh4eEhdzQiIqIChY+6ZJaSkoIBAwZAp9PBYDAAAPbt24fp06fLnKzgOnnyJNauXYtjx46ZTM8nIqKCjz0+Mjt16pTJTuzA06njlk47p7xJkoTPPvsMy5Ytg1qthiiK+OCDDzB79mxuwUFE5CZY+MjMz8/PpOgBni4M6O/vL1Mix0tJScGMGTPw119/oUqVKhg2bBgKFSpk8/skJCRgxYoVkCQJWq0WAPDLL7/gnXfeQceOHW1+P1fwxx9/YMOGDcjOzsa7776LOnXqyB2JiMiuWPjIrG7duqhQoQKuXLkCURQhCAIEQcDAgQNtep9nH/Qajcam17XWtWvX8N577yErKwt6vR6HDx/Gvn37sHXrVpuPcTp16hQUCoVZoXnq1Cm3LHxOnDiBNm3aGB+xzpo1C1OnTkWPHj1kTkZEZD8c4yMzDw8PxMfHo3379ihbtizefPNNrF27Fm+99ZZNrv/gwQN07twZJUuWRMmSJdGrVy88evTIJte2hXnz5iE7O9tYjIiiiN9//x1bt261+b2KFCli9khLoVAgMDDQ7NysrCycPn0aycnJxsLA3v45zssRPv30U2i1WuMvSZLw+eefIzMz02EZiIgcjYWPE/D398ecOXNw9OhRJCQkoG7duja7dp8+fbB//37jPlvbt2/HkCFDbHZ9a926dctsRWiVSoU7d+7Y/F6dO3dGQEAA1Gq18T6+vr7o1q2byXlnz55FjRo10LBhQ9SpUwfvv/8+Hj58aPM8z9y5cwft2rVDaGgoSpYsiREjRhh76Gzh4cOH2Lp1KzZt2oTbt28bj6emppoVWnq9Hn///bfN7k1E5GxY+BRgjx49wt69e0322RJFEZs3bzZ73COX119/3ViIPJOTk4PXXnvN5vcKDAzErl270L59e9SoUQPt2rVDYmIiihcvbnLvzp074969e8Zjp06dwrBhw2yeB3i67cdHH32EI0eOwGAwQBRFxMXFYfz48Ta5/pUrV/DWW28hOjoaffv2Ra1atZCUlAQAKFmyZK49YCEhITa5NxGRM2LhQ7IaOHAgatasCaVSCQ8PDwiCgCFDhtjsUd+/BQcHY86cOdi2bRvmzZuH0NBQk/dTUlKQlpZm0hMiiiL27t1rlzx//fUXfvvtN7PidM2aNTa5/scff4z79+9Dp9NBFEU8efIE3bt3h16vx/Tp06FWq6HRaKBWqyEIAr755hv4+fnZ5N5ERM6Ig5sLsEKFCqFevXo4cuSI8YNVrVajSZMmUCqVMqd7ysPDA+vXr0diYiJu376NV155BTVr1pQtj7e3d67HLd3c9UXyGtNji7E+kiTh/PnzJteSJAn37t1DWloaatWqhT179mDt2rXIyclBgwYNUL9+favvS0TkzFj4FHA//PADPv74Y+zduxeCIKBhw4aYM2eO3LFMKJVKNG7cWO4YAIBSpUqhQYMGOHjwoLFYVCqVGDBggN3uV6lSJVy5csU41kmtVqN169ZWX1sQBPj5+eHBgwe5Hgee7un2xRdfWH0vIiJXwUddBVxAQAB+/vlnpKam4vr161i+fLld1sgpKARBwJIlS9CpUycUL14cYWFhGDduHPr27WuX+ykUCqxZswaRkZHGYy1atMA333xjk+uPGTPGZN83pVKJgQMHwsfHxybXJyJyNezxcRP2elRTEPn4+GDmzJkOu1+JEiWQmJiIjIwMqFSqPB+3WaJHjx7w8/NDXFwcRFFEq1atEB0dbbPrExG5GkHiZkVmMjIyrF48TxAEaDQa4/oorkKlUplNL3dmbGfHYDs7hqu2M8C2dhS28/Pl57ObPT65eLagmzWUSiU0Gg0eP37sNFPH88PX19elFrBjOzsG29kxXLWdAba1o7Cdny8/hQ/H+BAREZHbYOFDREREboOFjxvLysrCmDFjUKdOHTRp0gQJCQlyRyqwcnJykJqaisePH8sdhYjIrbHwcVOSJKFHjx748ccfkZycjJMnTyI6Ohq//PKL3NEKnK1bt6J8+fKoUaMGypYti7lz58odiYjIbbHwcVPJycnYs2ePyVYJkiTh22+/lTFVwXPp0iX06tULWVlZAJ6uyDx+/Hhs2LBB5mRERO6JhY+bysjIyPX4v1f5Jevs3bsXKpX55MnNmzfLkIaIiFj4uKkKFSqYLZSnVqtRr149mRIVTGq12mztCkEQzHakJyIix2Dh46YKFy6MZcuWwcvLy7ilwSuvvOLQFYvdQdOmTaFWq022jQCALl26yJSIiMi9sfBxY++++y5OnjyJ1atXY/Pmzdi2bRsCAgIsvt7Dhw9x+PBhnD592qUWBLOnEiVKYOPGjShXrhxUKhWCg4OxZMkS1K1bV+5oRERuiSs3u7miRYuiQYMGVl/n0KFD+Oijj/D48WNIkoQ33ngDq1evNu4C7s6qVq2KX3/9Ve4YREQE9viQDWRmZqJr16549OiRcTzLqVOnMHLkSJmTERERmWLhQ1a7dOmS2d4xoiji4MGDMiUiIiLKHQsfslqhQoVe6jgREZFcWPiQ1SpUqIB69eqZTNFWKBQYMmSIjKmIiIjMWTy4+cmTJ0hMTMT169eRnZ1t8p4gCBg6dKjV4cg1KBQKrFixAmPHjsXevXvh4+ODQYMGoWPHjnJHIyIiMmFR4bNv3z60b98e9+/fz/V9Fj7ux8fHBzExMXLHICIiei6LHnUNGDAAVapUwdmzZ5GTkwODwWDyi2u4EBERkTOyqMfnz6/n/pEAACAASURBVD//xMyZM/Hqq6/aOg8RERGR3VjU41OnTh1cunTJ1lmIyI2cO3cOcXFx2LJlC3JycuSOQ0RuwqIen++++w4dO3aERqNBVFQU/P39zc4JDAy0OhwRFUyLFy/G6NGjodFooNPpULFiRWzatIkrfROR3VlU+Pj7+yM8PBx9+/aFIAi5nsNxPuQMHj16hOXLl+PmzZuoUKECPvzwQ6hU3KlFTleuXMHo0aMhSZKxp+fy5cuYMGECpkyZYvX1Dx06hPPnz6N48eLo1KmT1dcjooLFok+Abt264eDBgxg2bBgqVKgAjUZj61xEVsvIyEDDhg3x119/wWAwQBAEJCQkYOXKlVAqlXLHczhJkvDrr7/i8uXLCA0NRVRUlCztcOHCBahUKoiiaDwmiiKOHz9u9bXHjRuH+fPnG3uS5s2bh/Xr18PHx8fqaxNRwWBR4ZOYmIjvvvsOXbt2tXUeIpuZN28ebty4YfIBu3//fmzevBmtWrWSMZnjSZKEESNGYMWKFdBoNBBFEXXr1sWqVatMFp50hKJFi0Kn05kdT01NhSiKFuc5evQo5s2bB0mSjGuLnT9/HrNmzcKoUaOsykxEBYdFg5tDQ0NRuHBhW2chspm//voLBw4cMCl6AEClUiE1NVWmVPLZuXMnVqxYAYPBgOzsbOj1ehw6dAg//PCDw7PUrl0boaGhZscfPXqEhIQEi6978eJFeHh4mBzTarU4c+aMxdckooLHosJn/PjxmDhxItLT022dh8hqu3fvRq1atXDixAmz93Q6HcLDw2VIZRu//vorYmJisGjRIty5cyffX3f+/HmznhRRFHH+/HlbR3whhUKB119/3ey4Wq3GrVu3LL5uUFBQroVuiRIlLL4mERU8Fj3qiouLQ2pqKsLDw/H666+bzeoSBAEbN260SUCil/HkyRNER0ebTY8WBAFKpRLvvvsuWrRoIVM668ydOxfjx4+HRqOBJEmIiYnB9u3bUbp06Rd+bfHixWEwGEyOqdVqFC9e3E5pn++1117D9u3bTQoVrVaL8uXLW3zNhg0bombNmjh58iREUYRKpYK3tzf3jCMiExb1+GRmZqJ8+fKoUaMGlEolMjMzTX5lZGTYOidRvqSmpuLx48dmx1UqFWJiYhAbGwuFwvX25r1+/TrGjx9vnAml1WqRkZGBkSNH5uvr27ZtizJlyhh7fVQqFXx9fdGnTx97xs5T//79ERkZCbVaDU9PTyiVSnTq1AlRUVEWX1OlUuGXX37BsGHD0LRpU3Tv3h1JSUku3cNHRLb30j0+kiRh3bp18Pb2hqenpz0yEVksr/WjgoOD0aVLF+PrrKws6PV6FCpUyFHRrJKSkmJ2TKfTITk5OV9f7+3tjW3btmHGjBm4cOECwsLCMHToUAQHB9s6ar7zbN68GRs3bsStW7dQqVIlNGrUKM/lMfLL09MTw4YNM7729fVFZmamtXGJqAB56cJHFEUUL14cGzdudNlHBpQ/OTk5WLBgAc6dO4eQkBD079/f6cdLFC9eHD179kRsbKxx5pAgCPjyyy8BPC14Bg8ejA0bNgAAqlevjmXLlslWAORXaGgoJEkyOaZUKhEWFpbva/j6+mLs2LG2jmYxDw8PrrNDRA730oWPRqNByZIluUBhAafT6dC+fXvjeAm1Wo3Vq1dj7969uc7IcSaTJ09GREQEtm/fDk9PT/Tq1QuNGzcGAIwcORKbN282nnvmzBl06dIFu3btcupHYBEREejbty++//57SJIEpVIJpVKJCRMmyB2NiMilWDS4ecCAAZg+fToaN27Mx10F1I4dO3DixAljr4koinj06BFmz56NyZMny5zu+RQKBfr164d+/fqZvRcfH28yoFan0+Hs2bO4efOm0xd0//3vf1GtWjUcPnwYvr6+6Nq1KyIiIuSORUTkUiwqfFJTU5GcnIywsDC8++67CAoKMnk2LwgCZs2aZbOQ5Hg3b96ESqUyWWhOp9Ph+vXrMqayXl5jSJy5t+cZQRDQvn17tG/fXu4oREQuy6LCJyEhAR4eHvDw8MCxY8fM3mfh4/oqVaoErVZrckyj0eC1116TKZFtdOjQAbGxscZeH7VajSpVqjj9GB8iIrINiwqf3GaYUMFSp04dREdH48cff4RGo4Fer0fFihVdfk2U//73v9BqtVi9ejUMBgNq166NRYsWWT2biIiIXAO3qaY8TZw4EU2bNsWFCxdQvHhxvP/++2ZbArgaDw8PzJw5EzExMTAYDA7fp4qIiORlceHz119/YebMmTh48CDu37+PwMBA1KtXD0OGDHH6QaKUf/Xr10f9+vXljmFzz2ZFERGRe7FoROe5c+dQuXJlLFy4ECEhIXjvvfcQEhKChQsXokqVKrLs/0NERET0Ihb1+AwfPhwRERHYsWMHAgICjMfT09PRuHFjDB8+HFu3brVZSCIiIiJbsKjwOXjwIOLi4kyKHgAICAjA6NGj0a1bN5uEI3J3t2/fxsWLF+Hv74/KlSu7xLR7IiJnZlHho1KpzHa/fiYnJ4djJ4hsID4+Hv3794coipAkCQ0aNMDy5cu5aCgRkRUs+vGxYcOGGD16tNkGiZcvX8aXX36JRo0a2SRcbmJjY9G1a1d07twZc+bMMVmFNzdbtmzBxx9/jI4dO6Jv3774/fff7ZaNyFZu3LiBfv36QavVGvfoOnjwIKZMmfLcr5MkCbt27cKcOXOwZs0aZGdnOyIuEZHLsKjHZ/r06ahfvz4iIyPx2muvISgoCGlpaTh79izCwsIwffp0W+cE8HQbhX379mHatGnw9vbGN998g7i4OPTs2TPX8xMTE7FlyxaMGjUK4eHhuHv3Lh8VkEs4ffq02aakoihi//79eX6NJEkYMWIEYmNjoVarodfrsWDBAiQkJLjMLvRERPZmURUQFhaGs2fPYvr06ahQoQIMBgMqVKiAGTNm4MyZMyhVqpStcwIAdu3ahdatWyM4OBh+fn7o3LkzEhMTcz3XYDAgLi4O//nPf1C6dGkIgoBixYqhSJEidslGZEu+vr4wGAwmxwRBgL+/f55fc/DgQaxYsQJ6vR7Z2dkQRRHJycmYPXu2veMSEbmMfPf4tGvXDlOmTEG5cuWwfPlytGjRAoMHD8bgwYPtmc9EamoqypYta3xdtmxZPHz4EOnp6WYDre/du4e7d+/ixo0bmDt3LiRJQp06ddC9e3cuWkdOr3bt2oiMjMSlS5eMj3MFQXjuv7fk5GRoNBqTx1uiKPLxLhHRP+S78ImPj8fnn3+OcuXKoVevXjh8+LDDe0+ys7Ph4+NjfP3s91lZWWaFz927dwEAx48fx8yZM6HVajFhwgT88ssv+PDDD83OfXY+8HTDymLFilmV9dkAb1cb6C0IgktlLqjt7OXlhfj4eHzxxRdISkpCYGAgRo4ciQYNGuT5NaGhoSabygJPJyKEhYVZ3T4FtZ2djau2M8C2dhS2s/XyXfiEhoZi06ZNCAoKgiRJuHXrFlJTU/M8Pyws7KWCTJo0CYcOHcrz/fj4eHh6euLx48fGY0+ePAHw9EPi355trdCuXTv4+voCAFq3bo34+Hizwmft2rVYvHix8XXPnj0xcODAl8qfFz8/P5tcx5E0Go3cEV5aQWzngIAArF69Ot/X69y5M77//nscPnwYWq0WGo0GhQsXxldffWX2g4GlCmI7OyNXbGeAbe0obGfr5Lvw+fTTTzF8+HBMnDgRgiCgbdu2uZ4nSRIEQYBer3+pICNHjnzhOWFhYUhJSUFkZCQA4OrVqyhcuHCu/6mHhobm+5FW+/btTbZlUCgUSE9Pz2fy3CmVSvj5+SEjI+Ol20JOPj4+JsWls2M7m1qzZg0WLlyI8+fPIzg4GP3794eXlxe/n12Eq7YzwLZ2FLbz8+Xnh7x8Fz5Dhw5Fy5YtcfHiRbRq1QqTJ09GhQoVrAr4sqKiorB27VrUqFEDPj4+WL16NaKionI918PDA++88w7Wr1+PcuXKQRRFbNq0CW+++abZuUWLFkXRokWNr+/evWuzvyC9Xu9S/6gkSXKpvM+wnZ9SKpUYMGCAyTFb3oft7Biu1s4A29pR2M7We6np7OXKlUO5cuXQo0cPdOjQAWXKlMnX16WmpqJEiRJQqazbDL5x48a4c+cOhg0bBr1ej7fffhsfffSR8f2vv/4akZGR6NSpEwCgT58+WLBgAaKjo+Hl5YV69eqhffv2VmWggkur1WLcuHFYvXo1DAYDWrZsiUmTJsHb21vuaEREZCOC9O/FQmxMr9dDo9Hg2LFjqF69uj1vZTP/HOhsKaVSiYCAAKSnpztNlZsfvr6+yMzMlDtGvtmynUeMGIG4uDjjLCq1Wo2mTZvixx9/tEVUE67Uzjk5OVAoFAgJCeH3s5256v8bANvaUdjOz/fPpzd5cchqfnaurYisZjAYsHLlSpOVwJ89HnWl5+m2lJmZia5du6JUqVIoUaIEmjVrhgcPHsgdi4jIKlzGmAhPi/N/TwV/5kXbohRUAwYMwO7du40/uOzevRu9e/eWORURkXVY+BDhaXfsO++8YzITUKVSoUqVKs9dLbmgEkUR27dvNyn6tFotdu/ebVxGgojIFbHwIfo/CxcuRNWqVY2vy5cvjxUrVsiYSD6CIMgdgYjILqybZkVUgBQpUgRbtmzB33//DYPBgNDQULfd1FalUqFZs2bYsWOHsddHo9GgXr16nOVGRC6NhQ/RPwiCgNDQULtd//Lly1i1ahX0ej3eeustNG3a1G73stbcuXMxYMAAbN26FQDQqFEjzJ07V+ZURETWsXvhIwgC6tevb9w2gshdnTx5Eq1atYLBYIAkSViwYAG++OILDB06VO5ouSpUqBCWLVsGrVYLpVKJoKAgl5v6S0T0b3bvx1coFNizZw/Kly9v71sRObXPPvsMoihCFEXodDpIkoSJEyfi9u3bckd7Lo1G45J7AxER5SbfhY9CoYBSqcz3LyIylZqaCoPBYHJMkiTs2rXL7DgREdlHvh91TZ8+3TjTQ6fTYebMmdBoNGjTpg2CgoJw69YtbNiwAaIoOm3XPZGcIiIi8Ntvv5k9Kvr000+xceNGrFixAh4eHjKlIyJyDy+1O/szn3/+OapVq4YNGzaYzHqZNm0aWrdujZs3b9o2JVEBEBMTgxYtWiAnJ8dsUcSDBw9i5syZ+Pzzz2VKR9YwGAyYMWMGfvzxR4iiiEaNGmHy5MkoVKiQ3NGI6F8sGuOzdOlSfPLJJ2ZTfRUKBT755BMsW7bMJuGICpLIyEgcOHAAzZs3N3scLIoijhw5IlMyslZMTAymTZuGtLQ0pKenY8OGDejduze36yFyQhYVPllZWbh27Vqu7127dg3Z2dnWZCJyChcuXEB8fDxOnDhhsw+wkiVLomPHjmbHFQoFihQpYpN7kOMtXrzYZMsTrVaLxMREpx+4TuSOLJrO3qZNG3z++efw8vJCmzZtULhwYTx8+BDr16/HF198gTZt2tg6J5FDTZo0CTExMVCr1dDpdGjbti0WLFhgkwUN3333XVSqVAnJyckQRREKhQIKhQIDBw60QXKSQ05OTq7H+UMgkfOx6H/xefPmoVGjRoiOjkZgYCA8PT0RGBiI6OhoREVFcZEzcmn79+/HjBkzADx9BCVJEuLj4222fYWHhwcSExPxwQcfIDIyEu+88w4SEhLw+uuv2+T65HjvvfeeyT5vSqUSYWFhKFmypIypiCg3FvX4+Pr64pdffsHvv/+OpKQk3Lp1CyEhIXjjjTfwyiuv2DojkUOdPHkSarXa5Kd4vV6P48ePo0ePHja5h7+/v7G4Itc3Y8YMdO3aFUePHgUAhISEYPXq1VCpuDg+kbOx6l/lK6+8wkKHCpyAgACzMT0qlQqBgYEyJSJn5+/vj02bNuHPP/+EVqtFmTJlTHqAiMh5WDxgQRRFLFy4EP/5z3/QuHFjXL58GQCwZs0a/P777zYLSORobdu2RfHixY0fXEqlEh4eHoiOjpY5mfN5tgDjwoULjet4uStBEFC6dGlUqFCBRQ+RE7Oox+fq1ato2LAh7t69i2rVquHgwYPIzMwE8HR8xLZt27BkyRKbBiVyFD8/P2zfvh3jx4/HhQsXEBYWhjFjxiA8PFzuaE5FkiQMHjwYP/30EzQaDXQ6HapXr45169ZxIUYicloWFT6DBw9GsWLFkJSUBH9/f5N9fOrXr48vvvjCZgGJ5FC8eHEO0n+BHTt24Oeff4bBYDDOXvrtt9+waNEiDBo0SOZ0RES5s6jw2bt3L1atWoWiRYuaLb8fHBzMlZuJ3MDFixehUqlM/g8QRZGPuonIqVk0xkelUuW5oNvt27e5TDuRGwgODjbbXFWtViMkJESmREREL2ZR4VO/fn3ExMSYDGQUBAGSJGHRokWIioqyWUAick5t2rRBpUqVjAN51Wo1/P390a9fP5mTERHlzaJHXZMnT8bbb7+NyMhItGrVCoIgYN68eTh37hwuX76MpKQkW+ckIifj4eGBhIQEzJ8/H7///jtKliyJAQMGoFixYnJHIyLKk0WFT6VKlXDixAl8/fXXWLVqFZRKJRISEtCwYUPExcUhIiLC1jmJyAl5e3tj+PDhcsdwqJSUFJw6dQq+vr6oV68eZ7ARuRiLFzAsU6YMd2EnIreybt06fPLJJ1AqldDr9ahQoQLi4+Ph7+8vdzQiyifrd1z8P9euXcOuXbtw//59W12SiMhp3Lp1CwMGDIBer4dWq4Ver8eVK1cwevRouaMR0UuwqPAZNmwYPv30U+Pr9evXo2LFimjcuDHKly+PEydO2CwgEZEzuHjxotksNlEUcfz4cZkSEZElLCp81q9fj5o1axpfjxo1Cs2bN8eZM2fw5ptvYsyYMTYLSETkDAICAswKH0EQULRoUZkSOZcHDx7g2LFjuHz5cp7LnRA5A4sKn5s3byIsLAwA8Mcff+DSpUsYM2YMXnvtNQwaNIg/ARGRUxJFEZs3b8aSJUuMO6nnV5UqVdCwYUPj9H1BECAIAkaOHGmPqC5l9+7diIiIQPPmzfH222+ja9euyMnJkTsWUa4sGtxcuHBhpKWlAQB27tyJwMBA1KhRA8DTKa5ZWVm2S0hEZANZWVlo27YtTp8+DZVKhZycHAwaNAhffvllvr5eEAQsW7YM06dPx4EDB+Dv74+BAwfirbfesnNy53b79m306NHDuG0JAOzZsweTJk3CV199JWMyotxZ1OPzzjvvYOzYsZg3bx4mT56MNm3aGN+7dOmSsTeIiMhZzJ49G2fOnIFOp0N2djYkScKcOXNequdHo9Fg5MiR2Lx5M+Li4ty+6AGAM2fOmCxmCzztWduzZ49MiYiez6LCZ8aMGQgODsbIkSMRFhaGb775xvjeihUrUK9ePZsFJCKyhdOnT5t9QHt4eOD8+fMyJSoYvL29zcY+AeDWReS0LHrUFRoait27d+f63vbt2+Hp6WlVKCIiWytRogRUKhV0Op3xmE6nQ1BQkIypXN8bb7yByMhIJCcnGwtLQRAwYMAAmZMR5c6qdXwkScKlS5dw+PBhXLp0CZIkwc/PDxqNxlb5iIhsYtCgQfDy8oJK9fTnPbVajSpVqqBx48YyJ3NtGo0G69atQ+vWrREcHIxKlSrh+++/R7NmzeSORpQri1dunj9/PsaPH487d+4YjxUvXhxjx45F//79bRKOiMhWwsPDsWfPHsyePRt///03qlatiiFDhhhnaZHlAgMDERsbi8zMTLmjEL2QRYXPokWLMHDgQHz44Yf44IMPEBQUhNu3b2PNmjUYOHAg1Go1evfubeusRERWCQ8PR0xMjNwxiEhGFhU+M2bMwODBgzFz5kyT461atUKxYsUwbdo0Fj5ERETkdCwa45OSkoL3338/1/datGiBa9euWZOJiKjAO336NHr37o02bdpgypQpXPCPyEEs6vEJCQnB4cOH0bBhQ7P3jhw5gpCQEKuDEREVVCdPnkSLFi1gMBhgMBiQlJSE48eP4+eff5Y7GlGBZ1Hh85///Afjx49HTk4OOnTogKCgIKSlpeHnn3/G1KlTMXbsWFvnJCIqMCZNmmQseoCnC/7t3bsXx44dQ9OmTWVOR1SwWVT4jB49Gunp6Zg6dSomTpz4/xdTqTBo0CCMHj3aZgGJiAqa27dvmy36p1Qqce/ePZkSEbkPQbJiG9179+7h6NGjSE9PR2BgIN58800UKVLElvlkkZGRAQ8PD6uuIQgCNBoNtFqtS+1U/O8F3pwd29kx2M629cknnyA2NhZardZ4TKFQ4Ny5c3jllVdcrp0B523rvPB72jEc3c75+ey2eB0fAChSpAiaN29uzSWcklarNfkPyRJKpRIajQaPHz+GXq+3UTL78/X1dam1ONjOjsF2tq1Ro0bh8OHDSE5OhkqlgiiKmDp1KoKDgwHA5doZcN62zgu/px3D0e1s08Jn3bp1L3Xzdu3avdT5RETWOn36NKZOnYq0tDTUqFHD5FG8MylcuDB27tyJvXv34sGDB6hatSoqVaokdywit5DvwqdDhw75vqggCC5VQROR6zt79iyaNWsGvV4Pg8GAc+fO4dixY9iyZYtTbqPj4eGBJk2ayB2DyO3ku/BJSUmxZw4iIqvMnj3bWPQAT2dKnTt3Dnv37uV+XM9x7949ZGZmomTJksZ9zIgKsnx/l4eHhxt/n5iYiNTUVPTq1cvsvKVLlyI8PNzkfCIie7tz547ZTCmVSoX79+/LlMi5iaKITz/9FD/99BMAoFixYli1ahWqVq0qczIi+7Jo5eYxY8bg9u3bub53584djBkzxqpQREQvq1atWmYbjoqiiCpVqsiUyLlNnToV69evN76+d+8eOnbsiIyMDBlTEdmfRYXP+fPnUbNmzVzfq169Os6fP29VKCKilzV06FDUqlULgiBArVZDoVAgJiYGkZGRckdzSgkJCRBF0fjaYDDgwYMHOHv2rIypiOzPoge6giDg4cOHub6Xnp7Ogc1E5HCenp745ZdfcOTIEdy9exevvvoqqlWr5lJTfx0ptwHfkiSZ9ZoRFTQW9fjUqlUL8+bNM1uMSJIkzJ8/H7Vq1bJJOCKil6FUKlGnTh20bt0a5cqVkzuOU4uOjoZSqTS+VqvVKFeuHMf4UIFnUY/PuHHj0KBBA1SpUgU9e/ZESEgI/v77byxfvhzJycnYu3evjWMSEZEtdevWDU+ePMHMmTPx6NEjvPnmm5g/f77Vq9YTOTuLCp+33noLiYmJ+Oyzz/D555/DYDBAoVAYj9euXdvWOYmIyIYEQUC/fv3Qr18/uaMQOZTFizbUqVMHv/76K7KyspCeng5/f394e3vbMhsRERGRTVk0xuefvLy8UKJECRY9RGQkSRIWLFiAN954A1WrVsWoUaOQnZ0tdywiIus2KSUiys2sWbMwadIk4wzPpUuX4vbt2/jhhx9kTkZE7s7qHh8ion+bO3euybIWoigiPj4e9+7dkzEVERELHyKyg7weaz1+/NjBSYiITLHwISKbe/vtt00WwlMoFAgNDUVoaKiMqYiIWPgQkR3MmzcPFStWNL5+tgHmPxfMIyKSAwc3E5HNFStWDDt37sTFixeh0+lQsWJFeHl5yR2L6IWuX7+OnTt3wmAwoEGDBoiIiJA7EtkYCx8isguVSoXXXntN7hhE+ZaUlIQOHTrAYDAAAL766ivExcXh3XfflTcY2RQfdREREQHo27cvsrOzkZOTg5ycHGi1WvTp08dsX0pybSx8iIjI7YmiiBs3bpgVOQ8ePMD9+/dlSkX2wMKHiIjcnlqtRuHChc2OazSaXI+T62LhQ0REBGDSpEkQBAEKhQKCIEAQBEyYMAEqFYfDFiT82yQiIgLQoUMHFCtWDOvWrYPBYMD777+PJk2ayB2LbIyFDxER0f+pX78+6tevL3cMsiM+6iIiIiK3wcKHiIiI3AYLHyIiInIbLHyIiIjIbbDwISIiIrfBwoeIiIjcBgsfIiIichssfIiIiMhtsPAhIiIit8HCh4iIiNwGCx8iIiJyGyx8iIiIyG2w8CEiIiK3wcKHiIiI3IZK7gAvKzY2Ftu2bYNOp0OdOnXQr18/qNXqXM+9evUqFi9ejGvXrkGj0aBu3bqIjo6GUql0cGoiIiJyBi7V47Njxw7s27cP06ZNw6JFi3Djxg3ExcXlef6UKVNQqVIlxMbGYvr06Th9+jQSEhIcmJiIiIiciUsVPrt27ULr1q0RHBwMPz8/dO7cGYmJibmeK0kS0tLS0KBBAyiVShQpUgQ1atTAn3/+6eDURGQver0eZ86cQVJSEjIzM+WOQ0QuwKUKn9TUVJQtW9b4umzZsnj48CHS09PNzhUEAa1atUJiYiJEUcSdO3dw/PhxVK9e3ZGRichOHjx4gObNmyMqKgotWrRAtWrVcPz4cbljEZGTc6kxPtnZ2fDx8TG+fvb7rKwsBAQEmJ3/5ptvYtasWdi4cSMMBgOioqJQp04dh+UlIvsZMWIEzp49a3ydkZGBLl264NSpU/D29pYxmWsSRRHfffcdTp48iaJFi6Jfv34mP2gSFRROU/hMmjQJhw4dyvP9+Ph4eHp64vHjx8ZjT548AQB4eXmZnZ+ZmYlx48YhOjoaUVFRePToEWbNmoWlS5eiV69eJufevXsXd+/eNb5WKBQoVqyYVX+eZwOoXW0gtSAILpWZ7ewYztjOBw4cgCiKxteSJCE9PR3Xrl1D5cqVAbCd88tgMKB79+7Yt28fRFGESqXCmjVrsGfPHpQvXz5f12BbOwbb2XpOU/iMHDnyheeEhYUhJSUFkZGRAJ7O2ipcuHCuvT23bt2CJElo0qQJAMDf3x9RUVFYvXq1WeGzdu1aLF682Pi6Z8+eGDhwoDV/HCM/Pz+bXMeRNBqN3BFeGtvZMZypnX19fXHv3j2z4yVKlDD5P4Ht/GJ79uzB7t27YTAYAAA6nQ6SJCEmJgZr1qzJ93XY1o7BdraO0xQ+Fy08MgAAGjpJREFU+REVFYW1a9eiRo0a8PHxwerVqxEVFZXruaGhoVAqldi1axcaNGiAJ0+eYPfu3ShTpozZue3bt0f9+vWNrxUKRa7jhl6GUqmEn58fMjIyoNfrrbqWI/n4+Jj0qjk7trNjOGM7DxkyBMOGDTN+WKvVarzzzjsIDAw0/vtlO+fPlStXoFKpoNVqjcf0ej2uXr2a7/8LrWnrCxcu4ODBg/D09ESzZs2s7nHPD2f8ns4Pfk8/X24dIf/mUoVP48aNcefOHQwbNgx6vR5vv/02PvroI+P7X3/9NSIjI9GpUyd4e3tj9OjRWLp0Kb7//nuo1WpUqVIFvXv3Nrtu0aJFUbRoUePru3fv2uwvSK/Xu9Q/KkmSXCrvM2xnx3Cmdu7atSsEQcD8+fORlZWFqKgojBs3zlgIAWzn/CpXrpzJY0PgaSFZuXLlfOewtK3Xr1+P/v37Q61Ww2AwYNy4cdiyZQvKlSv30teyhDN9T+cHv6etJ0iSJMkdwtn8c7yPpZRKJQICApCenu40f9n54evr61LTgtnOjsF2dgw523nq1KmYOnUqPDw8oNfrUbp0aWzduhWFCxfO19db0taZmZmoVKmSSU+TUqlEtWrVsHXr1pe61svi97RjOLqd/9mJkReX6vEhIiL7GDFiBOrVq4fTp0+jSJEiaN68ud1nx6WmppoUPcDTnoFLly7Z9b7k3lj4EBERAKB27dqoXbu2w+5XvHjxXI8HBQU5LAO5H5dawJCIiAqOYsWKYfDgwcapzgqFAgqFAt98843MyaggY48PERHJZsyYMahYsSISExPh5eWFrl27ombNmnLHogKMhQ8REclGEAR06tQJnTp1kjsKuQk+6iIiIiK3wcKHiIiI3AYLHyIiInIbLHyIiIjIbXBwMxERye7Jkye4dOkSPDw8ULFiRafazZsKFhY+REQkq7Nnz6JTp07G7YJef/11rFmzBoGBgTIno4KIj7qIiEg2Wq0WnTt3xv37943Hzp8/jyFDhsiYigoy9vgQEZFsUlNTkZaWZnJMFEUcPHhQpkRU0LHwISKyg19//RW//vorvL290a5dO5QoUULuSE4pr41Q7b1BKrkvPuoiIrKxRYsWoW3btpg9ezYmTpyIunXr4uLFi3LHckohISFo2rQp1Gq18ZhSqcSAAQNkTEUFGQsfIiIbSktLw5dffglJkpCTkwOtVosnT55g+PDhckdzSoIgYNGiRejatStKlCiB0qVLY/z48ejfv7/c0aiA4qMuIiIbSk1NhcFgMDmm1+vxxx9/yJTI+Xl5eWHKlCmYMmWK3FHIDbDHh4jIhkqWLGl2TKFQICwsTIY0RPRvLHyIiGwoODgYn332GRQKBZRKJdRqNdRqNSZNmiR3NCICH3UREdnciBEjEBkZiQMHDsDb2xtdunRBuXLl5I5FRGDhQ0RkFy1atECLFi3kjkFE/8JHXUREROQ2WPgQERGR22DhQ0RERG6DhQ8RERG5DRY+RERE5DY4q4uISEZ///03pkyZgpSUFFSqVAmTJ0+GUqmUOxZRgcXCh4hIJmlpaXjvvffw8OFD6HQ6HDt2DLt378bevXvh4+MjdzyiAomPuoiIZLJ06VJkZGRAp9MBAERRxN9//43/be/ug6Ko/ziAv3fv9pSYDAR8KlGBDqPIktRUjIwysSRLDTN0DMwytZqeSyvIpnGadMqHUQcscsiy1NSJCoXQMuwBJ/MhSpMnTZk8I3lQuTvu+/vDuF8nYAJ3u3e379eMo7e3fPezH3F5u9/dvfXr12tcGZH/YvAhItKIxWJp8YGmkiTBYrFoVBGR/2PwISLSSGxsLCRJcllmt9tx/fXXa1QRkf9j8CEi0siDDz6IpKQkyLKMLl26QJIkzJw5E+PGjdO6NK/W2NiodQnkw3hxMxGRRmRZxpo1a7Br1y4cO3YMUVFRSEpKQk1NjdaleaXt27dj3rx5OHXqFEJCQrB06VKMGTNG67LIxzD4EBFpSJIkjBo1CgB4G/tF7N+/H9OmTUNTUxMA4NSpU5g+fTry8/MxaNAgjasjX8KpLiIi8np5eXktgqHBYEBeXh7q6+tRVVUFq9WqUXXkSxh8iIjI61149xsACCHw/fffIzIyEnFxcTCbzdi2bZsG1ZEvYfAhIiKvN3bsWOfzjprZ7Xbs3r3bGYoaGhowY8YM/P7771qUSD6CwYeISGN///03SktLUVdXp3UpXmvw4MHIyspyPtE6MDAQQ4YMgRDCZT1ZlvH1119rUSL5CAYfIiINLVu2DGazGbfccgsiIyORk5OjynYvPHviC5KTk1FWVoZDhw6hrKwMERERLZ6DJISA0cj7dqhtDD5ERBrJz8/H66+/7jxrYbfbkZ6ejj179nhsm3v37sWQIUPQu3dvREZG4sMPP/TYtjxBlmUEBwdDlmWkpKS4BB+DwYAuXbrwFne6KAYfIiKNFBYWtjhjYTKZsHPnTo9sr7q6Gvfeey+qqqoAALW1tXjiiSewfft2j2zP0+Lj45GdnY2ePXvCaDQiKioKW7ZsQa9evbQujbwYzwcSEWmk+WnN/yaEgMlk8sj2CgsLYbVaXe6QEkLg448/xh133OGRbXra+PHjMX78eK3LIB/C4NMKk8mELl26dGqM5oNZYGBgi4vvvJnRaMTll1+udRmXjH1WB/vsGWlpacjOzoYkSRBCwGAwQFEUTJkyxSN1K4rSImgB56ePOrs9b+/1hfg9rQ5v7DODTyusVmunH4RlMBhgMpnQ0NDgfNKoL7j88st96s4S9lkd7LNnDBgwABs2bMCzzz6L48ePIyIiAu+//z5CQ0M9UvewYcMgSZIzaAHnQ09SUlKnt+ftvb4Qv6fVoXafL+WkBYMPEZGGRo4cieLiYgDnf0gEBwd77LO6+vXrhw8//BBpaWmoqamB0WjEK6+8ggkTJnhke0TeiMGHiEhH4uPj8euvv+LUqVMICgqCoihal0SkKgYfIiKdkWUZYWFhWpdBpAnezk5ERC2cOXMG5eXlOHPmjNalELkVgw8REbnIzc1FZGQkhg4diqioKKxbt07rkojchsGHiIiciouL8dRTTzk/0sJms+HJJ5/Ed999p3FlRO7B4ENERE4FBQUtPutKURQUFhZqVBGRe/HiZiIicmrrqdG8+6vzTp48ic2bN6Ourg4333wzRowYoXVJusTgQ0REThMmTMDSpUudDzls/p3P+umc8vJyjB07FvX19ZAkCVarFZmZmZg9e7bWpekOp7qIiMhp4MCB+OSTTxAeHg5FUdCvXz9s2LABZrNZ69J82vPPP4/a2lpYrVY0NjZCCIFXX30Vf/zxh9al6Q7P+BARkYuRI0eipKRE6zL8yqFDh5wXjP9bRUUFrrzySg0q0i+e8SEiIvKwvn37wmAwuCwTQqBPnz4aVaRfDD5EREQe9vrrr0NRFBiNRsiyDIPBgEcffRQDBgzQujTd4VQXERGRhw0aNAhFRUXIzc1FfX09hg8fjvvuu0/rsnSJwYeIiEgFUVFRyMjI0LoM3eNUFxEREekGgw8RERHpBqe6iIiILkIIga1bt+Lnn39GaGgoHnjgAQQHB2tdFnUQgw8REdFFPP3001i3bh1kWYYkSVi5ciUKCgrQs2dPrUujDuBUFxERURt+/PFH5ObmoqmpCTabDVarFadOncKiRYu0Lo06iMGHiIioDeXl5S0+uNVms+Hw4cMaVUSdxeBDRETUhvDwcFitVpdlRqMRERERGlVEncXgQ0RE1IZhw4Zh0qRJMBqNMBqNMJlMCAoKwosvvqh1adRBvLiZiIioDZIkYcWKFUhISMC+ffvQvXt3TJ8+HWFhYVqXRh3E4ENERHQRkiQhJSUFKSkpWpdCbsCpLiIiItINBh8iIiLSDQYfIiIi0g0GHyIiItINBh8iIiLSDQYfIiIi0g0GHyIiItINBh8iIiLSDQYfIiLqsLNnz+KZZ55Bnz59cM0112DhwoWw2+1al0XUJj65mYiIOmzevHn4/PPPYbPZAAArV66E1WrFwoULNa6MqHU840NERB1SV1eHLVu2OEMPANhsNuTk5EAI0enxGxoasGDBAowZMwZTp07Fnj17Oj0mEc/4EBFRhzQ2Nra63GazQQgBSZI6PLbdbsfkyZOxd+9e2Gw2yLKMoqIifPbZZ4iLi+vwuEQ840NERB0SEhKC6OhoGI3//z+0oiiIj4+HLHfux0txcTH27NnjPJvkcDjgcDiwZMmSTo1L2qmvr8fq1auRmZmJ9evXw+FwaFIHz/gQEVGHSJKEDz74ACkpKThy5AgA4Nprr8WqVas6PfZff/0Fg8Hg8sPR4XDAYrF0emxSX21tLRITE3Hs2DEIISCEQF5eHnJycjodktuLwYeIiDqsX79+2LVrFywWC86cOYP+/fu75QdZbGwsmpqaXJYpioKhQ4d2emxS39KlS3H06FGX68G2bduG/Px8JCUlqVqL30517du3D/Pnz8eUKVMwffp0rcshIvJbRqMRV199NSIiItz2v/fIyEgsXrwYsixDURTIsowbbrgBL7zwglvGJ3X9/vvvLqEHOB9kKysrVa/Fb8/4dO3aFbfffjsSEhKQm5urdTlERNROqampGD58OA4cOIDu3btj+PDhLtcTke+IiIiAoigu4cdut6Nv376q1+K330Fmsxlmsxn79+/XuhQiIuqgyMhIREZGal0GddLjjz+OTZs2obq6Gg6HA5IkISEhQfVpLsCPgw8RERF5h6CgIBQVFWHt2rWorq5GdHQ0pk6dqvqFzQCDDwDAYrG43CkgyzLCwsI6NabBYHD53VdIkuRTNbPP6mCf1eGrfQbYa7X4cp+Dg4PxxBNPaFyRjwafRYsWobi4uM33t27d2q7xNm7ciKysLOfrGTNmYO7cuR2u79+6devmlnHUZDKZtC6h3dhndbDP6vDFPgPstVrY587xyeDj7qv6J06ciISEBOdrWZZRU1PTqTENBgO6deuG2traFrdkerPAwEA0NDRoXcYlY5/VwT6rw1f7DLDXamGfLy44OPg/1/HJ4HMpHA4H7Ha781OCrVYrJEmCoigt1g0NDUVoaKjztcVicdtfUFNTk0/9oxJC+FS9zdhndbDP6vC1PgPstVrY587z2+Bz8OBBzJ8/3/l60qRJ6NGjB7KzszWsioiIiLTkt8EnNja23df6EBERkX/z2yc3ExEREV2IwYeIiIh0g8GHiIiIdIPBh4iIiHSDwYeIiIh0g8GHiIiIdIPBh4iIiHRDEkIIrYvwRxaLBRs3bsTEiRNdngpN7sU+q4N9Vgf7rB72Wh3e2Gee8fEQi8WCrKwsl099J/djn9XBPquDfVYPe60Ob+wzgw8RERHpBoMPERER6YYhIyMjQ+si/FVAQABuuukmXHbZZVqX4tfYZ3Wwz+pgn9XDXqvD2/rMi5uJiIhINzjVRURERLrB4ENERES6YdS6AH+3b98+rF+/HkeOHIHJZMLatWu1Lskn5ebm4ssvv4TdbsfIkSPx6KOPQlGUVtc9fPgwsrKyUFlZie7du+Ohhx7C0KFDne8nJyejS5cukCQJABATEwNe6naeO/t84MABrFq1CtXV1QgPD8e8efMwYMAAtXbFq7Wnz2VlZcjKykJFRQVMJhPi4+ORlpYGg8EAAJg5cyb+/vtvyPL5/8eGhYVhxYoVqu2LN3NnnysrK7Fs2TJUVFSgZ8+emDVrFgYNGqTm7ni1S+31yZMnMWfOHJdljY2NuOuuuzBr1iwAKhyjBXnUb7/9Jr766iuRn58vpk2bpnU5Pik/P1/MnDlTnDhxQpw+fVo899xz4r333mt13bq6OpGamioKCgqE3W4XJSUlYuLEieKPP/5wrjN+/Hhx9OhRlar3He7s8+nTp8WUKVNEYWGhsFqt4tNPPxVpaWnCarWquEfeqT19FkKIRx55ROTk5Ai73S4sFouYM2eO2Lx5s/P99PR0UVJSokLlvsWdfbbZbCI9PV2sX79eWK1W8fXXX4uUlBRRU1Oj0t54t/b2+t/q6urEfffdJw4ePOhc5uljNKe6PMxsNmP06NHo3bu31qX4rIKCAtxzzz3o1asXunXrhilTpqCwsLDVdUtLSxEYGIjExEQYDAbExcUhOjoaO3bsULdoH+TOPu/evRu9e/fGbbfdBkVRcM8990AIgb1796q4R96pPX0WQuDPP//E6NGjYTAYEBISgri4OFRWVqpcte9xZ5/379+PxsZGTJo0CYqiYNSoUQgPD8e3336r5i55rfb0+kI7d+5EWFgYYmJiPFzl/zH4kNerqqpCRESE83VERAROnz6NmpqaVtcXF9yoKIRARUWFy7IFCxZg2rRpeO2111BVVeX2mn2RO/tcVVXlMq0lSRL69+/PXqN9fZYkCcnJySgsLITNZsPJkydRUlKCwYMHu6z39ttvIzU1FS+99BJ++eUXj++DL3Bnn6uqqtC/f3/ndGLzeAyg57X32PFvhYWFSExMbLHck8doBh/yeufOnUNgYKDzdfOfz54922Ld6Oho1NbWYtu2bbDb7fjxxx9RWlqKxsZG5zpvvPEGsrKysHr1akREROCVV17BmTNnPL8jXs6dfT579qzLWM3jtTaW3rSnzwAwdOhQfPfdd5g8eTLS09NhNpsxcuRI5/tPPfUUsrOzsWbNGsTHxyMzMxN//vmnZ3fCB7izz/x+vrj29rpZeXk5ysrKcNttt7ks9/Qxmhc3d8KiRYtQXFzc5vtbt25VsRrfdCk97Nq1KxoaGpzLmv8BBAQEtFi/W7duePnll/Huu+8iJycHAwcORHx8vMtFdtdddx0AQFEUpKamoqioCKWlpYiLi3PXbnkdtfscEBDQ4kDV0NDQ6lj+xN19rqurQ2ZmJtLS0pCYmIj6+nq88847yMnJwUMPPQQALlME48aNwzfffIM9e/YgKSnJXbvlddTuc0BAgMtYgD6+nwH39/rfCgsLMXjwYISEhLgs9/QxmsGnE1544QWtS/B5l9LD8PBwlJeXOw/wZWVluOKKKxAcHNzq+jExMXjrrbecr5999lncfvvtbY7ffOeAP1O7z+Hh4cjPz3e+1zwN5s8/jAH397m6uhpCCNx5550AgKCgICQmJuKjjz5yBp8LybLcYhrS36jd5/DwcGzcuBEOh8M53VVeXo5bbrnFjXvlnTxx7AAAu92OHTt2YPbs2f85vruP0Zzq8jCHwwGr1Qq73Q4AsFqtsNlsGlflWxITE7FlyxZUV1ejrq4OH330Uatzws2OHDkCm82Gc+fO4ZNPPsHp06edp1Krqqpw5MgRNDU1obGxEevWrYPVakV0dLRau+O13Nnn4cOH48SJEygqKoLNZnOe/bzhhhtU2Rdv1p4+X3nllTAYDCgoKEBTUxPq6urw1VdfOa+fOnnyJA4ePAibzQabzYb8/HwcPnwYN954o5q75JXc2efY2FiYTCZs2rQJNpsNu3btQmVlpcuUo56199gBAD/88AMAuDwCA1DnGM2PrPCw/fv3Y/78+S7LevTogezsbI0q8j1CCHzwwQf44osv0NTUhBEjRmD27NnOaZWMjAzExMTg/vvvBwAsWbIEP/zwA4QQiI2NxcyZM9GrVy8A55+rtHLlSlgsFphMJkRFRWHGjBl8vgzc22fg/Pf+6tWrnc/xmTt3rssFkHrV3j4fOHAAOTk5OHbsGBRFwfXXX49Zs2bhiiuuQFVVFRYvXowTJ07AaDSib9++SE1NRWxsrJa76BXc2WcAqKiowPLly1FRUYEePXrgkUce4XN8/tHeXgPAwoUL0atXLzz88MMuY6lxjGbwISIiIt3gVBcRERHpBoMPERER6QaDDxEREekGgw8RERHpBoMPERER6QaDDxEREekGgw8RERHpBoMPERER6QaDDxHRPyoqKpCRkYHjx49rXQoReQiDDxHRPyoqKpCZmcngQ+THGHyIiIhINxh8iEhTt956K+6++26XZXv37oUkSdixY8d/fn1OTg4kScJPP/2EpKQkBAYG4uqrr8batWtbrJuXl4dhw4YhICAAYWFhmD17NhoaGgAAO3bswOjRowEAQ4YMgSRJkCSp8ztIRF6FwYeI/MKDDz6IMWPGYPPmzbjxxhsxY8YMlJaWOt/fsGEDkpOTERsbi08//RRvvvkmNm3ahPT0dADA4MGDsWLFCgDAe++9h927d2P37t2a7AsReY5R6wKIiNxh7ty5eOyxxwAAI0aMQF5eHjZu3IgFCxZACIFnnnkGKSkpyM7Odn5N7969MW7cOLz88su49tprERMTAwC47rrrcNNNN2myH0TkWTzjQ0R+YcyYMc4/BwYGol+/fjh27BgA4NChQ6isrMT9998Pu93u/JWQkABZllFSUqJV2USkMp7xISK/EBQU5PLaZDLh3LlzAACLxQIAuPfee1v92qNHj3q2OCLyGgw+RKSprl27wmq1uiyrqalx6za6d+8OAFi+fDmGDRvW4v0+ffq4dXtE5L0YfIhIU1dddRW2b98OIYTzLqpt27a5dRsDBw7EVVddhbKyMsyZM6fN9UwmEwA4zxQRkf9h8CEiTU2aNAlr1qzBvHnzMGHCBBQXF2PDhg1u3YYkSViyZAmmTp2KhoYG3HXXXQgMDERlZSXy8vLwxhtvwGw2w2w2w2Aw4N1334XRaITRaORFzkR+hhc3E5Gmxo4dizfffBNbt27FhAkTcODAAaxatcrt25k8eTI+//xz/Prrr3jggQeQnJyMxYsXo3///ujZsycAIDQ0FCtWrMDOnTsxatQoDBkyxO11EJG2JCGE0LoIIiIiIjXwjA8RERHpBq/xISKv5XA44HA42nzfYDDwYyWIqF14xoeIvNZrr70GRVHa/PX+++9rXSIR+Rhe40NEXuv48eM4fvx4m+8PGDAAISEhKlZERL6OwYeIiIh0g1NdREREpBsMPkRERKQbDD5ERESkGww+REREpBsMPkRERKQbDD5ERESkGww+REREpBsMPkRERKQb/wOXhc6QhG4UEAAAAABJRU5ErkJggg==\n"},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":["<ggplot: (8761765179969)>"]},"metadata":{},"execution_count":54},{"output_type":"stream","name":"stdout","text":["time: 374 ms (started: 2022-05-21 22:14:42 +00:00)\n"]}]},{"cell_type":"code","source":["# plot the control function vs the closed form (ideally straight line...)\n","dataf = pd.DataFrame( { 'pi_net': mequation.pi_net(internal_sample).cpu().detach().numpy().reshape(-1).tolist(), \n","                       'closed_form': (((mu-r)/(gamma*(sigma**2)))*np.exp(-r*(1.0-time))).numpy().tolist() } )\n","ggplot(dataf, aes(x='pi_net', y='closed_form')) + geom_point()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":466},"id":"GHfTC6GljYnd","executionInfo":{"status":"ok","timestamp":1653171287442,"user_tz":-60,"elapsed":440,"user":{"displayName":"Hans Roggeman","userId":"10574434403170915342"}},"outputId":"d6b04db7-5844-47d9-dded-0b9def1c2c00"},"execution_count":55,"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 640x480 with 1 Axes>"],"image/png":"iVBORw0KGgoAAAANSUhEUgAAAjQAAAGvCAYAAABMwk8eAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAAPYQAAD2EBqD+naQAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOzdeXxM1/8/8NedOzPZQwixhjTWUNVaa6k9VWqJtSVaWymlqLRKVSyli1LtRxBLqSVFBY19K1K0lq6hqD1iCSEkIsls9/eHX+7XNItkMpk7V17Px6OPunfu3Puek0nmNeeee64gSZIEIiIiIhXTKF0AERERUWEx0BAREZHqMdAQERGR6jHQEBERkeox0BAREZHqMdAQERGR6jHQEBERkeox0BAREZHqaZUuwJGSkpKULuGJBEGAm5sb0tPTobY5D/V6PQwGg9Jl5Bvb2nHY1o6j1rZWWzsDbGtH8vX1feI27KFxMhqNBu7u7tBo1PejcXFxUbqEAmFbOw7b2nHU2tZqa2eAbe1s1PVTICIiIsoBAw0RERGpHgMNERERqR4DDREREakeAw0RERGpHgMNERERqR4DDREREakeAw0RERGpHgMNERERqR4DDREREakeAw0RERGpHgMNFSsWiwXp6elKl0FERHbGQEPFgiRJmD9/Pvz9/eHv748mTZrg1KlTSpdFRER2wkBDxcL333+PGTNmIDMzEwBw5coVdOvWDXfv3lW4MiIisgcGGioW1q1bB4vFIi+bzWakpKQgNjZWwaqIiMheGGiIiIhI9RhoqFjo1asXRFGUlzUaDTw9PdGiRQsFqyIiInthoKFiITQ0FB988AG0Wi0AoEKFCti8eTN8fX0VroyIiOxBq3QBRI4gCALee+89jBkzBg8fPoSXl5dVjw0REakbe2ioWBFFEV5eXkqXQUREdsZAQ0RERKrHQENERESqx0BDREREqidIkiQpXYSjpKSkwMXFReky8iQIAvR6PQwGA9T2o9FqtTCZTEqXkW9sa8dhWzuOWttabe0MsK0dKT+f3cXqKieDwQCDwaB0GXkSRRF6vR5paWkwm81Kl1MgXl5eSE1NVbqMfGNbOw7b2nHU2tZqa2eAbe1I+Qk0POVEREREqsdAQ0RERKrHQENERESqx0BDREREqsdAQ0RERKrHQENERESqx0BDREREqsdAQ0RERKrHQENERESqx0BDREREqsdAQ0RERKrHQENERESqx0BDREREqsdAQ0RERKrHQENERESqx0BDREREqsdAQ0RERKrHQENERESqx0BDREREqsdAQ0RERKrHQENERESqx0BDREREqsdAQ0RERKrHQENERESqx0BDREREqsdAQ0RERKrHQENERESqx0BDREREqsdAQ0RERKrHQENERESqx0BDREREqsdAQ0RERKrHQENERESqx0BDREREqsdAQ0RERKrHQENERESqx0BDREREqsdAQ0RERKrHQENERESqx0BDREREqqdVugAA6NOnj9WywWBAw4YNMXny5By379q1K1xcXCAIAgAgKCgIU6dOLeoyiYiIyEk5RaBZv369/G+z2YwhQ4agefPmeT7nq6++QqVKlYq6NCIiIlIBpzvl9PvvvyMjIwPNmjVTuhQiIiJSCafooXncvn370LJlS7i4uOS53eTJk2E2m1G9enUMHDgQ/v7+DqqQiIiInI1TBZqUlBQcO3YMn376aZ7bzZo1CzVr1oTRaMTGjRsxZcoULFiwAO7u7lbbJSUlISkpSV7WaDQoU6ZMkdRuL6IoWv1fTQRBUFXdbGvHYVs7jlrbWm3tDLCtnY1TBZoDBw6gfPnyqFmzZp7b1a1bFwCg0+kQGhqK/fv34/Tp02jQoIHVdtHR0ViyZIm8PHDgQIwaNcr+hRcBb29vpUuwiV6vV7qEAmNbOw7b2nHU2NZqbGeAbe0snCrQ7Nu3D+3bty/w87Kudvqvnj17olWrVvKyRqNBcnKyzfU5giiK8Pb2RkpKCsxms9LlFIiHhwfS0tKULiPf2NaOw7Z2HLW2tdraGWBbO5KPj88Tt3GaQHPhwgXEx8ejdevWeW4XHx8Po9GIqlWrwmQyITo6GgaDIcdeHV9fX/j6+srLSUlJqnnTmc1m1dSaRZIk1dUMsK0diW3tOGpra7W2M8C2dhZOE2j27t2Lhg0b5pjC+vTpg/DwcNSpUwf37t3DwoULkZSUBL1ej2rVqmHatGnw9PRUoGoiIiJyBk4TaIYPH57rY4/PU1OvXj0sXLjQESURERGRSjjdPDREREREBcVAQ0RERKrHQENERESqx0BDREREqsdAQ0RERKrHQENERESqx0BDREREqsdAQ0RERKrHQENERESqx0BDREREqsdAQ0RERKrHQENERESqx0BDREREqsdAQ0RERKrHQENERESqx0BDREREqsdAQ0RERKrHQENERESqx0BDREREqsdAQ0RERKrHQENERESqx0BDREREqsdAQ0RERKrHQENERESqx0BDREREqsdAQ0RERKrHQENERESqx0BDREREqsdAQ0RERKrHQENERESqx0BDREREqsdAQ0RERKrHQENERESqx0BDREREqsdAQ0RERKrHQENERESqx0BDREREqsdAQ0RERKrHQENERESqx0BDREREqsdAQ0RERKrHQENERESqJ0iSJCldhKOkpKTAxcVF6TLyJAgC9Ho9DAYD1Paj0Wq1MJlMSpeRb2xrx2FbO45a21pt7QywrR0pP5/dWgfU4TQMBgMMBoPSZeRJFEXo9XqkpaXBbDYrXU6BeHl5ITU1Veky8o1t7Thsa8dRa1urrZ0BtrUj5SfQ8JQTERERqR4DDREREakeAw0RERGpHgMNERERqR4DDREREakeAw0RERGpXrG6bJvI3v7880/88ssvcHd3R+fOneHr66t0SURExRIDDZGNVq9ejfHjx0Ov18NiseDTTz/F9u3b8cwzzyhdGhFRscNTTkQ2SEpKQlhYGCwWCzIyMmAwGHD//n2MHz9e6dKIiIolBhoiG1y5ciXbzKAmkwlnzpxRqCIiouKNgYbIBuXKlcu2ThAEVKhQQYFqiIiIgYbIBhUrVsSIESMgiiIEQYAoihBFEZ988onSpRERFUscFExko2nTpqFOnTqIjY2Fh4cHQkNDUa9ePaXLIiIqlhhoiGwkCAL69u2Lvn37Kl0KEVGxx1NOREREpHoMNERERKR6DDRERESkegw0REREpHoMNERERKR6Nl/l9PDhQ+zbtw9Xr15FRkaG1WOCIGDcuHGFLo6IiIgoP2wKNAcPHkTPnj1x9+7dHB9noCEiIiJHsumU0zvvvIN69eohLi4OmZmZsFgsVv/99x43REREREXJph6aK1euYN68eahTp4696yEiIiIqMJt6aJo3b46zZ8/auxYiIiIim9jUQxMZGYnevXtDr9ejXbt2KFmyZLZtSpUqVejiiIiIiPLDpkBTsmRJVKlSBcOHD4cgCDluw3E0RERE5Cg2BZoBAwbg0KFDGD9+PGrUqAG9Xm/vuoiIiIjyzaZAs2/fPkRGRiI0NNTe9RAREREVmE2DgitWrIgSJUrYuxYiIiIim9gUaKZPn45PP/0UycnJ9q6HiIiIqMBsOuW0Zs0axMfHo0qVKqhfv362q5wEQcCPP/5olwKJiIiInsSmQJOamorq1atbLRMREREppcCBRpIkbNy4Ee7u7nB1dS2KmoiIiIgKpMBjaIxGI8qWLYt9+/YVRT1EREREBVbgQKPX61GpUiVOnEdEREROw+a7bc+dOxcZGRn2roeIiIiowGwaFBwfH49///0X/v7+aN26Nfz8/KxugSAIAr7++mu7FUlERESUF5sCzdatW+Hi4gIXFxccP3482+MMNERERORINgWaS5cu2bsOIiIiIpvZNIaGiIiIyJnY1EMDANeuXcO8efNw6NAh3L17F6VKlULLli0xZswYVKxY0Z41ZjNv3jzExsZCq/2/8iMiIlCmTJkiPS4RERE5J5sCzcmTJ/HSSy/BaDSiQ4cOqF+/PhITE7Fo0SIsW7YMsbGxqFOnjr1rtdKtWze8+eabRXoMIiIiUgebAk1YWBgCAwOxe/du+Pj4yOuTk5MRHByMsLAw7Nixw25FEhEREeXFpkBz6NAhrFmzxirMAICPjw8++ugjDBgwwC7F5WXXrl3YtWsXfH190aVLF3To0KHIj0lERETOyaZAo9VqkZmZmeNjmZmZEEWxUEU9SZcuXTB48GB4eHjg1KlT+Pzzz+Hh4YFmzZpZbZeUlISkpCR5WaPROP04m6y2K+o2LAqCIKiqbra147CtHUetba22dgbY1s5GkCRJKuiTevXqhb/++gvbtm1DjRo15PXnzp1D586d8dxzz+GHH36wa6F5iYqKwrVr1/D+++9brY+MjMSSJUvk5YEDB2LUqFEOq4uIiIgcw6Yemrlz56JVq1YICgpC3bp14efnh1u3biEuLg7+/v6YO3euvevMkyAIyCmX9ezZE61atZKXNRoNkpOTHVlagYmiCG9vb6SkpKjuflkeHh5IS0tTuox8Y1s7DtvacdTa1mprZ4Bt7Uj/HeKSE5sCjb+/P+Li4vDtt9/i0KFDSE5ORo0aNTB48GAMGjQInp6etuw23w4dOoQXXngBrq6uOHPmDLZt24Zhw4Zl287X1xe+vr7yclJSkmredGazWTW1ZpEkSXU1A2xrR2JbO47a2lqt7QywrZ1FvgNNjx498MUXX6BatWpYuXIlOnfujHfffRfvvvtuUdaXo61btyIiIgIWiwW+vr4IDQ3FSy+95PA6yL4ePHiAjz/+GD///DO8vb0xbtw4dOnSRemyiIhIBfI9hkar1eLw4cNo0qQJRFHEL7/8gsaNGxd1fXb1+ABhZyWKInx8fJCcnKy6BO3l5YXU1FSbnms2m9GtWzf8/vvvMBqNAB6dSvz222/x6quv2rNMWXFtayWwrR1HrW2ttnYG2NaO9PjZltzku4emYsWK2LJlC/z8/CBJEm7evIn4+Phct/f398/vrokQFxeHo0ePWq2TJAlfffVVkQUaIiJ6euQ70IwdOxZhYWH49NNPIQgCQkJCctxOkiQIgqCqtErKS01NzXFwt9q+RRARkTLyHWiyxjOcOXMGXbt2xeeff251yTZRYQQFBcHV1RXp6enyOp1Ox7FRRESULwW6yqlatWqoVq0a3nzzTfTq1QsBAQH5el58fDwqVKhgdTNJoseVLl0aK1aswMCBA5GRkQFJktCwYUNMnTpV6dKIiEgFbEoYy5cvz/e2ZrMZAQEBOH78OF544QVbDkfFRNu2bfHnn3/i9OnT8PT0RN26dZ/K2SyJiMj+HNJlYsNkxFRMlSpVCs2bN1e6DCIiUhmN0gUQERERFRYDDREREakeAw0RERGpHgMNERERqR4DDREREalekQcaQRDQqlUreHl5FfWhiIiIqJgq8su2NRoN9u/fX9SHISIiomIs34FGo9FAEIR875j3ciIiIiJHyXegmTt3rhxoTCYT5s2bB71ej+7du8PPzw83b97E5s2bYTQaMW7cuCIrmIiIiOi/CnS37SwTJkzA888/j82bN0Oj+b9hOF9++SW6deuGGzdu2LdKIiIiojzYNCh4xYoVGDlypFWYAR6dlho5ciS+++47uxRHRERElB82BZr09HRcvnw5x8cuX76MjIyMwtREREREVCA2XeXUvXt3TJgwAW5ubujevTtKlCiB+/fvY9OmTZg4cSK6d+9u7zqJiIiIcmVToImIiMDDhw8xePBgDB48GDqdDkajEZIkISQkBPPnz7d3nURERES5sinQeHl5YcOGDTh9+jSOHTuGmzdvonz58mjUqBFq165t7xqJiIiI8lSoifVq167NAENERESKs/nWB0ajEYsWLcKQIUMQHByMc+fOAQDWrVuH06dP261AIiIioiexqYfm4sWLaN++PZKSkvD888/j0KFDSE1NBQDExsZi586dWL58uV0LJSIiIsqNTT007777LsqUKYOLFy9i3759kCRJfqxVq1aIjY21W4FERERET2JTD82BAwfw/fffw9fXN9s9m8qVK8eZgomIiMihbOqh0Wq1Vr0yj0tMTISnp2ehiiIiIiIqCJsCTatWrTBnzhwYjUZ5nSAIkCQJixcvRrt27exWIBEREdGT2HTK6fPPP0ezZs0QFBSErl27QhAERERE4OTJkzh37hyOHTtm7zqJiIiIcmVTD02tWrXw22+/oVmzZvj+++8hiiK2bt2KatWq4dixYwgMDLR3nURERES5snlivYCAAN5Vm4iIiJyCzRPr/dfly5exd+9e3L171167JCIiIsoXmwLN+PHjMXbsWHl506ZNqFmzJoKDg1G9enX89ttvdiuQiIiI6ElsCjSbNm1Cw4YN5eVJkyahU6dO+Pvvv9G4cWNMnjzZbgUSERERPYlNgebGjRvw9/cHAFy4cAFnz57F5MmTUbduXYwePRonTpywa5FEREREebEp0JQoUQK3bt0CAOzZswelSpVCgwYNAAAuLi5IT0+3X4VERERET2DTVU4vvfQSpkyZgsTERHz55Zfo3r27/NjZs2fl3hsiIiIiR7Cph+arr75CuXLl8OGHH8Lf3x8zZ86UH1u1ahVatmxptwKJiIiInsSmHpqKFSvip59+yvGxXbt2wdXVtVBFERERERWEzRPrAYAkSfj3339x9+5dlCpVCjVq1IC3t7e9aiMiIiLKF5sn1luwYAHKly+PoKAgtGjRAkFBQahQoQIWLlxoz/qIiIiInsimHprFixdj1KhReP3119G3b1/4+fkhMTER69atw6hRo6DT6TB06FB711poer0eLi4uSpeRJ0EQAAAeHh6QJEnhagpGq9XCy8tL6TLyjW3tOGxrx1FrW6utnQG2tbMRJBt+CrVr18bLL7+MefPmZXts7Nix2LlzJ86cOWOXAu0pKSlJ6RKeSBRF+Pj4IDk5GWazWelyCsTLywupqalKl5FvbGvHYVs7jlrbWm3tDLCtHcnX1/eJ29h0yunSpUt49dVXc3ysc+fOuHz5si27JSIiIrKJTYGmfPny+OWXX3J87Ndff0X58uULVRQRERFRQdg0hmbIkCGYPn06MjMz0atXL/j5+eHWrVv44YcfMHv2bEyZMsXedRIRERHlyqZA89FHHyE5ORmzZ8/Gp59++n8702oxevRofPTRR3YrkIiIiOhJbAo0giBgzpw5mDRpEo4ePYrk5GSUKlUKjRs3RunSpe1dIxEREVGeCjWxXunSpdGpUyd71UJERERkk3wHmo0bNxZoxz169ChwMURF4caNG9ixYwcMBgNeeuklBAUFKV0SERHZWb4DTa9evfK9U0EQVHVNPj29Tp48ia5duyIzMxOCIMBkMmHx4sXo2rWr0qUREZEd5TvQXLp0qSjrICoSo0aNwsOHD60C9jvvvIP27ds/lTNlEhEVV/kONFWqVJH/vW/fPsTHx2PQoEHZtluxYgWqVKlitT2RUs6fP5+ttzAjIwM3btxgoCEieorYNLHe5MmTkZiYmONjt2/fxuTJkwtVFJG9lC1bNts6QRBQpkwZBaohIqKiYlOgOXXqFBo2bJjjYy+88AJOnTpVqKKI7OWzzz6DRqOBRqOBIAjQaDSYNGkSvL29lS6NiIjsyOZ5aO7fv5/jY2q7SRc93YKDg7FlyxasW7cOmZmZ6NChA7p166Z0WUREZGc2BZomTZogIiICPXr0kG+fDgCSJGHBggVo0qSJ3QokKqzGjRujcePGSpdBRERFyKZAM23aNLRp0wb16tXDwIEDUb58eVy/fh0rV67Ev//+iwMHDti5TCIiIqLc2RRoXnzxRezbtw8ffPABJkyYAIvFAo1GI69v2rSpveskIiIiypXNtz5o3rw5Dh8+jPT0dCQnJ6NkyZJwd3e3Z21ERERE+VKoezkBgJubG9zc3OxRCxEREZFNbLpsm4iIiMiZMNAQERGR6jHQEBERkeox0BAREZHqMdAQERGR6jHQEBERkeox0BAREZHqMdAQERGR6jHQEBERkeox0BAREZHqMdAQETkJk8mE1NRUpcsgUiUGGiIihUmShNmzZ6Ny5cp45pln0KBBA5w8eVLpsohUhYGGiEhh3333HebMmQOTyQQASEhIQM+ePZGcnKxwZUTqwUBDRKSwH374AWazWV62WCxISUnB8ePHFayKSF0YaIiIFCYIQrZ1kiQpUAmRejHQEBEprG/fvhBFUV4WRRE+Pj5o0qSJglURqQsDDRGRwkJDQzFx4kTo9XoAQNWqVbFx40aUKFFC4cqI1EOrdAFERMWdIAgYM2YM3n33XWRkZMDNzU3pkohUhz00REROQhAEhhkiGzHQEBERkeox0BAREZHqMdAQERGR6jHQEBERkeo5xVVORqMRixYtwl9//YXU1FT4+vqiT58+aNWqVY7bd+3aFS4uLvJkVEFBQZg6daoDKyYiIiJn4hSBxmw2o1SpUvjkk0/g5+eH06dPY/r06fDz80OtWrVyfM5XX32FSpUqObhSIiIickZOccrJ1dUV/fv3R7ly5SAIAoKCglC7dm2cPn1a6dKIiIhIBZyih+a/MjIycP78eXTp0iXXbSZPngyz2Yzq1atj4MCB8Pf3z7ZNUlISkpKS5GWNRoMyZcoUSc32kjX9+ePToKuFIAiqqptt7Thsa8dRa1urrZ0BtrWzESQnuwOaxWLBF198AYPBgI8//jjHm7adPHkSNWvWhNFoxMaNG7F3714sWLAA7u7uVttFRkZiyZIl8vLAgQMxatSoIn8NRERE5FhOFWgkSUJERATi4+Mxbdq0fM+YOWTIEIwcORINGjSwWq/WHhpvb2+kpKTAbDYrXU6BeHh4IC0tTeky8o1t7Thsa8dRa1urrZ0BtrUj+fj4PHEbpznlJEkSFi1ahEuXLmHGjBkFmv47p14cAPD19YWvr6+8nJSUpJo3ndlsVk2tWSRJUl3NANvakdjWjqO2tlZrOwNsa2fhNIEmMjISZ8+exSeffJLt1NHj4uPjYTQaUbVqVZhMJkRHR8NgMKBmzZoOrJaIiIiciVMEmlu3bmH79u3Q6XQYPHiwvL5Xr17o06cP+vTpg/DwcNSpUwf37t3DwoULkZSUBL1ej2rVqmHatGnw9PRU8BUQERGRkpwi0JQtWxYxMTG5Pr5+/Xr53/Xq1cPChQsdURYRERGphFPMQ0NERERUGAw0REREpHoMNERERKR6DDRERESkegw0REREpHoMNERERKR6DDRERESkegw0REREpHoMNERERKR6DDRERESkegw0REREpHpOcS8nIiJHOX/+PHbu3AlJkhAcHIyaNWsqXRIR2QEDDREVGz///DP69u0LjeZR5/SsWbOwevVqtGvXTuHKiKiweMqJiJyeJEk4d+4cjhw5gtu3b9u8n+HDh8NoNCIzMxOZmZkwmUx4++23IUmSHaslIiUw0BCRUzObzXj77bfRrFkzdOvWDc899xw2bdpU4P08fPgwxzB07949pKSk2KNUIlIQAw0RObWFCxciJiZGXjYajRgxYgQuXLhQoP24ubnBy8sr3+uJSF0YaIjIqe3fvx8mk8lqnVarxYkTJwq0H0EQMGfOHAiCAFEUIYoiBEHAF198IY+pISL14qBgInJqJUqUgCAIVuNczGYzPDw8CryvkJAQ+Pn54ccff4QkSejSpQtatmxpz3KJSCEMNETk1IYNG4Zt27YBeDQ4WKfToUKFCmjTpo1N+2vWrBmaNWtmzxKJyAmwn5WInFrTpk2xfv161KtXDxUqVECHDh2wbds2m3poiOjpxR4aomLk7t27mDt3Ls6dO4fAwECMGzcOZcqUUbqsJ2rVqhVatWqldBlE5MQYaIiKiZSUFLRv3x43b96E0WjEzz//jK1bt+LgwYPw8fFRujwiGAwG6HQ6CIKgdCmkQjzlRFRMREVFITExEUajEcCjy5/v3LmD7777TuHKqLi7dOkSmjRpgkqVKqFy5cqYPXs2JzukAmMPDVExcevWrWwfEhaLBbdu3VKoIqJHEx6GhIQgMTERkiQhMzMTc+bMQYkSJTBs2DClyyMVYQ8NUTFRt27dHL/11qlTR4FqiB75448/cP36dau5hsxmM6KiohSsitSIgYaomAgJCUHXrl2h0Wjg6uoKjUaDjh074vXXX1e6NCrGcju1ZLFYHFwJqR1POREVE4IgYNGiRejXrx8uX76MypUro02bNhyASYqqX78+fH19cffuXZjNZgCPZoLu2bOnwpWR2jDQEBUjgiDwEmhyKp6enti4cSPefPNNXLx4ERqNBkOHDsXo0aOVLo1UhoGGiIgUVatWLZw6dQoJCQlwd3eHXq9XuiRSIQYaIiJSnCAIKFmypNJlkIpxUDARERGpHgMNERERqR4DDREREakeAw0RERGpHgcFO1hcXByOHTsGLy8vdOzYEd7e3kqXREREpHoMNA60atUqhIWFQa/Xw2w2o2zZstixYwfKly+vdGlERESqxlNODnLjxg2EhYXBYrEgIyMDRqMRiYmJ+PDDD5UujYiISPUYaBzk/Pnz2e5ZYjKZEBcXp1BFRERETw8GGgfx8/PLFmg0Gg3KlSunUEVERERPDwYaB6levTr69u0LrfbRsCWNRgONRoOpU6cqWxgREdFTgIOCHUQQBHzzzTeoX78+Dh8+DG9vbwwZMgT16tVTujQiIiLVE6T/ngd5iqWkpMDFxUXpMvIkCAL0ej0MBkO2U1TOTqvVwmQyKV1GvrGtHYdt7ThqbWu1tTPAtnak/Hx2F6seGoPBAIPBoHQZ2Tx48AAJCQnw9fWFn58f9Ho90tLSYDablS6tQLy8vJCamqp0GfkmiqJTt/X169dx584dBAQEwNPT0+oxtrXjsK0dQ23tDLCtHSk/gYZjaBS2detW1K5dGy1btkTt2rUxdepUVSV9sj+z2Yxx48bhueeeQ9u2bREUFIQ9e/YoXRYRkVNjoFHQuXPnMHToUGRkZMjrIiIisGLFCuWKIgCPes1OnTqFW7duOfzYkZGRWLt2rbycnp6OgQMH4urVqw6vhYhILRhoFHT48GH5qqcsZrMZ27dvV6giAoCYmBjUqlULrVu3Rp06dRAeHu7QXrPdu3fneH77xA6/s6kAACAASURBVIkTDquBiEhtGGgU5OLiku2DUhAEuLq6KlQR/fvvvxg2bBgyMzPldZGRkVizZo3DanBzc8u2zmKx8H1BRJQHBhoFBQcHw8vLC6IoyusEQcBbb72lYFXF25EjR3LsNdu3b5/Dahg6dCgEQZCXtVotypUrh5YtWzqsBiIitWGgUVDp0qWxdetWPP/88/D09ETVqlWxZs0avPTSS0qXVmy5urrm2Gvm7u7usBratWuHZcuWISAgACVKlEDz5s2xdevWbFc6ZXnw4AHu3LnDweSkqK1bt2LMmDH44IMPeHqUFFGsLtt2RtWqVcOOHTvk5cd7a8jxgoOD4e3tjXv37snjWARBwIABAxxaR5cuXdClS5c8t8nMzMTYsWOxYcMGAI/eS1FRUQgICHBEiUSyb775BjNnzoQkSRAEAd999x3WrFmD9u3bK10aFSPsoSGnZzKZEB8fj7t37xb5sUqVKoWtW7eiQYMG8Pb2RmBgIFavXo2mTZsW+bELaurUqfjxxx/l5UuXLqF3795OOdcSPb1SU1Mxc+ZMWCwWSJIEi8UCi8WCCRMmKF0aFTPsoSGndvLkSfTr1w83btwAAPTs2RPffPMN9Hp9kR0zMDAQW7duLbL920tMTAyMRqO8bDabceXKFVy4cAG1a9dWsDIqTm7dugWLxZJtfWJiogLVUHHGQENO68GDB+jdu7dVz0xMTAzKly+P8PBwBStzDhpNzh2sua0vStu2bcPmzZuh0WjQs2dPBAcHO7wGUkaFChXg4uJidWWgKIoIDAxUsCoqjnjKiZzWqVOnkJSUZPXtz2g0qqL3xBFCQ0OtrsjS6XQICgpCtWrVHFrH0qVLMXjwYGzevBkbN25EaGgoVq9e7dAaSDlubm6IiIiAKIpwcXGBXq+Hm5sb5s+fr3RpVMywh4acVm6nlXQ6nYMrcU5hYWHIyMjA0qVLYTAY0LhxY0RGRjp0YLnZbEZ4eLhV6JQkCZMnT0b//v2tLj+np1e3bt0QGBiI2NhY6HQ6dO7cGRUqVFC6LCpmGGjIadWpUwc1a9bExYsX5bEioihi8ODBClfmHERRRHh4OKZMmQKLxaLIFXKpqak5DkJOS0tDZmYmJwMsRurWrYu6desqXQYVYzzlRE5Lr9cjOjoaL774IlxcXODj44PJkydjyJAhSpfmVARBUOxy/xIlSsDX19eqJ0aj0aBixYoMM0TkUOyhIYfJmvitIKch/Pz8EB0dXVQlUSEJgoBly5ahb9++kCQJkiRBp9Nh6dKlSpdGRMUMAw0VOaPRiClTpmDNmjUwm83o0KEDvvnmG3h7eytdGtlBs2bNcOTIERw4cACCIKBt27YcP0FEDsdAQ0UuPDwc3333nTwOZvfu3Rg0aBA2bNjAQaNPicqVK8uzKUuShDt37sBisWQ7HUVEVFQ4hoaKXFRUlNUEcEajEbGxsUhKSlKwKioKycnJ6N69O2rVqoWgoCB07NgRt27dUrosIioGGGioyGXdE+m/zGaz3Y/14MEDJCcn232/lD9vv/02jh8/Li/HxcVh0KBBClZERMUFAw0VuY4dO1rNHaPValG7dm34+fnZ7RgPHz7EoEGDEBAQgBo1aqBt27a4fv263fZPT2YymXDgwIFsvXHHjh1DamqqgpXR08ZkMmHfvn1Yv349/vnnH6XLISfBQENF7quvvkLLli3l5Ro1auD777+369iKCRMmYNeuXfLy6dOn8dprr+V4jxmyzYMHDxAfH28VWB4nCEKuP1PeRZ7s5eHDh+jSpQv69++P9957D61bt0ZkZKTSZZETYKAphD179qBTp05o3rw5JkyYgLS0NKVLckpeXl5Yt24dzpw5g5MnT+LAgQOoWLGiXY+xdetWqw9ak8mE06dPs5fGDiRJwqeffopnnnkGDRo0QK1atXDw4MFs24miiF69eln1xul0OnTq1Anu7u6OLJmeYrNnz8Zff/0Fs9mMzMxMSJKEjz/+mD01xKucbLVnzx6EhobKPQCXL1/GP//8g82bN/PbaC5Kly5dZPt2phs1Pm2ioqLw9ddfy/MIpaSkoH///vjll19QuXJlq21nz54NURTluYM6d+6MOXPm2HTczMxMREdH4/r166hWrRq6du3KnyfhxIkT2XoJ9Xo9Tp48iaCgIIWqImfAQGOjuXPnWp3OMBgM+PXXX/HXX3/hhRdeULCy4qlv375YsWKF/IdOp9Ohfv36KF++vMKVqd+2bduyDeCWJAmHDx/Ga6+9ZrXezc0NX3/9NebNmwegYJMoPi49PR1du3bFqVOnoNFoYDabsWnTJixfvpyhppgrW7YsNBqN1d9fk8lUpF+YSB34l8FG9+/fz7ZOo9HkuJ6K3tSpUxEaGgq9Xg9RFNGiRQusWrWKc6DYQU43Cc2aETg3eY2nyY8lS5bg1KlTMBqNyMzMhMlkwu7du7Flyxab90nKy8jIwO+//44///wTmZmZNu3jvffeg1arlYOtTqfD888/j1atWtmzVFIhBhobNWvWLNsfdK1Wyy5Phej1enzxxRdISEjAtWvXsH79en5js5N+/fpZhRNRFOHl5YXWrVsX2THPnz+f7XJ/URRx/vz5IjsmFa2LFy/ixRdfxMsvv4wOHTqgZcuWuHr1aoH3U6dOHezevRtdu3bFiy++iOHDhyM6OhpaLU84FHcMNDaaOnUqnn/+eQCP/tDq9XosXbrUrpciO4O4uDi0a9cOAQEBaNGiBY4cOaJ0SXlS8kaNWVJSUrBhwwasXLkSZ86cUbQWewgODkZERATKlCkDrVaLWrVqISYmpkgDY6VKlbJ9YbBYLKhUqRIA4PDhw5gzZw4iIyM5cZ9KDBgwADdu3JCXr169avMcRXXq1MGSJUsQExOD8PBwDjonAIAgZY30KwbsPTOt2WzG77//jpSUFNSpUwflypUr9D5FUYSPjw+Sk5OLZOK5gkhISECLFi2QkZEBs9kMQRCg1Wqxd+/eHHuivLy8VDXfSGZmJpKTkyGKIsqUKWPzfiwWCxYuXIjo6GiYzWYkJCTg4cOHEEURRqMRERER6NWrlx0rV19bF/R9fe/ePbRt2xaJiYkwGo3QarV49tlnsWXLFixZsgTTpk2DXq+HJEnw8PDArl27EBAQUCS1P+1t7QgpKSkIDAzMtl4QBCQkJECv16uunQHnbOv8UGNb+/r6PnEb9tEVgiiKaNSokdJlFJkff/wRRqNR/kXNupvyunXrMG3aNIWrK5z9+/dj8ODBePDgAQAgNDQUX375pU29O9OmTcPixYuznSLJWh49ejTatGnDU2AFULJkSezfvx9LlizBtWvXUK1aNQwZMgS3b9/GtGnTIEmSPAbDYrFgwoQJWL9+fZHUsmvXLmzbtg0uLi7o3bs3ateuXSTHyQ+LxYJNmzbh9OnTKFeuHF577TV4enoqVk9+ubq6QhAE/Pf7s1ar5akishu+kyhXGRkZ2QZ2SpKEjIwMhSqyj+vXr+ONN96weh1r165FYGAgRo0aVaB9ZWZmYtGiRXlO4GcymXDx4kUGmgIqUaIEwsLCrNZdunQp23Ymkwn//vsvgEeT/61cuRIJCQmoXr06QkND8xy8/CSLFi3ClClTIIoiBEHAokWLsHHjRjRt2tTmfdpKkiQMHToUO3bskAfELl26FLt373b6O9fr9XoMGjQIK1eulIO+VqvF8OHDedUa2Q3fSZSrVq1awWAwWK2zWCxo27atQhXZx/Hjx7N1D5tMJqxatQqnTp0q0L7S0tLyNRtx2bJlC7RfR8rMzFTNjMoVK1bM9i1fFEVUrlwZDx48QHBwMGbOnInly5fjo48+Qq9evXK9l9iT3Lt3D+Hh4ZAkCSaTSe6tHD9+vD1eSoHt2bMH27dvh8lkgsFggMFgQHx8PP73v/8pUk9BzZw5E2PGjEGVKlVQtWpVvP/++5g8ebLSZdFThIGGctWwYUPMnTtX7hIWBAGTJ0/Gyy+/XKj9Go1GLFq0CCNGjEB4eHiRzuZ78uRJhISEoGHDhggNDUV8fDxcXV1z/AC/fPky2rZti++++y7f+/fx8UHlypVzPVWl1WoxYMAAVKlSxebXYIvk5GSEhYWhY8eOeOutt3DhwoVs21y+fBlt2rRBpUqVUKlSJXzyySdOH2wCAgIwcuRIiKIIURSh0+mg0+kwa9YsREZG4sqVKzAYDHIAOXbsGDZu3GjTsW7cuJGtPSwWi2KzT1+8eDFbb5PRaFTNlV9arRYffvghTpw4gePHj+O9995TfAA/PV14yonyFBoaiq5duyIhIQHlypVDqVKlCrU/i8WC0NBQxMbGwmQyQRAELF26FNu2bUP9+vXtVPUjFy5cwCuvvCJ/s7569SpiY2Px7bffonz58vKA08drA4APPvgArVu3zlcIEQQBq1atQs+ePeW7fPv4+KBx48aQJAmtW7d2+N2m09LS0LFjR1y9ehVGoxF//vkn9u7di/3796Nq1aoAHk1cFxISgps3bwKAPHi5RIkSGD16tEPrLaipU6eifv36+OWXX+Dp6Yn+/fsjMDAQS5cuzTaDrCiKNl0aDDzqDdJqtVY9PBqNxuHhNIu/v3+216fT6eSfqS2yep8Kc1qOyFmwh4aeyNvbG0FBQYUOMwBw4MABHDhwQP6QkCQJBoMBXbt2xb179wq9/8etXLkSZrNZPr1ksViQnp6O/v37Izw8HE2bNs3x/L0gCDh79my+j1OnTh0cO3YM69atww8//IATJ05g5cqVWLVqFYYMGeLwMQIxMTFymAEeXY2XkZGBJUuWyNvExcUhISHB6sPaZDLh+++/d2itthAEASEhIfjiiy8wZcoU+eqZqlWrZvtgNpvNNgcQb29vfPHFFxAEAS4uLtDr9XBxccHXX38tb5OZmYm4uDicOXOmyK9y6dixI1q1agWdTidPFeHn52dTAJUkCV9//TX8/f1RsWJFtG7dOsdevMJITk7G0KFDUbt2bTRq1EgV7y1SN/bQkEPduHEjxxlkMzIyEBUVhZEjR9rtWKmpqTl+yFgsFnzyySf4448/0KdPH/z0009WpxbMZnOBL+P29vYu0onmCuLu3bvyJeNZTCaT1bQFuc3WoOZZHIYNG4aNGzfiwoUL8hU1zZo1Q0hIiM37HDBgAOrXr48dO3bAxcUF3bp1k3tEzp07h969e+PatWsAgLp162L9+vWFmgIgLxqNBmvWrMGaNWtw+vRp+Pn5YdCgQShZsmSB97Vy5Up8+umn8u/HmTNnEBISgiNHjtjlqimTyYTevXvjn3/+gdFoRFJSEsaOHQutVovevXsXev9EOWGgoSJx9uxZzJo1C9euXUO9evXw8ccfw8fHBzVq1Mj1m6y95wlq0qQJoqKicnwsaxzEzJkz0bx5cwCPgo5Op0O7du0KfforJiYGixYtQnp6Ojp06ID333/fqvfg6tWrmD9/Pm7evIl69erhnXfegaura6GOmaV+/frZBnNnTQ+f5dlnn0WFChWQmJgo/zy0Wi369OljlxqUkDUfTVRUFK5fv47AwED07du30OM0mjVrhmeffdZqncViweuvvy6fsgMevedHjhyJH374oVDHy4tWq8Wbb75Z6P2sWbPG6vfQbDYjMTERJ06csEsw//vvv/HXX39ZrbNYLIiIiHCaQCNJEpYsWYIlS5YgMzMTwcHBmD59OifpUzEGmqfQxYsXcfbsWZQpUwYNGjRw+P2MLly4gA4dOsBgMMBsNuOff/7BkSNHsG/fPjRq1Aht2rTB/v37sz1vy5YtiImJQePGjTFr1iybvnk+rk+fPjh+/Hi2Qb4ajUa+S3Tjxo2xd+9ezJ8/H8nJyXjxxRcxcuTIQrXZhg0bMHLkSLm34+zZs7hw4QKWLVsGAIiPj0ebNm3w8OFDmEwm7NmzB/v378fmzZvtMidH8+bNMXbsWMydOxd6vR5GoxFt27bF0KFD5W3c3d2xceNGDBgwAOfOnYNGo8GQIUPw7rvvFvr4SnJ3d7d6nYWVlpYGDw+PbOtv3ryJK1euWK0zGo04fPiw3Y5dlHL7UmGvQeHp6ek5zjvz8OFDu+zfHhYuXIjp06fLbREVFYUbN25g9erVvAecSjHQPGWWLVuGSZMmQaPRwGQyITg4GCtWrLDqHXj48CHS09NRqlQpCIKAc+fOYcaMGYiPj0dQUBCmTp2a52XGx48fR0REBO7fv48WLVrg3Xfftdr/okWL5DADPPpDf+XKFcyYMQOvv/461q5dix49euDIkSMQRREmkwmSJOHy5csAHvWe/PPPP9i9e3eON0bML0EQ8OWXX6JSpUqYOXMmdDqdfNPEb775Rt6uXr16WLhwoc3H+a/PP//c6g+50WhETEwM4uPj4e/vj6+//loOM1mPnzhxAnv27MErr7xilxomTpyIevXq4aeffkK5cuXw9ttvZwtLgYGBOHLkCFJTU+Hq6mr1M3zw4AFOnToFvV6PunXrOv2g0Zs3byI1NRX+/v5wcXEp9P5OnjyJQYMG4fLly9DpdPjggw8wZswY+YPOzc0tx+fZ49iOkHU6KOs9qNFo4OPjgwYNGthl/3Xq1IGnpycePHgg/y5k9X46i4iICKtgZzQasXv3bty8eRPly5dXsDKyFQPNUyQuLg4TJ06EJEnyN639+/djwYIFGDNmDIxGI8aPHy8PzgsMDMQXX3whTzJnNpvx77//4siRI4iNjc1xsq5vv/0WEyZMkJd/+eUX/Pnnn1i5cqW8LikpKcd5XlasWIFly5bh7bffxqZNm3DkyBHEx8dj2bJlVt3TRqMRp0+fxs8//wxfX1+YTCbUqlUrx2/K+TF27Fg0b94cP/30E7RaLbp3757jNOw5MRqNBf4wz+2O61nrr127lm1uFJ1Oh8TExAIdJy8bN27EyJEj5at0Vq1ahW3btsk9U4/z8vKyWo6Li0Pv3r1x584dAECtWrWwYcMGp7xPmdFoxOjRoxEdHQ3g0QzDa9asQePGjW3e5927d9GjRw+kpKTIx/jss89QunRpDBgwAMCjK9m6deuG7du3y2OVtFot3n777UK+IscYNmwYEhMTsWDBAlgsFpQvXx6rV69GiRIl8vV8SZLy7MUoWbIkoqKiEBoaKr/vW7VqhSlTptilfnvIrbcoLS3NwZWQvfAqp6fIn3/+ma1Hw2g04tdffwUAzJo1Cxs2bJAfu3z5Mt58801kZmZa9abcvn0bmzdvzrb/+Ph4TJw40Wqd2WzGzp07ERcXh+TkZPz444/Q6/U5njrJOsbixYvx+eefY8qUKfjyyy8RHx+fbVuNRoPx48ejffv26NixIxo2bIiZM2eiU6dOePXVV7Fq1apcB7BevHgRW7ZsweHDh+VjNmrUCBMmTMD48ePzFWZ2796NWrVqoUKFCggKCsLWrVvl2yQ8SePGjXO8sunixYsAHo1f+W9IyszMRK1atfK1/ydJSkrCqFGjYDab5Z/tjRs30LBhQ2zatCnP55pMJvTr10++BB14dArxnXfesUtt9jZ79mzExMTIy/fv38drr72Gu3fvZtv20qVLiImJQWxsbLbLnx939OjRbAPKzWZztrEx8+fPxxtvvAE/Pz9UrFgREyZMwPvvv1/o15SQkIDhw4ejffv2GDFihNUNHQvq1q1b2L17N2JjY61mxtZoNAgPD0d8fDzOnj2LP/74A3Xr1n3i/nbv3o1nn30W5cqVQ+PGjXHixIlct23atKk8ZcCvv/6KqKioXHu2/lvzDz/8gLVr18oDrovCSy+9ZPV7qNFo4OfnB39//yI7Zk7++OMPTJw4EePHj8fOnTsdeuynjWp7aB48eICIiAj8/vvvcHNzQ0hICLp166Z0WYoqUaJEtp4RjUYjX269ceNGqz/kZrM5xw9pQRByvIR6165duZ5jj4uLw+uvvy5/EFosFvn0zn+fo9FoMGfOHKvl/8oapJglKSkJ8+bNk5dPnDiB5OTkbGM+Vq1ahbCwMPlU1osvvoi1a9fKf0iPHj2K6OhoGAwGdO7cGa+//rr83NTUVGzatAn//PMPli9fLtd9+/ZteS6Ztm3bYsmSJXlONT9r1izs2rUr2/rJkyejW7dueOedd7Bjxw5cuHABWq0WBoMBI0aMsNt0+ufPn8/xA9tiseDtt99G1apVrQYIPy4hIcFqoCvwKOQePXrULrXZ286dO61eqyRJSEtLw19//YU2bdrI69etW4cxY8ZAo9HAbDajfv36iI6OLtQVPa6urvjss8/w2WefFeo1PC4xMRHt2rVDSkoKTCYTTp06hYMHDyI2NjZfN+d73MGDB9GvXz8YjUZYLBY888wz2Lx5s1VPm4uLS75Pk504cQIDBgyQfy+uXLmCHj164Oeff8710nhPT08899xz+a45Li4OISEhSE9PB/BoHqG1a9eiWbNmeT7vypUrGDVqFOLi4uDj44MpU6Y88eq2r776Cq+99hr++OMPAEDp0qWxdu3aQp3mLqiffvoJ/fr1A/Dovbt69WqEh4fb9WpPR7hx4wZiYmKQkZGBFi1a2O3UZUGptocmMjISRqMRy5cvx9SpU7Fhwwb89ttvitYkSRKio6MRFhaGqVOn2n1ehyfp0KEDAgIC5G8dGo0GoihixIgRAJDr1R7/XW8wGPDCCy9k285sNuc6b8vixYtx9+5dGI1G+Q+om5sbXn755Wy9Nf8NXY8HHkEQoNfr5UCSG7PZjBkzZmD58uXyunPnziEsLAwWiwVGoxGSJOH48eP48ssvAQA7duxA165dsXLlSnz//ffo378/vvnmGyQkJCAqKgqNGzfGhx9+iBUrVuQa3H7++We5tyImJgbNmjVD7dq18cYbb+D27dvya8jJrVu3cPLkSbRs2RJnz56FyWSCv78/oqKiMHXq1Fxfa0HlddmwTqfD3r17c308tw94Z73yI6crwyRJsvqQjo+Px5gxY2A2m+X3ZlxcHD755JMc99m0aVN4eXlZ/V6IouiQq3NWr16NBw8eyO99k8mE+/fvY+3atQXaT1paGt544w2kp6fDZDLBYrHgypUrGDt2rM21RUdHW723LRYLLBYLtm/fbvM+/2vYsGF48OCBfGuHjIwMDBo0KM/ByikpKejSpQtOnDiBtLQ0uYdrz549eR6rVKlS2LFjB2JjY7Fnzx6cOHEiX71U9vT+++/Lc2Vltee0adPy3RvsDM6cOYMWLVpg+vTpmD17Nl555RWsWbNGkVpUGWgyMjJw+PBhDBgwAO7u7qhatSqCg4Of+AYuauHh4XjnnXewatUqREZGonXr1vj7778ddvyLFy8iMzMTRqMRgiAgICAA27dvl39JQ0NDrcKFVqtF9erV0bVrVwCQg1BYWBhatGiRbf9t27bN8cN6+PDhOH/+fLYA8vDhQ4wePRoeHh5WQSinU0VarRYzZ85EdHQ0/vjjj2zjOnIzYcIE+TTK33//nS08Pd678P7778Nisch/PCRJwrhx49CgQQOMHTsWSUlJVncXz4nRaJTvqTN06FCcO3cOSUlJ2Lt3L7p164aMjAz4+fll61rPurKqb9++uHXrlrz+0qVL2LJlS75ea34988wz6NOnT44/K0mS8ryM2dfXFz169LDqihdFEWPGjLFrjfby1ltvWb23dDodAgMDrQL5yZMnswXxvHqdfHx8sHHjRnm8kV6vx4cffojQ0NAieAXWkpOTs314S5KU4ym0vJw7dw6pqalW64xGY6G+9GUN3s9pvT2YzWZcuHDB6vcv67VnjefKycGDB3H79m2rOiRJwooVK554TFEUUbt2bdSvX1+R0J7TuDmLxWLX8XRFbdy4cUhLS4PBYEBmZiYkSUJYWJjdJ0rND1UGmmvXrkGSJKtuzoCAgBzHYjjKpUuXsHDhQvnDMuteMh999JFDjn/37l2EhITI55wlScKlS5dw5swZeZuxY8fK851oNBo0aNAA0dHRiIyMxK5du7B48WL8/PPP+OCDD3I8Ro0aNbBq1Sr5W7xGo8F7772HGTNm5DiYUBAE1KpVC2PHjn3i5aAajQZdunRBy5YtUbZsWYwePTpf84dIkoRVq1YBeDQQMadTbqVLl4YkSXIPyuMe783Jr6y7Lv/3SqYLFy7g6NGj0Ov1mD9/PkRRlLv09Xo9wsLCcOvWLau2yApI9pR1Fdfw4cOzrQeALl265Pn8//3vfxg2bBiqVq2K6tWrY+bMmXIvn7Pp3bs3Zs+ejXLlysHT0xPNmzfHpk2brHpufHx8sn3oCoKQ593P69ati+PHj+PSpUu4d+8exo4d65BLeV944YVs70WLxZLrKcLc+Pj45Li+MHflDg4OzlabyWSyOrVXGKIo5vhFRhTFPAcrGwyGHHuOHx8z5KwCAgKy1e7i4qKqq6zOnTuX40UgSnweq3IMTUZGRrY07eHhIZ93zZKUlGQ1WZtGoymyWTyzZsB9/Bc+6/5BBZnYK2vbgk4GltNARovFgvXr16N///7yPsPDwzFlyhRYLBarYzRq1Chfx+nYsSMuXbqEpKQklCpVSv4mP336dKu5V0RRxMiRI1GyZMkcvwlntVXWKably5ejUqVK8uNjxoyBq6srli1bBqPRiCZNmmD79u05XoGQ9Vpat26NZ599FqdOnYLRaIRGo5FDl1arRUBAAC5dulSouTZ0Oh26deuGc+fOZXtMo9EgIyMDoigiJCQE1apVw08//QRRFPHqq68iMzMzx326uLgU+OctCEKezxFFEbNmzUKbNm0wduxY3Lx5E5UqVcKCBQueOPjYzc0NM2bMwIwZMwpUU15sfV/nx6BBg/K8X9aLL76IJk2a4LfffpN7LwVBwIQJE55YT4kSJeQbYTpCr169cPjwYaxcuRJ6vR4GgwGDBg1Ct27d8h2oRFFElSpV0LNnT8TExMhjjARBwKRJk2x+LR07dsTnn3+OSZMmwWQywc3NDQsXLizQGJm8CIKAGTNmYOzYsfLfEY1Gg0mTJuU5mLhZs2bZ2kar1aJTp05F/nMrP8yH2wAADhZJREFU7Pt6wYIF6NKli9UUDvPnz893D7WtnvT3oyAqVqyIlJQUq88+QRBQqVIlx998VFKh8+fPSyEhIVbrDh06JI0YMcJq3aJFi6QGDRrI//3vf/8rspri4+MlQRAkAPJ/Wq1Wevnll4vsmI+Ljo6WdDqd1fEBSK1bt3bI8SVJkmJiYqRXX31VCg4OlhYuXChZLBZJkiSpZ8+e2erS6XTSzJkzpf3790u3b9/O1/5Pnz4tubq6ZmvjiIgIeZuUlBRp1KhR0gsvvCB16tRJOnr0qPzY0aNHJQ8PD8nFxUVydXWVRFHMVtfj9fXp00e6cOGC1L17d0kURUmn00n9+/eX0tLSpI8//jhbe7u6ukrXrl3LtX6z2Sw1bdpU0uv1VvXPnTvXxhbPv6yfRXGVlpYmvffee1KjRo2kV155RTp06JDSJeXp6NGj0rp166Tjx4/bvA+DwSCFh4dLDRo0kFq2bClFR0fbpbb09HTpypUrUmZmpl3291+bN2+WunfvLnXp0kVatWpVvp6zc+dOycvLS/69GjVqlGQ2m4ukPnu7fPmyNHfuXOmzzz6TfvvtN6XLKbCDBw9KOp1O0mq1kkajkTQajTR16lRFahEkSX03b8nIyEC/fv0wb948+RK71atXIyEhAR9++KG8nSN7aIBHEzVNmTIFer0ekiTBw8MDe/fuRUBAQL73IYoivL29kZKSUqCb3d25cweNGjVCSkqK3AMhiiLmzp0rz51R1Dw8PHLsQdm1axf69etn1Xvj5eWFY8eOFfjKjaNHjyI0NBR37tyBIAgYPXo0wsPD8/3t9erVq9i2bRtMJhPatWuHWbNmYffu3fI3d+n/3yG7S5cuePPNN+XuYLPZDEEQ5GWj0Yi33npLvmTY3d0dK1asQPv27fM8ftbpi4MHD8LV1RUjR47EqFGjCnw6I7e2dla2vq+dAdvaMQrbzunp6YiPj0fp0qUL/HfFVsW1rf/r5MmTiIqKQnp6Olq3bl0kVxzndhr1caoMNAAwZ84cZGRkYNy4cbh9+zY+/vhjjBkzJs/Lxex9r6CcHD58GEePHoWnpye6d++e54y7ORFFET4+PkhOTi7wL8hff/2FgQMHIiEhAVqtFu+//z7GjRvnsGm8vby8sg1EzLJ27VpMmTIF9+/fR40aNRAZGYmgoCCbjmM2m3Hr1i14e3vbPNke8Kit3d3dMXHiRBw4cAAlSpTAqFGj0KpVq3w9X/r/sxvfv38fgYGBRd5N/Li82toZFeZ9rTS2tWOorZ0BtrUj5SekqjbQPHjwAPPnz5fnoenRo8cTU6EjAk1h2eMXJDU1Fe7u7g4/f5mfXxLpCTOMOpJa/xgB6vuDxLZ2HLW2tdraGWBbO1J+Ao0qBwUDj+bLePz0Ev0fR/YUFJSzhBkiInq6qPKybSIiIqLHMdAQERGR6jHQEBERkeox0BAREZHqMdAQERGR6jHQEBERkeox0BAREZHqMdAQERGR6jHQEBERkeox0BAREZHqMdAQERGR6jHQEBERkeqp9m7bT6ukpCRER0ejZ8+e+bq7KNmObe04bGvHYVs7Dtv6/7V3vzFVln8cx9+nIxyRqXiQv5rCWhhn1lLKapEnOJhutlyRbbVW/DG3spW2uVqtxLBk5MqK1gOsqIkzsWzqaJkgPklEKlcUD5x22NgqOCokNpCT5/fgt9iPmv48eM59cx0+r0fcf7ivz/nufvDlum7OPb5ohmacCQQC1NbWEggE7I4S81Rr66jW1lGtraNajy9qaERERMR4amhERETEeM6KiooKu0PIaAkJCdxyyy1MmTLF7igxT7W2jmptHdXaOqr1+KGHgkVERMR4WnISERER46mhEREREeNNsjuAXNrnn3/OoUOH6OnpITExkYKCAh555BGcTqfd0Yz1ww8/8Omnn3Ly5Eni4+P55JNPLnv+iRMnqK2tpaurC7fbTWlpKYsWLbIordnCrfWpU6eora3F7/cTHx9Pfn4+ZWVlut+vQDi17u3tZc2aNaP2DQ0NsXz5clavXh3tqEYL954GaGxs5IsvvuDs2bO43W7Wrl1Lbm6uBWknHjU041goFOKZZ54hOzubM2fOsGnTJqZMmUJxcbHd0Yw1efJkioqK8Hq9bN++/bLnDgwM8Oqrr1JSUsLdd9/N8ePH2bx5M++88w6ZmZkWJTZXOLUGqK6u5o477mDTpk309fWxYcMG9u/fz4oVKyxIa7Zwap2SksKuXbtGtgcGBnj88cfJz8+PdkzjhXtPNzU10djYyIsvvsjcuXMJBAJcc40WRqJFlR3HiouLuf7665k0aRKpqal4vV5+/vlnu2MZLScnh4KCAjIyMv7vuZ2dnSQmJuLz+XA6neTl5TFv3jxaWlqiHzQGhFPrUChET08PBQUFOJ1OkpOTycvLo6ury4Kk5gun1v90+PBhUlJS8Hg8UUgWW8Kp88WLF6mvr6e8vJysrCwcDgcpKSkkJydbkHRiUkNjkJ9++ok5c+bYHWNC+ec/AYZCIfx+vz1hYpjD4eC+++6jqamJ4eFhent7aW9vZ+HChXZHi3lNTU34fD67Y8Sc06dPEwgE6O7upry8nLKyMj744AOGh4ftjhaz1NAYYv/+/fj9fu6//367o0wY8+bN448//uDAgQMEg0GOHTtGZ2cnQ0NDdkeLSYsWLaK1tZWVK1dSXl5OTk4Od955p92xYtovv/zCqVOnKCwstDtKzPn7dQjt7e1s3bqVN954g46ODnbv3m1zstilZ2hsUlVVxTfffHPJ43v37h35+dChQzQ0NPDaa68xbdo0K+IZKZyaXolp06bx8ssv8+GHH1JXV8cNN9xAfn4+cXFxVxvVeJGu9blz59i4cSNlZWX4fD4GBgZ4++23qauro7S09GrjGi3Stf5fTU1NLFy4UMsgRL7OLpcLgAceeICpU6cCsGLFCvbu3cvDDz889qBySWpobPLCCy9c0XktLS189NFHVFZWMnv27CinMtuV1jQcHo+HLVu2jGyvX7+eoqKiiI9jmkjX+rfffiMUCrF06VIAkpKS8Pl87Ny5c8I3NNG4rwGCwSAtLS08+eSTUbm+aSJd51mzZumPH4tpyWkcO3z4MNu2bWPDhg3MnTvX7jgx4eLFi1y4cIFgMAjAhQsXLrumffLkSYaHhxkcHKShoYH+/n5Nz1+hcGo9a9YsnE4nBw8e5K+//uLcuXM0NzeTnZ1tZWRjhXtfA7S1tQHoawjCEE6dXS4XixcvZs+ePZw/f56+vj727dunekeRXn0wjq1atYrTp0+P6vI9Hg96/dbY/fjjj7z00kuj9qWmprJt2zYAKioq8Hg8PPTQQwC8+eabtLW1EQqFuPHGG1m1ahXp6emW5zZRuLXu6Oigrq6O7u5u4uLiuOmmm1i9ejXTp0+3PLtpwq01QGVlJenp6TzxxBOWZjVZuHX+888/ef/992lrayMhIYG77rqLxx57TDM3UaKGRkRERIynJScRERExnhoaERERMZ4aGhERETGeGhoRERExnhoaERERMZ4aGhERETGeGhoRERExnhoaERERMZ4aGhERETGeGhoRsVxWVhZPP/20LWNv3bqVxsZGW8YWkejRqw9ExHLff/89M2bMICsry/Kxs7KyuPfee6mpqbF8bBGJnkl2BxCRiWfBggV2RxCRGKMlJxGJqJKSEubPn8+XX37J/PnzmTx5Mnl5ebS2to6cE+6Sk8PhoLq6moqKCtLS0pg5cyalpaWcP39+1Hnd3d08+uijzJw5k4SEBBYvXsy33347atyuri7ee+89HA4HDoeDurq6q/7MImI/NTQiEnG//vorTz31FOvXr2fXrl24XC6WLl1KT0/PmK9ZU1PDiRMn+Pjjj3nllVfYsWMHlZWVI8fPnj1Lfn4+x48f59133+Wzzz4jMTGRwsLCkXH37NlDeno6Dz74IEeOHOHIkSMsX778qj+viNhPS04iEnFnzpyhoaGBwsJCALxeL9deey1vvfUWmzdvHtM1MzIyqK+vB2DZsmV899137N69m6qqKuC/D/v29fXR1tZGamoqAD6fj5ycHLZs2UJ1dTULFizA5XKRlpbG7bffHoFPKiLjhWZoRCTipk+fPtLM/L1dVFTE0aNHx3zNJUuWjNr2eDx0d3ePbB84cICCggLcbjfBYJBgMIjT6cTr9XLs2LExjysiZtAMjYhEXEpKyr/2paWl0dnZOeZrJiUljdqOj49naGhoZDsQCNDa2kpcXNy/fve6664b87giYgY1NCIScb29vf/a9/vvv5ORkRG1Md1uN8uWLRv1XM3fXC5X1MYVkfFBDY2IRFx/fz/Nzc0jy079/f0cPHiQNWvWRG3MoqIitm/fTm5uLomJiZc8Lz4+nsHBwajlEBF7qKERkYhzu92Ul5ezceNGkpKSqKqqIhQKsXbt2qiN+dxzz1FfX4/X6+XZZ59lzpw59Pb2cvToUTIzM1m3bh0Aubm5NDc38/XXXzNjxgyys7NJTk6OWi4RsYYeChaRiMvIyKCmpoaqqipWrlzJ4OAgX331FWlpaVEbMzk5mdbWVm6++Waef/557rnnHtatW4ff7+e2224bOe/1119n9uzZFBcXc+utt7Jv376oZRIR6+jVByISUSUlJbS3t9PR0WF3FBGZQDRDIyIiIsbTMzQiYqtgMHjJYw6HA6fTaWEaETGVlpxExDZ+v5/s7OxLHvd6vbS0tFgXSESMpRkaEbFNZmbmZb/Fd+rUqRamERGTaYZGREREjKeHgkVERMR4amhERETEeGpoRERExHhqaERERMR4amhERETEeGpoRERExHhqaERERMR4/wGKHFAbtNERTwAAAABJRU5ErkJggg==\n"},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":["<ggplot: (8761765228977)>"]},"metadata":{},"execution_count":55},{"output_type":"stream","name":"stdout","text":["time: 202 ms (started: 2022-05-21 22:14:48 +00:00)\n"]}]},{"cell_type":"markdown","source":["## Stock Option reads"],"metadata":{"id":"7zhOYawdgRKW"}},{"cell_type":"markdown","metadata":{"id":"Tz5tUJuYaXKu"},"source":["### Single Stock European Call option - sampling methodology\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"Ok58PL-Eif4f"},"source":["#### EuropeanOptionNet"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LoQaeAOdif4g"},"outputs":[],"source":["class EuropeanOptionNet(nn.Module):\n","    def __init__(self , NL  , NN, activation = torch.tanh  ):\n","        super(EuropeanOptionNet, self).__init__()\n","        self.NL = NL\n","        self.NN = NN\n","        ### Number of stocks + time\n","        ### ( t , xi)\n","        self.Input = 1 + 1\n","        self.fc_input = nn.Linear(self.Input,self.NN)\n","        torch.nn.init.xavier_uniform_(self.fc_input.weight)\n","        self.linears = nn.ModuleList([nn.Linear(self.NN, self.NN) for i in range(self.NL)])\n","        for i, l in enumerate(self.linears):    \n","            torch.nn.init.xavier_uniform_(l.weight)\n","        self.fc_output = nn.Linear(self.NN,1)\n","        torch.nn.init.xavier_uniform_(self.fc_output.weight)\n","        self.act = activation\n","        \n","    def forward(self, x):\n","        # pdb.set_trace()\n","        h = self.act( self.fc_input(x)  )\n","        for i, l in enumerate(self.linears):\n","            h = self.act( l(h) )\n","        out = self.fc_output(h)\n","        return out \n","    "]},{"cell_type":"markdown","metadata":{"id":"LQuS9M6yif4g"},"source":["#### EuropeanBlackScholesSingleStock"]},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"code","id":"Qo8tjXrwif4h"},"outputs":[],"source":["import math\n","\n","class EuropeanBlackScholesSingleStock():\n","    \n","    def __init__(self , net, is_call = True):\n","\n","        self.C = 0.0           \n","        self.R = 0.05         # Interest Rate (Yearly)\n","\n","        self.SIGMA = 0.25  # Volatility (Yearly)\n","        self.RU = 1.0      # stock corrolation\n","        \n","        self.K = 50.0              # Strike Price \n","        self.T = 1.0               # Maturation time (in YEAR)\n","        self.MAX_X = self.K*3.0   # MAX price\n","        ## for accept reject purpose!\n","        ## free boundry problems\n","        self.net = net\n","        \n","        self.weights = None\n","        self.eps = 1E9\n","        self.weights_tbl = []\n","\n","        self.gamma = 0.0001\n","        self.beta = 0.0001\n","\n","        self.is_call = is_call\n","        self.log_normal_dist = torch.distributions.LogNormal(self.R-self.C, self.SIGMA)\n","        self.log_normal_dist_5 = torch.distributions.LogNormal(self.R-self.C, self.SIGMA*5.0)\n","\n","        self.xbreaks = None\n","        self.tbreaks = None\n","\n","\n","    def reset_weights(self):\n","        self.weights = None\n","        self.eps = 1E9\n","        self.weights_tbl = []\n","\n","    def g(self , x):\n","        # pay off function - 1 is the stock dimension, 0 is the time dimension\n","        if self.is_call:\n","          return torch.max( x[:,1].reshape(-1,1) - self.K , torch.zeros([len(x),1]).cuda() ) \n","        else:\n","          return torch.max( self.K - x[:,1].reshape(-1,1) , torch.zeros([len(x),1]).cuda() ) \n","\n","\n","    def mu(self, x):\n","        ## should test it! output dimension is important !\n","        return (self.R-self.C)*x.reshape(-1,1)\n","\n","    def sigma(self , x):\n","        return self.SIGMA*x.reshape(-1,1)\n","\n","    @staticmethod\n","    def to_device(x, to_cpu):\n","      if to_cpu:\n","        return x.cpu()\n","      else:\n","        return x.cuda()\n","\n","    def sample(self , sample_method_X = \"U\", size = 2**8, to_cpu = False ):\n","        '''\n","        Sampling function\n","        '''\n","        # 4 samples returned:\n","        # internal, boundary, initial, terminal\n","        if sample_method_X in [\"U\",\"UE3\"] :\n","            range_multiplier = 3.0 if sample_method_X == \"UE3\" else 1.0\n","            # internal samples\n","            x = self.to_device(torch.cat(( torch.rand([size,1])*self.T , -self.MAX_X*range_multiplier*torch.rand([size, 1])+self.MAX_X*range_multiplier) , dim = 1 ),to_cpu)\n","            ### Terminal time samples\n","            x_terminal = self.to_device(torch.cat( ( torch.zeros(size, 1) + self.T , -self.MAX_X*range_multiplier*torch.rand([size, 1])+self.MAX_X*range_multiplier ) , dim = 1 ),to_cpu)\n","            ### initial time samples\n","            # x_initial = torch.cat( ( torch.zeros(size, 1), -self.MAX_X*range_multiplier*torch.rand([size, 1])+self.MAX_X*range_multiplier ) , dim = 1 ).cuda()\n","            ### initial time samples\n","            x_initial = self.to_device(torch.cat( ( torch.zeros(size, 1), self.K*torch.ones( size, 1)) , dim = 1 ),to_cpu)\n","            ### non-zero\n","            stock_space = self.K*0.8*torch.rand([size, 1]) if self.is_call else self.K*(1.2 + torch.rand([size, 1]))\n","            x_nonzero = self.to_device(torch.cat( ( torch.rand([size,1])*self.T, stock_space ) , dim = 1 ),to_cpu)\n","            compare = self.net(x_nonzero) \n","            mask = compare < 0\n","            x_nonzero = x_nonzero[mask.reshape(-1),:]\n","            # x_initial = torch.cat( ( torch.zeros(size, 1), -self.MAX_X*range_multiplier*torch.rand([size, 1])+self.MAX_X*range_multiplier) , dim = 1 ).cuda()\n","            return x , x_terminal , x_initial, x_nonzero\n","    \n","        if sample_method_X in [\"LN\", \"LN5\"]:\n","            ln_dist = self.log_normal_dist_5 if sample_method_X == \"LN5\" else self.log_normal_dist\n","            # internal samples\n","            x = self.to_device(torch.cat(( torch.rand([size,1])*self.T , torch.maximum(ln_dist.sample((size,)).reshape(-1,1)*self.K,torch.Tensor([0.0]))   ) , dim = 1 ),to_cpu)\n","            ### Terminal time samples\n","            x_terminal = self.to_device(torch.cat( ( torch.zeros(size, 1) + self.T , torch.maximum(ln_dist.sample((size,)).reshape(-1,1)*self.K,torch.Tensor([0.0])) ) , dim = 1 ), to_cpu)\n","            ### initial time samples\n","            x_initial = self.to_device(torch.cat( ( torch.zeros(size, 1), self.K*torch.ones( size, 1)) , dim = 1 ),to_cpu)\n","            # x_initial = torch.cat( ( torch.zeros(size, 1),            torch.maximum(ln_dist.sample((size,)).reshape(-1,1)*self.K,torch.Tensor([0.0])) ), dim = 1 ).cuda()\n","            ### non-zero\n","            stock_space = self.K*0.8*torch.maximum(ln_dist.sample((size,)).reshape(-1,1),torch.Tensor([0.0]))  if self.is_call else self.K*(1.2 + torch.maximum(ln_dist.sample((size,)).reshape(-1,1),torch.Tensor([0.0])) )\n","            x_nonzero = self.to_device(torch.cat( ( torch.rand([size,1])*self.T, stock_space ) , dim = 1 ),to_cpu)\n","            compare = self.net(x_nonzero) \n","            mask = compare < 0\n","            x_nonzero = x_nonzero[mask.reshape(-1),:]\n","            return (x , x_terminal , x_initial, x_nonzero)\n","\n","        raise ValueError(f\"{sample_method_X} is not a supported sampling method\")\n","        \n","    def sample_stratified(self , sample_method_X = \"U\", size = 2**8, to_cpu = False ):\n","\n","      if self.xbreaks is None and self.tbreaks is None:\n","        return self.sample(sample_method_X, size, to_cpu)\n","\n","      internal_strata_xts = []\n","      terminal_strata_xts = []\n","      initial_strata_xts = []\n","      nonzero_strata_xts = []\n","\n","      # pdb.set_trace()\n","      \n","      if sample_method_X in [\"U\",\"UE3\"]:\n","\n","          range_multiplier = 3.0 if sample_method_X == \"UE3\" else 1.0\n","          xbreaks_used = self.xbreaks[:] if self.xbreaks is not None else [0,range_multiplier*self.MAX_X]\n","          tbreaks_used = self.tbreaks[:] if self.tbreaks is not None else [0,self.T]\n","          if xbreaks_used[-1] < range_multiplier*self.MAX_X:\n","            xbreaks_used.append(range_multiplier*self.MAX_X)\n","          while xbreaks_used[0] < 0.0:\n","            xbreaks_used.pop(0)\n","          if not xbreaks_used:\n","            xbreaks_used = [0,range_multiplier*self.MAX_X]\n","          if xbreaks_used[0] > 0.0:            \n","            xbreaks_used.insert(0, 0.0)\n","\n","          if tbreaks_used[-1] < self.T:\n","            tbreaks_used.append(self.T)\n","          xbreaks_range = xbreaks_used[-1]-xbreaks_used[0]\n","          tbreaks_range = tbreaks_used[-1]-tbreaks_used[0]\n","          \n","          # if len(xbreaks_used)<1:\n","          #   # pdb.set_trace()\n","          #   pass\n","\n","          total_strat_processed = 0\n","          # internal samples\n","          for stratum_x_count in range(len(xbreaks_used)-1):\n","\n","            num_samples_in_stratum = 0\n","            if len(xbreaks_used) > 2:  # x division takes priority so assign it if there is no T division\n","              range_ratio_x_stratum = (xbreaks_used[stratum_x_count+1]-xbreaks_used[stratum_x_count])/xbreaks_range\n","              num_samples_in_stratum = math.ceil(range_ratio_x_stratum*size)\n","\n","            for stratum_t_count in range(len(self.tbreaks)-1):\n","\n","              if num_samples_in_stratum == 0: # there is only a T division, so use it\n","                range_ratio_t_stratum = (tbreaks_used[stratum_t_count+1]-tbreaks_used[stratum_t_count])/tbreaks_range\n","                num_samples_in_stratum = math.ceil(range_ratio_t_stratum*size)\n","              else:\n","                # there is both an X and a T division, assign the number of samples uniformly, assuming same scale of X and T\n","                stratum_coverage_on_unit_square = \\\n","                  ((xbreaks_used[stratum_x_count+1]-xbreaks_used[stratum_x_count])/xbreaks_range)*\\\n","                  ((tbreaks_used[stratum_t_count+1]-tbreaks_used[stratum_t_count])/tbreaks_range)\n","                num_samples_in_stratum = math.ceil(stratum_coverage_on_unit_square * size)\n","\n","              ### internal samples\n","              internal_stratum_t_sample = tbreaks_used[stratum_t_count] + torch.rand([num_samples_in_stratum,1])*(tbreaks_used[stratum_t_count+1]-tbreaks_used[stratum_t_count])\n","              internal_stratum_x_sample = xbreaks_used[stratum_x_count] + torch.rand([num_samples_in_stratum,1])*(xbreaks_used[stratum_x_count+1]-xbreaks_used[stratum_x_count])\n","              internal_stratum_xt = self.to_device(torch.cat(( internal_stratum_t_sample , internal_stratum_x_sample) , dim = 1 ),to_cpu)\n","              if internal_stratum_xt.numel()<1:\n","                pdb.set_trace()\n","                pass\n","              \n","              internal_strata_xts.append(internal_stratum_xt)\n","\n","              ### Terminal time samples\n","              terminal_stratum_x_sample = xbreaks_used[stratum_x_count] + torch.rand([num_samples_in_stratum,1])*(xbreaks_used[stratum_x_count+1]-xbreaks_used[stratum_x_count])\n","              terminal_stratum_xt = self.to_device(torch.cat( ( torch.zeros(num_samples_in_stratum, 1) + self.T , terminal_stratum_x_sample ) , dim = 1 ),to_cpu)\n","              terminal_strata_xts.append(terminal_stratum_xt)\n","\n","              ### initial time samples\n","              # x_initial = torch.cat( ( torch.zeros(size, 1), -self.MAX_X*range_multiplier*torch.rand([size, 1])+self.MAX_X*range_multiplier ) , dim = 1 ).cuda()\n","              ### initial time samples\n","              initial_stratum_xt = self.to_device(torch.cat( ( torch.zeros(num_samples_in_stratum, 1), self.K*torch.ones( num_samples_in_stratum, 1)) , dim = 1 ),to_cpu)\n","              initial_strata_xts.append(initial_stratum_xt)\n","\n","              ### non-zero value samples\n","              stratum_mapped_stock_space = None\n","              if self.is_call:\n","                stratum_mapped_stock_space = self.K*(1.0/xbreaks_used[-1])* np.array([ xbreaks_used[stratum_x_count], xbreaks_used[stratum_x_count+1]])\n","              else:\n","                stratum_mapped_stock_space = self.K + self.K*(1.0/xbreaks_used[-1])*np.array([ xbreaks_used[stratum_x_count], xbreaks_used[stratum_x_count+1]])              \n","              nonzero_stratum_x_sample = stratum_mapped_stock_space[0] + torch.rand([num_samples_in_stratum, 1])*(stratum_mapped_stock_space[1]-stratum_mapped_stock_space[0])\n","              nonzero_stratum_xt = self.to_device(torch.cat( ( torch.rand([num_samples_in_stratum,1])*self.T, nonzero_stratum_x_sample ) , dim = 1 ),to_cpu)\n","              compare = self.net(nonzero_stratum_xt) \n","              mask = compare < 0\n","              nonzero_stratum_xt = nonzero_stratum_xt[mask.reshape(-1),:]\n","              nonzero_strata_xts.append(nonzero_stratum_xt)\n","\n","              total_strat_processed += 1 \n","\n","              # if len(np.where([x.numel()!=4 for x in internal_strata_xts])[0]) >0:\n","              #   pdb.set_trace()\n","              #   pass\n","              # if len(internal_strata_xts) == 3:\n","              #   pdb.set_trace() # the problem is the next one\n","              #   pass\n","\n","          \n","          # x_initial = torch.cat( ( torch.zeros(size, 1), -self.MAX_X*range_multiplier*torch.rand([size, 1])+self.MAX_X*range_multiplier) , dim = 1 ).cuda()\n","          return internal_strata_xts , terminal_strata_xts , initial_strata_xts, nonzero_strata_xts\n","    \n","      raise ValueError(f\"{sample_method_X} is not a supported sampling method\")\n","\n","\n","    def criterion(self, x , x_terminal , x_initial, x_nonzero, loss_transforms = [torch.square]):\n","        '''\n","        Loss function that helps network find solution to equation\n","        '''   \n","        # pdb.set_trace()     \n","        d = torch.autograd.grad(\n","            self.net(x), \n","            x, \n","            grad_outputs=torch.ones_like(self.net(x)) ,\n","            create_graph=True )\n","        dt  = d[0][:,0].reshape(-1,1)\n","        dx1 = d[0][:,1].reshape(-1,1)\n","        # du/dxdx\n","        dx1x1 = torch.autograd.grad(dx1, \n","                                    x , \n","                                    grad_outputs=torch.ones_like(dx1) ,\n","                                    create_graph = True)[0][:,1].reshape(-1,1)\n","        if loss_transforms is None:\n","          loss_transforms = [torch.square]\n","        intC = None\n","        terC = None\n","        iniC = None\n","        nzC = None\n","\n","        if len(x) == 0:\n","          # print('zero batch size for domain!')\n","          intC = [ torch.tensor(0).cuda().float() for loss_transform in loss_transforms ] \n","        else:\n","          # x is above the free boundary ( so immediate pay-off is positive )\n","          intC_loss = dt + self.mu(x[:,1])*( dx1 ) + 0.5*( (self.sigma(x[:,1])*self.sigma(x[:,1]))*dx1x1 ) - self.R*self.net(x)\n","          intC = [ loss_transform(intC_loss) for loss_transform in loss_transforms ] \n","\n","        # Terminal Condition - should be equal (both in- and out of the money)\n","        terC = [ loss_transform( self.g(x_terminal) - self.net(x_terminal) ) for loss_transform in loss_transforms ]\n","\n","        # pdb.set_trace()\n","        # Initial Condition - should be equal (both in- and out of the money)\n","        # Time is time to maturity \n","        initial_px_est = self.net(x_initial)\n","        iniC = [ loss_transform( initial_px_est - bs_price(\"C\" if self.is_call else \"P\", \n","                                                           torch.Tensor([self.K]), \n","                                                           torch.Tensor([self.K]), \n","                                                           torch.Tensor([self.T]), \n","                                                           torch.Tensor([self.SIGMA]), \n","                                                           torch.Tensor([self.R])).to(initial_px_est.device)  ) for \\\n","                 loss_transform in loss_transforms ]\n","        # closed_form_initial_pxs = bs_price(\"C\" if self.is_call else \"P\", self.K, x_initial[:,1], x_initial[:,0], torch.Tensor([self.SIGMA]).to(initial_px_est.device), self.R ).to(initial_px_est.device)\n","        # iniC = loss_transform( initial_px_est - closed_form_initial_pxs )\n","\n","        if len(x_nonzero) == 0:\n","          nzC = [ torch.tensor(0).cuda().float() for loss_transform in loss_transforms ] \n","        else:\n","          nzC = [ loss_transform(self.net(x_nonzero)) for loss_transform in loss_transforms ]\n","        return  intC , terC , iniC, nzC\n","\n","    def calculateLoss(self, batch_x, train = True, loss_transforms = [ torch.square ], keep_batch = False):\n","        '''\n","        Helper function that Sample and Calculate loss,\n","        '''        \n","        # x , x_terminal , x_initial = self.sample(sample_method_X, size)\n","        x , x_terminal , x_initial, x_nonzero = batch_x\n","        x = Variable( x , requires_grad=True)\n","        Ls = self.criterion( x , x_terminal , x_initial, x_nonzero, loss_transforms = loss_transforms )\n","        intC , terC , iniC, nzC = Ls\n","\n","        numActive = np.sum([1 if xb.numel()>0 else 0 for xb in batch_x ])\n","        # DOm = torch.mean(DO).detach().cpu().float().item()\n","        # TCm = torch.mean(TC).detach().cpu().float().item()\n","        # BCm = torch.mean(BC).detach().cpu().float().item()\n","        return_losses = []\n","        for lc in range(len(loss_transforms)):\n","          if not keep_batch:\n","            loss_equalWeightedByType = (1./numActive*torch.mean(intC[lc]) + 1./numActive*torch.mean(terC[lc]) + 1./numActive*torch.mean(iniC[lc]) + 1./numActive*torch.mean(nzC[lc]))\n","            return_losses.append( [ loss_equalWeightedByType , \n","                                    1./numActive*torch.mean(intC[lc]) , 1./numActive*torch.mean(terC[lc]) , 1./numActive*torch.mean(iniC[lc]), 1./numActive*torch.mean(nzC[lc]) , \n","                                    loss_equalWeightedByType ] )            \n","          else:\n","            return_losses.append( [intC.numpy(), terC.numpy(), iniC.numpy(), nzC.numpy()] )\n","        return return_losses\n","\n","    def calculateLossUsingKLMinMax(self , batch_x , train = True, loss_transforms = [ torch.square ], keep_batch = False):\n","        '''\n","        Helper function that Samples and Calculate loss,\n","        This is adapted in that it changes the weights on the losses\n","        and the distribution of sampling to maximize the loss provided \n","        the KL distance of the loss is within positive constraints\n","        beta represents the constraints on the weights\n","        gamma represents the constraints on the sampling distribution\n","        (each representing an upper bound the KL distribution)\n","        '''        \n","        # x , x_terminal , x_initial = self.sample(sample_method_X, size)\n","        x , x_terminal , x_initial, x_nonzero = batch_x\n","        x = Variable( x, requires_grad=True)\n","        Ls = self.criterion( x , x_terminal , x_initial, x_nonzero, loss_transforms = loss_transforms)\n","        intC , terC , iniC, nzC = Ls\n","\n","        if self.weights is None:\n","          self.weights = torch.ones(1,len(Ls)).to(intC[0].device)/len(Ls)\n","        \n","        # print([DOt, TCt, BCt, torch.log(DOt + TCt + BCt), 1.0/self.gamma * torch.log(DOt + TCt + BCt)])\n","\n","        numActive = np.sum([1 if xb.numel()>0 else 0 for xb in batch_x ])\n","\n","        return_losses = []\n","        for lc in range(len(loss_transforms)):\n","          if not keep_batch:\n","            intCt = self.weights[0,0] * torch.pow((1.0/intC[lc].numel() if intC[lc].numel() > 0 else 0.0) * torch.sum( torch.exp(self.beta * intC[lc])), self.gamma/self.beta) \n","            terCt = self.weights[0,1] * torch.pow((1.0/terC[lc].numel() if terC[lc].numel() > 0 else 0.0) * torch.sum( torch.exp(self.beta * terC[lc])), self.gamma/self.beta) \n","            iniCt = self.weights[0,2] * torch.pow((1.0/iniC[lc].numel() if iniC[lc].numel() > 0 else 0.0) * torch.sum( torch.exp(self.beta * iniC[lc])), self.gamma/self.beta) \n","            nzCt = self.weights[0,3] * torch.pow((1.0/nzC[lc].numel() if nzC[lc].numel() > 0 else 0.0) * torch.sum( torch.exp(self.beta * nzC[lc])), self.gamma/self.beta) \n","            loss_equalWeightedByType = (1./numActive*torch.mean(intC[lc]) + 1./numActive*torch.mean(terC[lc]) + 1./numActive*torch.mean(iniC[lc]) + 1./numActive*torch.mean(nzC[lc]))\n","            transformed_loss = 1.0/self.gamma * torch.log(intCt + terCt + iniCt + nzCt)\n","            return_losses.append( [ transformed_loss , \n","                                    1./numActive*torch.mean(intC[lc]) , 1./numActive*torch.mean(terC[lc]) , 1./numActive*torch.mean(iniC[lc]), 1./numActive*torch.mean(nzC[lc]) , \n","                                    loss_equalWeightedByType ] )            \n","          else:\n","            return_losses.append( [intC[lc].numpy(), terC[lc].numpy(), iniC[lc].numpy(), nzC[lc].numpy()] )\n","        return return_losses\n","\n","        # loss_equalWeightedByType = (1./numActive*torch.mean(intC) + 1./numActive*torch.mean(terC) + 1./numActive*torch.mean(iniC) + 1./numActive*torch.mean(nzC))\n","        # return   transformed_loss, 1./numActive*torch.mean(intC) , 1./numActive*torch.mean(terC) , 1./numActive*torch.mean(iniC) , loss_equalWeightedByType\n","\n","\n","    def calculateLossKLMinMaxGamma(self , batch_x , train = True, loss_transforms = [ torch.square ], keep_batch = False):\n","        '''\n","        Helper function that Samples and Calculate loss,\n","        This is adapted in that it changes the weights on the losses\n","        and the distribution of sampling to maximize the loss provided \n","        the KL distance of the loss is within positive constraints\n","        beta represents the constraints on the weights\n","        gamma represents the constraints on the sampling distribution\n","        (each representing an upper bound the KL distribution)\n","        '''        \n","        # x , x_terminal , x_initial = self.sample(sample_method_X, size)\n","        x , x_terminal , x_initial, x_nonzero = batch_x\n","        x = Variable( x, requires_grad=True)\n","        Ls = self.criterion( x , x_terminal , x_initial, x_nonzero, loss_transforms = loss_transforms)\n","        intC , terC , iniC, nzC = Ls\n","\n","        if self.weights is None:\n","          self.weights = torch.ones(1,len(Ls)).to(intC[0].device)/len(Ls)\n","        \n","        # print([DOt, TCt, BCt, torch.log(DOt + TCt + BCt), 1.0/self.gamma * torch.log(DOt + TCt + BCt)])\n","        numActive = np.sum([1 if xb.numel()>0 else 0 for xb in batch_x ])\n","\n","        return_losses = []\n","        for lc in range(len(loss_transforms)):\n","          if not keep_batch:\n","            intCt = self.weights[0,0] * (1.0/intC[lc].numel() if intC[lc].numel() > 0 else 0.0) * torch.sum( torch.exp(self.gamma * intC[lc])) \n","            terCt = self.weights[0,1] * (1.0/terC[lc].numel() if terC[lc].numel() > 0 else 0.0) * torch.sum( torch.exp(self.gamma * terC[lc])) \n","            iniCt = self.weights[0,2] * (1.0/iniC[lc].numel() if iniC[lc].numel() > 0 else 0.0) * torch.sum( torch.exp(self.gamma * iniC[lc])) \n","            nzCt = self.weights[0,3] * (1.0/nzC[lc].numel() if nzC[lc].numel() > 0 else 0.0) * torch.sum( torch.exp(self.gamma * nzC[lc])) \n","            loss_equalWeightedByType = (1./numActive*torch.mean(intC[lc]) + 1./numActive*torch.mean(terC[lc]) + 1./numActive*torch.mean(iniC[lc]) + 1./numActive*torch.mean(nzC[lc]))\n","            transformed_loss = 1.0/self.gamma * torch.log(intCt + terCt + iniCt + nzCt)\n","            return_losses.append( [ transformed_loss , \n","                                    1./numActive*torch.mean(intC[lc]) , 1./numActive*torch.mean(terC[lc]) , 1./numActive*torch.mean(iniC[lc]), 1./numActive*torch.mean(nzC[lc]) , \n","                                    loss_equalWeightedByType ] )            \n","          else:\n","            return_losses.append( [intC[lc].numpy(), terC[lc].numpy(), iniC[lc].numpy(), nzC[lc].numpy()] )\n","        return return_losses\n","\n","    "]},{"cell_type":"markdown","metadata":{"id":"3cFXznN2if4k"},"source":["#### TrainEuropeanBlackScholesSingleStock"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Fiii9F30if4n"},"outputs":[],"source":["class TrainEuropeanBlackScholesSingleStock():\n","    \n","    def __init__(self , net , equation , BATCH_SIZE , debug = False):\n","        self.history_mean_hooks = [] \n","        self.history_surfaces_hooks = None       \n","        self.history_tl = []\n","        self.history_internal = []\n","        self.history_terminal = []\n","        self.history_initial = []              \n","        self.history_nonzero = []\n","        self.BATCH_SIZE = BATCH_SIZE\n","        self.net = net\n","        self.model = equation        \n","        self.debug = debug  \n","        self.hook_interval = 20      \n","        if self.debug == True:\n","            self.hooks = {}            \n","            self.get_all_layers(self.net)\n","\n","        self.optimizer_used = optim.Adam\n","\n","        self.use_early_stop = False\n","        self.early_stop_patience = 10\n","        self.early_stop_delta = 0.0        \n","        self.best_loss = np.Inf\n","        self.monitored_loss_type = \"Train_L2\"\n","        self.early_stop_counter = 0\n","\n","        self.stop_epoch = 0\n","\n","        self.validation_sample = None\n","        self.validation_losses = None\n","        self.train_losses = None        \n","        \n","\n","    def train(self , epoch , lr, eqLossFn = 'calculateLoss', sample_method_X = \"U\", key_loss_func = torch.square, huber_delta = 0.5):\n","        \n","        self.validation_losses = np.ones((epoch, 6*3 - 1), dtype='float32') * np.nan\n","        self.train_losses = np.ones((epoch, 6*2 -1 ), dtype='float32') * np.nan\n","\n","        optimizer = self.optimizer_used(self.net.parameters(), lr)\n","        # optimizer = optim.SGD(self.net.parameters(), lr)\n","        loss_avg = 0.0\n","        loss_calc_method = None\n","        try:\n","            loss_calc_method = getattr(self.model, eqLossFn)\n","        except AttributeError:\n","            raise NotImplementedError(\"Class `{}` does not implement `{}`\".format(self.model.__class__.__name__, eqLossFn))\n","        \n","        for e in range(epoch):\n","            optimizer.zero_grad()\n","            # pdb.set_trace()\n","            sample_batch = self.model.sample(sample_method_X = sample_method_X, size=self.BATCH_SIZE)\n","\n","            losses_L2, losses_ABS = loss_calc_method( sample_batch, loss_transforms = [ key_loss_func, torch.abs ], keep_batch = False )\n","            # pdb.set_trace()\n","            loss , internal , terminal , initial, nonzero, losses_equalWeightedByType = losses_L2\n","            loss_abs , internal_abs , terminal_abs , initial_abs, nonzero_abs, losses_equalWeightedByType_abs = losses_ABS\n","            max_loss_L2 = torch.max(torch.tensor([internal , terminal , initial, nonzero]))\n","\n","            self.train_losses[e,:] = [ to_cpu_detach(loss) , to_cpu_detach(internal) , to_cpu_detach(terminal) , to_cpu_detach(initial), to_cpu_detach(nonzero), \n","                                       to_cpu_detach(loss_abs) , to_cpu_detach(internal_abs) , to_cpu_detach(terminal_abs) , to_cpu_detach(initial_abs), to_cpu_detach(nonzero_abs), to_cpu_detach(losses_equalWeightedByType_abs)]\n","\n","            if self.debug == True and (self.validation_sample is not None):\n","              losses_L2_validation, losses_ABS_validation, losses_Huber_valiation = loss_calc_method( self.validation_sample, \n","                                                                                                     loss_transforms = [ torch.square, torch.abs, partial(huber_loss_zero_target, delta=huber_delta) ], \n","                                                                                                     keep_batch = False )\n","              validation_loss_list = [*to_cpu_detach(losses_L2_validation),*to_cpu_detach(losses_ABS_validation),*to_cpu_detach(losses_Huber_valiation)]\n","              validation_loss_list = validation_loss_list.pop(5) # the L2 loss is duplicated at index 1\n","              self.validation_losses[e,:] = validation_loss_list\n","            \n","            if self.use_early_stop:\n","              loss_to_check = losses_equalWeightedByType\n","              if self.monitored_loss_type == \"Train_L2\":\n","                pass\n","              elif self.monitored_loss_type == \"Train_L1\":             \n","                loss_to_check = losses_equalWeightedByType_abs\n","              elif self.monitored_loss_type == \"Train_MAXL2\":             \n","                loss_to_check = max_loss_L2\n","\n","              if loss_to_check < (self.best_loss-self.early_stop_delta):\n","                self.best_loss = loss_to_check\n","                self.early_stop_counter = 0\n","                # print(f\"New Loss to beat for early Stop at epoch {e}, original loss: {losses_equalWeightedByType} with patience {self.early_stop_patience}\")\n","              else:\n","                self.early_stop_counter += 1\n","              if self.early_stop_counter>=self.early_stop_patience:\n","                print(f\"Early Stop at epoch {e}, {self.monitored_loss_type}: {loss_to_check} with patience {self.early_stop_patience}\")\n","                break\n","            \n","            loss_avg = loss_avg + float(loss.item())\n","            loss.backward()\n","\n","            optimizer.step()\n","            if (e % self.hook_interval == (self.hook_interval-1)) or e == 0:\n","\n","                loss_avg = loss_avg/self.hook_interval\n","                print(\"Epoch {} - lr {} -  key loss: {} - eqWeighted loss: {} - L1 loss {} - Max Loss {}\".format(e , lr , loss, losses_equalWeightedByType, loss_abs, max_loss_L2 ))\n","\n","                # loss_avg = 0\n","                ## report detailed loss ## ## puting inside no grad??? for memory optimization!\n","                # tl , dl , il , bl, _ = self.model.calculateLoss( 2**6 )  # note that this is the standard loss!!\n","\n","                self.history_tl.append( loss_avg )\n","                self.history_internal.append( internal )\n","                self.history_terminal.append( terminal )\n","                self.history_initial.append( initial )\n","                self.history_nonzero.append( nonzero )\n","\n","                if self.debug == True and (self.validation_sample is not None):\n","                    mean = []\n","                    for l in self.hooks:\n","                        mean.append(torch.mean( self.hooks[l] ).item())\n","                    self.history_mean_hooks.append( mean )\n","                    xinternal, xterminal, xinitial, xnonzero = self.validation_sample\n","                    xinternal_res = self.model.net(xinternal).detach()\n","                    xterminal_res = self.model.net(xterminal).detach()\n","                    xinitial_res = self.model.net(xinitial).detach()\n","                    xnonzero_res = self.model.net(xnonzero).detach()\n","\n","                    # pdb.set_trace()\n","                    df_internal = self.create_result_df(e, xinternal, xinternal_res, \"INTERNAL\")\n","                    df_terminal = self.create_result_df(e, xterminal, xterminal_res, \"TERMINAL\")\n","                    df_initial = self.create_result_df(e, xinitial, xinitial_res, \"INITIAL\")\n","                    df_nonzero = self.create_result_df(e, xnonzero, xnonzero_res, \"NONZERO\")\n","                    \n","                    if self.history_surfaces_hooks is None:\n","                      self.history_surfaces_hooks = pd.concat([df_internal, df_terminal, df_initial, df_nonzero],axis=0)\n","                    else:\n","                      self.history_surfaces_hooks = pd.concat([self.history_surfaces_hooks,pd.concat([df_internal, df_terminal, df_initial,df_nonzero],axis=0) ], axis=0)\n","\n","        self.stop_epoch = e\n","\n","    def train_stratified(self , epoch , lr, \n","                         eqLossFn = 'calculateLoss', \n","                         sample_method_X = \"U\", \n","                         key_loss_func = torch.square, \n","                         huber_delta = 0.5\n","                         ):\n","        \n","        self.validation_losses = np.ones((epoch, 6*3 - 1), dtype='float32') * np.nan\n","        self.train_losses = np.ones((epoch, 6*2), dtype='float32') * np.nan\n","\n","        optimizer = self.optimizer_used(self.net.parameters(), lr)\n","        # optimizer = optim.SGD(self.net.parameters(), lr)\n","        loss_avg = 0.0\n","        loss_calc_method = None\n","        try:\n","            loss_calc_method = getattr(self.model, eqLossFn)\n","        except AttributeError:\n","            raise NotImplementedError(\"Class `{}` does not implement `{}`\".format(self.model.__class__.__name__, eqLossFn))\n","        \n","        for e in range(epoch):\n","            optimizer.zero_grad()\n","            \n","            internal_xts_bts, terminal_xts_bts, initial_xts_bts, nonzero_xts_bts = self.model.sample_stratified(sample_method_X = sample_method_X, size=self.BATCH_SIZE)\n","            validation_stratum_losses = None #np.array([])#.reshape(1,self.validation_losses.shape[1])\n","            training_stratum_losses = None # np.array([])#.reshape(1,self.train_losses.shape[1])              \n","            \n","            # pdb.set_trace()\n","            for stratum_count in range(len(internal_xts_bts)):              \n","              sample_batch = (internal_xts_bts[stratum_count], \n","                              terminal_xts_bts[stratum_count], \n","                              initial_xts_bts[stratum_count], \n","                              nonzero_xts_bts[stratum_count])  \n","              stratum_losses_L2, stratum_losses_ABS = loss_calc_method( sample_batch, loss_transforms = [ key_loss_func, torch.abs ], keep_batch = False )\n","              if np.isnan(stratum_losses_L2[0].detach().cpu().item()):\n","                pdb.set_trace()\n","                pass\n","              \n","              if training_stratum_losses is not None:\n","                training_stratum_losses = torch.vstack([training_stratum_losses, torch.tensor([*to_cpu_detach(stratum_losses_L2), *to_cpu_detach(stratum_losses_ABS)]) ]) \n","              else:\n","                training_stratum_losses = torch.tensor([*to_cpu_detach(stratum_losses_L2), *to_cpu_detach(stratum_losses_ABS)], requires_grad=True)             \n","\n","            training_loss_for_epoch = torch.sum(training_stratum_losses,0)\n","\n","            loss , internal , terminal , initial, nonzero, losses_equalWeightedByType, \\\n","            loss_abs , internal_abs , terminal_abs , initial_abs, nonzero_abs, losses_equalWeightedByType_abs = training_loss_for_epoch            \n","            max_loss_L2 = torch.max(torch.tensor([internal , terminal , initial, nonzero]))\n","\n","            self.train_losses[e,:] = training_loss_for_epoch.detach().numpy()\n","\n","            if self.debug == True and (self.validation_sample is not None):\n","              losses_L2_validation, losses_ABS_validation, losses_Huber_valiation = \\\n","                loss_calc_method( self.validation_sample, \n","                                  loss_transforms = [ torch.square, torch.abs, partial(huber_loss_zero_target, delta=huber_delta) ], \n","                                  keep_batch = False )\n","              validation_loss = [*to_cpu_detach(losses_L2_validation),\n","                                              *to_cpu_detach(losses_ABS_validation),\n","                                              *to_cpu_detach(losses_Huber_valiation)]\n","              validation_loss = validation_loss.pop(5) # the L2 loss is duplicated at index 1                \n","              self.validation_losses[e,:] = validation_loss\n","\n","            if self.use_early_stop:\n","              loss_to_check = losses_equalWeightedByType\n","              if self.monitored_loss_type == \"Train_L2\":\n","                pass\n","              elif self.monitored_loss_type == \"Train_L1\":             \n","                loss_to_check = losses_equalWeightedByType_abs\n","              elif self.monitored_loss_type == \"Train_MAXL2\":             \n","                loss_to_check = max_loss_L2\n","              if loss_to_check < (self.best_loss-self.early_stop_delta):\n","                self.best_loss = loss_to_check\n","                self.early_stop_counter = 0\n","                # print(f\"New Loss to beat for early Stop at epoch {e}, original loss: {losses_equalWeightedByType} with patience {self.early_stop_patience}\")\n","              else:\n","                self.early_stop_counter += 1\n","              if self.early_stop_counter>=self.early_stop_patience:\n","                print(f\"Early Stop at epoch {e}, {self.monitored_loss_type}: {loss_to_check} with patience {self.early_stop_patience}\")\n","                break\n","            loss_avg = loss_avg + float(loss.item())\n","            loss.backward()\n","\n","            optimizer.step()\n","            if (e % self.hook_interval == (self.hook_interval-1)) or e == 0:\n","                loss_avg = loss_avg/self.hook_interval\n","                print(\"Epoch {} - lr {} -  key loss: {} - eqWeighted loss: {} - L1 loss {} - Max Loss {}\".format(e , lr , loss, losses_equalWeightedByType, loss_abs, max_loss_L2 ))\n","                # loss_avg = 0\n","                ## report detailed loss ## ## puting inside no grad??? for memory optimization!\n","                # tl , dl , il , bl, _ = self.model.calculateLoss( 2**6 )  # note that this is the standard loss!!\n","                self.history_tl.append( loss_avg )\n","                self.history_internal.append( internal )\n","                self.history_terminal.append( terminal )\n","                self.history_initial.append( initial )\n","                self.history_nonzero.append( nonzero )\n","                if self.debug == True and (self.validation_sample is not None):\n","                    mean = []\n","                    for l in self.hooks:\n","                        mean.append(torch.mean( self.hooks[l] ).item())\n","                    self.history_mean_hooks.append( mean )\n","                    xinternal, xterminal, xinitial, xnonzero = self.validation_sample\n","                    xinternal_res = self.model.net(xinternal).detach()\n","                    xterminal_res = self.model.net(xterminal).detach()\n","                    xinitial_res = self.model.net(xinitial).detach()\n","                    xnonzero_res = self.model.net(xnonzero).detach()\n","\n","                    # pdb.set_trace()\n","                    df_internal = self.create_result_df(e, xinternal, xinternal_res, \"INTERNAL\")\n","                    df_terminal = self.create_result_df(e, xterminal, xterminal_res, \"TERMINAL\")\n","                    df_initial = self.create_result_df(e, xinitial, xinitial_res, \"INITIAL\")\n","                    df_nonzero = self.create_result_df(e, xnonzero, xnonzero_res, \"NONZERO\")\n","                    \n","                    if self.history_surfaces_hooks is None:\n","                      self.history_surfaces_hooks = pd.concat([df_internal, df_terminal, df_initial, df_nonzero],axis=0)\n","                    else:\n","                      self.history_surfaces_hooks = pd.concat([self.history_surfaces_hooks,pd.concat([df_internal, df_terminal, df_initial,df_nonzero],axis=0) ], axis=0)\n","\n","        self.stop_epoch = e\n","\n","\n","    def hook_fn(self, m, i, o):\n","              self.hooks[m] = o.detach()\n","            \n","    def get_all_layers(self, net):\n","      for name, layer in net._modules.items():\n","          if isinstance(layer, nn.ModuleList):\n","              for n , l in layer.named_children():\n","                l.register_forward_hook(self.hook_fn)\n","          else:\n","              # it's a non sequential. Register a hook\n","              layer.register_forward_hook(self.hook_fn)\n","    \n","    def create_result_df(self, e, xsample, xsample_res, sample_type):\n","      df_xsample = pd.DataFrame(xsample.cpu().numpy(), columns = [\"Time\", \"S1\"])\n","      df_xsample[\"Epoch\"] = e\n","      df_xsample[\"Sample\"] = sample_type\n","      df_xsample[\"Result\"] = xsample_res.cpu().numpy()\n","      return df_xsample\n","\n"]},{"cell_type":"code","source":["%load_ext autotime"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SHZt1ElQSamQ","executionInfo":{"status":"ok","timestamp":1652380830005,"user_tz":-60,"elapsed":6,"user":{"displayName":"Hans Roggeman","userId":"10574434403170915342"}},"outputId":"1c4c5fe0-483d-4f43-d726-c9ef99e36770"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["time: 88.3 µs (started: 2022-05-12 18:40:29 +00:00)\n"]}]},{"cell_type":"markdown","source":["### Gather and write data for Options"],"metadata":{"id":"TfQMuQwrCeLl"}},{"cell_type":"markdown","source":["### Eu Call - graph daa\n","\n"],"metadata":{"id":"Loc_Z2vdKC1o"}},{"cell_type":"code","source":["EuCallModel_SL_U = EuropeanOptionNet(NL = 5, NN = 100)\n","bsSampler = EuropeanBlackScholesSingleStock(EuCallModel_SL_U) # we just use this for sampling\n","test_data = bsSampler.sample(\"U\", 2**4, to_cpu=True)[0].detach()\n","\n","# print(os.listdir(f\"/content/drive/MyDrive/data_papers/{paper_name}/model_finals\"))\n","EuCallModel_SL_U.load_state_dict(torch.load(f\"/content/drive/MyDrive/data_papers/{paper_name}/model_finals/EuCallSs_20220508213150_calculateLoss_U_39999_0p0001_5_100\"))\n","\n","print(EuCallModel_SL_U.forward(test_data).reshape(1,-1).detach().numpy())\n","print(bs_price(\"C\", torch.Tensor([ bsSampler.K  ]), test_data[:,1], test_data[:,0], torch.Tensor([bsSampler.SIGMA]), bsSampler.R ))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"v53mvFhfKzYo","executionInfo":{"status":"ok","timestamp":1652380926437,"user_tz":-60,"elapsed":692,"user":{"displayName":"Hans Roggeman","userId":"10574434403170915342"}},"outputId":"4cd075ff-6e19-40ce-f4f4-f7ae3b9e85ac"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[[8.9800308e+01 9.5424133e+01 7.8339272e+01 2.4258792e-02 9.0189537e+01\n","  5.6233746e+01 1.7798603e-02 5.7656673e+01 8.4578033e+01 3.6767288e+01\n","  2.3450342e+01 2.8047562e-02 8.8104210e+01 4.8364162e-02 4.1489244e-02\n","  8.2620573e+00]]\n","tensor([9.2890e+01, 9.8947e+01, 8.1140e+01, 0.0000e+00, 9.9221e+01, 5.7002e+01,\n","        0.0000e+00, 5.8736e+01, 9.0462e+01, 3.7688e+01, 2.5026e+01, 5.5379e-07,\n","        9.6243e+01, 1.0014e-05, 2.1134e-04, 6.0158e+00])\n","time: 496 ms (started: 2022-05-12 18:42:05 +00:00)\n"]}]},{"cell_type":"code","source":["def create_surface_result_df(sampled_data, exact_results, fits, sample_type):\n","  df = pd.DataFrame(sampled_data.cpu().detach().numpy(), columns = [\"Time\", \"S1\"])\n","  df[\"Sample\"] = sample_type\n","  df[\"Estimate\"] = fits.cpu().detach().numpy()\n","  df[\"Exact\"] = exact_results.cpu().detach().numpy()\n","  return df\n","\n","def get_df_fits(dir_name, title, sampled_internal_data, exact_results, model = None):\n","  if model is None:\n","    model = EuropeanOptionNet(NL = 5, NN = 100)\n","  model.load_state_dict(torch.load(f\"/content/drive/MyDrive/data_papers/{paper_name}/model_finals/{dir_name}\"))\n","  model_fits = model.forward(sampled_internal_data)\n","  df_model = create_surface_result_df(sampled_internal_data, exact_results, model_fits, title)\n","  df_model = df_model.sort_values(by=['Time','S1'], ascending=[True, True]).reset_index()\n","  df_model.drop(['index'], axis=1, inplace=True)\n","  df_model[\"diff\"] = df_model.Estimate - df_model.Exact\n","  df_model['diff_abs'] = np.abs(df_model[\"diff\"].tolist())\n","  df_model['perc_abs'] = np.abs(1.0 - df_model.Estimate/df_model.Exact)\n","  return df_model"],"metadata":{"id":"K1DfD2l5lzdG","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1652381075099,"user_tz":-60,"elapsed":341,"user":{"displayName":"Hans Roggeman","userId":"10574434403170915342"}},"outputId":"5bbc551e-1cb8-46fa-bd44-996af8983222"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["time: 14.5 ms (started: 2022-05-12 18:44:34 +00:00)\n"]}]},{"cell_type":"code","source":["import os\n","from pprint import pprint as pp\n","pp(os.listdir(f\"/content/drive/MyDrive/data_papers/{paper_name}/model_finals\"))"],"metadata":{"id":"mh7K115o5jsQ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1652381093595,"user_tz":-60,"elapsed":429,"user":{"displayName":"Hans Roggeman","userId":"10574434403170915342"}},"outputId":"56bf2a8f-7a66-4e15-9e91-7a0ec8511e1b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['EuCallSs_20220508213150_calculateLoss_U_39999_0p0001_5_100',\n"," 'EuCallSs_20220508223001_calculateLoss_LN_39999_0p0001_5_100',\n"," 'EuCallSs_20220508230212_calculateLossUsingKLMinMax_U_39999_0p0001_5_100',\n"," 'EuCallSs_20220508232650_calculateLossUsingKLMinMax_LN_39999_0p0001_5_100',\n"," 'EuCallSs_Huber0p1_20220509080833_calculateLoss_U_39999_0p0001_5_100',\n"," 'EuCallSs_Huber0p1_20220509083018_calculateLoss_LN_39999_0p0001_5_100',\n"," 'EuCallSs_Huber0p1_20220509085253_calculateLossUsingKLMinMax_U_39999_0p0001_5_100',\n"," 'EuCallSs_Huber0p1_20220509091521_calculateLossUsingKLMinMax_LN_39999_0p0001_5_100',\n"," 'EuCallSs_20220510143114_calculateLossUsingKLMinMax_U_39999_0p0001_5_100_beta1p0000000000000001e-07_gamma0p0001',\n"," 'EuCallSs_20220510145422_calculateLossUsingKLMinMax_U_39999_0p0001_5_100_beta0p0001_gamma0p0001',\n"," 'EuCallSs_20220510151626_calculateLossUsingKLMinMax_U_39999_0p0001_5_100_beta0p0001_gamma1p0000000000000001e-07',\n"," 'EuCallSs_20220510160809_calculateLossKLMinMaxGamma_U_39999_0p0001_5_100_beta0p0001_gamma0p0001',\n"," 'EuCallSs_20220510163042_calculateLossKLMinMaxGamma_U_39999_0p0001_5_100_beta0p0001_gamma1p0000000000000001e-07',\n"," 'EuCallSs_20220510165222_calculateLossKLMinMaxGamma_U_39999_0p0001_5_100_beta0p0001_gamma0p1',\n"," 'EuCallSs_20220510180749_calculateLossKLMinMaxGamma_U_39999_0p0001_5_100_beta0p0001_gamma0p001']\n","time: 4.29 ms (started: 2022-05-12 18:44:52 +00:00)\n"]}]},{"cell_type":"code","source":["EuCallModel_SL_U = EuropeanOptionNet(NL = 5, NN = 100)\n","bsSampler = EuropeanBlackScholesSingleStock(EuCallModel_SL_U) # we just use this for sampling\n","sampled_internal_data = bsSampler.sample(\"U\", 2**14, to_cpu=True)[0]\n","exact_results = bs_price(\"C\", torch.Tensor([ bsSampler.K  ]), sampled_internal_data[:,1], sampled_internal_data[:,0], torch.Tensor([bsSampler.SIGMA]), bsSampler.R )\n","\n","df_EuCallModel_SL_U = get_df_fits(\"EuCallSs_20220508213150_calculateLoss_U_39999_0p0001_5_100\", \"SL_U\", sampled_internal_data, exact_results, model=EuropeanOptionNet(NL = 5, NN = 100))\n","df_EuCallModel_SL_LN = get_df_fits(\"EuCallSs_20220508223001_calculateLoss_LN_39999_0p0001_5_100\", \"SL_LN\", sampled_internal_data, exact_results, model=EuropeanOptionNet(NL = 5, NN = 100))\n","df_EuCallModel_KL_U = get_df_fits(\"EuCallSs_20220508230212_calculateLossUsingKLMinMax_U_39999_0p0001_5_100\", \"KL_U\", sampled_internal_data, exact_results, model=EuropeanOptionNet(NL = 5, NN = 100))\n","df_EuCallModel_KL_LN = get_df_fits(\"EuCallSs_20220508232650_calculateLossUsingKLMinMax_LN_39999_0p0001_5_100\", \"KL_LN\", sampled_internal_data, exact_results, model=EuropeanOptionNet(NL = 5, NN = 100))\n","\n","df_EuCallModel_HL_U = get_df_fits(\"EuCallSs_Huber0p1_20220509080833_calculateLoss_U_39999_0p0001_5_100\", \"HL_U\", sampled_internal_data, exact_results, model=EuropeanOptionNet(NL = 5, NN = 100))\n","df_EuCallModel_HL_LN = get_df_fits(\"EuCallSs_Huber0p1_20220509083018_calculateLoss_LN_39999_0p0001_5_100\", \"HL_LN\", sampled_internal_data, exact_results, model=EuropeanOptionNet(NL = 5, NN = 100))\n","df_EuCallModel_KLH_U = get_df_fits(\"EuCallSs_Huber0p1_20220509085253_calculateLossUsingKLMinMax_U_39999_0p0001_5_100\", \"KLH_U\", sampled_internal_data, exact_results, model=EuropeanOptionNet(NL = 5, NN = 100))\n","df_EuCallModel_KLH_LN = get_df_fits(\"EuCallSs_Huber0p1_20220509091521_calculateLossUsingKLMinMax_LN_39999_0p0001_5_100\", \"KLH_LN\", sampled_internal_data, exact_results, model=EuropeanOptionNet(NL = 5, NN = 100))\n","\n","df_EuCallModel_KL_U_B1eM7_G1eM4 = get_df_fits(\"EuCallSs_20220510143114_calculateLossUsingKLMinMax_U_39999_0p0001_5_100_beta1p0000000000000001e-07_gamma0p0001\", \"KL_U_B1eM7_G1eM4\", sampled_internal_data, exact_results, model=EuropeanOptionNet(NL = 5, NN = 100))\n","df_EuCallModel_KL_U_B1eM4_G1eM4 = get_df_fits(\"EuCallSs_20220510145422_calculateLossUsingKLMinMax_U_39999_0p0001_5_100_beta0p0001_gamma0p0001\", \"KL_U_B1eM4_G1eM4\", sampled_internal_data, exact_results, model=EuropeanOptionNet(NL = 5, NN = 100))\n","df_EuCallModel_KL_U_B1eM4_G1eM7 = get_df_fits(\"EuCallSs_20220510151626_calculateLossUsingKLMinMax_U_39999_0p0001_5_100_beta0p0001_gamma1p0000000000000001e-07\", \"KL_U_B1eM4_G1eM7\", sampled_internal_data, exact_results, model=EuropeanOptionNet(NL = 5, NN = 100))\n","\n","df_EuCallModel_GKL_U_GO1eM4 = get_df_fits(\"EuCallSs_20220510160809_calculateLossKLMinMaxGamma_U_39999_0p0001_5_100_beta0p0001_gamma0p0001\", \"GKL_U_GO1eM4\", sampled_internal_data, exact_results, model=EuropeanOptionNet(NL = 5, NN = 100))\n","df_EuCallModel_GKL_U_GO1eM7 = get_df_fits(\"EuCallSs_20220510163042_calculateLossKLMinMaxGamma_U_39999_0p0001_5_100_beta0p0001_gamma1p0000000000000001e-07\", \"GKL_U_GO1eM7\", sampled_internal_data, exact_results, model=EuropeanOptionNet(NL = 5, NN = 100))\n","df_EuCallModel_GKL_U_GO1eM1 = get_df_fits(\"EuCallSs_20220510165222_calculateLossKLMinMaxGamma_U_39999_0p0001_5_100_beta0p0001_gamma0p1\", \"GKL_U_GO1eM1\", sampled_internal_data, exact_results, model=EuropeanOptionNet(NL = 5, NN = 100))\n","df_EuCallModel_GKL_U_GO1eM3 = get_df_fits(\"EuCallSs_20220510180749_calculateLossKLMinMaxGamma_U_39999_0p0001_5_100_beta0p0001_gamma0p001\", \"GKL_U_GO1eM3\", sampled_internal_data, exact_results, model=EuropeanOptionNet(NL = 5, NN = 100))\n"],"metadata":{"id":"pCi_ZME_MLDv","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1652382231771,"user_tz":-60,"elapsed":1795,"user":{"displayName":"Hans Roggeman","userId":"10574434403170915342"}},"outputId":"bcb29706-f53b-400a-df00-4973f52f3655"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["time: 1.4 s (started: 2022-05-12 19:03:49 +00:00)\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YypqhcEoy16o","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1652382456549,"user_tz":-60,"elapsed":416,"user":{"displayName":"Hans Roggeman","userId":"10574434403170915342"}},"outputId":"edb3e2d4-e54c-4175-87a7-6ac67b232081"},"outputs":[{"output_type":"stream","name":"stdout","text":["time: 20.7 ms (started: 2022-05-12 19:07:36 +00:00)\n"]}],"source":["surface_df = pd.concat([df_EuCallModel_SL_U, df_EuCallModel_SL_LN, df_EuCallModel_KL_U, df_EuCallModel_KL_LN, \n","                        df_EuCallModel_HL_U, df_EuCallModel_HL_LN, df_EuCallModel_KLH_U, df_EuCallModel_KLH_LN,\n","                        df_EuCallModel_KL_U_B1eM7_G1eM4, df_EuCallModel_KL_LU_B1eM4_G1eM4, df_EuCallModel_KL_LU_B1eM4_G1eM7,\n","                        df_EuCallModel_GKL_U_GO1eM4, df_EuCallModel_GKL_U_GO1eM7, df_EuCallModel_GKL_U_GO1eM1, df_EuCallModel_GKL_U_GO1eM3\n","                        ], axis=0)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FKfzE-7Q0oMy","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1652382620352,"user_tz":-60,"elapsed":2047,"user":{"displayName":"Hans Roggeman","userId":"10574434403170915342"}},"outputId":"7b71a21d-bfdc-4c4c-9409-c8e653817029"},"outputs":[{"output_type":"stream","name":"stdout","text":["time: 1.72 s (started: 2022-05-12 19:10:18 +00:00)\n"]}],"source":["surface_df.to_csv(f\"{paper_name}_EuCallss_{datetime.datetime.now():%Y%m%d}.csv\", index=False)"]},{"cell_type":"code","source":["# print(df_EuCallModel_SL_U[df_EuCallModel_SL_U.Exact>0.1].sort_values(by='perc_abs', ascending=False).head(20))\n","# print(df_EuCallModel_KL_U[df_EuCallModel_KL_U.Exact>0.1].sort_values(by='perc_abs', ascending=False).head(20))\n","# print(df_EuCallModel_SL_LN[df_EuCallModel_SL_LN.Exact>0.1].sort_values(by='perc_abs', ascending=False).head(20))\n","# print(df_EuCallModel_KL_LN[df_EuCallModel_KL_LN.Exact>0.1].sort_values(by='perc_abs', ascending=False).head(20))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dVp3zyx9Mg8Z","executionInfo":{"status":"ok","timestamp":1652382248567,"user_tz":-60,"elapsed":423,"user":{"displayName":"Hans Roggeman","userId":"10574434403170915342"}},"outputId":"fc46d2dc-92ff-479f-e970-9fe5dfc54884"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["time: 929 µs (started: 2022-05-12 19:04:08 +00:00)\n"]}]},{"cell_type":"code","source":["# ### R Code\n","\n","# require(ggplot2)\n","# require(ggthemes)\n","# require(data.table)\n","# require(dplyr)\n","# require(interp)\n","# require(gridExtra)\n","# require(ggpubr)\n","\n","# setwd(\"/Users/hansroggeman/Code/dgm\")\n","# eucall_data = fread(\"dgm_lossfunctional_EuCallss.csv\")\n","\n","\n","# get_diff_abs_display <- function(data, interval=1.0) {\n","#   #establish the min and max of scale\n","#   grandmin <- 0.0\n","#   grandmax <- ceiling(max(data$diff_abs))\n","#   #define the number of breaks.  In this case 8 +1\n","#   mybreaks <- seq(grandmin, grandmax, length.out = grandmax/interval)\n","#   #Function to return the desired number of colors\n","#   mycolors<- function(x) {\n","#     colors<-colorRampPalette(c(\"darkblue\",\"dodgerblue\",\"green\",\"yellow\",\"orange\",\"darkred\" ))( grandmax/interval )\n","#     colors[1:x]\n","#   }\n","#   #Function to create labels for legend\n","#   breaklabel <- function(x, breaks = mybreaks){\n","#     labels<- paste0(sapply( breaks[1:(length(breaks)-1)], function(x) {  as.character(round(x,1))   }), \"-\",\n","#                     sapply( breaks[2:length(breaks)], function(x) {  as.character(round(x,1))   }) )\n","#     labels[1:x]\n","#   }\n","#   return(list(grandmin, grandmax, mybreaks, mycolors, breaklabel))\n","# }\n","\n","# diff_abs_list = get_diff_abs_display(eucall_data)\n","# diff_abs_breaks = diff_abs_list[[3]]\n","# diff_abs_colorf = diff_abs_list[[4]]\n","# diff_abs_lblsf = diff_abs_list[[5]]\n","\n","# get_display_params <- function(data, column_name = \"diff_abs\", interval=1.0) {\n","#   #establish the min and max of scale\n","#   grandmin <- floor(min(data[,get(column_name)]))\n","#   grandmax <- ceiling(max(data[,get(column_name)]))\n","#   #define the number of breaks.  In this case 8 +1\n","#   mybreaks <- seq(grandmin, grandmax, length.out = grandmax/interval)\n","#   #Function to return the desired number of colors\n","#   mycolors<- function(x) {\n","#     colors<-colorRampPalette(c(\"darkblue\",\"dodgerblue\",\"green\",\"yellow\",\"orange\",\"darkred\" ))( grandmax/interval )\n","#     colors[1:x]\n","#   }\n","#   #Function to create labels for legend\n","#   breaklabel <- function(x, breaks = mybreaks){\n","#     labels<- paste0(sapply( breaks[1:(length(breaks)-1)], function(x) {  as.character(round(x,1))   }), \"-\",\n","#                     sapply( breaks[2:length(breaks)], function(x) {  as.character(round(x,1))   }) )\n","#     labels[1:x]\n","#   }\n","#   return(list(grandmin, grandmax, mybreaks, mycolors, breaklabel))\n","# }\n","\n","\n","# # ggplot(sample_n(eucall_data[(Exact>0.0) & (Sample==\"SL_U\")],1000), aes(x=Time, y=S1, z=perc_abs)) + geom_contour()\n","# # ggplot(data, aes(x, y, z = z1)) +\n","# #   geom_contour_filled(breaks= mybreaks, show.legend = TRUE) +\n","# #   scale_fill_manual(palette=mycolors, values=breaklabel(8), name=\"Value\", drop=FALSE) +\n","# #   theme(legend.position = \"right\")\n","\n","# contour_log10_perc_abs <- function(d1, title_str, palette = \"Spectral\") {\n","#   d1$perc_abs = log10(d1$perc_abs)\n","#   grid <- with(d1, interp::interp(Time, S1, perc_abs))\n","#   griddf <- subset(data.frame(Time = rep(grid$x, nrow(grid$z)),\n","#                               S1 = rep(grid$y, each = ncol(grid$z)),\n","#                               perc_abs = as.numeric(grid$z)),\n","#                    !is.na(perc_abs))\n","#   p<- ggplot(griddf, aes(Time, S1, z = perc_abs)) +\n","#     geom_contour_filled(colour = \"white\", show.legend = T) +\n","#     scale_fill_brewer(palette = palette, direction = -1) +\n","#     theme_fivethirtyeight() + ggtitle(title_str)\n","#   return(p)\n","# }\n","\n","# get_legend<-function(myggplot){\n","#   tmp <- ggplot_gtable(ggplot_build(myggplot))\n","#   leg <- which(sapply(tmp$grobs, function(x) x$name) == \"guide-box\")\n","#   legend <- tmp$grobs[[leg]]\n","#   return(legend)\n","# }\n","\n","# contour_diff_abs <- function(d1, title_str, breaks, palette, breaklabels, show.legend = FALSE) {\n","#   grid <- with(d1, interp::interp(Time, S1, diff_abs))\n","#   griddf <- subset(data.frame(Time = rep(grid$x, nrow(grid$z)),\n","#                               S1 = rep(grid$y, each = ncol(grid$z)),\n","#                               diff_abs = as.numeric(grid$z)),\n","#                    !is.na(diff_abs))\n","#   p<- ggplot(griddf, aes(Time, S1, z = diff_abs)) +\n","#     geom_contour_filled(colour = \"white\", breaks=breaks, show.legend = show.legend) +\n","#     scale_fill_manual(palette=palette, values=breaklabels, name=\"diff_abs\", drop=FALSE) +\n","#     # scale_fill_brewer(palette = palette, direction = -1) +\n","#     ggtitle(title_str)\n","#   return(p)\n","# }\n","\n","# contour_column <- function(column_name, d1, title_str, breaks, palette, breaklabels, show.legend = FALSE) {\n","#   grid <- with(d1, interp::interp(Time, S1, get(column_name)))\n","#   griddf <- subset(data.table(Time = rep(grid$x, nrow(grid$z)),\n","#                               S1 = rep(grid$y, each = ncol(grid$z)),\n","#                               column_name = as.numeric(grid$z)),!is.na(eval(column_name)))\n","#   griddf[,eval(column_name):=column_name]\n","#   griddf[,column_name:=NULL]\n","#   p <- ggplot(griddf, aes(Time, S1, z = get(column_name))) +\n","#     geom_contour_filled(colour = \"white\", breaks=breaks, show.legend = show.legend) +\n","#     scale_fill_manual(palette=palette, values=breaklabels, name=column_name, drop=FALSE) +\n","#     # scale_fill_brewer(palette = palette, direction = -1) +\n","#     ggtitle(title_str)\n","#   return(p)\n","# }\n","\n","# SL_U_Acc_perc_abs = contour_log10_perc_abs(eucall_data[(Exact>0.0) & (Sample==\"SL_U\")], \"European Call, log(10) percentage difference - Adam on L2 Loss, Uniform Sampling\")\n","# SL_LN_Acc_perc_abs = contour_log10_perc_abs(eucall_data[(Exact>0.0) & (Sample==\"SL_LN\")], \"European Call, log(10) percentage difference - Adam on L2 Loss, LN Sampling\")\n","# KL_U_Acc_perc_abs = contour_log10_perc_abs(eucall_data[(Exact>0.0) & (Sample==\"KL_U\")], \"European Call, log(10) percentage difference - Adam on KL(L2) Loss, Uniform Sampling\")\n","# KL_LN_Acc_perc_abs = contour_log10_perc_abs(eucall_data[(Exact>0.0) & (Sample==\"KL_LN\")], \"European Call, log(10) percentage difference - Adam on KL(L2) Loss, LN Sampling\")\n","\n","# SL_U_Acc_diff_abs = contour_diff_abs(eucall_data[(Exact>0.0) & (Sample==\"SL_U\")],\n","#                                      \"European Call, ABS difference - Adam on L2 Loss, Uniform Sampling\",\n","#                                      palette=diff_abs_colorf,\n","#                                      breaks=diff_abs_breaks, breaklabels = diff_abs_lblsf(length(diff_abs_breaks)-1))\n","# SL_LN_Acc_diff_abs = contour_diff_abs(eucall_data[(Exact>0.0) & (Sample==\"SL_LN\")], \"European Call, ABS difference - Adam on L2 Loss, LN Sampling\",\n","#                                       palette=diff_abs_colorf,\n","#                                       breaks=diff_abs_breaks, breaklabels = diff_abs_lblsf(length(diff_abs_breaks)-1))\n","# KL_U_Acc_diff_abs = contour_diff_abs(eucall_data[(Exact>0.0) & (Sample==\"KL_U\")], \"European Call, ABS difference - Adam on KL(L2) Loss, Uniform Sampling\",\n","#                                      palette=diff_abs_colorf,\n","#                                      breaks=diff_abs_breaks, breaklabels = diff_abs_lblsf(length(diff_abs_breaks)-1))\n","# KL_LN_Acc_diff_abs = contour_diff_abs(eucall_data[(Exact>0.0) & (Sample==\"KL_LN\")], \"European Call, ABS difference - Adam on KL(L2) Loss, LN Sampling\",\n","#                                       palette=diff_abs_colorf,\n","#                                       breaks=diff_abs_breaks, breaklabels = diff_abs_lblsf(length(diff_abs_breaks)-1))\n","\n","# diff_abs_legend = get_legend(contour_diff_abs(eucall_data[(Exact>0.0) & (Sample==\"SL_U\")],\n","#                             \"European Call, ABS difference - Adam on L2 Loss, Uniform Sampling\",\n","#                             palette=diff_abs_colorf,\n","#                             breaks=diff_abs_breaks, \n","#                             breaklabels = diff_abs_lblsf(length(diff_abs_breaks)-1), \n","#                             show.legend=T))\n","# blankPlot <- ggplot()+geom_blank(aes(1,1)) + cowplot::theme_nothing()\n","\n","\n","# eucall_data[, `SL_U_KL_U_diff_abs`:={ mean(.SD[Sample==\"SL_U\",diff_abs]-.SD[Sample==\"KL_U\",diff_abs]) },\n","#                by=list(S1,Time)]\n","# eucall_data[, `SL_LN_KL_LN_diff_abs`:={ mean(.SD[Sample==\"SL_LN\",diff_abs]-.SD[Sample==\"KL_LN\",diff_abs]) },\n","#             by=list(S1,Time)]\n","# eucall_data[, `HL_LN_KLH_LN_diff_abs`:={ mean(.SD[Sample==\"HL_LN\",diff_abs]-.SD[Sample==\"KLH_LN\",diff_abs]) },\n","#             by=list(S1,Time)]\n","# eucall_data[, `SL_U_HL_U_diff_abs`:={ mean(.SD[Sample==\"SL_U\",diff_abs]-.SD[Sample==\"HL_U\",diff_abs]) },\n","#             by=list(S1,Time)]\n","\n","# disp_pr = get_display_params(eucall_data, \"SL_U_HL_U_diff_abs\", 0.1)\n","# SL_U_HL_U_diff_abs_breaks = disp_pr[[3]]\n","# SL_U_HL_U_diff_abs_colorf = disp_pr[[4]]\n","# SL_U_HL_U_diff_abs_lblsf = disp_pr[[5]]\n","\n","# p_SL_U_HL_U_diff_abs_l = \n","#   contour_column(  \"SL_U_HL_U_diff_abs\",\n","#                     distinct(eucall_data[(Exact>0.0) & (Sample==\"KL_LN\"), .(Time, S1,SL_U_HL_U_diff_abs)]), \n","#                     \"European Call, difference - L2 vs. HL, U Sampling\",\n","#                     palette=SL_U_HL_U_diff_abs_colorf,\n","#                     breaks=SL_U_HL_U_diff_abs_breaks, \n","#                     breaklabels = SL_U_HL_U_diff_abs_lblsf(length(SL_U_HL_U_diff_abs_breaks)-1),\n","#                     show.legend = T )\n","# p_SL_U_Acc_diff_abs_l = \n","#   contour_diff_abs( eucall_data[(Exact>0.0) & (Sample==\"SL_U\")],\n","#                     \"European Call, ABS difference - Adam on L2 Loss, Uniform Sampling\",\n","#                     palette=diff_abs_colorf,\n","#                     breaks=diff_abs_breaks, \n","#                     breaklabels = diff_abs_lblsf(length(diff_abs_breaks)-1),\n","#                     show.legend = T )\n","\n","# ggarrange(\n","#   p_SL_U_HL_U_diff_abs_l, p_SL_U_Acc_diff_abs_l,\n","#   common.legend = FALSE, legend = \"bottom\"\n","# )\n","\n","# ggarrange(\n","#   SL_U_Acc_diff_abs, SL_LN_Acc_diff_abs,\n","#   common.legend = TRUE, legend = \"bottom\"\n","# )\n","\n","# ggarrange(\n","#   SL_U_Acc_diff_abs, SL_LN_Acc_diff_abs,\n","#   common.legend = TRUE, legend = \"bottom\"\n","# )\n","\n","# ggarrange(\n","#   SL_U_Acc_diff_abs, KL_U_Acc_diff_abs,\n","#   common.legend = TRUE, legend = \"bottom\"\n","# )\n","\n","# # ggarrange(\n","# #   ggarrange(SL_U_Acc_diff_abs, SL_LN_Acc_diff_abs, ncol = 2),                # First row with line plot\n","# #   # Second row with box and dot plots\n","# #   ggarrange(KL_U_Acc_diff_abs, KL_LN_Acc_diff_abs, ncol = 2),\n","# #   nrow = 2,\n","# #   common.legend = TRUE\n","# # )\n","\n","\n","\n","# # grid.arrange(diff_abs_legend, blankPlot,  SL_U_Acc_diff_abs, SL_LN_Acc_diff_abs,\n","# #              ncol=2, nrow = 2,\n","# #              widths = c(2.7, 2.7), heights = c(0.5, 2.5))\n","\n","\n","# # grid.arrange(SL_U_Acc_diff_abs, SL_LN_Acc_diff_abs, diff_abs_legend, ncol=3, widths=c(2.3, 2.3, 0.4))\n","\n","# # grid.arrange(SL_U_Acc_diff_abs,SL_LN_Acc_diff_abs,KL_U_Acc_diff_abs,KL_LN_Acc_diff_abs, nrow=1, ncol=4)\n","\n","# # grid.arrange(SL_U_Acc_diff_abs,SL_LN_Acc_diff_abs,KL_U_Acc_diff_abs, nrow=1, ncol=3)\n","# # grid.arrange(SL_U_Acc_diff_abs,SL_LN_Acc_diff_abs,nrow=1,ncol=2)\n","\n","\n","\n"],"metadata":{"id":"Cu16vtNyrqO9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# from matplotlib.mlab import griddata\n","# import matplotlib.pyplot as plt\n","\n","# # First we'll make a regular grid to interpolate onto\n","# data = df_EuCallModel_SL_U.copy()\n","\n","# numcols, numrows = 30, 30\n","# xi = np.linspace(data.Time.min(), data.Time.max(), numcols)\n","# yi = np.linspace(data.S1.min(), data.S1.max(), numrows)\n","# xi, yi = np.meshgrid(xi, yi)\n","\n","# #-- Interpolate at the points in xi, yi\n","# # \"griddata\" expects \"raw\" numpy arrays, so we'll pass in\n","# # data.x.values instead of just the pandas series data.x\n","# x, y, z = data.Time.values, data.S1.values, data.delta.values\n","# zi = griddata(x, y, z, xi, yi)\n","\n","# #-- Display the results\n","# fig, ax = plt.subplots()\n","# im = ax.contourf(xi, yi, zi)\n","# ax.scatter(data.Time, data.S1, c=data.delta, s=100,\n","#            vmin=zi.min(), vmax=zi.max())\n","# fig.colorbar(im)\n","\n","\n","# #  ggplot(df_EuCallModel_SL_U, aes('Time', 'S1', z = 'delta')) + geom_contour()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":391},"id":"nSd5wrOwsgnF","executionInfo":{"status":"error","timestamp":1651849487181,"user_tz":-60,"elapsed":386,"user":{"displayName":"Hans Roggeman","userId":"10574434403170915342"}},"outputId":"10207ea8-9752-43dc-b11e-a82a60d4a647"},"execution_count":null,"outputs":[{"output_type":"error","ename":"ImportError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)","\u001b[0;32m<ipython-input-84-2e512c55019e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmlab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgriddata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# First we'll make a regular grid to interpolate onto\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_EuCallModel_SL_U\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mImportError\u001b[0m: cannot import name 'griddata' from 'matplotlib.mlab' (/usr/local/lib/python3.7/dist-packages/matplotlib/mlab.py)","","\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"],"errorDetails":{"actions":[{"action":"open_url","actionText":"Open Examples","url":"/notebooks/snippets/importing_libraries.ipynb"}]}}]}]}