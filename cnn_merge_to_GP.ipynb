{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"cnn_merge_to_GP.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm","mount_file_id":"1JC2_91sM3E-f1jdXuhyGxJn3VWCOP9Sm","authorship_tag":"ABX9TyN23W7lovr5ycGtnZ5QcWeh"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"mR2TvAiGQilA","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1621871014660,"user_tz":-60,"elapsed":14289,"user":{"displayName":"Hans Roggeman","photoUrl":"","userId":"10574434403170915342"}},"outputId":"707a6163-e73f-47e3-c6c0-7167be55c808"},"source":["%pip install keras_self_attention\n","%pip install keras-tuner\n","%pip install gpflow"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Collecting keras_self_attention\n","  Downloading https://files.pythonhosted.org/packages/c3/34/e21dc6adcdab2be03781bde78c6c5d2b2136d35a1dd3e692d7e160ba062a/keras-self-attention-0.49.0.tar.gz\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from keras_self_attention) (1.19.5)\n","Requirement already satisfied: Keras in /usr/local/lib/python3.7/dist-packages (from keras_self_attention) (2.4.3)\n","Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from Keras->keras_self_attention) (2.10.0)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from Keras->keras_self_attention) (3.13)\n","Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.7/dist-packages (from Keras->keras_self_attention) (1.4.1)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from h5py->Keras->keras_self_attention) (1.15.0)\n","Building wheels for collected packages: keras-self-attention\n","  Building wheel for keras-self-attention (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for keras-self-attention: filename=keras_self_attention-0.49.0-cp37-none-any.whl size=19468 sha256=6101b26a6d9f00f386006b8c1e2a8cbe8acc27abdb8f87160f2f54acc1b42b1e\n","  Stored in directory: /root/.cache/pip/wheels/6f/9d/c5/26693a5092d9313daeae94db04818fc0a2b7a48ea381989f34\n","Successfully built keras-self-attention\n","Installing collected packages: keras-self-attention\n","Successfully installed keras-self-attention-0.49.0\n","Collecting keras-tuner\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/20/ec/1ef246787174b1e2bb591c95f29d3c1310070cad877824f907faba3dade9/keras-tuner-1.0.2.tar.gz (62kB)\n","\u001b[K     |████████████████████████████████| 71kB 6.4MB/s \n","\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (20.9)\n","Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (0.16.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (1.19.5)\n","Requirement already satisfied: tabulate in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (0.8.9)\n","Collecting terminaltables\n","  Downloading https://files.pythonhosted.org/packages/9b/c4/4a21174f32f8a7e1104798c445dacdc1d4df86f2f26722767034e4de4bff/terminaltables-3.1.0.tar.gz\n","Collecting colorama\n","  Downloading https://files.pythonhosted.org/packages/44/98/5b86278fbbf250d239ae0ecb724f8572af1c91f4a11edf4d36a206189440/colorama-0.4.4-py2.py3-none-any.whl\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (4.41.1)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (2.23.0)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (1.4.1)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (0.22.2.post1)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->keras-tuner) (2.4.7)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->keras-tuner) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->keras-tuner) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->keras-tuner) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->keras-tuner) (2020.12.5)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->keras-tuner) (1.0.1)\n","Building wheels for collected packages: keras-tuner, terminaltables\n","  Building wheel for keras-tuner (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for keras-tuner: filename=keras_tuner-1.0.2-cp37-none-any.whl size=78938 sha256=1de2525ac18384ff051d226c21d1963dd09462e6a30e1c3cb245e3c74ea4c6d9\n","  Stored in directory: /root/.cache/pip/wheels/bb/a1/8a/7c3de0efb3707a1701b36ebbfdbc4e67aedf6d4943a1f463d6\n","  Building wheel for terminaltables (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for terminaltables: filename=terminaltables-3.1.0-cp37-none-any.whl size=15356 sha256=ca005cf041ccc7bfad7b2a53e802ec699b59b85238805c1ecbec13556a32c51d\n","  Stored in directory: /root/.cache/pip/wheels/30/6b/50/6c75775b681fb36cdfac7f19799888ef9d8813aff9e379663e\n","Successfully built keras-tuner terminaltables\n","Installing collected packages: terminaltables, colorama, keras-tuner\n","Successfully installed colorama-0.4.4 keras-tuner-1.0.2 terminaltables-3.1.0\n","Collecting gpflow\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/55/25/f3d0b5a7bea6c371ddbce6f2fb17b668d2782379be9c70cc40d2f063b67c/gpflow-2.2.1-py3-none-any.whl (271kB)\n","\u001b[K     |████████████████████████████████| 276kB 14.7MB/s \n","\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from gpflow) (20.9)\n","Requirement already satisfied: tensorflow>=2.2.0 in /usr/local/lib/python3.7/dist-packages (from gpflow) (2.4.1)\n","Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from gpflow) (56.1.0)\n","Collecting dataclasses\n","  Downloading https://files.pythonhosted.org/packages/26/2f/1095cdc2868052dd1e64520f7c0d5c8c550ad297e944e641dbf1ffbb9a5d/dataclasses-0.6-py3-none-any.whl\n","Collecting multipledispatch>=0.6\n","  Downloading https://files.pythonhosted.org/packages/89/79/429ecef45fd5e4504f7474d4c3c3c4668c267be3370e4c2fd33e61506833/multipledispatch-0.6.0-py3-none-any.whl\n","Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from gpflow) (1.4.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from gpflow) (1.19.5)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from gpflow) (3.7.4.3)\n","Requirement already satisfied: tensorflow-probability>0.10.0 in /usr/local/lib/python3.7/dist-packages (from gpflow) (0.12.1)\n","Requirement already satisfied: tabulate in /usr/local/lib/python3.7/dist-packages (from gpflow) (0.8.9)\n","Collecting deprecated\n","  Downloading https://files.pythonhosted.org/packages/fb/73/994edfcba74443146c84b91921fcc269374354118d4f452fb0c54c1cbb12/Deprecated-1.2.12-py2.py3-none-any.whl\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->gpflow) (2.4.7)\n","Requirement already satisfied: absl-py~=0.10 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->gpflow) (0.12.0)\n","Requirement already satisfied: grpcio~=1.32.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->gpflow) (1.32.0)\n","Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->gpflow) (1.12)\n","Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->gpflow) (0.2.0)\n","Requirement already satisfied: six~=1.15.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->gpflow) (1.15.0)\n","Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->gpflow) (1.1.0)\n","Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->gpflow) (0.3.3)\n","Requirement already satisfied: tensorboard~=2.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->gpflow) (2.4.1)\n","Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->gpflow) (1.1.2)\n","Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->gpflow) (0.36.2)\n","Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->gpflow) (1.12.1)\n","Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->gpflow) (3.12.4)\n","Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->gpflow) (1.6.3)\n","Requirement already satisfied: tensorflow-estimator<2.5.0,>=2.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->gpflow) (2.4.0)\n","Requirement already satisfied: h5py~=2.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->gpflow) (2.10.0)\n","Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->gpflow) (3.3.0)\n","Requirement already satisfied: dm-tree in /usr/local/lib/python3.7/dist-packages (from tensorflow-probability>0.10.0->gpflow) (0.1.6)\n","Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from tensorflow-probability>0.10.0->gpflow) (4.4.2)\n","Requirement already satisfied: cloudpickle>=1.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow-probability>0.10.0->gpflow) (1.3.0)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow>=2.2.0->gpflow) (1.8.0)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow>=2.2.0->gpflow) (0.4.4)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow>=2.2.0->gpflow) (2.23.0)\n","Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow>=2.2.0->gpflow) (1.30.0)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow>=2.2.0->gpflow) (2.0.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow>=2.2.0->gpflow) (3.3.4)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow>=2.2.0->gpflow) (1.3.0)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow>=2.2.0->gpflow) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow>=2.2.0->gpflow) (2020.12.5)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow>=2.2.0->gpflow) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow>=2.2.0->gpflow) (2.10)\n","Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow>=2.2.0->gpflow) (4.7.2)\n","Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow>=2.2.0->gpflow) (4.2.2)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow>=2.2.0->gpflow) (0.2.8)\n","Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.4->tensorflow>=2.2.0->gpflow) (4.0.1)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow>=2.2.0->gpflow) (3.1.0)\n","Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.7/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3.6\"->google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow>=2.2.0->gpflow) (0.4.8)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard~=2.4->tensorflow>=2.2.0->gpflow) (3.4.1)\n","Installing collected packages: dataclasses, multipledispatch, deprecated, gpflow\n","Successfully installed dataclasses-0.6 deprecated-1.2.12 gpflow-2.2.1 multipledispatch-0.6.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"dWN1YdD7Qvc2","executionInfo":{"status":"ok","timestamp":1621871089976,"user_tz":-60,"elapsed":1863,"user":{"displayName":"Hans Roggeman","photoUrl":"","userId":"10574434403170915342"}}},"source":["import tensorflow as tf\n","from tensorflow.keras.models import Sequential, load_model, Model\n","from tensorflow.keras.layers import BatchNormalization, Dense, LeakyReLU, Dropout\n","from keras_self_attention import SeqSelfAttention, SeqWeightedAttention\n","import site\n","import pandas as pd\n","import numpy as np\n","import matplotlib\n","import os"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"nmcD3FuxQw7Q","executionInfo":{"status":"ok","timestamp":1621871089977,"user_tz":-60,"elapsed":4,"user":{"displayName":"Hans Roggeman","photoUrl":"","userId":"10574434403170915342"}}},"source":["pd.set_option('display.width', 400)\n","pd.set_option('display.max_columns', 40)"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"rfyld79IQ0j0","executionInfo":{"status":"ok","timestamp":1621871090857,"user_tz":-60,"elapsed":883,"user":{"displayName":"Hans Roggeman","photoUrl":"","userId":"10574434403170915342"}}},"source":["import tensorflow as tf\n","from tensorflow.keras.utils import to_categorical\n","import h5py as h5\n","import matplotlib.pyplot as plt\n","from tensorflow.keras.models import Model\n","import errno\n","import os\n","from collections import defaultdict\n","from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard\n","from tensorflow.summary import create_file_writer\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import confusion_matrix\n","import kerastuner as kt\n","from kerastuner import HyperModel\n","import numpy as np\n","import itertools\n","import multiprocessing\n","import tensorflow as tf\n","from tensorflow.keras.models import Sequential, load_model, Model\n","from tensorflow.keras.layers import BatchNormalization, Dense, LeakyReLU, Dropout\n","from keras_self_attention import SeqSelfAttention, SeqWeightedAttention\n","import site\n","import pandas as pd\n","import numpy as np\n","import matplotlib\n","import os"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"1DZ2zSmhRDJf","executionInfo":{"status":"ok","timestamp":1621871092432,"user_tz":-60,"elapsed":2,"user":{"displayName":"Hans Roggeman","photoUrl":"","userId":"10574434403170915342"}}},"source":["def get_features_model(model_name, combined_models):\n","    for ids, models in combined_models:\n","        if models[0].name == model_name:\n","            return models[1]\n","    return None\n","\n","def get_features_from_combined_models(combined_models, X_input):\n","    data_features = []\n","    for ids, models in combined_models:\n","        data_features.append(np.array(models[1].predict(X_input), dtype='float64'))\n","    return np.concatenate(tuple(data_features), axis=1)\n"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"Nn8uaSm8Cjzv","executionInfo":{"status":"ok","timestamp":1621871093374,"user_tz":-60,"elapsed":339,"user":{"displayName":"Hans Roggeman","photoUrl":"","userId":"10574434403170915342"}}},"source":["def coShuffled_vectors(X, Y):\n","    if tf.shape(X)[0] == tf.shape(Y)[0]:\n","        test_idxs = tf.range(start=0, limit=tf.shape(X)[0], dtype=tf.int32)\n","        shuffled_test_idxs = tf.random.shuffle(test_idxs)\n","        return (tf.gather(X, shuffled_test_idxs), tf.gather(Y, shuffled_test_idxs))\n","    else:\n","        raise ValueError(f\"0-dimension has to be the same {tf.shape(X)[0]} != {tf.shape(Y)[0]}\")\n","\n","\n","def getNpArrayFromH5(hf_Data):\n","    X_train = hf_Data['Train_Data']  # Get train set\n","    X_train = np.array(X_train)\n","    Y_train = hf_Data['Label']  # Get train label\n","    Y_train = np.array(Y_train)\n","    return X_train, Y_train\n","\n","# data extraction\n","def getData(is500=True, shuffle=False, ise2e=False, include_secondary=False, validation_split=None, isColab=False):\n","    if not include_secondary:\n","        hf_Train = h5.File(\n","            f'./{\"data\" if not isColab else \"drive/MyDrive/data_papers/ncRNA\"}/{\"e2e_Train_Data\" if ise2e else \"Fold_10_Train_Data\"}_{str(500) if is500 else str(1000)}.h5', 'r')\n","        hf_Test = h5.File(\n","            f'./{\"data\" if not isColab else \"drive/MyDrive/data_papers/ncRNA\"}/{\"e2e_Test_Data\" if ise2e else \"Fold_10_Test_Data\"}_{str(500) if is500 else str(1000)}.h5', 'r')\n","    else:\n","        hf_Train = h5.File(f'./{\"data\" if not isColab else \"drive/MyDrive/data_papers/ncRNA\"}/e2e_Train_Secondary_Data_1136.h5', 'r')\n","        hf_Test = h5.File(f'./{\"data\" if not isColab else \"drive/MyDrive/data_papers/ncRNA\"}/e2e_Test_Secondary_Data_1136.h5', 'r')\n","\n","    X_train, Y_train = getNpArrayFromH5(hf_Train)\n","    X_test, Y_test = getNpArrayFromH5(hf_Test)\n","    Y_train = to_categorical(Y_train, 13)  # Process the label of tain\n","    Y_test = to_categorical(Y_test, 13)  # Process the label of te\n","\n","    if shuffle:\n","        X_train, Y_train = coShuffled_vectors(X_train, Y_train)\n","        X_test, Y_test = coShuffled_vectors(X_test, Y_test)\n","\n","    X_validation = Y_validation = None\n","    if validation_split is not None:\n","        # sklearn split shuffles anyway\n","        X_train, X_validation, Y_train, Y_validation = train_test_split(X_train, Y_train, test_size=validation_split)\n","\n","    return X_train, Y_train, X_test, Y_test, X_validation, Y_validation\n","\n","\n","def getE2eData(is500=True, shuffle=False, include_secondary=False, isColab=False):\n","    if not include_secondary:\n","        hf_Train = h5.File(\n","            f'./{\"data\" if not isColab else \"drive/MyDrive/data_papers/ncRNA\"}/e2e_Train_Data_{str(500) if is500 else str(1000)}.h5', 'r')\n","        hf_Test = h5.File(\n","            f'./{\"data\" if not isColab else \"drive/MyDrive/data_papers/ncRNA\"}/e2e_Test_Data_{str(500) if is500 else str(1000)}.h5', 'r')\n","    else:\n","        hf_Train = h5.File(f'./{\"data\" if not isColab else \"drive/MyDrive/data_papers/ncRNA\"}/e2e_Train_Secondary_Data_1136.h5', 'r')\n","        hf_Test = h5.File(f'./{\"data\" if not isColab else \"drive/MyDrive/data_papers/ncRNA\"}/e2e_Test_Secondary_Data_1136.h5', 'r')\n","\n","    X_train, Y_train = getNpArrayFromH5(hf_Train)\n","    X_test, Y_test = getNpArrayFromH5(hf_Test)\n","    Y_train = to_categorical(Y_train, 13)  # Process the label of tain\n","    Y_test = to_categorical(Y_test, 13)  # Process the label of te\n","\n","    if shuffle:\n","        X_train, Y_train = coShuffled_vectors(X_train, Y_train)\n","        X_test, Y_test = coShuffled_vectors(X_test, Y_test)\n","\n","    hf_Val = h5.File(f'./{\"data\" if not isColab else \"drive/MyDrive/data_papers/ncRNA\"}/e2e_Val_Secondary_Data_1136.h5', 'r') if include_secondary else h5.File(\n","        f'./{\"data\" if not isColab else \"drive/MyDrive/data_papers/ncRNA\"}/e2e_Val_Data_{str(500) if is500 else str(1000)}.h5', 'r')\n","    X_validation, Y_validation = getNpArrayFromH5(hf_Val)\n","    Y_validation = to_categorical(Y_validation, 13)  # Process the label of tain\n","\n","    return X_train, Y_train, X_test, Y_test, X_validation, Y_validation\n","\n","\n","def getE2eDataJustSecondary(shuffle=False,isColab=False):\n","    hf_Train = h5.File(f'./{\"data\" if not isColab else \"drive/MyDrive/data_papers/ncRNA\"}/e2e_Train_just_Secondary_Data_1000.h5', 'r')\n","    hf_Test = h5.File(f'./{\"data\" if not isColab else \"drive/MyDrive/data_papers/ncRNA\"}/e2e_Test_just_Secondary_Data_1000.h5', 'r')\n","\n","    X_train, Y_train = getNpArrayFromH5(hf_Train)\n","    X_test, Y_test = getNpArrayFromH5(hf_Test)\n","    Y_train = to_categorical(Y_train, 13)  # Process the label of tain\n","    Y_test = to_categorical(Y_test, 13)  # Process the label of te\n","\n","    if shuffle:\n","        X_train, Y_train = coShuffled_vectors(X_train, Y_train)\n","        X_test, Y_test = coShuffled_vectors(X_test, Y_test)\n","\n","    hf_Val = h5.File(f'./{\"data\" if not isColab else \"drive/MyDrive/data_papers/ncRNA\"}/e2e_Val_just_Secondary_Data_1000.h5', 'r')\n","    \n","    X_validation, Y_validation = getNpArrayFromH5(hf_Val)\n","    Y_validation = to_categorical(Y_validation, 13)  # Process the label of tain\n","\n","    return X_train, Y_train, X_test, Y_test, X_validation, Y_validation\n"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"RHCMi9z-xlo-","executionInfo":{"status":"ok","timestamp":1621871095344,"user_tz":-60,"elapsed":253,"user":{"displayName":"Hans Roggeman","photoUrl":"","userId":"10574434403170915342"}}},"source":["def reverse_one_hot(Y_input):\n","    return np.apply_along_axis(np.argmax, 1, Y_input) + 1\n","    \n","def sparse_setdiff(a1, a2):\n","    a1a = a1.reshape(a1.shape[0], -1)\n","    a2a = a2.reshape(a2.shape[0], -1)\n","    spa2a = [np.where(x)[0].tolist() for x in a2a]\n","    spa1a = [np.where(x)[0].tolist() for x in a1a]\n","    idxs_to_keep = []\n","    for idx, sample in enumerate(spa1a):\n","        try:\n","            spa2a.index(sample)\n","        except ValueError:\n","            # not in list\n","            idxs_to_keep.append(idx)\n","    return a1[idxs_to_keep], idxs_to_keep\n","\n","def get_combined_features_from_models(\n","    \n","        to_combine,\n","        X_train, Y_train,\n","        X_test, Y_test,\n","        reverse_one_hot=False,\n","        normalize_X_func=None):\n","    \n","    models = []\n","    models_dict = {}\n","    X_trains_out = []\n","    X_test_out = []\n","    XY_dict = defaultdict(lambda: defaultdict(lambda: defaultdict(lambda: defaultdict(lambda: None))))\n","\n","    models_have_different_inputs = isinstance(Y_train,list)\n","\n","    if reverse_one_hot:\n","        if models_have_different_inputs:\n","            Y_train_new = np.apply_along_axis(np.argmax, 1, Y_train) + 1\n","            Y_test_new = np.apply_along_axis(np.argmax, 1, Y_test) + 1\n","        else:\n","            Y_train_new = [ np.apply_along_axis(np.argmax, 1, y_train) + 1 for y_train in Y_train ]  \n","            Y_test_new = [ np.apply_along_axis(np.argmax, 1, y_test) + 1 for y_test in Y_test ]              \n","    else:\n","        if models_have_different_inputs:\n","            Y_train_new = Y_train.copy()\n","            Y_test_new = Y_test.copy()\n","        else:\n","            Y_train_new = [ y_train.copy() for y_train in Y_train ] \n","            Y_test_new = [ y_test.copy() for y_test in Y_train ] \n","            \n","\n","    extraction_counter =0\n","    for model_file_name, layer_name, kwargs in to_combine:\n","        model_here = None\n","        if isinstance(model_file_name, tf.keras.models.Model):\n","            model_here = model_file_name\n","            model_file_name = model_here.name\n","        else:\n","            if model_file_name in models_dict.keys():\n","                model_here = models_dict[model_file_name]\n","            else:\n","                model_here = tf.keras.models.load_model(model_file_name,\n","                                                        **kwargs) if kwargs is not None else tf.keras.models.load_model \\\n","                    (model_file_name)\n","\n","        features_model = Model(model_here.input,\n","                               get_layer_by_name(model_here.layers, layer_name).output)\n","        \n","        if normalize_X_func is None:\n","            X_trains_out.append(np.array(features_model.predict(X_train if not models_have_different_inputs else X_train[extraction_counter]), dtype='float64'))\n","            X_test_out.append(np.array(features_model.predict(X_test if not models_have_different_inputs else X_test[extraction_counter]), dtype='float64'))\n","        else:\n","            X_trains_out.append(np.array(normalize_X_func(features_model.predict(X_train if not models_have_different_inputs else X_train[extraction_counter])), dtype='float64'))\n","            X_test_out.append(np.array(normalize_X_func(features_model.predict(X_test if not models_have_different_inputs else X_test[extraction_counter])), dtype='float64'))\n","        XY_dict[model_file_name][layer_name]['Train']['X'] = X_trains_out[-1]\n","        XY_dict[model_file_name][layer_name]['Test']['X'] = X_test_out[-1]\n","        XY_dict[model_file_name][layer_name]['Train']['Y'] = Y_train_new\n","        XY_dict[model_file_name][layer_name]['Test']['Y'] = Y_test_new\n","        models.append(((model_file_name, layer_name), (model_here, features_model)))\n","        models_dict[model_file_name] = model_here\n","        extraction_counter += 1\n","\n","    X_train_new = np.concatenate(tuple(X_trains_out), axis=1)\n","    X_test_new = np.concatenate(tuple(X_test_out), axis=1)\n","\n","    data_train = (X_train_new, Y_train_new)\n","    data_test = (X_test_new, Y_test_new)\n","\n","    return models, data_train, data_test, XY_dict\n","\n","def get_layer_by_name(layers, name, return_first=True):\n","    matching_named_layers = [l for l in layers if l.name == name]\n","    if not matching_named_layers:\n","        return None\n","    return matching_named_layers[0] if return_first else matching_named_layers\n","\n","\n","def make_dir_if_not_exist(used_path):\n","    if not os.path.isdir(used_path):\n","        try:\n","            os.mkdir(used_path)\n","        except OSError as exc:\n","            if exc.errno != errno.EEXIST:\n","                raise exc\n","            else:\n","                raise ValueError(f'{used_path} directoy cannot be created because its parent directory does not exist.')\n","\n","\n","def source_model(model_func, model_name, input_shape):\n","    m = None\n","    if isinstance(model_func, tf.keras.models.Model):\n","        m = model_func\n","        m._name = model_name\n","    else:\n","        m = model_func(model_name, input_shape)\n","    return m"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"vjtTz4aoKrVq","executionInfo":{"status":"ok","timestamp":1621871098939,"user_tz":-60,"elapsed":1406,"user":{"displayName":"Hans Roggeman","photoUrl":"","userId":"10574434403170915342"}}},"source":["import gpflow\n","from gpflow.utilities import ops, print_summary, set_trainable\n","from gpflow.config import set_default_float, default_float, set_default_summary_fmt\n","from gpflow.ci_utils import ci_niter\n","import random\n","\n","\n","def get_gp_acc(mGP, data_gp):\n","    (Y_test_GP_mean, Y_test_GP_variance) = mGP.predict_y(data_gp[0])\n","    Y_test_GP_mean = Y_test_GP_mean.numpy()\n","    Y_test_pred = []\n","    for i in range(data_gp[0].shape[0]):\n","        Y_test_pred.append(np.argmax(Y_test_GP_mean[i,]))\n","    diffs = Y_test_pred - data_gp[1]\n","    test_acc = sum(1 for x in diffs if x == 0) / data_gp[0].shape[0]\n","    return test_acc, Y_test_pred, (Y_test_GP_mean, Y_test_GP_variance)\n","\n","def get_features_model(model_name, combined_models):\n","    for ids, models in combined_models:\n","        if models[0].name == model_name:\n","            return models[1]\n","    return None\n","\n","def get_features_from_combined_models(combined_models, X_input):\n","    data_features = []\n","    for ids, models in combined_models:\n","        data_features.append(np.array(models[1].predict(X_input), dtype='float64'))\n","    return np.concatenate(tuple(data_features), axis=1)"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"VM12SQkLykKU","executionInfo":{"status":"ok","timestamp":1621871107570,"user_tz":-60,"elapsed":6483,"user":{"displayName":"Hans Roggeman","photoUrl":"","userId":"10574434403170915342"}}},"source":["# 'new' data \n","X_train_1000e, Y_train_1000e, X_test_1000e, Y_test_1000e, X_val_1000e, Y_val_1000e = getE2eData(is500=False,\n","                                                                                                    include_secondary=False,\n","                                                                                                    isColab=True)\n","X_train_1000e_w2nd, Y_train_1000e_w2nd, X_test_1000e_w2nd, Y_test_1000e_w2nd, X_val_1000e_w2nd, Y_val_1000e_w2nd = getE2eData(is500=False, include_secondary=True, isColab=True)\n","X_train_1000e_j2nd, Y_train_1000e_j2nd, X_test_1000e_j2nd, Y_test_1000e_j2nd, X_val_1000e_j2nd, Y_val_1000e_j2nd = getE2eDataJustSecondary(isColab=True)"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VRzhAOuY0B33","executionInfo":{"status":"ok","timestamp":1621871107570,"user_tz":-60,"elapsed":11,"user":{"displayName":"Hans Roggeman","photoUrl":"","userId":"10574434403170915342"}},"outputId":"6223f8ff-1330-47cb-f74c-fec68e93f3cd"},"source":["print (X_train_1000e.shape)\n","print (X_train_1000e_w2nd.shape)\n","print (X_train_1000e_j2nd.shape)"],"execution_count":10,"outputs":[{"output_type":"stream","text":["(6858, 1000, 8)\n","(6858, 1136, 12)\n","(6858, 1000, 3)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"TuiFwxcoziU9","executionInfo":{"status":"ok","timestamp":1621871107571,"user_tz":-60,"elapsed":5,"user":{"displayName":"Hans Roggeman","photoUrl":"","userId":"10574434403170915342"}}},"source":["# merge into a new train:\n","X_new_train = np.concatenate( (X_train_1000e, X_val_1000e), axis=0 )\n","Y_new_train = np.concatenate( (Y_train_1000e, Y_val_1000e), axis=0 )    \n","\n","X_new_train_j2nd = np.concatenate( (X_train_1000e_j2nd, X_val_1000e_j2nd), axis=0 )\n","Y_new_train_j2nd = np.concatenate( (Y_train_1000e_j2nd, Y_val_1000e_j2nd), axis=0 )    \n","\n","X_new_train_w2nd = np.concatenate( (X_train_1000e_w2nd, X_val_1000e_w2nd), axis=0 )\n","Y_new_train_w2nd = np.concatenate( (Y_train_1000e_w2nd, Y_val_1000e_w2nd), axis=0 )    \n"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"v1DOk2gzcupg","executionInfo":{"status":"ok","timestamp":1621871535021,"user_tz":-60,"elapsed":158343,"user":{"displayName":"Hans Roggeman","photoUrl":"","userId":"10574434403170915342"}},"outputId":"a49263ac-a825-463d-92d3-85e2e9b8183b"},"source":["# CNNs no secondary\n","mCNN1_1000 = load_model(\"./drive/MyDrive/data_papers/ncRNA/CNN_baseline_May16_e2e1000_256.h5\") # CNN on 256 1st dens\n","mCNN1_1000._name = \"cnn_merged_newdata_finalist_1\"\n","\n","mCNN2_1000 = load_model(\"./drive/MyDrive/data_papers/ncRNA/CNN_baseline_May16_e2e.h5\")   # CNN on 128 1st dens\n","mCNN2_1000._name = \"cnn_merged_newdata_finalist_2\"\n","\n","mCNN_1000 = load_model(\"./drive/MyDrive/data_papers/ncRNA/cnn_noTest_20210516_model_445_0.998\")   # CNN on 128 1st dens\n","mCNN_1000._name = \"cnn_merged_newdata_colab_finalist\"\n","\n","mCNN_1000 = load_model(\"./drive/MyDrive/data_papers/ncRNA/cnn_noTest_20210516_model_445_0.998\")   # CNN on 128 1st dens\n","mCNN_1000._name = \"cnn_merged_newdata_colab_finalist\"\n","\n","# CNN w/ secondary\n","mCNN_1000_w2nd = load_model(\"./drive/MyDrive/data_papers/ncRNA/CNN_baseline_May16_e2e_secondary.h5\", custom_objects=SeqWeightedAttention.get_custom_objects())\n","mCNN_1000_w2nd._name = \"cnn_merged_newdata_w_secondary_finalist\"\n","\n","# CNN secondary only\n","mCNN_1000_j2nd = load_model(\"./drive/MyDrive/data_papers/ncRNA/cnn_j2nd_noTest_20210516_model_488_0.990\", custom_objects=SeqWeightedAttention.get_custom_objects())\n","mCNN_1000_j2nd._name = \"cnn_merged_newdata_j_secondary_finalist\"\n","\n","# RNN on the same data\n","RNN_1000 = load_model(\"./drive/MyDrive/data_papers/ncRNA/RNN_baseline_17May_180.h5\", custom_objects=SeqWeightedAttention.get_custom_objects())   # RNN on 180ep 1000 ts\n","RNN_1000._name = \"rnn_merged_newdata_colab_finalist\"\n","\n","# RNN with secondary still needs to continue fit ## requires the validation in the fit data!\n","RNN_1000_w2nd = load_model(\"./drive/MyDrive/data_papers/ncRNA/rnn_newdata_w2nd_colab_continue_fit_epoch_22_accuracy_0.959.h5\", custom_objects=SeqWeightedAttention.get_custom_objects())   # RNN on 180ep 1000 ts\n","RNN_1000_w2nd._name = \"rnn_newdata_w2nd_colab_continue_fit\"\n","\n","# RNN on the e2e data just secondary\n","RNN_1000_j2nd = load_model(\"./drive/MyDrive/data_papers/ncRNA/rnn_newdata_j2nd_colab_continue_fit.h5\", custom_objects=SeqWeightedAttention.get_custom_objects())   # RNN on 180ep 1000 ts\n","RNN_1000_j2nd._name = \"rnn_newdata_j2nd_colab_continue_fit\"\n","\n","\n","mCNN1_1000.evaluate(X_test_1000e, Y_test_1000e)  # 96.15% \n","mCNN2_1000.evaluate(X_test_1000e, Y_test_1000e)  # 95.80 %  \n","mCNN_1000.evaluate(X_test_1000e, Y_test_1000e)  # 95.57% \n","mCNN_1000_w2nd.evaluate(X_test_1000e_w2nd, Y_test_1000e_w2nd)  # 94.64 %\n","mCNN_1000_j2nd.evaluate(X_test_1000e_j2nd, Y_test_1000e_j2nd)  # 72.96 %\n","RNN_1000.evaluate(X_test_1000e, Y_test_1000e)  # 95.45 %\n","RNN_1000_w2nd.evaluate(X_test_1000e_w2nd, Y_test_1000e_w2nd)  # 91.72 %\n","RNN_1000_j2nd.evaluate(X_test_1000e_j2nd, Y_test_1000e_j2nd)  # 63.52 %"],"execution_count":12,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:Layer gru will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n","WARNING:tensorflow:Layer gru will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n","WARNING:tensorflow:Layer gru will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n","WARNING:tensorflow:Layer gru_1 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n","WARNING:tensorflow:Layer gru_1 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n","WARNING:tensorflow:Layer gru_1 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n","WARNING:tensorflow:Layer gru_4 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n","WARNING:tensorflow:Layer gru_4 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n","WARNING:tensorflow:Layer gru_4 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n","WARNING:tensorflow:Layer gru_5 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n","WARNING:tensorflow:Layer gru_5 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n","WARNING:tensorflow:Layer gru_5 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n","WARNING:tensorflow:Layer gru will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n","WARNING:tensorflow:Layer gru will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n","WARNING:tensorflow:Layer gru will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n","WARNING:tensorflow:Layer gru_1 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n","WARNING:tensorflow:Layer gru_1 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n","WARNING:tensorflow:Layer gru_1 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n","27/27 [==============================] - 17s 8ms/step - loss: 0.2015 - accuracy: 0.9615\n","27/27 [==============================] - 0s 5ms/step - loss: 0.2149 - accuracy: 0.9580\n","27/27 [==============================] - 0s 5ms/step - loss: 0.2126 - accuracy: 0.9557\n","27/27 [==============================] - 0s 6ms/step - loss: 0.2043 - accuracy: 0.9464\n","27/27 [==============================] - 1s 5ms/step - loss: 1.7761 - accuracy: 0.7296\n","27/27 [==============================] - 32s 1s/step - loss: 0.2070 - accuracy: 0.9545\n","27/27 [==============================] - 36s 1s/step - loss: 0.3620 - accuracy: 0.9172\n","27/27 [==============================] - 32s 1s/step - loss: 1.3527 - accuracy: 0.6352\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["[1.3526557683944702, 0.6351981163024902]"]},"metadata":{"tags":[]},"execution_count":12}]},{"cell_type":"code","metadata":{"id":"edqmmHpEOhUT"},"source":["data_train_ll_no2nd_j2nd[0].shape"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"yBTr_vs33xmj","executionInfo":{"status":"ok","timestamp":1621871863561,"user_tz":-60,"elapsed":314806,"user":{"displayName":"Hans Roggeman","photoUrl":"","userId":"10574434403170915342"}}},"source":["    to_combine_last_layers_no2nd_j2nd = [\n","        (mCNN1_1000, \"dense_26\", None),\n","        (mCNN2_1000, \"dense_14\", None),\n","        (mCNN_1000_j2nd,\"dense_5\", None)\n","    ]\n","\n","    combined_models_no2nd_j2nd, data_train_ll_no2nd_j2nd, data_test_ll_no2nd_j2nd, data_access_ll_no2nd_j2nd = get_combined_features_from_models(\n","        to_combine_last_layers_no2nd_j2nd,\n","        [ X_new_train, X_new_train, X_new_train_j2nd],\n","        [ Y_new_train, Y_new_train, Y_new_train_j2nd], \n","        [ X_test_1000e, X_test_1000e, X_test_1000e_j2nd],\n","        [ Y_test_1000e, Y_test_1000e, Y_test_1000e_j2nd],\n","        reverse_one_hot=False)\n","\n","    to_combine_last_layers_no2nd_j2nd_rNo2nd = [\n","        (mCNN1_1000, \"dense_26\", None),\n","        (mCNN_1000_j2nd,\"dense_5\", None),\n","        (RNN_1000,\"dense_3\", None)\n","    ]\n","\n","    combined_models_no2nd_j2nd_rNo2nd, data_train_ll_no2nd_j2nd_rNo2nd, data_test_ll_no2nd_j2nd_rNo2nd, data_access_ll_no2nd_j2nd_rNo2nd = get_combined_features_from_models(\n","        to_combine_last_layers_no2nd_j2nd_rNo2nd,\n","        [ X_new_train, X_new_train_j2nd, X_new_train],\n","        [ Y_new_train, Y_new_train_j2nd, Y_new_train], \n","        [ X_test_1000e, X_test_1000e_j2nd, X_test_1000e],\n","        [ Y_test_1000e, Y_test_1000e_j2nd, Y_test_1000e],\n","        reverse_one_hot=False)\n","\n","\n"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"id":"EOSL6e-pdD7h","executionInfo":{"status":"ok","timestamp":1621872177001,"user_tz":-60,"elapsed":313445,"user":{"displayName":"Hans Roggeman","photoUrl":"","userId":"10574434403170915342"}}},"source":["    to_combine_penul_layers_no2nd_j2nd = [\n","        (mCNN1_1000, \"dense_25\", None),\n","        (mCNN2_1000, \"dense_13\", None),\n","        (mCNN_1000_j2nd,\"dense_4\", None)\n","    ]\n","\n","    combined_models_penul_no2nd_j2nd, data_train_ll_penul_no2nd_j2nd, data_test_ll_penul_no2nd_j2nd, data_access_ll_penul_no2nd_j2nd = get_combined_features_from_models(\n","        to_combine_penul_layers_no2nd_j2nd,\n","        [ X_new_train, X_new_train, X_new_train_j2nd],\n","        [ Y_new_train, Y_new_train, Y_new_train_j2nd], \n","        [ X_test_1000e, X_test_1000e, X_test_1000e_j2nd],\n","        [ Y_test_1000e, Y_test_1000e, Y_test_1000e_j2nd],\n","        reverse_one_hot=False)\n","\n","    to_combine_penul_layers_no2nd_j2nd_rNo2nd = [\n","        (mCNN1_1000, \"dense_25\", None),\n","        (mCNN_1000_j2nd,\"dense_4\", None),\n","        (RNN_1000,\"dense_2\", None)\n","    ]\n","\n","    combined_models_penul_no2nd_j2nd_rNo2nd, data_train_ll_penul_no2nd_j2nd_rNo2nd, data_test_ll_penul_no2nd_j2nd_rNo2nd, data_access_ll_penul_no2nd_j2nd_rNo2nd = get_combined_features_from_models(\n","        to_combine_penul_layers_no2nd_j2nd_rNo2nd,\n","        [ X_new_train, X_new_train_j2nd, X_new_train],\n","        [ Y_new_train, Y_new_train_j2nd, Y_new_train], \n","        [ X_test_1000e, X_test_1000e_j2nd, X_test_1000e],\n","        [ Y_test_1000e, Y_test_1000e_j2nd, Y_test_1000e],\n","        reverse_one_hot=False)"],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"id":"TBeY_W2ru1XM","executionInfo":{"status":"ok","timestamp":1621872798312,"user_tz":-60,"elapsed":621320,"user":{"displayName":"Hans Roggeman","photoUrl":"","userId":"10574434403170915342"}}},"source":["    to_combine_last_layers_no2nd_rNo2nd = [\n","        (mCNN1_1000, \"dense_26\", None),\n","        (RNN_1000,\"dense_3\", None)\n","    ]\n","\n","    combined_models_no2nd_rNo2nd, data_train_ll_no2nd_rNo2nd, data_test_ll_no2nd_rNo2nd, data_access_ll_no2nd_rNo2nd = get_combined_features_from_models(\n","        to_combine_last_layers_no2nd_rNo2nd,\n","        [ X_new_train, X_new_train],\n","        [ Y_new_train,  Y_new_train], \n","        [ X_test_1000e,  X_test_1000e],\n","        [ Y_test_1000e,  Y_test_1000e],\n","        reverse_one_hot=False)\n","    \n","    to_combine_penul_layers_no2nd_rNo2nd = [\n","        (mCNN1_1000, \"dense_25\", None),\n","        (RNN_1000,\"dense_2\", None)\n","    ]\n","\n","    combined_models_no2nd_rNo2nd_penul, data_train_penul_no2nd_rNo2nd, data_test_penul_no2nd_rNo2nd, data_access_penul_no2nd_rNo2nd = get_combined_features_from_models(\n","        to_combine_penul_layers_no2nd_rNo2nd,\n","        [ X_new_train, X_new_train],\n","        [ Y_new_train,  Y_new_train], \n","        [ X_test_1000e,  X_test_1000e],\n","        [ Y_test_1000e,  Y_test_1000e],\n","        reverse_one_hot=False)\n"],"execution_count":15,"outputs":[]},{"cell_type":"code","metadata":{"id":"mh5YoViKuPMA","executionInfo":{"status":"ok","timestamp":1621874031697,"user_tz":-60,"elapsed":1233394,"user":{"displayName":"Hans Roggeman","photoUrl":"","userId":"10574434403170915342"}}},"source":["    to_combine_last2_layers_no2nd_rNo2nd = [\n","        (mCNN1_1000, \"dense_25\", None),\n","        (mCNN1_1000, \"dense_26\", None),\n","        (RNN_1000,\"dense_2\", None),\n","        (RNN_1000,\"dense_3\", None)\n","    ]\n","\n","    combined_models_last2_no2nd_rNo2nd, data_train_last2_no2nd_rNo2nd, data_test_last2_no2nd_rNo2nd, data_access_last2_no2nd_rNo2nd = get_combined_features_from_models(\n","        to_combine_last2_layers_no2nd_rNo2nd,\n","        [ X_new_train, X_new_train, X_new_train, X_new_train],\n","        [ Y_new_train,  Y_new_train, Y_new_train,  Y_new_train], \n","        [ X_test_1000e,  X_test_1000e, X_test_1000e,  X_test_1000e],\n","        [ Y_test_1000e,  Y_test_1000e, Y_test_1000e,  Y_test_1000e],\n","        reverse_one_hot=False)\n","    \n","    to_combine_last2_layers_no2nd_j2nd_rNo2nd = [\n","        (mCNN1_1000, \"dense_25\", None),\n","        (mCNN1_1000, \"dense_26\", None),\n","        (mCNN_1000_j2nd,\"dense_4\", None),\n","        (mCNN_1000_j2nd,\"dense_5\", None),\n","        (RNN_1000,\"dense_2\", None),\n","        (RNN_1000,\"dense_3\", None)\n","    ]\n","\n","    combined_models_last2_no2nd_j2nd_rNo2nd, data_train_last2_no2nd_j2nd_rNo2nd, data_test_last2_no2nd_j2nd_rNo2nd, data_access_last2_no2nd_j2nd_rNo2nd = get_combined_features_from_models(\n","        to_combine_last2_layers_no2nd_j2nd_rNo2nd,\n","        [ X_new_train, X_new_train, X_new_train_j2nd, X_new_train_j2nd, X_new_train, X_new_train],\n","        [ Y_new_train,  Y_new_train, Y_new_train_j2nd, Y_new_train_j2nd, Y_new_train, Y_new_train], \n","        [ X_test_1000e,  X_test_1000e, X_test_1000e_j2nd, X_test_1000e_j2nd, X_test_1000e, X_test_1000e],\n","        [ Y_test_1000e,  Y_test_1000e, Y_test_1000e_j2nd, Y_test_1000e_j2nd, Y_test_1000e, Y_test_1000e],\n","        reverse_one_hot=False)"],"execution_count":16,"outputs":[]},{"cell_type":"code","metadata":{"id":"eKrbiGyWON7e","executionInfo":{"status":"ok","timestamp":1621877081821,"user_tz":-60,"elapsed":258,"user":{"displayName":"Hans Roggeman","photoUrl":"","userId":"10574434403170915342"}}},"source":["def get_gp_oos(data_gp, data_test, lengthscales_input, white_variance, kernel_func, num_inducing=100, num_it=10000):\n","  try:\n","    lengthscales = tf.convert_to_tensor([lengthscales_input] * data_gp[0].shape[1], dtype=default_float())\n","    kernel = (kernel_func_map[kernel_func](lengthscales=lengthscales)  + gpflow.kernels.White(variance=white_variance)) if white_variance > 0.0 else kernel_func_map[kernel_func](lengthscales=lengthscales)\n","    invlink = gpflow.likelihoods.RobustMax(np.max(data_test[1])+1)  # Robustmax inverse link function\n","    likelihood = gpflow.likelihoods.MultiClass(np.max(data_test[1])+1, invlink=invlink)  # Multiclass likelihood\n","    M = num_inducing # Number of inducing locations\n","    Z = data_gp[0][sorted(random.sample(range(0,data_gp[0].shape[0]),M)),:].copy()\n","    mGP = gpflow.models.SVGP(\n","        kernel=kernel,\n","        likelihood=likelihood,\n","        inducing_variable=Z,\n","        num_latent_gps=np.max(data_test[1])+1,\n","        whiten=True,\n","        q_diag=False,\n","    )\n","    # Only train the variational parameters\n","    set_trainable(mGP.kernel.kernels[1].variance, True)\n","    set_trainable(mGP.inducing_variable, True)\n","    opt = gpflow.optimizers.Scipy()\n","    opt_logs = opt.minimize(\n","        mGP.training_loss_closure(data_gp), mGP.trainable_variables,\n","        options=dict(maxiter=ci_niter(num_it))\n","    )\n","    test_acc, Y_test_pred, (gp_mean, gp_var) = get_gp_acc(mGP, data_test)\n","    print(test_acc, lengthscales_input, white_variance, kernel_func_map[kernel_func], num_inducing)  \n","    return test_acc, lengthscales_input, white_variance, kernel_func, num_inducing, Y_test_pred, mGP\n","  except :\n","     return -1.0, lengthscales_input, white_variance, kernel_func, num_inducing, None, mGP\n"],"execution_count":18,"outputs":[]},{"cell_type":"code","metadata":{"id":"VT-6YsoOLMQ4","executionInfo":{"status":"ok","timestamp":1621877086286,"user_tz":-60,"elapsed":253,"user":{"displayName":"Hans Roggeman","photoUrl":"","userId":"10574434403170915342"}}},"source":["# reproducibility:\n","np.random.seed(0)\n","tf.random.set_seed(123)"],"execution_count":19,"outputs":[]},{"cell_type":"code","metadata":{"id":"4QnYqsDmVPHl","executionInfo":{"status":"ok","timestamp":1621877087447,"user_tz":-60,"elapsed":2,"user":{"displayName":"Hans Roggeman","photoUrl":"","userId":"10574434403170915342"}}},"source":["kernel_func_map = dict(zip(list(range(7)), \n","                           [gpflow.kernels.Cosine, \n","                            gpflow.kernels.SquaredExponential, \n","                            gpflow.kernels.Exponential, \n","                            gpflow.kernels.Matern12, \n","                            gpflow.kernels.Matern32, \n","                            gpflow.kernels.Matern52, \n","                            gpflow.kernels.RationalQuadratic]))  "],"execution_count":20,"outputs":[]},{"cell_type":"code","metadata":{"id":"ccIAlfrhSh2p","executionInfo":{"status":"ok","timestamp":1621877088630,"user_tz":-60,"elapsed":2,"user":{"displayName":"Hans Roggeman","photoUrl":"","userId":"10574434403170915342"}}},"source":["input_sets = { 'lengthscales': [1e-2,1e-1,1,10.0,100.0], \n","                'white_variance' : [ 1e-3, 1e-2, 1e-1, 1.0, 10.0],\n","                   'kernel_funcs': list(range(7)),\n","              'num_inducing' : [20,40,60,80,120,200]\n","                   }\n","combs = np.stack(np.meshgrid(input_sets['lengthscales'],input_sets['white_variance'],input_sets['kernel_funcs'],input_sets['num_inducing']),-1).reshape(-1,len(input_sets.keys()))"],"execution_count":21,"outputs":[]},{"cell_type":"code","metadata":{"id":"KzCy6jqJiSrh"},"source":["# running the whole combination set\n","# results = np.apply_along_axis(lambda x: get_gp_oos(x[0],x[1],int(x[2]), int(x[3])) , 1, combs) "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"COHe5i4fX_RE","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1621877847298,"user_tz":-60,"elapsed":749725,"user":{"displayName":"Hans Roggeman","photoUrl":"","userId":"10574434403170915342"}},"outputId":"6d4099da-8038-4f01-f20f-fc837dbb16b9"},"source":["# just running one\n","data_gp_train = (data_train_ll_no2nd_j2nd[0], reverse_one_hot(data_train_ll_no2nd_j2nd[1][0])-1)\n","data_gp_test = (data_test_ll_no2nd_j2nd[0], reverse_one_hot(data_test_ll_no2nd_j2nd[1][0])-1)\n","resultsA = [ get_gp_oos(data_gp_train, data_gp_test, 0.1,0.01,4, 250, 4000),  get_gp_oos(data_gp_train, data_gp_test, 0.1,0.01,4, 100, 4000) ] \n","\n","data_gp_train = (data_train_ll_no2nd_j2nd_rNo2nd[0], reverse_one_hot(data_train_ll_no2nd_j2nd_rNo2nd[1][0])-1)\n","data_gp_test = (data_test_ll_no2nd_j2nd_rNo2nd[0], reverse_one_hot(data_test_ll_no2nd_j2nd_rNo2nd[1][0])-1)                                                                                                    \n","resultsB = [ get_gp_oos(data_gp_train, data_gp_test, 0.1,0.01,4, 250, 4000),  get_gp_oos(data_gp_train, data_gp_test, 0.1,0.01,4, 100, 4000) ] "],"execution_count":22,"outputs":[{"output_type":"stream","text":["0.9522144522144522 0.1 0.01 <class 'gpflow.kernels.stationaries.Matern32'> 250\n","0.9615384615384616 0.1 0.01 <class 'gpflow.kernels.stationaries.Matern32'> 100\n","0.9603729603729604 0.1 0.01 <class 'gpflow.kernels.stationaries.Matern32'> 250\n","0.9615384615384616 0.1 0.01 <class 'gpflow.kernels.stationaries.Matern32'> 100\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Q8baeJ0FsBBH","colab":{"base_uri":"https://localhost:8080/"},"outputId":"4789c84e-4d5b-481a-d6b8-538367caad36"},"source":["# just running one repeatedly\n","data_gp_train = (data_train_ll_no2nd_j2nd[0], reverse_one_hot(data_train_ll_no2nd_j2nd[1][0])-1)\n","data_gp_test = (data_test_ll_no2nd_j2nd[0], reverse_one_hot(data_test_ll_no2nd_j2nd[1][0])-1)\n","resultsGroupA = [ get_gp_oos(data_gp_train, data_gp_test, 0.1,0.01,4, 250, 4000) for i in range(100) ]\n","\n","oos_fn = \"/content/gp_ll_no2nd256_no2nd128_j2nd256.csv\"\n","gp_no2nd256_no2nd128_j2nd256_oos_acc = np.array([x[0] for x in resultsGroupA])\n","gp_no2nd256_no2nd128_j2nd256_oos_acc.tofile(oos_fn, sep=\",\")\n","\n","from google.colab import files\n","files.download(oos_fn)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["0.958041958041958 0.1 0.01 <class 'gpflow.kernels.stationaries.Matern32'> 250\n","0.9615384615384616 0.1 0.01 <class 'gpflow.kernels.stationaries.Matern32'> 250\n","0.9627039627039627 0.1 0.01 <class 'gpflow.kernels.stationaries.Matern32'> 250\n","0.9638694638694638 0.1 0.01 <class 'gpflow.kernels.stationaries.Matern32'> 250\n","0.951048951048951 0.1 0.01 <class 'gpflow.kernels.stationaries.Matern32'> 250\n","0.9638694638694638 0.1 0.01 <class 'gpflow.kernels.stationaries.Matern32'> 250\n","0.9568764568764568 0.1 0.01 <class 'gpflow.kernels.stationaries.Matern32'> 250\n","0.9638694638694638 0.1 0.01 <class 'gpflow.kernels.stationaries.Matern32'> 250\n","0.9557109557109557 0.1 0.01 <class 'gpflow.kernels.stationaries.Matern32'> 250\n","0.9603729603729604 0.1 0.01 <class 'gpflow.kernels.stationaries.Matern32'> 250\n","0.9557109557109557 0.1 0.01 <class 'gpflow.kernels.stationaries.Matern32'> 250\n","0.9592074592074592 0.1 0.01 <class 'gpflow.kernels.stationaries.Matern32'> 250\n","0.9568764568764568 0.1 0.01 <class 'gpflow.kernels.stationaries.Matern32'> 250\n","0.9568764568764568 0.1 0.01 <class 'gpflow.kernels.stationaries.Matern32'> 250\n","0.9615384615384616 0.1 0.01 <class 'gpflow.kernels.stationaries.Matern32'> 250\n","0.958041958041958 0.1 0.01 <class 'gpflow.kernels.stationaries.Matern32'> 250\n","0.9627039627039627 0.1 0.01 <class 'gpflow.kernels.stationaries.Matern32'> 250\n","0.9615384615384616 0.1 0.01 <class 'gpflow.kernels.stationaries.Matern32'> 250\n","0.9592074592074592 0.1 0.01 <class 'gpflow.kernels.stationaries.Matern32'> 250\n","0.958041958041958 0.1 0.01 <class 'gpflow.kernels.stationaries.Matern32'> 250\n","0.9568764568764568 0.1 0.01 <class 'gpflow.kernels.stationaries.Matern32'> 250\n","0.9603729603729604 0.1 0.01 <class 'gpflow.kernels.stationaries.Matern32'> 250\n","0.9615384615384616 0.1 0.01 <class 'gpflow.kernels.stationaries.Matern32'> 250\n","0.9615384615384616 0.1 0.01 <class 'gpflow.kernels.stationaries.Matern32'> 250\n","0.9638694638694638 0.1 0.01 <class 'gpflow.kernels.stationaries.Matern32'> 250\n","0.9592074592074592 0.1 0.01 <class 'gpflow.kernels.stationaries.Matern32'> 250\n","0.9592074592074592 0.1 0.01 <class 'gpflow.kernels.stationaries.Matern32'> 250\n","0.958041958041958 0.1 0.01 <class 'gpflow.kernels.stationaries.Matern32'> 250\n","0.9627039627039627 0.1 0.01 <class 'gpflow.kernels.stationaries.Matern32'> 250\n","0.9603729603729604 0.1 0.01 <class 'gpflow.kernels.stationaries.Matern32'> 250\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"vaR50KWoTWq1"},"source":["from sklearn.preprocessing import MinMaxScaler, StandardScaler\n","\n","def get_gp_oos_minmaxscaler(data_gp, data_test, lengthscales_target_avg, maxDev_ratio, kernel_func, num_inducing=100, num_it=4000):\n","  try:\n","    maxDev = lengthscales_target_avg*maxDev_ratio\n","    sd_train_features = np.apply_along_axis(lambda x: np.std(x)**2, 0, data_gp_train[0])\n","    scalerMM = MinMaxScaler()\n","    scaledMM = scalerMM.fit_transform(sd_train_features.reshape(-1,1)).reshape(1,-1)\n","    lengthscales = lengthscales_target_avg + ( scaledMM - 0.5 )*maxDev\n","\n","    lengthscales = tf.convert_to_tensor(lengthscales, dtype=default_float())\n","    kernel = kernel_func_map[kernel_func](lengthscales=lengthscales)\n","    invlink = gpflow.likelihoods.RobustMax(np.max(data_test[1])+1)  # Robustmax inverse link function\n","    likelihood = gpflow.likelihoods.MultiClass(np.max(data_test[1])+1, invlink=invlink)  # Multiclass likelihood\n","    M = num_inducing # Number of inducing locations\n","    Z = data_gp[0][sorted(random.sample(range(0,data_gp[0].shape[0]),M)),:].copy()\n","    mGP = gpflow.models.SVGP(\n","        kernel=kernel,\n","        likelihood=likelihood,\n","        inducing_variable=Z,\n","        num_latent_gps=np.max(data_test[1])+1,\n","        whiten=True,\n","        q_diag=False,\n","    )\n","    # Only train the variational parameters\n","    # set_trainable(mGP.kernel.kernels[1].variance, True)\n","    set_trainable(mGP.inducing_variable, False)\n","    opt = gpflow.optimizers.Scipy()\n","    opt_logs = opt.minimize(\n","        mGP.training_loss_closure(data_gp), mGP.trainable_variables,\n","        options=dict(maxiter=ci_niter(num_it))\n","    )\n","    test_acc, Y_test_pred, (gp_mean, gp_var) = get_gp_acc(mGP, data_test)\n","    print(test_acc, lengthscales_target_avg, maxDev_ratio, kernel_func_map[kernel_func], num_inducing)  \n","    return test_acc, lengthscales_target_avg, maxDev_ratio, kernel_func, num_inducing, Y_test_pred, mGP\n","  except :\n","     return -1.0, lengthscales_target_avg, maxDev_ratio, kernel_func, num_inducing, None, None\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MtTIvHkvFApG"},"source":["data_gp_train = (data_train_ll_no2nd_j2nd_rNo2nd[0], reverse_one_hot(data_train_ll_no2nd_j2nd_rNo2nd[1][0])-1)\n","data_gp_test = (data_test_ll_no2nd_j2nd_rNo2nd[0], reverse_one_hot(data_test_ll_no2nd_j2nd_rNo2nd[1][0])-1) "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"RywSyHHvnGCL"},"source":["# input_sets_varLengthscale = { 'lengthscales': [0.05,0.1,0.2,1.0], 'max_devs' : [ 0.1, 0.25, 0.5, 0.9], 'kernel_funcs': [1,2,3,4,5,6],'num_inducing' : [200] }\n","input_sets_varLengthscale = { 'lengthscales': [ x*0.05 + 0.25 for x in range(12)], 'max_devs' : [ x*0.05 + 0.05 for x in range(18) ], 'kernel_funcs': [6],'num_inducing' : [200] }\n","combs_varLengthscale = np.stack(np.meshgrid(input_sets_varLengthscale['lengthscales'],\n","                                            input_sets_varLengthscale['max_devs'],\n","                                            input_sets_varLengthscale['kernel_funcs'],\n","                                            input_sets_varLengthscale['num_inducing']),-1).reshape(-1,len(input_sets_varLengthscale.keys()))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"R5Dv_N94o9pX","outputId":"27533c7c-d14c-4ca7-b7f2-28a8b420c0c4"},"source":["# running the whole combination set\n","import warnings\n","warnings.filterwarnings(\"ignore\", category=np.VisibleDeprecationWarning) \n","results_minMaxScaler_no2nd_j2nd_rNo2nd = np.apply_along_axis(lambda x: get_gp_oos_minmaxscaler(data_gp_train, data_gp_test, x[0],x[1],int(x[2]), int(x[3])) , 1, combs_varLengthscale) "],"execution_count":null,"outputs":[{"output_type":"stream","text":["0.9592074592074592 0.25 0.05 <class 'gpflow.kernels.stationaries.RationalQuadratic'> 200\n","0.9615384615384616 0.3 0.05 <class 'gpflow.kernels.stationaries.RationalQuadratic'> 200\n","0.9533799533799534 0.35 0.05 <class 'gpflow.kernels.stationaries.RationalQuadratic'> 200\n","0.9615384615384616 0.4 0.05 <class 'gpflow.kernels.stationaries.RationalQuadratic'> 200\n","0.9487179487179487 0.45 0.05 <class 'gpflow.kernels.stationaries.RationalQuadratic'> 200\n","0.9557109557109557 0.5 0.05 <class 'gpflow.kernels.stationaries.RationalQuadratic'> 200\n","0.9533799533799534 0.55 0.05 <class 'gpflow.kernels.stationaries.RationalQuadratic'> 200\n","0.9440559440559441 0.6000000000000001 0.05 <class 'gpflow.kernels.stationaries.RationalQuadratic'> 200\n","0.9324009324009324 0.65 0.05 <class 'gpflow.kernels.stationaries.RationalQuadratic'> 200\n","0.9568764568764568 0.7 0.05 <class 'gpflow.kernels.stationaries.RationalQuadratic'> 200\n","0.9370629370629371 0.75 0.05 <class 'gpflow.kernels.stationaries.RationalQuadratic'> 200\n","0.9475524475524476 0.8 0.05 <class 'gpflow.kernels.stationaries.RationalQuadratic'> 200\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5RAv8oAbvAYC","executionInfo":{"status":"ok","timestamp":1621614136723,"user_tz":-60,"elapsed":172,"user":{"displayName":"Hans Roggeman","photoUrl":"","userId":"10574434403170915342"}},"outputId":"659e92d3-f5a6-4bfd-bc1d-b01c76826bae"},"source":["combs_varLengthscale"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[1.0e-01, 1.0e-01, 4.0e+00, 2.0e+02],\n","       [2.0e-01, 1.0e-01, 4.0e+00, 2.0e+02],\n","       [1.0e-01, 2.5e-01, 4.0e+00, 2.0e+02],\n","       [2.0e-01, 2.5e-01, 4.0e+00, 2.0e+02],\n","       [1.0e-01, 5.0e-01, 4.0e+00, 2.0e+02],\n","       [2.0e-01, 5.0e-01, 4.0e+00, 2.0e+02],\n","       [1.0e-01, 9.0e-01, 4.0e+00, 2.0e+02],\n","       [2.0e-01, 9.0e-01, 4.0e+00, 2.0e+02]])"]},"metadata":{"tags":[]},"execution_count":134}]},{"cell_type":"code","metadata":{"id":"qbuTiiz3sakS"},"source":["# just running one repeatedly\n","\n","resultsGroupA = [ get_gp_oos(data_gp_train, data_gp_test, 0.1,0.01,4, 250, 4000) for i in range(400) ]\n","oos_fn = \"/content/gp_no2nd256_no2nd128_j2nd256.csv\"\n","gp_no2nd256_no2nd128_j2nd256_oos_acc = np.array([x[0] for x in resultsGroupA])\n","gp_no2nd256_no2nd128_j2nd256_oos_acc.tofile(oos_fn, sep=\",\")\n","from google.colab import files\n","files.download(oos_fn)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"az4jyNeYJHmG"},"source":["## strange behaviour for penultimate layers (ignore for now)\n","\n","\n","data_gp_train = (data_train_ll_penul_no2nd_j2nd[0], reverse_one_hot(data_train_ll_penul_no2nd_j2nd[1][0])-1)\n","data_gp_test = (data_test_ll_penul_no2nd_j2nd[0], reverse_one_hot(data_test_ll_penul_no2nd_j2nd[1][0])-1)\n","\n","lengthscales_input = 0.1\n","data_gp = data_gp_train\n","white_variance = 0.01\n","kernel_func = 4\n","num_inducing = 250\n","data_test = data_gp_test\n","num_it = 4000\n","\n","lengthscales = tf.convert_to_tensor([lengthscales_input] * data_gp[0].shape[1], dtype=default_float())\n","kernel = kernel_func_map[kernel_func](lengthscales=lengthscales) # (kernel_func_map[kernel_func](lengthscales=lengthscales)  + gpflow.kernels.White(variance=white_variance)) if white_variance > 0.0 else kernel_func_map[kernel_func](lengthscales=lengthscales)\n","invlink = gpflow.likelihoods.RobustMax(np.max(data_test[1])+1)  # Robustmax inverse link function\n","likelihood = gpflow.likelihoods.MultiClass(np.max(data_test[1])+1, invlink=invlink)  # Multiclass likelihood\n","M = num_inducing # Number of inducing locations\n","Z = data_gp[0][sorted(random.sample(range(0,data_gp[0].shape[0]),M)),:].copy()\n","mGP = gpflow.models.SVGP(\n","    kernel=kernel,\n","    likelihood=likelihood,\n","    inducing_variable=Z,\n","    num_latent_gps=np.max(data_test[1])+1,\n","    whiten=False,\n","    q_diag=False\n",")\n","# Only train the variational parameters\n","# set_trainable(mGP.kernel.kernels[1].variance, True)\n","set_trainable(mGP.inducing_variable, False)\n","opt = gpflow.optimizers.Scipy()\n","opt_logs = opt.minimize(\n","    mGP.training_loss_closure(data_gp), mGP.trainable_variables,\n","    options=dict(maxiter=ci_niter(num_it))\n",")\n","\n","(Y_test_GP_mean, Y_test_GP_variance) = mGP.predict_y(data_gp[0])\n","Y_test_GP_mean = Y_test_GP_mean.numpy()\n","Y_test_pred = []\n","for i in range(data_gp[0].shape[0]):\n","    Y_test_pred.append(np.argmax(Y_test_GP_mean[i,]))\n","diffs = Y_test_pred - data_gp[1]\n","Y_test_pred = np.array(Y_test_pred)\n","\n","    # test_acc = sum(1 for x in diffs if x == 0) / data_gp[0].shape[0]\n","    # return test_acc, Y_test_pred, (Y_test_GP_mean, Y_test_GP_variance)\n","import matplotlib.pyplot as plt\n","plt.plot(Y_test_pred)\n","\n","import seaborn as sns\n","# resultsC = [ get_gp_oos(data_gp_train, data_gp_test, 0.1,0.01,4, 250, 4000),  get_gp_oos(data_gp_train, data_gp_test, 0.1,0.01,4, 100, 4000) ] \n","\n","# np.max(np.array(Y_test_pred))\n","Y_test_pred = np.array(Y_test_pred)\n","print(data_gp[1][69:79])\n","print(Y_test_pred[69:79])\n","print(data_gp[1][2469:2479])\n","print(Y_test_pred[2469:2479])\n","# ok tough...\n","print(np.sum(Y_test_pred[Y_test_pred!=0] - data_gp[1][Y_test_pred!=0]))\n","print(Y_test_pred[Y_test_pred!=0].shape)\n","print(Y_test_pred.shape)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nsgMyqsPkReA"},"source":["def get_gp_varls_oos(lengthscales_input, white_variance, kernel_func, num_inducing=100, num_it=10000):\n","  try:\n","    lengthscales = tf.convert_to_tensor( np.random.uniform(lengthscales_input[0],lengthscales_input[1], size= data_gp_train[0].shape[1]).tolist(), dtype=default_float())\n","    kernel = (kernel_func_map[kernel_func](lengthscales=lengthscales)  + gpflow.kernels.White(variance=white_variance)) if white_variance > 0.0 else kernel_func_map[kernel_func](lengthscales=lengthscales)\n","    invlink = gpflow.likelihoods.RobustMax(data_test_ll_no2nd_j2nd[1][0].shape[1])  # Robustmax inverse link function\n","    likelihood = gpflow.likelihoods.MultiClass(data_test_ll_no2nd_j2nd[1][0].shape[1], invlink=invlink)  # Multiclass likelihood\n","    M = num_inducing # Number of inducing locations\n","    Z = data_gp_train[0][sorted(random.sample(range(0,data_gp_train[0].shape[0]),M)),:].copy()\n","    mGP = gpflow.models.SVGP(\n","        kernel=kernel,\n","        likelihood=likelihood,\n","        inducing_variable=Z,\n","        num_latent_gps=data_test_ll_no2nd_j2nd[1][0].shape[1],\n","        whiten=True,\n","        q_diag=False,\n","    )\n","    # Only train the variational parameters\n","    # set_trainable(mGP.kernel.kernels[1].variance, True)\n","    set_trainable(mGP.inducing_variable, False)\n","    opt = gpflow.optimizers.Scipy()\n","    opt_logs = opt.minimize(\n","        mGP.training_loss_closure(data_gp_train), mGP.trainable_variables,\n","        options=dict(maxiter=ci_niter(num_it))\n","    )\n","    test_acc, Y_test_pred, (gp_mean, gp_var) = get_gp_acc(mGP, data_gp_test)\n","    print(test_acc, lengthscales_input, white_variance, kernel_func_map[kernel_func], num_inducing)  \n","    return test_acc, lengthscales_input, white_variance, kernel_func, num_inducing, Y_test_pred, mGP\n","  except :\n","     return -1.0, lengthscales_input, white_variance, kernel_func, num_inducing, None, mGP\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SYJInOGYkOeZ","executionInfo":{"status":"ok","timestamp":1621461342297,"user_tz":-60,"elapsed":958,"user":{"displayName":"Hans Roggeman","photoUrl":"","userId":"10574434403170915342"}},"outputId":"318103b5-1be5-45a0-f900-4acb50f67cdf"},"source":["# data_gp_train = (data_train_ll_no2nd_j2nd[0], reverse_one_hot(data_train_ll_no2nd_j2nd[1][0])-1)\n","# data_gp_test = (data_test_ll_no2nd_j2nd[0], reverse_one_hot(data_test_ll_no2nd_j2nd[1][0])-1)\n","# data_gp_train = (data_train_ll_no2nd_j2nd_rNo2nd[0], reverse_one_hot(data_train_ll_no2nd_j2nd_rNo2nd[1][0])-1)\n","# data_gp_test = (data_test_ll_no2nd_j2nd_rNo2nd[0], reverse_one_hot(data_test_ll_no2nd_j2nd_rNo2nd[1][0])-1)\n","\n","np.max(data_gp_test[1])+1"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["12"]},"metadata":{"tags":[]},"execution_count":44}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Q8cpC0RWvDz1","executionInfo":{"status":"ok","timestamp":1621463323784,"user_tz":-60,"elapsed":33541,"user":{"displayName":"Hans Roggeman","photoUrl":"","userId":"10574434403170915342"}},"outputId":"6295f7a5-8096-497a-f78a-cd1115e9b209"},"source":["# just running one\n","data_gp_train = (data_train_ll_no2nd_j2nd[0], reverse_one_hot(data_train_ll_no2nd_j2nd[1][0])-1)\n","data_gp_test = (data_test_ll_no2nd_j2nd[0], reverse_one_hot(data_test_ll_no2nd_j2nd[1][0])-1)\n","resultsA = [ get_gp_oos(data_gp_train, data_gp_test, 0.1,0.01,4, 250, 4000),  get_gp_oos(data_gp_train, data_gp_test, 0.1,0.01,4, 100, 4000) ] \n","\n","data_gp_train = (data_train_ll_no2nd_j2nd_rNo2nd[0], reverse_one_hot(data_train_ll_no2nd_j2nd_rNo2nd[1][0])-1)\n","data_gp_test = (data_test_ll_no2nd_j2nd_rNo2nd[0], reverse_one_hot(data_test_ll_no2nd_j2nd_rNo2nd[1][0])-1)                                                                                                    \n","resultsB = [ get_gp_oos(data_gp_train, data_gp_test, 0.1,0.01,4, 250, 4000),  get_gp_oos(data_gp_train, data_gp_test, 0.1,0.01,4, 100, 4000) ] \n","\n","\n","data_gp_train = (data_train_ll_penul_no2nd_j2nd[0], reverse_one_hot(data_train_ll_penul_no2nd_j2nd[1][0])-1)\n","data_gp_test = (data_test_ll_penul_no2nd_j2nd[0], reverse_one_hot(data_test_ll_penul_no2nd_j2nd[1][0])-1)\n","\n","resultsC = [ get_gp_oos(data_gp_train, data_gp_test, 0.1,0.01,4, 250, 4000),  get_gp_oos(data_gp_train, data_gp_test, 0.1,0.01,4, 100, 4000) ] \n","\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["0.9638694638694638 0.1 0.01 <class 'gpflow.kernels.stationaries.Matern32'> 250\n","0.9603729603729604 0.1 0.01 <class 'gpflow.kernels.stationaries.Matern32'> 100\n","0.9568764568764568 0.1 0.01 <class 'gpflow.kernels.stationaries.Matern32'> 250\n","0.9557109557109557 0.1 0.01 <class 'gpflow.kernels.stationaries.Matern32'> 100\n","0.08158508158508158 0.1 0.01 <class 'gpflow.kernels.stationaries.Matern32'> 250\n","0.08158508158508158 0.1 0.01 <class 'gpflow.kernels.stationaries.Matern32'> 100\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TBvofHx0rwr5","executionInfo":{"status":"ok","timestamp":1621463564558,"user_tz":-60,"elapsed":4886,"user":{"displayName":"Hans Roggeman","photoUrl":"","userId":"10574434403170915342"}},"outputId":"72fc3ddd-5355-41bd-fba1-675562e220a2"},"source":["lengthscales = tf.convert_to_tensor([0.1] * data_gp_train[0].shape[1], dtype=default_float())\n","kernel = (kernel_func_map[4](lengthscales=lengthscales)  + gpflow.kernels.White(variance=0.01))\n","invlink = gpflow.likelihoods.RobustMax(np.max(data_gp_test[1])+1)  # Robustmax inverse link function\n","likelihood = gpflow.likelihoods.MultiClass(np.max(data_gp_test[1])+1, invlink=invlink)  # Multiclass likelihood\n","M = 250 # Number of inducing locations\n","Z = data_gp_train[0][sorted(random.sample(range(0,data_gp_train[0].shape[0]),M)),:].copy()\n","mGP = gpflow.models.SVGP(\n","    kernel=kernel,\n","    likelihood=likelihood,\n","    inducing_variable=Z,\n","    num_latent_gps=np.max(data_gp_test[1])+1,\n","    whiten=True,\n","    q_diag=False,\n",")\n","set_trainable(mGP.inducing_variable, False)\n","opt = gpflow.optimizers.Scipy()\n","opt_logs = opt.minimize(\n","    mGP.training_loss_closure(data_gp_train), mGP.trainable_variables,\n","    options=dict(maxiter=ci_niter(4000))\n",")\n","test_acc, Y_test_pred, (gp_mean, gp_var) = get_gp_acc(mGP, data_gp_test)\n","print(test_acc, 0.1, 0.01, kernel_func_map[4], 250)  \n","\n","(Y_test_GP_mean, Y_test_GP_variance) = mGP.predict_y(data_gp_test[0])\n","Y_test_GP_mean = Y_test_GP_mean.numpy()\n","Y_test_pred = []\n","for i in range(data_gp_test[0].shape[0]):\n","    Y_test_pred.append(np.argmax(Y_test_GP_mean[i,]))\n","\n","diffs = Y_test_pred - data_gp_test[1]\n","# test_acc = sum(1 for x in diffs if x == 0) / data_gp_test[0].shape[0]\n","# return test_acc, Y_test_pred, (Y_test_GP_mean, Y_test_GP_variance)\n","\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["0.08158508158508158 0.1 0.01 <class 'gpflow.kernels.stationaries.Matern32'> 250\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5eAX_fhqv45h","executionInfo":{"status":"ok","timestamp":1621463640116,"user_tz":-60,"elapsed":614,"user":{"displayName":"Hans Roggeman","photoUrl":"","userId":"10574434403170915342"}},"outputId":"ab787809-acc3-4994-acde-3140a624e781"},"source":["# np.unique(Y_test_pred)\n","data_gp_test[0]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[-2.28005457,  1.18560743, -1.87473881, ...,  2.22458434,\n","         0.18365669, -1.73513246],\n","       [-1.85952389, -1.43467045,  0.38176835, ...,  0.4277342 ,\n","        -1.3096354 ,  2.12281489],\n","       [-1.87429988, -0.03654051, -0.12345496, ...,  0.37061286,\n","        -0.21829401,  2.04799533],\n","       ...,\n","       [-1.93701923, -2.35466337,  1.07926047, ...,  0.88620865,\n","        -3.14220428,  0.96247303],\n","       [-1.42820859, -1.61642849, -0.89153689, ..., -0.22308743,\n","        -2.13899112, -2.12054086],\n","       [-1.37312782, -1.21590495,  1.60235393, ..., -0.40148723,\n","        -2.90022206, -1.19593   ]])"]},"metadata":{"tags":[]},"execution_count":62}]},{"cell_type":"code","metadata":{"id":"r8yv2fezvkFJ"},"source":["\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","data_gp_train = (data_train_ll_penul_no2nd_j2nd_rNo2nd[0], reverse_one_hot(data_train_ll_penul_no2nd_j2nd_rNo2nd[1][0])-1)\n","data_gp_test = (data_test_ll_penul_no2nd_j2nd_rNo2nd[0], reverse_one_hot(data_test_ll_penul_no2nd_j2nd_rNo2nd[1][0])-1)\n","\n","resultsD = [ get_gp_oos(data_gp_train, data_gp_test, 0.1,0.01,4, 250, 4000),  get_gp_oos(data_gp_train, data_gp_test, 0.1,0.01,4, 100, 4000) ] \n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"AYAWP6CYqsHr"},"source":["    lengthscales = tf.convert_to_tensor([lengthscales_input] * data_gp[0].shape[1], dtype=default_float())\n","    kernel = (kernel_func_map[kernel_func](lengthscales=lengthscales)  + gpflow.kernels.White(variance=white_variance)) if white_variance > 0.0 else kernel_func_map[kernel_func](lengthscales=lengthscales)\n","    invlink = gpflow.likelihoods.RobustMax(np.max(data_test[1])+1)  # Robustmax inverse link function\n","    likelihood = gpflow.likelihoods.MultiClass(np.max(data_test[1])+1, invlink=invlink)  # Multiclass likelihood\n","    M = num_inducing # Number of inducing locations\n","    Z = data_gp[0][sorted(random.sample(range(0,data_gp[0].shape[0]),M)),:].copy()\n","    mGP = gpflow.models.SVGP(\n","        kernel=kernel,\n","        likelihood=likelihood,\n","        inducing_variable=Z,\n","        num_latent_gps=np.max(data_test[1])+1,\n","        whiten=True,\n","        q_diag=False,\n","    )\n","    # Only train the variational parameters\n","    # set_trainable(mGP.kernel.kernels[1].variance, True)\n","    set_trainable(mGP.inducing_variable, False)\n","    opt = gpflow.optimizers.Scipy()\n","    opt_logs = opt.minimize(\n","        mGP.training_loss_closure(data_gp), mGP.trainable_variables,\n","        options=dict(maxiter=ci_niter(num_it))\n","    )\n","    test_acc, Y_test_pred, (gp_mean, gp_var) = get_gp_acc(mGP, data_test)\n","    print(test_acc, lengthscales_input, white_variance, kernel_func_map[kernel_func], num_inducing)  \n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YIeGY_AKEa2F","executionInfo":{"status":"ok","timestamp":1621454903221,"user_tz":-60,"elapsed":58852,"user":{"displayName":"Hans Roggeman","photoUrl":"","userId":"10574434403170915342"}},"outputId":"afa01cf7-4cd1-4639-d0b3-7ccd23349a90"},"source":["res2 = [get_gp_varls_oos( [ 0.08, 0.09] ,0.001,4, 40, 4000) for x in range(10)]"],"execution_count":null,"outputs":[{"output_type":"stream","text":["0.7668997668997669 [0.08, 0.09] 0.001 <class 'gpflow.kernels.stationaries.Matern32'> 40\n","0.9067599067599068 [0.08, 0.09] 0.001 <class 'gpflow.kernels.stationaries.Matern32'> 40\n","0.9615384615384616 [0.08, 0.09] 0.001 <class 'gpflow.kernels.stationaries.Matern32'> 40\n","0.8041958041958042 [0.08, 0.09] 0.001 <class 'gpflow.kernels.stationaries.Matern32'> 40\n","0.6655011655011654 [0.08, 0.09] 0.001 <class 'gpflow.kernels.stationaries.Matern32'> 40\n","0.9067599067599068 [0.08, 0.09] 0.001 <class 'gpflow.kernels.stationaries.Matern32'> 40\n","0.9393939393939394 [0.08, 0.09] 0.001 <class 'gpflow.kernels.stationaries.Matern32'> 40\n","0.8881118881118881 [0.08, 0.09] 0.001 <class 'gpflow.kernels.stationaries.Matern32'> 40\n","0.9382284382284383 [0.08, 0.09] 0.001 <class 'gpflow.kernels.stationaries.Matern32'> 40\n","0.9300699300699301 [0.08, 0.09] 0.001 <class 'gpflow.kernels.stationaries.Matern32'> 40\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"PqaCJDo6gDex"},"source":["# running the whole combination set\n","# results = np.apply_along_axis(lambda x: get_gp_oos(x[0],x[1],int(x[2]), int(x[3])) , 1, combs) \n","\n"],"execution_count":null,"outputs":[]}]}