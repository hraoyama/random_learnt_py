{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"DGM_HJB.ipynb","provenance":[],"collapsed_sections":["BErSeefeQwQi","bvy0WvxDGCxk","N-GO35FcJPP6","HrivvbmubiiY","fyFbPZr7I5RE","RNhAbZ727RC_","wClW1g9rbm8o","8RRoBgFQINMv","hp4BG1ewKF6o","65nooklCbsdy","I9z4wQvAP4GW","RDKmMCNNe0yi"],"machine_shape":"hm","background_execution":"on","authorship_tag":"ABX9TyN90qKog00j22NWGwxkdt4d"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"BErSeefeQwQi"},"source":["### Setup packages "]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":24506,"status":"ok","timestamp":1653149384180,"user":{"displayName":"Hans Roggeman","userId":"10574434403170915342"},"user_tz":-60},"id":"L8DGCgVxR2AB","outputId":"38b7ae09-986b-4b8b-cdfb-7f2b9b09616e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11887,"status":"ok","timestamp":1653149396057,"user":{"displayName":"Hans Roggeman","userId":"10574434403170915342"},"user_tz":-60},"id":"3xIx5C6UQn4u","outputId":"4aa1736e-b1f3-4ddb-d8ea-3e5dbf6c827c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting progressbar\n","  Downloading progressbar-2.5.tar.gz (10 kB)\n","Building wheels for collected packages: progressbar\n","  Building wheel for progressbar (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for progressbar: filename=progressbar-2.5-py3-none-any.whl size=12082 sha256=d6f0238feb5e8481dfb4b9e6365cc18f01cd5ac2e690c8465d42e39f58fb363a\n","  Stored in directory: /root/.cache/pip/wheels/f0/fd/1f/3e35ed57e94cd8ced38dd46771f1f0f94f65fec548659ed855\n","Successfully built progressbar\n","Installing collected packages: progressbar\n","Successfully installed progressbar-2.5\n","Requirement already satisfied: plotnine in /usr/local/lib/python3.7/dist-packages (0.6.0)\n","Requirement already satisfied: statsmodels>=0.9.0 in /usr/local/lib/python3.7/dist-packages (from plotnine) (0.10.2)\n","Requirement already satisfied: matplotlib>=3.1.1 in /usr/local/lib/python3.7/dist-packages (from plotnine) (3.2.2)\n","Requirement already satisfied: patsy>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from plotnine) (0.5.2)\n","Requirement already satisfied: scipy>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from plotnine) (1.4.1)\n","Requirement already satisfied: descartes>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from plotnine) (1.1.0)\n","Requirement already satisfied: mizani>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from plotnine) (0.6.0)\n","Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from plotnine) (1.21.6)\n","Requirement already satisfied: pandas>=0.25.0 in /usr/local/lib/python3.7/dist-packages (from plotnine) (1.3.5)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.1.1->plotnine) (3.0.9)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.1.1->plotnine) (1.4.2)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.1.1->plotnine) (2.8.2)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.1.1->plotnine) (0.11.0)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib>=3.1.1->plotnine) (4.2.0)\n","Requirement already satisfied: palettable in /usr/local/lib/python3.7/dist-packages (from mizani>=0.6.0->plotnine) (3.3.0)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.25.0->plotnine) (2022.1)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from patsy>=0.4.1->plotnine) (1.15.0)\n","Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (1.11.0+cu113)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch) (4.2.0)\n","Collecting ipython-autotime\n","  Downloading ipython_autotime-0.3.1-py2.py3-none-any.whl (6.8 kB)\n","Requirement already satisfied: ipython in /usr/local/lib/python3.7/dist-packages (from ipython-autotime) (5.5.0)\n","Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from ipython->ipython-autotime) (57.4.0)\n","Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from ipython->ipython-autotime) (0.8.1)\n","Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.7/dist-packages (from ipython->ipython-autotime) (5.1.1)\n","Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython->ipython-autotime) (4.4.2)\n","Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from ipython->ipython-autotime) (4.8.0)\n","Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from ipython->ipython-autotime) (1.0.18)\n","Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython->ipython-autotime) (0.7.5)\n","Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython->ipython-autotime) (2.6.1)\n","Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython->ipython-autotime) (1.15.0)\n","Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython->ipython-autotime) (0.2.5)\n","Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect->ipython->ipython-autotime) (0.7.0)\n","Installing collected packages: ipython-autotime\n","Successfully installed ipython-autotime-0.3.1\n","time: 134 µs (started: 2022-05-21 16:09:55 +00:00)\n"]}],"source":["%pip install progressbar\n","%pip install plotnine\n","%pip install torch\n","%pip install ipython-autotime\n","%load_ext autotime"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"EfIU_eNp3Zio","executionInfo":{"status":"ok","timestamp":1653149397968,"user_tz":-60,"elapsed":1919,"user":{"displayName":"Hans Roggeman","userId":"10574434403170915342"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"624a7d0a-dffa-49b5-fb9d-dab395d111d5"},"outputs":[{"output_type":"stream","name":"stdout","text":["time: 1.68 s (started: 2022-05-21 16:09:55 +00:00)\n"]}],"source":["from plotnine import *\n","from plotnine.themes import *"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"ZmUjYbArAuQT","executionInfo":{"status":"ok","timestamp":1653149400561,"user_tz":-60,"elapsed":2597,"user":{"displayName":"Hans Roggeman","userId":"10574434403170915342"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"73d2b44e-cc28-438d-a694-8c5c90e0953a"},"outputs":[{"output_type":"stream","name":"stdout","text":["time: 2.76 s (started: 2022-05-21 16:09:57 +00:00)\n"]}],"source":["import tensorflow as tf\n","from scipy.io import loadmat\n","import random\n","import math\n","import tensorflow_probability as tfp"]},{"cell_type":"markdown","metadata":{"id":"PieVKPfHHYQ6"},"source":["_paper_name_ establishes the reusable name of the paper, it represents the directory under data_papers on the google drive"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"BI4p7ZKb0Qz2","executionInfo":{"status":"ok","timestamp":1653149400562,"user_tz":-60,"elapsed":6,"user":{"displayName":"Hans Roggeman","userId":"10574434403170915342"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"c8070408-88f3-4b18-80b5-96e7051084f6"},"outputs":[{"output_type":"stream","name":"stdout","text":["time: 829 µs (started: 2022-05-21 16:10:00 +00:00)\n"]}],"source":["paper_name = \"dgm_hjb\""]},{"cell_type":"code","execution_count":7,"metadata":{"id":"433z6V3T2rB2","executionInfo":{"status":"ok","timestamp":1653149401279,"user_tz":-60,"elapsed":722,"user":{"displayName":"Hans Roggeman","userId":"10574434403170915342"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"e2966e65-776a-4cc3-f008-ac90d31f9240"},"outputs":[{"output_type":"stream","name":"stdout","text":["time: 590 ms (started: 2022-05-21 16:10:00 +00:00)\n"]}],"source":["import os, sys\n","import errno\n","\n","# make a directory if it does not exist\n","def make_dir_if_not_exist(used_path):\n","    if not os.path.isdir(used_path):\n","        try:\n","            os.mkdir(used_path)\n","        except OSError as exc:\n","            if exc.errno != errno.EEXIST:\n","                raise exc\n","            else:\n","                raise ValueError(f'{used_path} directoy cannot be created because its parent directory does not exist.')\n","\n","# make directories if they do not exist\n","\n","make_dir_if_not_exist(\"/content/drive/MyDrive/data_papers/\")\n","make_dir_if_not_exist(f\"/content/drive/MyDrive/data_papers/{paper_name}\")\n","make_dir_if_not_exist(f\"/content/drive/MyDrive/data_papers/{paper_name}/model_features/\")\n","make_dir_if_not_exist(f\"/content/drive/MyDrive/data_papers/{paper_name}/model_checkpoints/\")\n","make_dir_if_not_exist(f\"/content/drive/MyDrive/data_papers/{paper_name}/model_history/\")\n","make_dir_if_not_exist(f\"/content/drive/MyDrive/data_papers/{paper_name}/model_finals/\")\n","make_dir_if_not_exist(f\"/content/drive/MyDrive/data_papers/{paper_name}/model_predictions/\")\n","make_dir_if_not_exist(f\"/content/drive/MyDrive/data_papers/{paper_name}/model_ccs/\")\n","make_dir_if_not_exist(f\"/content/drive/MyDrive/data_papers/{paper_name}/summary_results/\")\n","make_dir_if_not_exist(f\"/content/drive/MyDrive/data_papers/{paper_name}/summary_results/temp/\")"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"uat0pG8aR3Rh","executionInfo":{"status":"ok","timestamp":1653149401280,"user_tz":-60,"elapsed":8,"user":{"displayName":"Hans Roggeman","userId":"10574434403170915342"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"2d7239ed-a905-47b9-9897-9293326dea0f"},"outputs":[{"output_type":"stream","name":"stdout","text":["time: 9.29 ms (started: 2022-05-21 16:10:00 +00:00)\n"]}],"source":["# Set up the imports\n","from sklearn.model_selection import train_test_split\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","import pandas as pd\n","import numpy as np\n","\n","import site\n","import os\n","import tensorflow as tf\n","import pandas as pd\n","import h5py as h5\n","import matplotlib.pyplot as plt\n","import errno\n","import numpy as np\n","import itertools\n","import multiprocessing\n","import json\n","import datetime\n","import random\n","from collections import defaultdict\n","from sklearn.model_selection import train_test_split\n","\n","pd.set_option('display.width', 400)\n","pd.set_option('display.max_columns', 40)\n"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"KpFjo3MkLus9","executionInfo":{"status":"ok","timestamp":1653149403868,"user_tz":-60,"elapsed":2595,"user":{"displayName":"Hans Roggeman","userId":"10574434403170915342"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"1256bd8a-92a1-45a7-a99f-fca21ac64055"},"outputs":[{"output_type":"stream","name":"stdout","text":["time: 2.89 s (started: 2022-05-21 16:10:00 +00:00)\n"]}],"source":["import torch \n","import matplotlib.pyplot as plt\n","import numpy as np\n","from torch.autograd import Variable\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","import matplotlib.pyplot as plt\n","from mpl_toolkits.mplot3d import Axes3D\n","from scipy.stats import norm\n","from matplotlib import cm\n","import pdb\n"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"CbfN42gpGZhC","executionInfo":{"status":"ok","timestamp":1653149406187,"user_tz":-60,"elapsed":2322,"user":{"displayName":"Hans Roggeman","userId":"10574434403170915342"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"a6ef3821-948e-4f8c-e605-418d8e3a37b2"},"outputs":[{"output_type":"stream","name":"stdout","text":["time: 2.04 s (started: 2022-05-21 16:10:03 +00:00)\n"]}],"source":["import plotly.graph_objects as go\n","import plotly.express as px\n","from pprint import pprint as pp"]},{"cell_type":"markdown","metadata":{"id":"bvy0WvxDGCxk"},"source":["### Shared functions across models"]},{"cell_type":"code","execution_count":18,"metadata":{"id":"cpVaz5dwXZNq","executionInfo":{"status":"ok","timestamp":1653149732077,"user_tz":-60,"elapsed":666,"user":{"displayName":"Hans Roggeman","userId":"10574434403170915342"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"4aa3440f-97bd-417e-dcee-3bbbb4f441ac"},"outputs":[{"output_type":"stream","name":"stdout","text":["time: 24.8 ms (started: 2022-05-21 16:15:31 +00:00)\n"]}],"source":["import pandas as pd\n","\n","def plot_report(train_instance):\n","        \n","    history_tl_cpu = [ x for x in train_instance.history_tl ]\n","    history_internal_cpu = [ x.cpu().detach().numpy() for x in train_instance.history_internal_cpu ]\n","    history_terminal_cpu = [ x.cpu().detach().numpy() for x in train_instance.history_terminal ]\n","    history_initial_cpu = [ x.cpu().detach().numpy() for x in train_instance.history_initial ]\n","    history_nonzero_cpu = [ x.cpu().detach().numpy() for x in train_instance.history_nonzero ]\n","\n","    obs_data = pd.DataFrame({\"Epochs\" : [ (x+1)*train_instance.hook_interval for x in range(len(history_initial_cpu))], \n","                             \"AvgLogLoss\": np.log(history_tl_cpu), \n","                             \"TerminalLogLoss\" :  np.log(history_terminal_cpu),\n","                             \"InternalLogLoss\" :  np.log(history_internal_cpu),\n","                             \"InitialLogLoss\" : np.log(history_initial_cpu),\n","                             \"NonZeroLogLoss\" : np.log(history_nonzero_cpu),\n","                             })\n","\n","    return (ggplot(obs_data, aes(\"Epochs\",\"AvgLogLoss\")) + geom_line() + geom_point(),\n","            ggplot(obs_data, aes(\"Epochs\",\"TerminalLogLoss\")) + geom_line() + geom_point(),\n","            ggplot(obs_data, aes(\"Epochs\",\"InternalLogLoss\")) + geom_line() + geom_point(),\n","            ggplot(obs_data, aes(\"Epochs\",\"InitialLogLoss\")) + geom_line() + geom_point(),\n","            ggplot(obs_data, aes(\"Epochs\",\"NonZeroLogLoss\")) + geom_line() + geom_point(),\n","            )\n","\n","def plot_activation_mean(train_instance):\n","    \n","    # pdb.set_trace()\n","\n","    if train_instance.debug == False:\n","        print( 'error: debug is off , turn it on and train again ' )\n","    else:\n","        history = np.array(train_instance.history_mean_hooks)\n","        jet= plt.get_cmap('jet')\n","        colors = iter(jet(np.linspace(0,1,10)))\n","        fig, ax = plt.subplots()\n","        for i in range(history.shape[1]):\n","            ax.plot(history[:,i], '--r', label= i , color=next(colors) )\n","        fig.suptitle('Layers activation mean value', fontsize=10)\n","        leg = ax.legend();\n"]},{"cell_type":"code","execution_count":19,"metadata":{"id":"QMAuMqdgU9kL","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1653149732572,"user_tz":-60,"elapsed":12,"user":{"displayName":"Hans Roggeman","userId":"10574434403170915342"}},"outputId":"2b00d456-eed0-4c5e-c4e1-4dc3aaf62ec5"},"outputs":[{"output_type":"stream","name":"stdout","text":["time: 630 µs (started: 2022-05-21 16:15:31 +00:00)\n"]}],"source":["# plot_report(train)\n","# plot_activation_mean(train)"]},{"cell_type":"code","execution_count":20,"metadata":{"id":"sCV-yFDXUV4J","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1653149732573,"user_tz":-60,"elapsed":11,"user":{"displayName":"Hans Roggeman","userId":"10574434403170915342"}},"outputId":"cf63a366-7738-4fcb-e6c2-4738f7fdb68e"},"outputs":[{"output_type":"stream","name":"stdout","text":["time: 1.15 ms (started: 2022-05-21 16:15:31 +00:00)\n"]}],"source":["# print( 'Value at 0' , net( torch.tensor( [ 0. , 1. , 1. , 1. ] ).cuda() ) )\n","# #%% save\n","# torch.save(net.state_dict(), './model3Assets')\n","# #%%\n","# net = TheModelClass(*args, **kwargs)\n","# net.load_state_dict(torch.load('./modelmodel3Assets'))\n","# net.eval()"]},{"cell_type":"code","execution_count":21,"metadata":{"id":"ONB5NopRa3fD","executionInfo":{"status":"ok","timestamp":1653149732573,"user_tz":-60,"elapsed":10,"user":{"displayName":"Hans Roggeman","userId":"10574434403170915342"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"11d02431-3482-40df-9c31-52aa1ff5fba5"},"outputs":[{"output_type":"stream","name":"stdout","text":["time: 31.7 ms (started: 2022-05-21 16:15:31 +00:00)\n"]}],"source":["# a set up that just maximizes the loss s.t. loss < eps (maximizeloss_weights_st) using the weights on the losses\n","from scipy.optimize import LinearConstraint, NonlinearConstraint\n","from scipy.optimize import Bounds\n","from functools import partial\n","from scipy.optimize import minimize\n","from functools import wraps\n","\n","def negative(f):\n","    @wraps(f)\n","    def g(*args,**kwargs):\n","        return - f(*args,**kwargs)\n","    # g.__name__ = f'negative({f.__name__})'\n","    return g\n","# kl_loss = nn.KLDivLoss(size_average=None, reduction=\"batchmean\")\n","\n","# we can add more minimization functions here later (e.g. SS diff)\n","def KLDiffHere( varX, loss_terms, log_target = False, reduction = \"mean\"):  \n","  target = torch.tensor([1./len(loss_terms)]*len(loss_terms))*torch.tensor(loss_terms)\n","  input = torch.tensor(varX*loss_terms)\n","  loss_pointwise = target * (torch.log(target) - torch.log(input))\n","  if reduction == \"mean\":  # default\n","      loss = loss_pointwise.mean()\n","  elif reduction == \"batchmean\":  # mathematically correct\n","      loss = loss_pointwise.sum() / input.size(0)\n","  elif reduction == \"sum\":\n","      loss = loss_pointwise.sum()\n","  else:  # reduction == \"none\"\n","      loss = loss_pointwise  \n","  return loss\n","\n","  # return torch.nn.KLDivLoss(varX*loss_terms,np.array([1./len(loss_terms)]*len(loss_terms))*loss_terms)\n","\n","def minimize_weights_st(loss_terms, loss_func):\n","  bounds = Bounds([0]*len(loss_terms), [1.0]*len(loss_terms))\n","  linear_constraint = LinearConstraint([[1]*len(loss_terms)], [1.0], [1.0])\n","  x0 = [0.25]*len(loss_terms)\n","  res = minimize( partial(loss_func, loss_terms=loss_terms), \n","                  x0, \n","                  method='trust-constr', \n","                  constraints=[linear_constraint],\n","                  options={'verbose': 0}, \n","                  bounds=bounds )\n","  return res\n","\n","def maximizeloss_weights_st(loss_terms, loss_func, eps):\n","  bounds = Bounds([0]*len(loss_terms), [1.0]*len(loss_terms))\n","  linear_constraint = LinearConstraint([[1]*len(loss_terms)], [1.0], [1.0])\n","  nonlinear_constraint  = NonlinearConstraint(negative(partial(loss_func, loss_terms=loss_terms)),1E-9,eps)\n","  # even though zero is the KL minimum it helps to put a negative number here to explore\n","\n","  x0 = [1.0/len(loss_terms)]*len(loss_terms)\n","  res = minimize( negative(partial(loss_func, loss_terms=loss_terms)), \n","                  x0, \n","                  method='trust-constr', \n","                  constraints=[linear_constraint, nonlinear_constraint],\n","                  options={'verbose': 0}, \n","                  bounds=bounds )\n","  return res\n"]},{"cell_type":"code","execution_count":22,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1653149732573,"user":{"displayName":"Hans Roggeman","userId":"10574434403170915342"},"user_tz":-60},"id":"RM0IVdZ_TXW3","outputId":"0cd0cde2-e05e-47d0-95b7-8d58c5a12b84"},"outputs":[{"output_type":"stream","name":"stdout","text":["[0.33334757 0.33333761 0.33331482]\n","time: 74.8 ms (started: 2022-05-21 16:15:31 +00:00)\n"]}],"source":["r1 = maximizeloss_weights_st( [ 34.25, 100.12, 23.45] , KLDiffHere, 1E9)\n","print(r1.x)"]},{"cell_type":"code","execution_count":23,"metadata":{"id":"ewko67bDIcz9","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1653149732573,"user_tz":-60,"elapsed":8,"user":{"displayName":"Hans Roggeman","userId":"10574434403170915342"}},"outputId":"75a00df5-6dd2-4059-8668-b290e8e8bacc"},"outputs":[{"output_type":"stream","name":"stdout","text":["time: 4.57 ms (started: 2022-05-21 16:15:31 +00:00)\n"]}],"source":["### There is an issue getting this to work because of nonlinear_constraint  = NonlinearConstraint(negative(partial(loss_func, loss_terms=loss_terms)),1E-9,eps)\n","\n","    # def calculateLossAdaptWeights(self , size = 2**8 , train = True, min_max = True):\n","    #     '''\n","    #     Helper function that Sample and Calculate loss,\n","    #     This is adapted in that it changes the weights on the losses to maximize the loss provided\n","    #     the KL distance of the new weighting is within self.eps of the previous distribution (starting at equally weighted)\n","    #     '''        \n","    #     x , x_terminal , x_boundary = self.sample(size)\n","    #     x = Variable( x , requires_grad=True)\n","    #     Ls = self.criterion( x , x_terminal , x_boundary )\n","    #     DO , TC , BC = Ls\n","    #     DOm = torch.mean(DO).detach().cpu().float().item()\n","    #     TCm = torch.mean(TC).detach().cpu().float().item()\n","    #     BCm = torch.mean(BC).detach().cpu().float().item()\n","\n","    #     losses_for_reweighting = [ torch.mean(lv).detach().cpu().float().item() for lv in Ls if list(lv.size())] \n","    #     mask_for_available_losses = [ True if list(lv.size()) else False for lv in Ls ]\n","\n","    #     # print([ DOm, TCm, BCm])\n","    #     # if is.nan(DOm):\n","    #     #   print(DO)\n","\n","    #     if self.weights is None:\n","    #       self.weights = torch.ones(1,len(Ls))/len(Ls)\n","\n","    #     # pdb.set_trace()\n","\n","    #     if min_max:\n","    #         r1 = maximizeloss_weights_st( losses_for_reweighting , KLDiffHere, self.eps)\n","    #         candidate_weigths = torch.zeros_like(self.weights).to(torch.device(\"cuda:0\"))\n","    #         candidate_weigths[0][mask_for_available_losses] = torch.tensor(r1.x).to(torch.device(\"cuda:0\")).float()\n","    #         self.weights = candidate_weigths.to(torch.device(\"cuda:0\"))\n","    #         self.weights_tbl.append(self.weights.detach().cpu().numpy())\n","\n","    #     numActive = np.sum([1 if list(lv.size()) else 0 for lv in Ls ])\n","    #     if train == True:\n","    #         return  (self.weights[0,0]*torch.mean(DO) + \n","    #                  self.weights[0,1]*torch.mean(TC) + \n","    #                  self.weights[0,2]*torch.mean(BC)) , \\\n","    #                  self.weights[0,0]*torch.mean(DO) , \\\n","    #                  self.weights[0,1]*torch.mean(TC) , \\\n","    #                  self.weights[0,2]*torch.mean(BC) , \\\n","    #                  (1./numActive*torch.mean(DO) + \n","    #                  1./numActive*torch.mean(TC) + \n","    #                  1./numActive*torch.mean(BC))             \n","    #     else:\n","    #         return  DO , TC , BC\n"]},{"cell_type":"code","execution_count":24,"metadata":{"id":"iyacROFeXgNp","executionInfo":{"status":"ok","timestamp":1653149732574,"user_tz":-60,"elapsed":9,"user":{"displayName":"Hans Roggeman","userId":"10574434403170915342"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"53c9d327-dd38-4720-c795-fb4287f1c973"},"outputs":[{"output_type":"stream","name":"stdout","text":["time: 7.74 ms (started: 2022-05-21 16:15:31 +00:00)\n"]}],"source":["import torch\n","from torch.distributions import Normal\n","\n","std_norm_cdf = Normal(0, 1).cdf\n","std_norm_pdf = lambda x: torch.exp(Normal(0, 1).log_prob(x))\n","\n","def bs_price(right, K, S, T, sigma, r):\n","    d_1 = (1 / (sigma * torch.sqrt(T))) * (torch.log(S / K) + (r + (torch.square(sigma) / 2)) * T)\n","    d_2 = d_1 - sigma * torch.sqrt(T)\n","    \n","    if right == \"C\":\n","        C = std_norm_cdf(d_1) * S - std_norm_cdf(d_2) * K * torch.exp(-r * T)\n","        return C\n","        \n","    elif right == \"P\":\n","        P = std_norm_cdf(-d_2) * K * torch.exp(-r * T) - std_norm_cdf(-d_1) * S\n","        return P"]},{"cell_type":"code","execution_count":25,"metadata":{"id":"sLsA5AvqpMM7","executionInfo":{"status":"ok","timestamp":1653149732574,"user_tz":-60,"elapsed":8,"user":{"displayName":"Hans Roggeman","userId":"10574434403170915342"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"090b54a3-5d24-4301-b2f2-3964c7877a25"},"outputs":[{"output_type":"stream","name":"stdout","text":["time: 1.94 ms (started: 2022-05-21 16:15:31 +00:00)\n"]}],"source":["import torch\n","\n","def to_cpu_detach(x):\n","  if isinstance(x, list):\n","    return [ y.detach().cpu().item() for y in x ]\n","  else:\n","    return x.detach().cpu().item()"]},{"cell_type":"code","execution_count":26,"metadata":{"id":"PC-E2SeX46A9","executionInfo":{"status":"ok","timestamp":1653149732574,"user_tz":-60,"elapsed":8,"user":{"displayName":"Hans Roggeman","userId":"10574434403170915342"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"bb4f503e-324b-499d-9569-00a123af815a"},"outputs":[{"output_type":"stream","name":"stdout","text":["time: 1.23 ms (started: 2022-05-21 16:15:31 +00:00)\n"]}],"source":["def huber_loss_zero_target(x, delta = 1.0):\n","  loss_function = torch.nn.HuberLoss(delta=delta)\n","  return loss_function(x, torch.zeros_like(x))\n"]},{"cell_type":"code","execution_count":27,"metadata":{"id":"MNYJyHWpeL66","executionInfo":{"status":"ok","timestamp":1653149732574,"user_tz":-60,"elapsed":7,"user":{"displayName":"Hans Roggeman","userId":"10574434403170915342"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"2da4c583-b670-42f3-e302-dc91dd70c887"},"outputs":[{"output_type":"stream","name":"stdout","text":["time: 22.7 ms (started: 2022-05-21 16:15:31 +00:00)\n"]}],"source":["def save_model_train(lr, eqObject, eqLossFn, sample_method, trainObj, eqType):\n","\n","        # self.u_net = u_net\n","        # self.pi_net = pi_net\n","        # self.wgamma = 0.0001\n","        # self.term_utility_func = term_utility_function\n","        # self.xbreaks = None\n","        # self.tbreaks = None\n","\n","        # self.MAX_X = 1.0\n","        # self.T = 1.0\n","        # self.MAX_MU = 0.2\n","        # self.MAX_SIGMA = 1.0\n","\n","        # self.pi_net_epoch = pi_net_epoch\n","        # self.pi_net_lr = pi_net_lr\n","        # self.loss_multiply = 1.0\n","\n","  model_id_str =  f\"{eqType}_{datetime.datetime.now():%Y%m%d%H%M%S}_{eqLossFn}_{sample_method}_{trainObj.stop_epoch}_{str(lr).replace('.','p')}_PiLr{str(eqObject.pi_net_lr).replace('.','p')}_PiEp{str(eqObject.pi_net_epoch)}\"\n","  \n","  if eqObject is not None:\n","    try:\n","        beta = getattr(eqObject,\"beta\")\n","        beta_str = str(beta).replace('.','p')\n","        model_id_str = model_id_str + f\"_beta{beta_str}\"\n","    except AttributeError:\n","        pass\n","    try:\n","        wgamma = getattr(eqObject,\"wgamma\")\n","        wgamma_str = str(wgamma).replace('.','p')\n","        model_id_str = model_id_str + f\"_wgamma{wgamma_str}\"\n","    except AttributeError:\n","        pass\n","  \n","  torch.save(net.state_dict(), f\"/content/drive/MyDrive/data_papers/{paper_name}/model_finals/{model_id_str}\")\n","  df_at_hookintervals = None\n","  train_losses = None\n","  validation_losses = None\n","  try:\n","      df_at_hookintervals = getattr(trainObj, \"history_surfaces_hooks\")\n","      if df_at_hookintervals is not None:\n","        df_at_hookintervals.to_csv(f\"/content/drive/MyDrive/data_papers/{paper_name}/model_checkpoints/validationHook_{trainObj.hook_interval}_{model_id_str}.csv\", index=False)\n","  except AttributeError:\n","      print(\"Class `{}` does not have `{}`\".format(trainObj.__class__.__name__, \"history_surfaces_hooks\"))\n","\n","  try:\n","      train_losses = getattr(trainObj,\"train_losses\")\n","      if train_losses is not None:\n","        train_losses.tofile(f\"/content/drive/MyDrive/data_papers/{paper_name}/model_checkpoints/trainlosses_{model_id_str}.csv\", sep = ',')    \n","  except AttributeError:\n","      print(\"Class `{}` does not have `{}`\".format(trainObj.__class__.__name__, \"train_losses\"))\n","      # raise NotImplementedError(\"Class `{}` does not have `{}`\".format(trainObj.__class__.__name__, \"train_losses\"))\n","\n","  try:\n","      validation_losses = getattr(trainObj,\"validation_losses\")\n","      if validation_losses is not None:\n","        validation_losses.tofile(f\"/content/drive/MyDrive/data_papers/{paper_name}/model_checkpoints/validationlosses_{model_id_str}.csv\", sep = ',')    \n","  except AttributeError:\n","      print(\"Class `{}` does not have `{}`\".format(trainObj.__class__.__name__, \"validation_losses\"))"]},{"cell_type":"code","source":["def save_model_train_stratified(lr, net,  eqLossFn, sample_method, trainObj, eqType, eqObject = None ):\n","\n","  model_id_str =  f\"{eqType}_{datetime.datetime.now():%Y%m%d%H%M%S}_{eqLossFn}_{sample_method}_{trainObj.stop_epoch}_{str(lr).replace('.','p')}_{net.NL}_{net.NN}\"\n","  \n","  if eqObject is not None:\n","    try:\n","        beta = getattr(eqObject,\"beta\")\n","        beta_str = str(beta).replace('.','p')\n","        model_id_str = model_id_str + f\"_beta{beta_str}\"\n","    except AttributeError:\n","        pass\n","    try:\n","        wgamma = getattr(eqObject,\"wgamma\")\n","        wgamma_str = str(wgamma).replace('.','p')\n","        model_id_str = model_id_str + f\"_gamma{wgamma_str}\"\n","    except AttributeError:\n","        pass\n","    try:\n","        xbreaks = getattr(eqObject,\"xbreaks\")\n","        xbreaks_str = str(len(xbreaks))\n","        model_id_str = model_id_str + f\"_StSaXbrks{xbreaks_str}\"\n","    except AttributeError:\n","        pass\n","    try:\n","        tbreaks = getattr(eqObject,\"tbreaks\")\n","        tbreaks_str = str(len(tbreaks))\n","        model_id_str = model_id_str + f\"_StSaTbrks{tbreaks_str}\"\n","    except AttributeError:\n","        pass\n","  \n","  torch.save(net.state_dict(), f\"/content/drive/MyDrive/data_papers/{paper_name}/model_finals/{model_id_str}\")\n","  df_at_hookintervals = None\n","  train_losses = None\n","  validation_losses = None\n","  try:\n","      df_at_hookintervals = getattr(trainObj, \"history_surfaces_hooks\")\n","      if df_at_hookintervals is not None:\n","        df_at_hookintervals.to_csv(f\"/content/drive/MyDrive/data_papers/{paper_name}/model_checkpoints/validationHook_{trainObj.hook_interval}_{model_id_str}.csv\", index=False)\n","  except AttributeError:\n","      print(\"Class `{}` does not have `{}`\".format(trainObj.__class__.__name__, \"history_surfaces_hooks\"))\n","\n","  try:\n","      train_losses = getattr(trainObj,\"train_losses\")\n","      if train_losses is not None:\n","        train_losses.tofile(f\"/content/drive/MyDrive/data_papers/{paper_name}/model_checkpoints/trainlosses_{model_id_str}.csv\", sep = ',')    \n","  except AttributeError:\n","      print(\"Class `{}` does not have `{}`\".format(trainObj.__class__.__name__, \"train_losses\"))\n","      # raise NotImplementedError(\"Class `{}` does not have `{}`\".format(trainObj.__class__.__name__, \"train_losses\"))\n","\n","  try:\n","      validation_losses = getattr(trainObj,\"validation_losses\")\n","      if validation_losses is not None:\n","        validation_losses.tofile(f\"/content/drive/MyDrive/data_papers/{paper_name}/model_checkpoints/validationlosses_{model_id_str}.csv\", sep = ',')    \n","  except AttributeError:\n","      print(\"Class `{}` does not have `{}`\".format(trainObj.__class__.__name__, \"validation_losses\"))"],"metadata":{"id":"ipogSsVTbv0k","executionInfo":{"status":"ok","timestamp":1653149732575,"user_tz":-60,"elapsed":8,"user":{"displayName":"Hans Roggeman","userId":"10574434403170915342"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"342e7b9a-4116-45b2-c0d8-5c83bde1353b"},"execution_count":28,"outputs":[{"output_type":"stream","name":"stdout","text":["time: 26.7 ms (started: 2022-05-21 16:15:31 +00:00)\n"]}]},{"cell_type":"markdown","metadata":{"id":"Tz5tUJuYaXKu"},"source":["### Merton Invest-Consumption Problem - Equation HJB optimization\n","\n","[Extensions of the Deep Galerkin Method](https://arxiv.org/pdf/1912.01455v3.pdf)"]},{"cell_type":"markdown","source":["##### Closed form terminal utility functions"],"metadata":{"id":"N-GO35FcJPP6"}},{"cell_type":"code","source":["def expTerminalUtilityOfWealth(x, gamma_discount = 1.0):\n","  return(-torch.exp(-gamma_discount*x))\n","\n","def expTerminalUtilityOfWealth_np(x, gamma_discount = 1.0):\n","  return(-np.exp(-gamma_discount*x))\n","\n","from functools import partial\n","\n","# should give a closed form solution for the control => PI(x,t) = [(mu-r)/(gamma*sigma^2)]*exp(-r*(T-t))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0cWoRXs02PoF","executionInfo":{"status":"ok","timestamp":1653149737764,"user_tz":-60,"elapsed":415,"user":{"displayName":"Hans Roggeman","userId":"10574434403170915342"}},"outputId":"a9609a29-9031-443e-fc72-df989f3cd187"},"execution_count":29,"outputs":[{"output_type":"stream","name":"stdout","text":["time: 3.04 ms (started: 2022-05-21 16:15:37 +00:00)\n"]}]},{"cell_type":"markdown","metadata":{"id":"HrivvbmubiiY"},"source":["#### MertonUtilityNet"]},{"cell_type":"code","execution_count":30,"metadata":{"id":"JRraqOG4aXKx","executionInfo":{"status":"ok","timestamp":1653149738451,"user_tz":-60,"elapsed":3,"user":{"displayName":"Hans Roggeman","userId":"10574434403170915342"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"3394cecf-1770-4562-d682-0e16219ca70d"},"outputs":[{"output_type":"stream","name":"stdout","text":["time: 11.4 ms (started: 2022-05-21 16:15:38 +00:00)\n"]}],"source":["class MertonUtilityNet(nn.Module):\n","    def __init__(self , NL  , NN, activation = torch.tanh  ):\n","        super(MertonUtilityNet, self).__init__()\n","        self.NL = NL\n","        self.NN = NN\n","        self.Input = 5 + 1  # wealth, time, mu, r, sigma, pi\n","        self.fc_input = nn.Linear(self.Input,self.NN)\n","        torch.nn.init.xavier_uniform_(self.fc_input.weight)\n","        self.linears = nn.ModuleList([nn.Linear(self.NN, self.NN) for i in range(self.NL)])\n","        for i, l in enumerate(self.linears):    \n","            torch.nn.init.xavier_uniform_(l.weight)\n","        self.fc_output = nn.Linear(self.NN,1)\n","        torch.nn.init.xavier_uniform_(self.fc_output.weight)\n","        self.act = activation\n","        \n","    def forward(self, x):\n","        h = self.act( self.fc_input(x)  )\n","        for i, l in enumerate(self.linears):\n","            h = self.act( l(h) )\n","        out = self.fc_output(h)\n","        return out "]},{"cell_type":"markdown","source":["#### MertonPiNet"],"metadata":{"id":"fyFbPZr7I5RE"}},{"cell_type":"code","source":["import torch.nn.functional as F\n","\n","class MertonPiNet(nn.Module):\n","    def __init__(self , NL  , NN, activation = torch.relu  ):\n","        super(MertonPiNet, self).__init__()\n","        self.NL = NL\n","        self.NN = NN\n","        self.Input = 5   # wealth, time, mu, r, sigma\n","        self.fc_input = nn.Linear(self.Input,self.NN)\n","        torch.nn.init.xavier_uniform_(self.fc_input.weight)\n","        self.linears = nn.ModuleList([nn.Linear(self.NN, self.NN) for i in range(self.NL)])\n","        for i, l in enumerate(self.linears):    \n","            torch.nn.init.xavier_uniform_(l.weight)            \n","        # self.fc_output_d = nn.Linear(self.NN, 2)\n","        # self.fc_output = torch.nn.Softmax(dim=1)\n","        self.fc_output = nn.Linear(self.NN, 1)\n","        torch.nn.init.xavier_uniform_(self.fc_output.weight)\n","        self.act = activation\n","        \n","    def forward(self, x):\n","        h = self.act( self.fc_input(x)  )\n","        for i, l in enumerate(self.linears):\n","            h = self.act( l(h) )\n","        # out = self.fc_output_d(h)\n","        out = self.fc_output(h)\n","        return out \n","        "],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PR7PHL4KI1S9","executionInfo":{"status":"ok","timestamp":1653149738758,"user_tz":-60,"elapsed":5,"user":{"displayName":"Hans Roggeman","userId":"10574434403170915342"}},"outputId":"b30af4e4-dfbd-4ccd-fb0c-554bba5c0d21"},"execution_count":31,"outputs":[{"output_type":"stream","name":"stdout","text":["time: 13.9 ms (started: 2022-05-21 16:15:38 +00:00)\n"]}]},{"cell_type":"markdown","source":["#### MertonAlternativePiNet\n","\n","[implement from github](https://github.com/Plemeur/DGM/blob/master/first_net.py)"],"metadata":{"id":"RNhAbZ727RC_"}},{"cell_type":"code","source":["\n","class LinearWithXavier(nn.Module):\n","    \"\"\" Copy of linear module from Pytorch, modified to have a Xavier init,\n","        TODO : figure out what to do with the bias\"\"\"\n","    def __init__(self, in_features, out_features, bias=True):\n","        super(LinearWithXavier, self).__init__()\n","        self.in_features = in_features\n","        self.out_features = out_features\n","        self.weight = torch.nn.Parameter(torch.Tensor(out_features, in_features))\n","        if bias:\n","            self.bias = torch.nn.Parameter(torch.Tensor(out_features))\n","        else:\n","            self.register_parameter('bias', None)\n","        self.reset_parameters()\n","    def reset_parameters(self):\n","        torch.nn.init.xavier_uniform_(self.weight)\n","        if self.bias is not None:\n","            torch.nn.init.uniform_(self.bias, -1, 1) #boundary matter?\n","    def forward(self, input):\n","        return torch.nn.functional.linear(input, self.weight, self.bias)\n","    def extra_repr(self):\n","        return 'in_features={}, out_features={}, bias={}'.format(\n","            self.in_features, self.out_features, self.bias is not None\n","        )\n","\n","\n","class DGM_layer(nn.Module):\n","    \"\"\" See readme for paper source\"\"\"\n","    def __init__(self, in_features, out_feature, residual=False):\n","        super(DGM_layer, self).__init__()\n","        self.residual = residual\n","\n","        self.Z = LinearWithXavier(out_feature, out_feature)\n","        self.UZ = LinearWithXavier(in_features, out_feature, bias=False)\n","        self.G = LinearWithXavier(out_feature, out_feature)\n","        self.UG = LinearWithXavier(in_features, out_feature, bias=False)\n","        self.R = LinearWithXavier(out_feature, out_feature)\n","        self.UR = LinearWithXavier(in_features, out_feature, bias=False)\n","        self.H = LinearWithXavier(out_feature, out_feature)\n","        self.UH = LinearWithXavier(in_features, out_feature, bias=False)\n","\n","    def forward(self, x, s):\n","        z = torch.tanh(self.UZ(x) + self.Z(s))\n","        g = torch.tanh(self.UG(x) + self.G(s))\n","        r = torch.tanh(self.UR(x) + self.R(s))\n","        h = torch.tanh(self.UH(x) + self.H(s * r))\n","        return (1 - g) * h + z * s\n","\n","\n","class MertonAlternativePiNet(nn.Module):\n","\n","    def __init__(self, in_size, out_size, neurons, depth):\n","        super(MertonAlternativePiNet, self).__init__()\n","        self.dim = in_size\n","        self.input_layer = LinearWithXavier(in_size, neurons)\n","        self.middle_layer = nn.ModuleList([DGM_layer(in_size, neurons) for i in range(depth)])\n","        self.final_layer = LinearWithXavier(neurons, out_size)\n","\n","    def forward(self, X):\n","        s = torch.tanh(self.input_layer(X))\n","        for i, layer in enumerate(self.middle_layer):\n","            s = torch.tanh(layer(X, s))\n","\n","        return self.final_layer(s)\n","\n","\n","\n","        "],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_c-dZ5b37NwV","executionInfo":{"status":"ok","timestamp":1653149740717,"user_tz":-60,"elapsed":293,"user":{"displayName":"Hans Roggeman","userId":"10574434403170915342"}},"outputId":"d1a33d20-0052-4725-a976-9b65a3cdedcb"},"execution_count":32,"outputs":[{"output_type":"stream","name":"stdout","text":["time: 60.4 ms (started: 2022-05-21 16:15:40 +00:00)\n"]}]},{"cell_type":"markdown","metadata":{"id":"wClW1g9rbm8o"},"source":["#### PiEquation"]},{"cell_type":"code","source":["class PiEquation():\n","\n","    def __init__(self , pi_net, du_dx, d2u_dx2):\n","        self.pi_net = pi_net\n","        self.wgamma = 0.0001\n","        self.du_dx = du_dx\n","        self.d2u_dx2 = d2u_dx2\n","\n","    def criterion(self, x_internal):\n","      #  time, wealth, mu, r, sigma\n","      pi_net_preds = self.pi_net(x_internal)\n","      # pi_net_preds = pi_net_preds[:,0].reshape(-1,1)\n","      pi_net_preds = pi_net_preds.reshape(-1,1)\n","\n","      dpi = torch.autograd.grad( pi_net_preds, \n","                                x_internal, \n","                                grad_outputs=torch.ones_like(pi_net_preds) ,\n","                                create_graph=True,\n","                                retain_graph=True)\n","      dpi_dt = dpi[0][:,0].reshape(-1,1)\n","      dpi_dx = dpi[0][:,1].reshape(-1,1)\n","\n","      d2pi_dx2 = torch.autograd.grad( dpi_dx, \n","                                      x_internal , \n","                                      grad_outputs=torch.ones_like(dpi_dx) ,\n","                                      create_graph = True,\n","                                      retain_graph=True)[0][:,1].reshape(-1,1)\n","      intC = None\n","      # pdb.set_trace()\n","      if len(x_internal) == 0:\n","        intC_loss = torch.tensor(0).cuda().float()  \n","      else:\n","        # pdb.set_trace()\n","        intC_loss = -(pi_net_preds*(x_internal[:,2].reshape(-1,1)-x_internal[:,3].reshape(-1,1)) + x_internal[:,3].reshape(-1,1)*x_internal[:,1].reshape(-1,1))*self.du_dx - \\\n","                                    0.5*(x_internal[:,4].reshape(-1,1)**2)*(pi_net_preds**2)*self.d2u_dx2\n","\n","        # print(f\"Pi Loss {torch.mean(intC_loss).item()} {x_internal.shape[0]} {torch.mean(self.du_dx)}\")          \n","\n","        # intC_loss = (pi_net_preds*(x_internal[:,2].reshape(-1,1)-x_internal[:,3].reshape(-1,1)) + x_internal[:,3].reshape(-1,1)*x_internal[:,1].reshape(-1,1))*self.du_dx + \\\n","        #                             0.5*(x_internal[:,4].reshape(-1,1)**2)*(pi_net_preds**2)*self.d2u_dx2\n","\n","      return  1.0*intC_loss\n","\n","    def calculatePiLoss(self, x_internal, keep_batch = False):\n","        '''\n","        Helper function that Sample and Calculate loss,\n","        '''        \n","        x_internal = Variable( x_internal , requires_grad=True)\n","        Ls = self.criterion( x_internal )\n","        \n","        return_losses = []\n","        if not keep_batch:\n","          loss_pi = torch.mean(Ls)           \n","          return loss_pi          \n","        else:\n","          return Ls\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uQTTkUhWuiJi","executionInfo":{"status":"ok","timestamp":1653149741816,"user_tz":-60,"elapsed":5,"user":{"displayName":"Hans Roggeman","userId":"10574434403170915342"}},"outputId":"b515ae3d-b2a5-4d82-dedf-cd71c6d2d2e3"},"execution_count":33,"outputs":[{"output_type":"stream","name":"stdout","text":["time: 27.6 ms (started: 2022-05-21 16:15:41 +00:00)\n"]}]},{"cell_type":"markdown","source":["#### TrainInternalPiWithDGM\n"],"metadata":{"id":"8RRoBgFQINMv"}},{"cell_type":"code","source":["class TrainInternalPiWithDGM():\n","    \n","    def __init__(self , u_equation, pi_equation, BATCH_SIZE , epoch, lr, debug = False, loss_multiply = 1.0):\n","        self.BATCH_SIZE = BATCH_SIZE\n","        self.u_model = u_equation        \n","        self.pi_model = pi_equation\n","        self.debug = debug  \n","        self.hook_interval = 20      \n","        if self.debug == True:\n","            self.hooks = {}            \n","            self.get_all_layers(self.pi_model.pi_net)\n","\n","        self.optimizer_used = optim.Adam\n","\n","        self.use_early_stop = False\n","        self.early_stop_patience = 10\n","        self.early_stop_delta = 0.0        \n","        self.best_loss = np.Inf\n","        self.early_stop_counter = 0\n","\n","        self.stop_epoch = 0\n","\n","        self.validation_sample = None\n","        self.validation_losses = None\n","        self.train_losses = None        \n","\n","        self.epoch = epoch\n","        self.lr = lr\n","\n","        self.loss_multiply = loss_multiply\n","        \n","    def train(self , eqLossFn = 'calculatePiLoss', sample_method_X = \"U\"):\n","        \n","        if self.validation_sample is not None:\n","          self.validation_losses = np.ones((self.epoch, 3 ), dtype='float32') * np.nan\n","        self.train_losses = np.ones((self.epoch, 1 ), dtype='float32') * np.nan\n","\n","        optimizer = self.optimizer_used(self.pi_model.pi_net.parameters(), self.lr)\n","        # optimizer = self.optimizer_used(self.u_model.pi_net.parameters(), self.lr)\n","        # optimizer = optim.SGD(self.net.parameters(), lr)\n","        \n","        loss_avg = 0.0\n","        # pdb.set_trace()\n","        loss_calc_method = None\n","        try:\n","            loss_calc_method = getattr(self.pi_model, eqLossFn)\n","        except AttributeError:\n","            raise NotImplementedError(\"Class `{}` does not implement `{}`\".format(self.pi_model.__class__.__name__, eqLossFn))\n","        \n","        for e in range(self.epoch):\n","\n","            optimizer.zero_grad()            \n","\n","            sample_batch = self.u_model.sample(sample_method_X = sample_method_X, size=self.BATCH_SIZE)\n","\n","            loss_avg = 0.0\n","            # pdb.set_trace()\n","            loss  = loss_calc_method( sample_batch[0], keep_batch = False )            \n","            # print(f\"Pi Net Epoch {e} Loss {round(loss.item(),5)}\")\n","\n","            self.train_losses[e,:] = [ to_cpu_detach(loss) ]\n","\n","            if self.debug == True and (self.validation_sample is not None):\n","              losses_L2_validation, losses_ABS_validation, losses_Huber_valiation = loss_calc_method( self.validation_sample, \n","                                                                                                     loss_transforms = [ torch.square, torch.abs, partial(huber_loss_zero_target, delta=huber_delta) ], \n","                                                                                                     keep_batch = False )\n","              validation_loss_list = [*to_cpu_detach(losses_L2_validation),\n","                                      *to_cpu_detach(losses_ABS_validation),\n","                                      *to_cpu_detach(losses_Huber_valiation)]\n","              self.validation_losses[e,:] = validation_loss_list\n","            \n","            if self.use_early_stop:\n","              loss_to_check = loss\n","              if loss_to_check < (self.best_loss-self.early_stop_delta):\n","                self.best_loss = loss_to_check\n","                self.early_stop_counter = 0\n","              else:\n","                self.early_stop_counter += 1\n","              if self.early_stop_counter>=self.early_stop_patience:\n","                # print(f\"Pi Early Stop at epoch {e}: {loss_to_check} with patience {self.early_stop_patience}\")\n","                break\n","            \n","            loss_avg = loss_avg + float(loss.item())\n","            loss.backward(retain_graph=True)\n","\n","            optimizer.step()\n","            if (e % self.hook_interval == (self.hook_interval-1)) or e == 0:\n","                loss_avg = loss_avg/self.hook_interval\n","                # print(\"Pi Epoch {} - lr {} -  key loss: {}\".format(e , self.lr , loss))\n","\n","        self.stop_epoch = e\n","\n","    def hook_fn(self, m, i, o):\n","              self.hooks[m] = o.detach()\n","            \n","    def get_all_layers(self, net):\n","      for name, layer in net._modules.items():\n","          if isinstance(layer, nn.ModuleList):\n","              for n , l in layer.named_children():\n","                l.register_forward_hook(self.hook_fn)\n","          else:\n","              # it's a non sequential. Register a hook\n","              layer.register_forward_hook(self.hook_fn)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VREn3fanpP1b","executionInfo":{"status":"ok","timestamp":1653149744018,"user_tz":-60,"elapsed":7,"user":{"displayName":"Hans Roggeman","userId":"10574434403170915342"}},"outputId":"d2499198-fbcd-40ba-eac0-88a204b5859c"},"execution_count":34,"outputs":[{"output_type":"stream","name":"stdout","text":["time: 86 ms (started: 2022-05-21 16:15:43 +00:00)\n"]}]},{"cell_type":"markdown","source":["#### MertonEquation"],"metadata":{"id":"hp4BG1ewKF6o"}},{"cell_type":"code","execution_count":35,"metadata":{"cellView":"code","id":"LBMZYQSPaXKy","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1653149747205,"user_tz":-60,"elapsed":1098,"user":{"displayName":"Hans Roggeman","userId":"10574434403170915342"}},"outputId":"a0ca272e-5122-4b95-e2de-3027df700150"},"outputs":[{"output_type":"stream","name":"stdout","text":["time: 899 ms (started: 2022-05-21 16:15:45 +00:00)\n"]}],"source":["import math\n","\n","class MertonEquation():\n","    \n","    def __init__(self , u_net, pi_net, pi_net_epoch, pi_net_lr, term_utility_function = partial(expTerminalUtilityOfWealth,gamma_discount=0.1) ):\n","\n","        self.u_net = u_net\n","        self.pi_net = pi_net\n","        self.wgamma = 0.0001\n","        self.term_utility_func = term_utility_function\n","        self.xbreaks = None\n","        self.tbreaks = None\n","\n","        self.MAX_X = 1.0\n","        self.T = 1.0\n","        self.MAX_MU = 0.2\n","        self.MAX_SIGMA = 1.0\n","\n","        self.pi_net_epoch = pi_net_epoch\n","        self.pi_net_lr = pi_net_lr\n","        self.loss_multiply = 1.0\n","\n","        self.FORCE_MU = None\n","        self.FORCE_R = None\n","        self.FORCE_SIGMA = None\n","\n","    def g(self,x):\n","        # Time, Wealth, Mu, R, Sigma\n","        return self.term_utility_func(x[:,1].reshape(-1,1))\n","\n","    @staticmethod\n","    def to_device(x, to_cpu):\n","      if to_cpu:\n","        return x.cpu()\n","      else:\n","        return x.cuda()\n","\n","    def mu_r_sample(self, size, range_multiplier = 1.0):\n","      mu_candidate = -self.MAX_MU*range_multiplier*torch.rand([size, 1])+self.MAX_MU*range_multiplier\n","      r_candidate = -self.MAX_MU*range_multiplier*torch.rand([size, 1])+self.MAX_MU*range_multiplier\n","      r_sample = torch.where(r_candidate < mu_candidate, r_candidate, mu_candidate)\n","      mu_sample = torch.where(r_candidate > mu_candidate, r_candidate, mu_candidate)\n","      return (mu_sample, r_sample)\n","\n","    def apply_forced_mu_r_sigma(self, mu_sample, r_sample, sigma_sample):\n","      if self.FORCE_MU is not None:\n","         mu_sample = self.FORCE_MU*torch.ones_like(mu_sample)            \n","      if self.FORCE_R is not None:\n","        r_sample = self.FORCE_R*torch.ones_like(r_sample)\n","      if self.FORCE_SIGMA is not None:\n","        sigma_sample = self.FORCE_SIGMA*torch.ones_like(sigma_sample)\n","      return mu_sample, r_sample, sigma_sample\n","\n","\n","    def sample(self , sample_method_X = \"U\", size = 2**8, to_cpu = False ):\n","        '''\n","        Sampling function\n","        '''\n","        if sample_method_X in [\"U\"]:\n","            range_multiplier = 1.0\n","            \n","            ### internal samples of Time, Wealth, Mu, R, Sigma\n","            mu_sample_internal, r_sample_internal = self.mu_r_sample(size, range_multiplier)\n","            sigma_sample_internal = -self.MAX_SIGMA*range_multiplier*torch.rand([size, 1])+self.MAX_SIGMA*range_multiplier\n","            mu_sample_internal, r_sample_internal, sigma_sample_internal = self.apply_forced_mu_r_sigma(mu_sample_internal, r_sample_internal, sigma_sample_internal)\n","            x_internal = self.to_device(torch.cat(( torch.rand([size,1])*self.T , # Time\n","                                                   -self.MAX_X*range_multiplier*torch.rand([size, 1])+self.MAX_X*range_multiplier, # Wealth\n","                                                    mu_sample_internal, # mu\n","                                                    r_sample_internal, # R\n","                                                    sigma_sample_internal # Sigma\n","                                                   ) , dim = 1 ),to_cpu)\n","            ### Terminal time samples\n","            mu_sample_terminal, r_sample_terminal = self.mu_r_sample(size, range_multiplier)\n","            sigma_sample_terminal = -self.MAX_SIGMA*range_multiplier*torch.rand([size, 1])+self.MAX_SIGMA*range_multiplier\n","            mu_sample_terminal, r_sample_terminal, sigma_sample_terminal = self.apply_forced_mu_r_sigma(mu_sample_terminal, r_sample_terminal, sigma_sample_terminal)\n","            x_terminal = self.to_device(torch.cat(( torch.zeros(size, 1) + self.T , # Time\n","                                                   -self.MAX_X*range_multiplier*torch.rand([size, 1])+self.MAX_X*range_multiplier, # Wealth\n","                                                    mu_sample_terminal, # mu\n","                                                    r_sample_terminal, # R\n","                                                    sigma_sample_terminal # Sigma\n","                                                   ) , dim = 1 ),to_cpu)\n","            \n","            # x_initial = torch.cat( ( torch.zeros(size, 1), -self.MAX_X*range_multiplier*torch.rand([size, 1])+self.MAX_X*range_multiplier) , dim = 1 ).cuda()\n","            return x_internal , x_terminal\n","\n","        raise ValueError(f\"{sample_method_X} is not a supported sampling method\")\n","        \n","    def sample_stratified(self , sample_method_X = \"U\", size = 2**8, to_cpu = False ):\n","\n","      if self.xbreaks is None and self.tbreaks is None:\n","        return self.sample(sample_method_X, size, to_cpu)\n","\n","      internal_strata_xts = []\n","      terminal_strata_xts = []\n","      \n","      if sample_method_X in [\"U\"]:\n","          range_multiplier = 1.0\n","          xbreaks_used = self.xbreaks[:] if self.xbreaks is not None else [0,range_multiplier*self.MAX_X]\n","          tbreaks_used = self.tbreaks[:] if self.tbreaks is not None else [0,self.T]\n","          if xbreaks_used[-1] < range_multiplier*self.MAX_X:\n","            xbreaks_used.append(range_multiplier*self.MAX_X)\n","          while xbreaks_used[0] < 0.0:\n","            xbreaks_used.pop(0)\n","          if not xbreaks_used:\n","            xbreaks_used = [0,range_multiplier*self.MAX_X]\n","          if xbreaks_used[0] > 0.0:            \n","            xbreaks_used.insert(0, 0.0)\n","\n","          if tbreaks_used[-1] < self.T:\n","            tbreaks_used.append(self.T)\n","          xbreaks_range = xbreaks_used[-1]-xbreaks_used[0]\n","          tbreaks_range = tbreaks_used[-1]-tbreaks_used[0]\n","\n","          total_strat_processed = 0\n","\n","          # internal samples\n","          for stratum_x_count in range(len(xbreaks_used)-1):\n","              \n","            num_samples_in_stratum = 0\n","            if len(xbreaks_used) > 2:  # x division takes priority so assign it if there is no T division\n","              range_ratio_x_stratum = (xbreaks_used[stratum_x_count+1]-xbreaks_used[stratum_x_count])/xbreaks_range\n","              num_samples_in_stratum = math.ceil(range_ratio_x_stratum*size)\n","\n","            for stratum_t_count in range(len(self.tbreaks)-1):\n","\n","              if num_samples_in_stratum == 0: # there is only a T division, so use it\n","                range_ratio_t_stratum = (tbreaks_used[stratum_t_count+1]-tbreaks_used[stratum_t_count])/tbreaks_range\n","                num_samples_in_stratum = math.ceil(range_ratio_t_stratum*size)\n","              else:\n","                # there is both an X and a T division, assign the number of samples uniformly, assuming same scale of X and T\n","                stratum_coverage_on_unit_square = \\\n","                  ((xbreaks_used[stratum_x_count+1]-xbreaks_used[stratum_x_count])/xbreaks_range)*\\\n","                  ((tbreaks_used[stratum_t_count+1]-tbreaks_used[stratum_t_count])/tbreaks_range)\n","                num_samples_in_stratum = math.ceil(stratum_coverage_on_unit_square * size)\n","\n","              range_multiplier = 1.0\n","\n","              ### internal samples of Time, Wealth, Mu, R, Sigma\n","              internal_stratum_t_sample = tbreaks_used[stratum_t_count] + torch.rand([num_samples_in_stratum,1])*(tbreaks_used[stratum_t_count+1]-tbreaks_used[stratum_t_count])\n","              internal_stratum_x_sample = xbreaks_used[stratum_x_count] + torch.rand([num_samples_in_stratum,1])*(xbreaks_used[stratum_x_count+1]-xbreaks_used[stratum_x_count])\n","              stratum_mu_sample_internal, stratum_r_sample_internal = self.mu_r_sample(num_samples_in_stratum, range_multiplier)\n","              stratum_sigma_sample_internal = -self.MAX_SIGMA*range_multiplier*torch.rand([num_samples_in_stratum, 1])+self.MAX_SIGMA*range_multiplier\n","              stratum_mu_sample_internal, stratum_r_sample_internal, stratum_sigma_sample_internal = \\\n","                self.apply_forced_mu_r_sigma(stratum_mu_sample_internal, stratum_r_sample_internal, stratum_sigma_sample_internal)\n","              x_internal_stratum = self.to_device(torch.cat(( internal_stratum_t_sample , # Time\n","                                                              internal_stratum_x_sample, # Wealth\n","                                                              stratum_mu_sample_internal, # mu\n","                                                              stratum_r_sample_internal, # R\n","                                                               # Sigma\n","                                                            ) , dim = 1 ),to_cpu)\n","              if not internal_strata_xts: \n","                internal_strata_xts = [ x_internal_stratum ] \n","              else:\n","                internal_strata_xts.append(x_internal_stratum) \n","\n","              ### Terminal time samples\n","              terminal_stratum_x_sample = xbreaks_used[stratum_x_count] + torch.rand([num_samples_in_stratum,1])*(xbreaks_used[stratum_x_count+1]-xbreaks_used[stratum_x_count])\n","              stratum_mu_sample_terminal, stratum_r_sample_terminal = self.mu_r_sample(num_samples_in_stratum, range_multiplier)\n","              stratum_sigma_sample_terminal = -self.MAX_SIGMA*range_multiplier*torch.rand([num_samples_in_stratum, 1])+self.MAX_SIGMA*range_multiplier\n","              stratum_mu_sample_terminal, stratum_r_sample_terminal, stratum_sigma_sample_terminal = \\\n","                self.apply_forced_mu_r_sigma(stratum_mu_sample_terminal, stratum_r_sample_terminal, stratum_sigma_sample_terminal)\n","              x_terminal_stratum = self.to_device(torch.cat(( torch.zeros(num_samples_in_stratum, 1) + self.T , # Time\n","                                                      terminal_stratum_x_sample, # Wealth\n","                                                      stratum_mu_sample_terminal, # mu\n","                                                      stratum_r_sample_terminal, # R\n","                                                      stratum_sigma_sample_terminal # Sigma\n","                                                    ) , dim = 1 ),to_cpu)\n","              if not terminal_strata_xts:\n","                terminal_strata_xts = [ x_terminal_stratum ] # terminal_stratum_xt[None,:,:]\n","              else:\n","                terminal_strata_xts.append(x_terminal_stratum) # torch.vstack((terminal_strata_xts,terminal_stratum_xt[None,:,: ]))\n","\n","              total_strat_processed += 1 \n","              # print((len(internal_strata_xts),xbreaks_used[stratum_x_count],tbreaks_used[stratum_t_count]))\n","\n","          # pdb.set_trace()\n","          # x_initial = torch.cat( ( torch.zeros(size, 1), -self.MAX_X*range_multiplier*torch.rand([size, 1])+self.MAX_X*range_multiplier) , dim = 1 ).cuda()\n","          return internal_strata_xts , terminal_strata_xts\n","    \n","      raise ValueError(f\"{sample_method_X} is not a supported sampling method\")\n","\n","    def criterion(self, x_internal , x_terminal, loss_transforms = [torch.square]):\n","        '''\n","        Loss function that helps network find solution to equation\n","        '''   \n","        # Time / Wealth / Mu / r / Sigma (sample data order)\n","        # pdb.set_trace()\n","\n","        # replace with closed form just to check\n","        # self.pi_net = lambda x: (((x[:,2]-x[:,3])/(1.0*(x[:,4]**2)))*torch.exp(-x[:,3]*(1.0-x[:,0])))\n","\n","        # pdb.set_trace()\n","        pi_used = self.pi_net(x_internal)  \n","        pi_used.detach_()\n","        # let's assign the first column as the allocation\n","        # pdb.set_trace()     \n","        # pi_used = pi_used[:,0].reshape(-1,1)\n","        pi_used = pi_used.reshape(-1,1)\n","        x_internal_before = x_internal.detach().clone()\n","        x_internal =  Variable(torch.cat((x_internal, pi_used), dim=1),requires_grad=True)\n","\n","        du = torch.autograd.grad( self.u_net(x_internal), \n","                                  x_internal, \n","                                  grad_outputs=torch.ones_like(self.u_net(x_internal)) ,\n","                                  create_graph=True,\n","                                  retain_graph=True )\n","        \n","        du_dt = du[0][:,0].reshape(-1,1)\n","        du_dx = du[0][:,1].reshape(-1,1)     \n","\n","        d2u_dx2 = torch.autograd.grad(  du_dx, \n","                                        x_internal , \n","                                        grad_outputs=torch.ones_like(du_dx) ,\n","                                        create_graph = True,\n","                                        retain_graph = True)[0][:,1].reshape(-1,1)\n","    \n","        # def pi_net_fn(x,du_dx = du_dx,d2u_dx2 = d2u_dx2): \n","        #   return (-(((x[:,2]-x[:,3])/(1.0*(x[:,4]**2)))*torch.div(du_dx,d2u_dx2).reshape(-1)))\n","\n","        # pi_net_fn2 = lambda x: (((x[:,2]-x[:,3])/(1.0*(x[:,4]**2)))*torch.exp(-x[:,3]*(1.0-x[:,0])))\n","\n","        pi_model = PiEquation(self.pi_net, du_dx, d2u_dx2)                \n","        pi_trainer = TrainInternalPiWithDGM(self, pi_model, x_internal.shape[0], \n","                                            self.pi_net_epoch, self.pi_net_lr, \n","                                            debug=True, loss_multiply=1.0)\n","        pi_trainer.use_early_stop = True\n","        pi_trainer.early_stop_patience = min(200,math.ceil(self.pi_net_epoch/10.0))\n","        pi_trainer.train()\n","        \n","        # self.pi_net =  pi_net_fn\n","        # self.pi_net =  pi_net_fn2\n","        if loss_transforms is None:\n","          loss_transforms = [torch.square]\n","\n","        intC = None\n","        terC = None\n","\n","        if len(x_internal) == 0:\n","          intC = [ torch.tensor(0).cuda().float() for loss_transform in loss_transforms ] \n","        else:\n","          # Time, Wealth, Mu, R, Sigma\n","          # pdb.set_trace()\n","          pi_net_preds = self.pi_net(x_internal_before)\n","          pi_net_preds.detach_()\n","          # pi_net_preds = pi_net_preds[:,0].reshape(-1,1)\n","          pi_net_preds = pi_net_preds.reshape(-1,1)\n","          intC_loss = du_dt + (pi_net_preds*(x_internal[:,2].reshape(-1,1)-x_internal[:,3].reshape(-1,1))+x_internal[:,3].reshape(-1,1)*x_internal[:,1].reshape(-1,1))*du_dx + 0.5*(x_internal[:,4].reshape(-1,1)**2)*(pi_net_preds**2)*d2u_dx2\n","          intC = [ loss_transform(intC_loss) for loss_transform in loss_transforms ] \n","\n","        # Terminal Condition - should be equal (both in- and out of the money)\n","        x_terminal_before = x_terminal.detach().clone()\n","        pi_net_preds_terminal = self.pi_net(x_terminal_before)\n","        pi_net_preds_terminal.detach_()\n","        # pi_net_preds_terminal = pi_net_preds_terminal[:,0].reshape(-1,1)\n","        pi_net_preds_terminal = pi_net_preds_terminal.reshape(-1,1)\n","        x_terminal =  Variable(torch.cat((x_terminal, pi_net_preds_terminal), dim=1),requires_grad=True)\n","\n","        terC = [ loss_transform( self.u_net(x_terminal) - self.g(x_terminal)   ) for loss_transform in loss_transforms ]\n","\n","        return  intC , terC\n","\n","    def calculateLoss(self, batch_x, train = True, loss_transforms = [ torch.square ], keep_batch = False):\n","        '''\n","        Helper function that Sample and Calculate loss,\n","        '''        \n","        # pdb.set_trace()\n","        x_internal , x_terminal = batch_x\n","        x_internal = Variable( x_internal , requires_grad=True)\n","        Ls = self.criterion( x_internal , x_terminal, loss_transforms = loss_transforms )\n","        intC , terC  = Ls\n","\n","        return_losses = []\n","        for lc in range(len(loss_transforms)):\n","          if not keep_batch:\n","            loss_equalWeightedByType = 0.5*torch.mean(intC[lc]) + 0.5*torch.mean(terC[lc])\n","            return_losses.append( [ loss_equalWeightedByType , \n","                                    0.5*torch.mean(intC[lc]) , 0.5*torch.mean(terC[lc]), \n","                                    loss_equalWeightedByType ] )            \n","          else:\n","            return_losses.append( [intC.numpy(), terC.numpy()] )\n","        return return_losses\n","\n","    def calculateLossUsingKLMinMax(self , batch_x , train = True, loss_transforms = [ torch.square ], keep_batch = False):\n","        '''\n","        Helper function that Samples and Calculate loss,\n","        This is adapted in that it changes the weights on the losses\n","        and the distribution of sampling to maximize the loss provided \n","        the KL distance of the loss is within positive constraints\n","        beta represents the constraints on the weights\n","        gamma represents the constraints on the sampling distribution\n","        (each representing an upper bound the KL distribution)\n","        '''        \n","        # x , x_terminal , x_initial = self.sample(sample_method_X, size)\n","        x , x_terminal = batch_x\n","        x = Variable( x, requires_grad=True)\n","        Ls = self.criterion( x , x_terminal , loss_transforms = loss_transforms)\n","        intC , terC = Ls\n","\n","        if self.weights is None:\n","          self.weights = torch.ones(1,len(Ls)).to(intC[0].device)/len(Ls)\n","        \n","        return_losses = []\n","        for lc in range(len(loss_transforms)):\n","          if not keep_batch:\n","            intCt = self.weights[0,0] * torch.pow((1.0/intC[lc].numel() if intC[lc].numel() > 0 else 0.0) * torch.sum( torch.exp(self.beta * intC[lc])), self.gamma/self.beta) \n","            terCt = self.weights[0,1] * torch.pow((1.0/terC[lc].numel() if terC[lc].numel() > 0 else 0.0) * torch.sum( torch.exp(self.beta * terC[lc])), self.gamma/self.beta) \n","            loss_equalWeightedByType = 0.5*torch.mean(intC[lc]) + 0.5*torch.mean(terC[lc]) \n","            transformed_loss = 1.0/self.gamma * torch.log(intCt + terCt)\n","            return_losses.append( [ transformed_loss , \n","                                    0.5*torch.mean(intC[lc]) , 0.5*torch.mean(terC[lc]),\n","                                    loss_equalWeightedByType ] )            \n","          else:\n","            return_losses.append( [intC[lc].numpy(), terC[lc].numpy()] )\n","        return return_losses\n","\n","\n","    def calculateLossKLMinMaxGamma(self , batch_x , train = True, loss_transforms = [ torch.square ], keep_batch = False):\n","        '''\n","        Helper function that Samples and Calculate loss,\n","        This is adapted in that it changes the weights on the losses\n","        and the distribution of sampling to maximize the loss provided \n","        the KL distance of the loss is within positive constraints\n","        beta represents the constraints on the weights\n","        gamma represents the constraints on the sampling distribution\n","        (each representing an upper bound the KL distribution)\n","        '''        \n","        # x , x_terminal , x_initial = self.sample(sample_method_X, size)\n","        x , x_terminal  = batch_x\n","        x = Variable( x, requires_grad=True)\n","        Ls = self.criterion( x , x_terminal, loss_transforms = loss_transforms)\n","        intC , terC  = Ls\n","\n","        if self.weights is None:\n","          self.weights = torch.ones(1,len(Ls)).to(intC[0].device)/len(Ls)\n","        \n","        return_losses = []\n","        for lc in range(len(loss_transforms)):\n","          if not keep_batch:\n","            intCt = self.weights[0,0] * (1.0/intC[lc].numel() if intC[lc].numel() > 0 else 0.0) * torch.sum( torch.exp(self.gamma * intC[lc])) \n","            terCt = self.weights[0,1] * (1.0/terC[lc].numel() if terC[lc].numel() > 0 else 0.0) * torch.sum( torch.exp(self.gamma * terC[lc])) \n","            loss_equalWeightedByType = 0.5*torch.mean(intC[lc]) + 0.5*torch.mean(terC[lc]) \n","            transformed_loss = 1.0/self.gamma * torch.log(intCt + terCt )\n","            return_losses.append( [ transformed_loss , \n","                                    0.5*torch.mean(intC[lc]) , 0.5*torch.mean(terC[lc]),\n","                                    loss_equalWeightedByType ] )            \n","          else:\n","            return_losses.append( [intC[lc].numpy(), terC[lc].numpy()] )\n","        return return_losses\n","\n","    "]},{"cell_type":"markdown","metadata":{"id":"65nooklCbsdy"},"source":["#### TrainHJBMertonWithDGM"]},{"cell_type":"code","source":["def attach_pi_used(x, pi_net, requires_grad=True):\n","  pi_used = pi_net(x)  \n","  pi_used.detach_()\n","  # pi_used = pi_used[:,0].reshape(-1,1)\n","  pi_used = pi_used.reshape(-1,1)\n","  \n","  before_x = x.detach().clone()\n","  new_x =  Variable(torch.cat((x, pi_used), dim=1),requires_grad=requires_grad)\n","  return before_x, new_x"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"74jqGI3o2GlN","executionInfo":{"status":"ok","timestamp":1653149747205,"user_tz":-60,"elapsed":5,"user":{"displayName":"Hans Roggeman","userId":"10574434403170915342"}},"outputId":"4afe91a1-2908-4082-d216-ff8b169f8af5"},"execution_count":36,"outputs":[{"output_type":"stream","name":"stdout","text":["time: 2.66 ms (started: 2022-05-21 16:15:46 +00:00)\n"]}]},{"cell_type":"code","execution_count":37,"metadata":{"id":"OtO8fV7oaXK2","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1653149748703,"user_tz":-60,"elapsed":1031,"user":{"displayName":"Hans Roggeman","userId":"10574434403170915342"}},"outputId":"2ab0b18e-6c89-45f5-afb4-485104324ae9"},"outputs":[{"output_type":"stream","name":"stdout","text":["time: 621 ms (started: 2022-05-21 16:15:46 +00:00)\n"]}],"source":["class TrainHJBMertonWithDGM():\n","    \n","    def __init__(self , net , equation , BATCH_SIZE , debug = False):\n","        self.history_mean_hooks = [] \n","        self.history_surfaces_hooks = None       \n","        self.history_tl = []\n","        self.history_internal = []\n","        self.history_terminal = []\n","        self.history_initial = []              \n","        self.history_nonzero = []\n","        self.BATCH_SIZE = BATCH_SIZE\n","        self.net = net\n","        self.model = equation        \n","        self.debug = debug  \n","        self.hook_interval = 20      \n","        if self.debug == True:\n","            self.hooks = {}            \n","            self.get_all_layers(self.net)\n","\n","        self.optimizer_used = optim.Adam\n","\n","        self.use_early_stop = False\n","        self.early_stop_patience = 10\n","        self.early_stop_delta = 0.0        \n","        self.best_loss = np.Inf\n","        self.monitored_loss_type = \"Train_L2\"\n","        self.early_stop_counter = 0\n","\n","        self.stop_epoch = 0\n","\n","        self.validation_sample = None\n","        self.validation_losses = None\n","        self.train_losses = None        \n","        \n","\n","    def train(self , epoch , lr, eqLossFn = 'calculateLoss', sample_method_X = \"U\", key_loss_func = torch.square, huber_delta = 0.5):\n","        \n","        if self.validation_sample is not None:\n","          self.validation_losses = np.ones((epoch, 3*4 ), dtype='float32') * np.nan\n","        self.train_losses = np.ones((epoch, 3*2 + 1 ), dtype='float32') * np.nan\n","\n","        optimizer = self.optimizer_used(self.net.parameters(), lr)\n","        \n","        loss_avg = 0.0\n","        loss_calc_method = None\n","        try:\n","            loss_calc_method = getattr(self.model, eqLossFn)\n","        except AttributeError:\n","            raise NotImplementedError(\"Class `{}` does not implement `{}`\".format(self.model.__class__.__name__, eqLossFn))\n","        \n","        for e in range(epoch):\n","\n","            optimizer.zero_grad()\n","            \n","            # pdb.set_trace()\n","            sample_batch = self.model.sample(sample_method_X = sample_method_X, size=self.BATCH_SIZE)\n","\n","            losses_L2, losses_ABS = loss_calc_method( sample_batch, loss_transforms = [ key_loss_func, torch.abs ], keep_batch = False )\n","            # pdb.set_trace()\n","            loss , internal , terminal , losses_equalWeightedByType = losses_L2\n","            loss_abs , internal_abs , terminal_abs , losses_equalWeightedByType_abs = losses_ABS\n","            max_loss_L2 = torch.max(torch.tensor([internal , terminal ]))\n","\n","            self.train_losses[e,:] = [ to_cpu_detach(loss) , to_cpu_detach(internal) , to_cpu_detach(terminal) , \n","                                       to_cpu_detach(loss_abs) , to_cpu_detach(internal_abs) , to_cpu_detach(terminal_abs), \n","                                       to_cpu_detach(losses_equalWeightedByType_abs)]\n","\n","            if self.debug == True and (self.validation_sample is not None):\n","              losses_L2_validation, losses_ABS_validation, losses_Huber_valiation = loss_calc_method( self.validation_sample, \n","                                                                                                     loss_transforms = [ torch.square, torch.abs, partial(huber_loss_zero_target, delta=huber_delta) ], \n","                                                                                                     keep_batch = False )\n","              validation_loss_list = [*to_cpu_detach(losses_L2_validation),\n","                                      *to_cpu_detach(losses_ABS_validation),\n","                                      *to_cpu_detach(losses_Huber_valiation)]\n","              # validation_loss_list = validation_loss_list.pop(5) # the L2 loss is duplicated at index 1\n","              self.validation_losses[e,:] = validation_loss_list\n","              # pdb.set_trace()\n","              # print(f\"Epoch {e} - Pi Pred (0.47) {self.model.pi_net(self.validation_sample[0]).item()}\")\n","\n","            \n","            if self.use_early_stop:\n","              loss_to_check = losses_equalWeightedByType\n","              if self.monitored_loss_type == \"Train_L2\":\n","                pass\n","              elif self.monitored_loss_type == \"Train_L1\":             \n","                loss_to_check = losses_equalWeightedByType_abs\n","              elif self.monitored_loss_type == \"Train_MAXL2\":             \n","                loss_to_check = max_loss_L2\n","\n","              if loss_to_check < (self.best_loss-self.early_stop_delta):\n","                self.best_loss = loss_to_check\n","                self.early_stop_counter = 0\n","                # print(f\"New Loss to beat for early Stop at epoch {e}, original loss: {losses_equalWeightedByType} with patience {self.early_stop_patience}\")\n","              else:\n","                self.early_stop_counter += 1\n","              if self.early_stop_counter>=self.early_stop_patience:\n","                print(f\"Early Stop at epoch {e}, {self.monitored_loss_type}: {loss_to_check} with patience {self.early_stop_patience}\")\n","                break\n","            \n","            loss_avg = loss_avg + float(loss.item())\n","            loss.backward()\n","\n","            optimizer.step()\n","            if (e % self.hook_interval == (self.hook_interval-1)) or e == 0:\n","\n","                loss_avg = loss_avg/self.hook_interval\n","                # pdb.set_trace()\n","                # print(f\"Epoch {e} - lr {lr} - Pi Weight {self.model.pi_net.fc_output.weight[0][0]} - key loss: {round(loss.item(),5)} - eqWeighted loss: {round(losses_equalWeightedByType.item(),5)} - L1 loss {round(loss_abs.item(),5)} - Max Loss {round(max_loss_L2.item(),5)}\")\n","                # print(f\"Epoch {e} - lr {lr} - Pi Weight {self.model.pi_net.fc_output.weight[0][0]} - key loss: {round(loss.item(),5)} - eqWeighted loss: {round(losses_equalWeightedByType.item(),5)} - L1 loss {round(loss_abs.item(),5)} - Max Loss {round(max_loss_L2.item(),5)}\")\n","                print(f\"Epoch {e} - lr {lr} - key loss: {round(loss.item(),5)} - eqWeighted loss: {round(losses_equalWeightedByType.item(),5)} - L1 loss {round(loss_abs.item(),5)} - Max Loss {round(max_loss_L2.item(),5)}\")\n","                # loss_avg = 0\n","                ## report detailed loss ## ## puting inside no grad??? for memory optimization!\n","                # tl , dl , il , bl, _ = self.model.calculateLoss( 2**6 )  # note that this is the standard loss!!\n","\n","                self.history_tl.append( loss_avg )\n","                self.history_internal.append( internal )\n","                self.history_terminal.append( terminal )\n","                \n","                if self.debug == True and (self.validation_sample is not None):\n","                    mean = []\n","                    for l in self.hooks:\n","                        mean.append(torch.mean( self.hooks[l] ).item())\n","                    self.history_mean_hooks.append( mean )\n","                    xinternal, xterminal = self.validation_sample\n","                    xinternal_before, xinternal_expanded = attach_pi_used(xinternal, self.model.pi_net, requires_grad=False)\n","                    xterminal_before, xterminal_expanded = attach_pi_used(xterminal, self.model.pi_net, requires_grad=False)\n","\n","                    xinternal_res = self.model.u_net(xinternal_expanded).detach()\n","                    xterminal_res = self.model.u_net(xterminal_expanded).detach()\n","\n","                    # pdb.set_trace()\n","                    df_internal = self.create_result_df(e, xinternal, xinternal_res, \"INTERNAL\")\n","                    df_terminal = self.create_result_df(e, xterminal, xterminal_res, \"TERMINAL\")\n","                    \n","                    if self.history_surfaces_hooks is None:\n","                      self.history_surfaces_hooks = pd.concat([df_internal, df_terminal],axis=0)\n","                    else:\n","                      self.history_surfaces_hooks = pd.concat([self.history_surfaces_hooks,pd.concat([df_internal, df_terminal],axis=0) ], axis=0)\n","\n","        self.stop_epoch = e\n","\n","    def hook_fn(self, m, i, o):\n","              self.hooks[m] = o.detach()\n","            \n","    def get_all_layers(self, net):\n","      for name, layer in net._modules.items():\n","          if isinstance(layer, nn.ModuleList):\n","              for n , l in layer.named_children():\n","                l.register_forward_hook(self.hook_fn)\n","          else:\n","              # it's a non sequential. Register a hook\n","              layer.register_forward_hook(self.hook_fn)\n","    \n","    def create_result_df(self, e, xsample, xsample_res, sample_type):\n","      df_xsample = pd.DataFrame(xsample.cpu().numpy(), columns = [\"Time\", \"S1\", \"Mu\", \"R\", \"Sigma\"])\n","      df_xsample[\"Epoch\"] = e\n","      df_xsample[\"Sample\"] = sample_type\n","      df_xsample[\"Result\"] = xsample_res.cpu().numpy()\n","      return df_xsample\n","\n","    def train_stratified(self , epoch , lr, \n","                         eqLossFn = 'calculateLoss', \n","                         sample_method_X = \"U\", \n","                         key_loss_func = torch.square, \n","                         huber_delta = 0.5\n","                         ):\n","        \n","        self.validation_losses = np.ones((epoch, 3*3 ), dtype='float32') * np.nan\n","        self.train_losses = np.ones((epoch, 3*2 + 1), dtype='float32') * np.nan\n","        optimizer = self.optimizer_used(self.net.parameters(), lr)\n","        # optimizer = optim.SGD(self.net.parameters(), lr)\n","        loss_avg = 0.0\n","        loss_calc_method = None\n","        try:\n","            loss_calc_method = getattr(self.model, eqLossFn)\n","        except AttributeError:\n","            raise NotImplementedError(\"Class `{}` does not implement `{}`\".format(self.model.__class__.__name__, eqLossFn))\n","        \n","        for e in range(epoch):\n","            optimizer.zero_grad()\n","            # pdb.set_trace()\n","            internal_xts_bts, terminal_xts_bts = self.model.sample_stratified(sample_method_X = sample_method_X, size=self.BATCH_SIZE)\n","            validation_stratum_losses = None #np.array([])#.reshape(1,self.validation_losses.shape[1])\n","            training_stratum_losses = None # np.array([])#.reshape(1,self.train_losses.shape[1])  \n","            training_value_to_optimize = torch.tensor(0.0,requires_grad=True)           \n","            \n","            # pdb.set_trace()\n","            for stratum_count in range(len(internal_xts_bts)):              \n","              sample_batch = (internal_xts_bts[stratum_count], \n","                              terminal_xts_bts[stratum_count])  \n","\n","              # pdb.set_trace()\n","              stratum_losses_L2, stratum_losses_ABS = loss_calc_method(sample_batch, \n","                                                                       loss_transforms = [ key_loss_func, torch.abs ], \n","                                                                       keep_batch = False )\n","              # if np.isnan(stratum_losses_L2[0].detach().cpu().item()):\n","              #   pdb.set_trace()\n","              #   pass\n","            \n","              if training_stratum_losses is not None:\n","                training_stratum_losses = torch.vstack([training_stratum_losses, torch.tensor([*to_cpu_detach(stratum_losses_L2), *to_cpu_detach(stratum_losses_ABS)]) ]) \n","              else:\n","                training_stratum_losses = torch.tensor([*stratum_losses_L2, *stratum_losses_ABS], requires_grad=False) \n","\n","              # pdb.set_trace()  \n","              training_value_to_optimize = training_value_to_optimize + stratum_losses_L2[0]\n","\n","            # pdb.set_trace()              \n","            training_loss_for_epoch = torch.sum(training_stratum_losses,0)\n","            loss = training_value_to_optimize\n","\n","            loss_optimized , internal , terminal, losses_equalWeightedByType, \\\n","            loss_abs , internal_abs , terminal_abs ,losses_equalWeightedByType_abs = training_loss_for_epoch            \n","            max_loss_L2 = torch.max(torch.tensor([internal , terminal ]))\n","\n","            self.train_losses[e,:] = training_loss_for_epoch.detach().numpy()\n","\n","            if self.debug == True and (self.validation_sample is not None):\n","              losses_L2_validation, losses_ABS_validation, losses_Huber_valiation = \\\n","                loss_calc_method( self.validation_sample, \n","                                  loss_transforms = [ torch.square, torch.abs, partial(huber_loss_zero_target, delta=huber_delta) ], \n","                                  keep_batch = False )\n","              validation_loss = [*to_cpu_detach(losses_L2_validation),\n","                                              *to_cpu_detach(losses_ABS_validation),\n","                                              *to_cpu_detach(losses_Huber_valiation)]\n","              # validation_loss = validation_loss.pop(5) # the L2 loss is duplicated at index 1                \n","              self.validation_losses[e,:] = validation_loss\n","\n","            if self.use_early_stop:\n","              loss_to_check = losses_equalWeightedByType\n","              if self.monitored_loss_type == \"Train_L2\":\n","                pass\n","              elif self.monitored_loss_type == \"Train_L1\":             \n","                loss_to_check = losses_equalWeightedByType_abs\n","              elif self.monitored_loss_type == \"Train_MAXL2\":             \n","                loss_to_check = max_loss_L2\n","              if loss_to_check < (self.best_loss-self.early_stop_delta):\n","                self.best_loss = loss_to_check\n","                self.early_stop_counter = 0\n","                # print(f\"New Loss to beat for early Stop at epoch {e}, original loss: {losses_equalWeightedByType} with patience {self.early_stop_patience}\")\n","              else:\n","                self.early_stop_counter += 1\n","              if self.early_stop_counter>=self.early_stop_patience:\n","                print(f\"Early Stop at epoch {e}, {self.monitored_loss_type}: {loss_to_check} with patience {self.early_stop_patience}\")\n","                break\n","\n","            loss_avg = loss_avg + float(loss.item())\n","            loss.backward()\n","\n","            optimizer.step()\n","            if (e % self.hook_interval == (self.hook_interval-1)) or e == 0:\n","                loss_avg = loss_avg/self.hook_interval\n","                print(\"Epoch {} - lr {} -  key loss: {} - eqWeighted loss: {} - L1 loss {} - Max Loss {}\".format(e , lr , loss, losses_equalWeightedByType, loss_abs, max_loss_L2 ))\n","                # loss_avg = 0\n","                ## report detailed loss ## ## puting inside no grad??? for memory optimization!\n","                # tl , dl , il , bl, _ = self.model.calculateLoss( 2**6 )  # note that this is the standard loss!!\n","                self.history_tl.append( loss_avg )\n","                self.history_internal.append( internal )\n","                self.history_terminal.append( terminal )\n","                if self.debug == True and (self.validation_sample is not None):\n","                    mean = []\n","                    for l in self.hooks:\n","                        mean.append(torch.mean( self.hooks[l] ).item())\n","                    self.history_mean_hooks.append( mean )\n","                    xinternal, xterminal, xinitial, xnonzero = self.validation_sample\n","                    xinternal_res = self.model.net(xinternal).detach()\n","                    xterminal_res = self.model.net(xterminal).detach()\n","\n","                    # pdb.set_trace()\n","                    df_internal = self.create_result_df(e, xinternal, xinternal_res, \"INTERNAL\")\n","                    df_terminal = self.create_result_df(e, xterminal, xterminal_res, \"TERMINAL\")\n","                    \n","                    if self.history_surfaces_hooks is None:\n","                      self.history_surfaces_hooks = pd.concat([df_internal, df_terminal],axis=0)\n","                    else:\n","                      self.history_surfaces_hooks = pd.concat([self.history_surfaces_hooks,pd.concat([df_internal, df_terminal],axis=0) ], axis=0)\n","\n","        self.stop_epoch = e\n"]},{"cell_type":"markdown","source":["### Test Case"],"metadata":{"id":"oy05I1QFh7EM"}},{"cell_type":"markdown","source":["#### Test Case NO Stratification"],"metadata":{"id":"U7zqglm1ewTL"}},{"cell_type":"code","source":["mequation = MertonEquation(MertonUtilityNet( NL = 1 , NN = 3 ), MertonPiNet( NL = 1 , NN = 3 ), 1, 10000.0)\n","# val_sample_to_use = tuple([ x.cpu().detach() for x in mequation.sample(sample_method_X=\"U\", size=1) ] )\n","val_sample_to_use = mequation.sample(sample_method_X=\"U\", size=1) \n","# # gamma = 1.0 # time = 0.0 # mu = 0.05 # r = 0.02 # sigma = 0.25   \n","val_sample_to_use[0][0,0] = 0.0\n","val_sample_to_use[0][0,2] = 0.05\n","val_sample_to_use[0][0,3] = 0.02\n","val_sample_to_use[0][0,4] = 0.25"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-yLM2WbUoymO","executionInfo":{"status":"ok","timestamp":1653149763337,"user_tz":-60,"elapsed":13386,"user":{"displayName":"Hans Roggeman","userId":"10574434403170915342"}},"outputId":"f4d69d7c-4ea2-4f3d-c65f-87b4946c4803"},"execution_count":38,"outputs":[{"output_type":"stream","name":"stdout","text":["time: 13.1 s (started: 2022-05-21 16:15:49 +00:00)\n"]}]},{"cell_type":"code","source":["# mequation.sample(sample_method_X=\"U\", size=1)"],"metadata":{"id":"ul_C1i9oos6m"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["seed = 123\n","torch.manual_seed(seed)\n","torch.cuda.manual_seed(seed)\n","torch.cuda.manual_seed_all(seed)\n","np.random.seed(seed)\n","random.seed(seed)\n","torch.backends.cudnn.benchmark = False\n","torch.backends.cudnn.deterministic = True\n","\n","# u_net, pi_net, pi_net_epoch, pi_net_lr\n","eqLossFn= 'calculateLoss'\n","sample_method= \"U\"\n","lr = 0.00001\n","lr_for_pi = 0.00001\n","max_pi_epochs = 1 # has to be low!!!\n","\n","u_net = MertonUtilityNet( NL = 5 , NN = 100 )\n","u_net.to(torch.device(\"cuda:0\")) \n","pi_net = MertonPiNet( NL = 6 , NN = 100 )\n","pi_net.to(torch.device(\"cuda:0\")) \n","## providing sampler with net so it can accept/reject based on net and other criterions\n","mequation = MertonEquation(u_net, pi_net, max_pi_epochs, lr_for_pi)\n","# mequation.FORCE_MU = 0.05\n","# mequation.FORCE_R = 0.02\n","# mequation.FORCE_SIGMA = 0.25\n","trainMertonAlloc = TrainHJBMertonWithDGM(u_net, mequation, BATCH_SIZE = 2**4 , debug = True)\n","trainMertonAlloc.hook_interval = 1000\n","# trainMertonAlloc.use_early_stop = True\n","# trainMertonAlloc.early_stop_patience = 1000\n","# trainMertonAlloc.validation_sample = val_sample_to_use\n","trainMertonAlloc.train(epoch = 40000 , lr = lr, eqLossFn = eqLossFn , sample_method_X = sample_method)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1653209012477,"user_tz":-60,"elapsed":273029,"user":{"displayName":"Hans Roggeman","userId":"10574434403170915342"}},"outputId":"e149b269-97fa-46ca-f1d2-31a37b6dbac6","id":"IUNDoPJRe6dL"},"execution_count":39,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 0 - lr 1e-05 - key loss: 0.75639 - eqWeighted loss: 0.75639 - L1 loss 0.62877 - Max Loss 0.75584\n","Epoch 999 - lr 1e-05 - key loss: 0.8136 - eqWeighted loss: 0.8136 - L1 loss 0.63786 - Max Loss 0.77269\n","Epoch 1999 - lr 1e-05 - key loss: 1.43362 - eqWeighted loss: 1.43362 - L1 loss 0.77919 - Max Loss 1.39169\n","Epoch 2999 - lr 1e-05 - key loss: 0.58593 - eqWeighted loss: 0.58593 - L1 loss 0.34036 - Max Loss 0.58533\n","Epoch 3999 - lr 1e-05 - key loss: 0.22854 - eqWeighted loss: 0.22854 - L1 loss 0.31654 - Max Loss 0.22189\n","Epoch 4999 - lr 1e-05 - key loss: 52.95992 - eqWeighted loss: 52.95992 - L1 loss 3.89326 - Max Loss 52.95525\n","Epoch 5999 - lr 1e-05 - key loss: 0.36115 - eqWeighted loss: 0.36115 - L1 loss 0.35635 - Max Loss 0.35775\n","Epoch 6999 - lr 1e-05 - key loss: 0.17927 - eqWeighted loss: 0.17927 - L1 loss 0.26141 - Max Loss 0.17682\n","Epoch 7999 - lr 1e-05 - key loss: 631.42969 - eqWeighted loss: 631.42969 - L1 loss 14.20627 - Max Loss 631.42859\n","Epoch 8999 - lr 1e-05 - key loss: 1606.25269 - eqWeighted loss: 1606.25269 - L1 loss 14.62698 - Max Loss 1606.25134\n","Epoch 9999 - lr 1e-05 - key loss: 2.95861 - eqWeighted loss: 2.95861 - L1 loss 0.80352 - Max Loss 2.95759\n","Epoch 10999 - lr 1e-05 - key loss: 0.47238 - eqWeighted loss: 0.47238 - L1 loss 0.36857 - Max Loss 0.47117\n","Epoch 11999 - lr 1e-05 - key loss: 1.2455 - eqWeighted loss: 1.2455 - L1 loss 0.57831 - Max Loss 1.24483\n","Epoch 12999 - lr 1e-05 - key loss: 2.45159 - eqWeighted loss: 2.45159 - L1 loss 0.91342 - Max Loss 2.45105\n","Epoch 13999 - lr 1e-05 - key loss: 14.39964 - eqWeighted loss: 14.39964 - L1 loss 2.07361 - Max Loss 14.3992\n","Epoch 14999 - lr 1e-05 - key loss: 4.06462 - eqWeighted loss: 4.06462 - L1 loss 1.15217 - Max Loss 4.06415\n","Epoch 15999 - lr 1e-05 - key loss: 0.92897 - eqWeighted loss: 0.92897 - L1 loss 0.52808 - Max Loss 0.92844\n","Epoch 16999 - lr 1e-05 - key loss: 9.83489 - eqWeighted loss: 9.83489 - L1 loss 1.81681 - Max Loss 9.83455\n","Epoch 17999 - lr 1e-05 - key loss: 60.84412 - eqWeighted loss: 60.84412 - L1 loss 4.05498 - Max Loss 60.84381\n","Epoch 18999 - lr 1e-05 - key loss: 1.00541 - eqWeighted loss: 1.00541 - L1 loss 0.48992 - Max Loss 1.00506\n","Epoch 19999 - lr 1e-05 - key loss: 27.61306 - eqWeighted loss: 27.61306 - L1 loss 2.75214 - Max Loss 27.61264\n","Epoch 20999 - lr 1e-05 - key loss: 2.30397 - eqWeighted loss: 2.30397 - L1 loss 0.76581 - Max Loss 2.30372\n","Epoch 21999 - lr 1e-05 - key loss: 2.16717 - eqWeighted loss: 2.16717 - L1 loss 0.82566 - Max Loss 2.16678\n","Epoch 22999 - lr 1e-05 - key loss: 2404.66968 - eqWeighted loss: 2404.66968 - L1 loss 25.17478 - Max Loss 2404.66919\n","Epoch 23999 - lr 1e-05 - key loss: 0.92034 - eqWeighted loss: 0.92034 - L1 loss 0.55983 - Max Loss 0.91997\n","Epoch 24999 - lr 1e-05 - key loss: 4118.32764 - eqWeighted loss: 4118.32764 - L1 loss 27.75603 - Max Loss 4118.32715\n","Epoch 25999 - lr 1e-05 - key loss: 640.84406 - eqWeighted loss: 640.84406 - L1 loss 10.54607 - Max Loss 640.84375\n","Epoch 26999 - lr 1e-05 - key loss: 0.58071 - eqWeighted loss: 0.58071 - L1 loss 0.40528 - Max Loss 0.58034\n","Epoch 27999 - lr 1e-05 - key loss: 181.39543 - eqWeighted loss: 181.39543 - L1 loss 6.14678 - Max Loss 181.39517\n","Epoch 28999 - lr 1e-05 - key loss: 2.07162 - eqWeighted loss: 2.07162 - L1 loss 0.84405 - Max Loss 2.07113\n","Epoch 29999 - lr 1e-05 - key loss: 2.55019 - eqWeighted loss: 2.55019 - L1 loss 0.90649 - Max Loss 2.54989\n","Epoch 30999 - lr 1e-05 - key loss: 2.09179 - eqWeighted loss: 2.09179 - L1 loss 0.70869 - Max Loss 2.09146\n","Epoch 31999 - lr 1e-05 - key loss: 5.08903 - eqWeighted loss: 5.08903 - L1 loss 0.94315 - Max Loss 5.08863\n","Epoch 32999 - lr 1e-05 - key loss: 287.47116 - eqWeighted loss: 287.47116 - L1 loss 6.69501 - Max Loss 287.47089\n","Epoch 33999 - lr 1e-05 - key loss: 12.01053 - eqWeighted loss: 12.01053 - L1 loss 1.44842 - Max Loss 12.01013\n","Epoch 34999 - lr 1e-05 - key loss: 9.72247 - eqWeighted loss: 9.72247 - L1 loss 1.33889 - Max Loss 9.72211\n","Epoch 35999 - lr 1e-05 - key loss: 1.36064 - eqWeighted loss: 1.36064 - L1 loss 0.57884 - Max Loss 1.3603\n","Epoch 36999 - lr 1e-05 - key loss: 12.66013 - eqWeighted loss: 12.66013 - L1 loss 1.746 - Max Loss 12.65978\n","Epoch 37999 - lr 1e-05 - key loss: 4.96938 - eqWeighted loss: 4.96938 - L1 loss 1.23957 - Max Loss 4.96891\n","Epoch 38999 - lr 1e-05 - key loss: 1.19485 - eqWeighted loss: 1.19485 - L1 loss 0.57044 - Max Loss 1.19445\n","Epoch 39999 - lr 1e-05 - key loss: 0.28074 - eqWeighted loss: 0.28074 - L1 loss 0.26602 - Max Loss 0.28031\n","time: 16h 26min 30s (started: 2022-05-21 16:17:01 +00:00)\n"]}]},{"cell_type":"code","source":["save_model_train(lr, u_net,  eqLossFn, sample_method, trainMertonAlloc, \"mertonAlloc\", mequation )"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":190},"id":"xh190QZvclvl","executionInfo":{"status":"error","timestamp":1653209533286,"user_tz":-60,"elapsed":371,"user":{"displayName":"Hans Roggeman","userId":"10574434403170915342"}},"outputId":"12ea09f7-fa46-4427-8f00-cb1531767481"},"execution_count":41,"outputs":[{"output_type":"error","ename":"TypeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-41-d4ba29614e59>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msave_model_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mu_net\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0meqLossFn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_method\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainMertonAlloc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"mertonAlloc\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmequation\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mTypeError\u001b[0m: save_model_train() takes 6 positional arguments but 7 were given"]},{"output_type":"stream","name":"stdout","text":["time: 21.2 ms (started: 2022-05-22 08:52:12 +00:00)\n"]}]},{"cell_type":"code","source":["# check control for closed form:\n","# PI(x,t) = [(mu-r)/(gamma*sigma^2)]*exp(-r*(T-t))\n","# ((mu-r)/(gamma*(sigma**2)))*np.exp(-r*(1.0-time))\n","# gamma = 1.0 # time = 0.0 # mu = 0.05 # r = 0.02 # sigma = 0.25   # PI\n","\n","gamma = 1.0\n","internal_sample, terminal_sample = mequation.sample(size=100, to_cpu=False)\n","mask = (internal_sample[:,0] > 0.1) & (internal_sample[:,4] > 0.1)\n","internal_sample = internal_sample[mask.reshape(-1),:]\n","# time, wealth, mu, r, sigma\n","time = internal_sample[:,0].cpu().detach()\n","wealth = internal_sample[:,1].cpu().detach()\n","mu = internal_sample[:,2].cpu().detach()\n","r = internal_sample[:,3].cpu().detach()\n","sigma = internal_sample[:,4].cpu().detach()\n","\n","# mequation.pi_net(internal_sample)[:,0]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":245},"id":"u35g5sAPbsG_","executionInfo":{"status":"error","timestamp":1653213312948,"user_tz":-60,"elapsed":401,"user":{"displayName":"Hans Roggeman","userId":"10574434403170915342"}},"outputId":"5513e9f9-28de-4925-ff3c-755dbac3774a"},"execution_count":1,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-46c47aa8b620>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mgamma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0minternal_sample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mterminal_sample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmequation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mto_cpu\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minternal_sample\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minternal_sample\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0minternal_sample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minternal_sample\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'mequation' is not defined"]}]},{"cell_type":"code","source":["# closed form value function\n","def Htx(x):\n","  return -torch.exp(-x[:,1].reshape(-1,1)*1.0*torch.exp(x[:,3].reshape(-1,1)*(1.0-x[:,0].reshape(-1,1))) - \n","                    0.5*(1.0-x[:,0].reshape(-1,1))*((x[:,2].reshape(-1,1)-x[:,3].reshape(-1,1))/(x[:,4].reshape(-1,1)))**2  )"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"O-NmMG33xGBu","executionInfo":{"status":"ok","timestamp":1653209539184,"user_tz":-60,"elapsed":276,"user":{"displayName":"Hans Roggeman","userId":"10574434403170915342"}},"outputId":"69f57069-1cdc-48df-9d94-7d12767463bc"},"execution_count":43,"outputs":[{"output_type":"stream","name":"stdout","text":["time: 2.22 ms (started: 2022-05-22 08:52:18 +00:00)\n"]}]},{"cell_type":"code","source":["# plot the fitted value function vs the closed form (ideally straight line...)\n","u_internal_sample = torch.cat((internal_sample, mequation.pi_net(internal_sample).reshape(-1,1)), dim=1)\n","u_net_results = u_net(u_internal_sample).detach().cpu().numpy().reshape(-1).tolist()\n","htx_results = Htx(u_internal_sample).cpu().detach().numpy().reshape(-1).tolist()\n","dataf2 = pd.DataFrame( { 'u_net': u_net_results, 'closed_form': htx_results } )\n","ggplot(dataf2, aes(x='u_net', y='closed_form')) + geom_point()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":466},"id":"Woj8BoAK5OLC","executionInfo":{"status":"ok","timestamp":1653209541765,"user_tz":-60,"elapsed":1404,"user":{"displayName":"Hans Roggeman","userId":"10574434403170915342"}},"outputId":"dac48463-b874-40f6-f2e2-06b84c9fa25c"},"execution_count":44,"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 640x480 with 1 Axes>"],"image/png":"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\n"},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":["<ggplot: (8743065076913)>"]},"metadata":{},"execution_count":44},{"output_type":"stream","name":"stdout","text":["time: 1.21 s (started: 2022-05-22 08:52:20 +00:00)\n"]}]},{"cell_type":"code","source":["# plot the control function vs the closed form (ideally straight line...)\n","dataf = pd.DataFrame( { 'pi_net': mequation.pi_net(internal_sample).cpu().detach().numpy().reshape(-1).tolist(), \n","                       'closed_form': (((mu-r)/(gamma*(sigma**2)))*np.exp(-r*(1.0-time))).numpy().tolist() } )\n","ggplot(dataf, aes(x='pi_net', y='closed_form')) + geom_point()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":466},"id":"GHfTC6GljYnd","executionInfo":{"status":"ok","timestamp":1653209547373,"user_tz":-60,"elapsed":1752,"user":{"displayName":"Hans Roggeman","userId":"10574434403170915342"}},"outputId":"f3800f9b-2385-46d7-97b2-75824e538579"},"execution_count":45,"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 640x480 with 1 Axes>"],"image/png":"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\n"},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":["<ggplot: (8743064973353)>"]},"metadata":{},"execution_count":45},{"output_type":"stream","name":"stdout","text":["time: 1.34 s (started: 2022-05-22 08:52:25 +00:00)\n"]}]},{"cell_type":"markdown","source":["### Extracting just the PiNet! And testing that"],"metadata":{"id":"I9z4wQvAP4GW"}},{"cell_type":"code","source":["gamma = 1.0\n","internal_sample, terminal_sample = mequation.sample(size=5, to_cpu=False)\n","mask = (internal_sample[:,0] > 0.1) & (internal_sample[:,4] > 0.1)\n","internal_sample = internal_sample[mask.reshape(-1),:]\n","# time, wealth, mu, r, sigma\n","time = internal_sample[:,0].cpu().detach()\n","wealth = internal_sample[:,1].cpu().detach()\n","mu = internal_sample[:,2].cpu().detach()\n","r = internal_sample[:,3].cpu().detach()\n","sigma = internal_sample[:,4].cpu().detach()\n","\n","\n","# closed form value function\n","def Htx(x):\n","  return -torch.exp(-x[:,1].reshape(-1,1)*1.0*torch.exp(x[:,3].reshape(-1,1)*(1.0-x[:,0].reshape(-1,1))) - \n","                    0.5*(1.0-x[:,0].reshape(-1,1))*((x[:,2].reshape(-1,1)-x[:,3].reshape(-1,1))/(x[:,4].reshape(-1,1)))**2  )\n","  \n","\n","# plot the fitted value function vs the closed form (ideally straight line...)\n","u_internal_sample = torch.tensor(torch.cat((internal_sample, mequation.pi_net(internal_sample).reshape(-1,1)), dim=1),requires_grad=True)\n","# u_net_results = u_net(u_internal_sample).detach().cpu().numpy().reshape(-1).tolist()\n","htx_results = Htx(u_internal_sample)\n","htx_results.backward()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":412},"id":"U-X-Q4BjXy1F","executionInfo":{"status":"error","timestamp":1652981790809,"user_tz":-60,"elapsed":423,"user":{"displayName":"Hans Roggeman","userId":"10574434403170915342"}},"outputId":"1480cfaa-28c4-46c3-d3d3-c0560c594f22"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"]},{"output_type":"error","ename":"RuntimeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-131-6869a04ffc41>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;31m# u_net_results = u_net(u_internal_sample).detach().cpu().numpy().reshape(-1).tolist()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0mhtx_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mHtx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mu_internal_sample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0mhtx_results\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    361\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 363\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m     \u001b[0mgrad_tensors_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_tensor_or_tensors_to_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m     \u001b[0mgrad_tensors_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_make_grads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_grads_batched\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mretain_graph\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36m_make_grads\u001b[0;34m(outputs, grads, is_grads_batched)\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequires_grad\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"grad can be implicitly created only for scalar outputs\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m                 \u001b[0mnew_grads\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemory_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreserve_format\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: grad can be implicitly created only for scalar outputs"]},{"output_type":"stream","name":"stdout","text":["time: 49.1 ms (started: 2022-05-19 17:36:30 +00:00)\n"]}]},{"cell_type":"code","source":["print(u_internal_sample.grad)\n","# htx_results.grad_fn(htx_results)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4HKXN7pCYE-Z","executionInfo":{"status":"ok","timestamp":1652981824062,"user_tz":-60,"elapsed":409,"user":{"displayName":"Hans Roggeman","userId":"10574434403170915342"}},"outputId":"55ce58e0-2f21-4674-f46f-124ad894aa23"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["None\n"]},{"output_type":"execute_result","data":{"text/plain":["tensor([[0.4881],\n","        [0.7296],\n","        [0.3478],\n","        [0.8353]], device='cuda:0', grad_fn=<NegBackward0>)"]},"metadata":{},"execution_count":133},{"output_type":"stream","name":"stdout","text":["time: 6.52 ms (started: 2022-05-19 17:37:03 +00:00)\n"]}]},{"cell_type":"code","source":["i_sample = torch.tensor(torch.cat((torch.tensor([[2.],[3.]]), torch.tensor([[4.],[4.]])), dim=1),requires_grad=True)\n","def test_fn(x):\n","  return torch.einsum(\"i->\", x[:,1]**2 + x[:,0] )\n","test_res = test_fn(i_sample)\n","test_res.backward()\n","i_sample.grad\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6VCHAg2MZUko","executionInfo":{"status":"ok","timestamp":1652982450893,"user_tz":-60,"elapsed":937,"user":{"displayName":"Hans Roggeman","userId":"10574434403170915342"}},"outputId":"fa3d9d2e-9cfe-45b7-9b9e-ce64ca90ffc3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  \"\"\"Entry point for launching an IPython kernel.\n"]},{"output_type":"execute_result","data":{"text/plain":["tensor([[1., 8.],\n","        [1., 8.]])"]},"metadata":{},"execution_count":141},{"output_type":"stream","name":"stdout","text":["time: 7.68 ms (started: 2022-05-19 17:47:29 +00:00)\n"]}]},{"cell_type":"code","source":["i_sample"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YndLg5EhZowC","executionInfo":{"status":"ok","timestamp":1652981928626,"user_tz":-60,"elapsed":397,"user":{"displayName":"Hans Roggeman","userId":"10574434403170915342"}},"outputId":"72ef13e5-df3b-4d7f-b971-0e086dfd77b6"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[2., 4.],\n","        [3., 4.]], requires_grad=True)"]},"metadata":{},"execution_count":135},{"output_type":"stream","name":"stdout","text":["time: 4.39 ms (started: 2022-05-19 17:38:48 +00:00)\n"]}]},{"cell_type":"markdown","metadata":{"id":"0JDjo9HZSq-y"},"source":["#### PiEquationWithFixedUtx"]},{"cell_type":"code","source":["class PiEquationWithFixedUtx():\n","\n","    def __init__(self , pi_net, u_fn):\n","        self.pi_net = pi_net\n","        self.wgamma = 0.0001\n","        self.u_fn = u_fn\n","\n","    def criterion(self, x_internal):\n","\n","\n","\n","      #  time, wealth, mu, r, sigma\n","      pi_net_preds = self.pi_net(x_internal)\n","      # pi_net_preds = pi_net_preds[:,0].reshape(-1,1)\n","      pi_net_preds = pi_net_preds.reshape(-1,1)\n","\n","      dpi = torch.autograd.grad( pi_net_preds, \n","                                x_internal, \n","                                grad_outputs=torch.ones_like(pi_net_preds) ,\n","                                create_graph=True,\n","                                retain_graph=True)\n","      dpi_dt = dpi[0][:,0].reshape(-1,1)\n","      dpi_dx = dpi[0][:,1].reshape(-1,1)\n","\n","      d2pi_dx2 = torch.autograd.grad( dpi_dx, \n","                                      x_internal , \n","                                      grad_outputs=torch.ones_like(dpi_dx) ,\n","                                      create_graph = True,\n","                                      retain_graph=True)[0][:,1].reshape(-1,1)\n","      intC = None\n","      # pdb.set_trace()\n","      if len(x_internal) == 0:\n","        intC_loss = torch.tensor(0).cuda().float()  \n","      else:\n","        # pdb.set_trace()\n","        intC_loss = -(pi_net_preds*(x_internal[:,2].reshape(-1,1)-x_internal[:,3].reshape(-1,1)) + x_internal[:,3].reshape(-1,1)*x_internal[:,1].reshape(-1,1))*self.du_dx - \\\n","                                    0.5*(x_internal[:,4].reshape(-1,1)**2)*(pi_net_preds**2)*self.d2u_dx2\n","\n","        # print(f\"Pi Loss {torch.mean(intC_loss).item()} {x_internal.shape[0]} {torch.mean(self.du_dx)}\")          \n","\n","        # intC_loss = (pi_net_preds*(x_internal[:,2].reshape(-1,1)-x_internal[:,3].reshape(-1,1)) + x_internal[:,3].reshape(-1,1)*x_internal[:,1].reshape(-1,1))*self.du_dx + \\\n","        #                             0.5*(x_internal[:,4].reshape(-1,1)**2)*(pi_net_preds**2)*self.d2u_dx2\n","\n","      return  1.0*intC_loss\n","\n","    def calculatePiLoss(self, x_internal, keep_batch = False):\n","        '''\n","        Helper function that Sample and Calculate loss,\n","        '''        \n","        x_internal = Variable( x_internal , requires_grad=True)\n","        u_value = self.u_fn(x_internal)\n","        u_value.backward()\n","        \n","\n","        Ls = self.criterion( x_internal )\n","        \n","        return_losses = []\n","        if not keep_batch:\n","          loss_pi = torch.mean(Ls)           \n","          return loss_pi          \n","        else:\n","          return Ls\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1652971110346,"user_tz":-60,"elapsed":4,"user":{"displayName":"Hans Roggeman","userId":"10574434403170915342"}},"outputId":"4fcce245-6f94-44b2-8459-474ebb394bd1","id":"QH6bbGt4Sq-0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["time: 29.6 ms (started: 2022-05-19 14:38:29 +00:00)\n"]}]},{"cell_type":"code","source":["# closed form value function\n","def Htx(x):\n","  return -torch.exp(-x[:,1].reshape(-1,1)*1.0*torch.exp(x[:,3].reshape(-1,1)*(1.0-x[:,0].reshape(-1,1))) - \n","                    0.5*(1.0-x[:,0].reshape(-1,1))*((x[:,2].reshape(-1,1)-x[:,3].reshape(-1,1))/(x[:,4].reshape(-1,1)))**2  )\n","\n","u_net = MertonUtilityNet( NL = 6 , NN = 100 )\n","u_net.to(torch.device(\"cuda:0\")) \n","pi_net = MertonPiNet( NL = 6 , NN = 100 )\n","pi_net.to(torch.device(\"cuda:0\")) \n","## providing sampler with net so it can accept/reject based on net and other criterions\n","\n","mequation = MertonEquation(u_net, pi_net, max_pi_epochs, lr_for_pi)\n","\n","\n","\n","\n","        # pi_model = PiEquation(self.pi_net, du_dx, d2u_dx2)                \n","        # pi_trainer = TrainInternalPiWithDGM(self, pi_model, x_internal.shape[0], \n","        #                                     self.pi_net_epoch, self.pi_net_lr, \n","        #                                     debug=True, loss_multiply=1.0)\n","        # pi_trainer.use_early_stop = True\n","        # pi_trainer.early_stop_patience = min(200,math.ceil(self.pi_net_epoch/10.0))\n","        # pi_trainer.train()\n"],"metadata":{"id":"zv1Z6rcHP-25"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### Test Case WITH Stratification"],"metadata":{"id":"RDKmMCNNe0yi"}},{"cell_type":"code","source":["seed = 123\n","torch.manual_seed(seed)\n","torch.cuda.manual_seed(seed)\n","torch.cuda.manual_seed_all(seed)\n","np.random.seed(seed)\n","random.seed(seed)\n","torch.backends.cudnn.benchmark = False\n","torch.backends.cudnn.deterministic = True\n","\n","# u_net, pi_net, pi_net_epoch, pi_net_lr\n","eqLossFn= 'calculateLoss'\n","sample_method= \"U\"\n","lr = 0.01\n","max_pi_epochs = 400\n","\n","u_net = MertonUtilityNet( NL = 3 , NN = 30 )\n","u_net.to(torch.device(\"cuda:0\")) \n","pi_net = MertonPiNet( NL = 3 , NN = 30 )\n","pi_net.to(torch.device(\"cuda:0\")) \n","## providing sampler with net so it can accept/reject based on net and other criterions\n","mequation = MertonEquation(u_net, pi_net, max_pi_epochs, lr)\n","mequation.xbreaks = np.linspace(0, mequation.MAX_X, 3).tolist()\n","mequation.tbreaks = np.linspace(0, mequation.T, 3).tolist()\n","trainMertonAlloc = TrainHJBMertonWithDGM(u_net, mequation, BATCH_SIZE = 2**8 , debug = True )\n","trainMertonAlloc.hook_interval = 10\n","trainMertonAlloc.use_early_stop = True\n","trainMertonAlloc.early_stop_patience = 20\n","# trainEuss.validation_sample = bsequation.sample(sample_method_X=\"U\", size=2**6)\n","trainMertonAlloc.train_stratified( epoch = 4000 , lr = lr, eqLossFn = eqLossFn , sample_method_X = sample_method)\n","# trainMertonAlloc.train(epoch = 4000 , lr = lr, eqLossFn = eqLossFn , sample_method_X = sample_method)\n","\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"mrIs88CIg4iT","executionInfo":{"status":"error","timestamp":1652714777005,"user_tz":-60,"elapsed":58922,"user":{"displayName":"Hans Roggeman","userId":"10574434403170915342"}},"outputId":"4ba7166d-13d2-43f8-cefa-fe1e3390cb7c"},"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["> <ipython-input-157-7434d0b31bb1>(174)train_stratified()\n","-> internal_xts_bts, terminal_xts_bts = self.model.sample_stratified(sample_method_X = sample_method_X, size=self.BATCH_SIZE)\n","(Pdb) self.model.sample_stratified(sample_method_X = sample_method_X, size=self.BATCH_SIZE)[0].shape\n","*** AttributeError: 'list' object has no attribute 'shape'\n","(Pdb) len(self.model.sample_stratified(sample_method_X = sample_method_X, size=self.BATCH_SIZE)[0])\n","4\n","(Pdb) n\n","> <ipython-input-157-7434d0b31bb1>(175)train_stratified()\n","-> validation_stratum_losses = None #np.array([])#.reshape(1,self.validation_losses.shape[1])\n","(Pdb) n\n","> <ipython-input-157-7434d0b31bb1>(176)train_stratified()\n","-> training_stratum_losses = None # np.array([])#.reshape(1,self.train_losses.shape[1])\n","(Pdb) n\n","> <ipython-input-157-7434d0b31bb1>(177)train_stratified()\n","-> training_value_to_optimize = torch.tensor(0.0,requires_grad=True)\n","(Pdb) n\n","> <ipython-input-157-7434d0b31bb1>(180)train_stratified()\n","-> for stratum_count in range(len(internal_xts_bts)):\n","(Pdb) n\n","> <ipython-input-157-7434d0b31bb1>(181)train_stratified()\n","-> sample_batch = (internal_xts_bts[stratum_count],\n","(Pdb) n\n","> <ipython-input-157-7434d0b31bb1>(182)train_stratified()\n","-> terminal_xts_bts[stratum_count])\n","(Pdb) n\n","> <ipython-input-157-7434d0b31bb1>(184)train_stratified()\n","-> pdb.set_trace()\n","(Pdb) n\n","> <ipython-input-157-7434d0b31bb1>(185)train_stratified()\n","-> stratum_losses_L2, stratum_losses_ABS = loss_calc_method(sample_batch,\n","(Pdb) n\n","> <ipython-input-157-7434d0b31bb1>(186)train_stratified()\n","-> loss_transforms = [ key_loss_func, torch.abs ],\n","(Pdb) n\n","> <ipython-input-157-7434d0b31bb1>(187)train_stratified()\n","-> keep_batch = False )\n","(Pdb) n\n","> <ipython-input-157-7434d0b31bb1>(192)train_stratified()\n","-> if training_stratum_losses is not None:\n","(Pdb) stratum_losses_L2\n","[tensor(0.0293, device='cuda:0', grad_fn=<AddBackward0>), tensor(0.0022, device='cuda:0', grad_fn=<MulBackward0>), tensor(0.0272, device='cuda:0', grad_fn=<MulBackward0>), tensor(0.0293, device='cuda:0', grad_fn=<AddBackward0>)]\n","(Pdb) q\n"]},{"output_type":"error","ename":"BdbQuit","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mBdbQuit\u001b[0m                                   Traceback (most recent call last)","\u001b[0;32m<ipython-input-159-2a67a21d2dc3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0mtrainMertonAlloc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mearly_stop_patience\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;31m# trainEuss.validation_sample = bsequation.sample(sample_method_X=\"U\", size=2**6)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m \u001b[0mtrainMertonAlloc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_stratified\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m4000\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meqLossFn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meqLossFn\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0msample_method_X\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample_method\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;31m# trainMertonAlloc.train(epoch = 4000 , lr = lr, eqLossFn = eqLossFn , sample_method_X = sample_method)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-157-7434d0b31bb1>\u001b[0m in \u001b[0;36mtrain_stratified\u001b[0;34m(self, epoch, lr, eqLossFn, sample_method_X, key_loss_func, huber_delta)\u001b[0m\n\u001b[1;32m    190\u001b[0m               \u001b[0;31m#   pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 192\u001b[0;31m               \u001b[0;32mif\u001b[0m \u001b[0mtraining_stratum_losses\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    193\u001b[0m                 \u001b[0mtraining_stratum_losses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtraining_stratum_losses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mto_cpu_detach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstratum_losses_L2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mto_cpu_detach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstratum_losses_ABS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m               \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-157-7434d0b31bb1>\u001b[0m in \u001b[0;36mtrain_stratified\u001b[0;34m(self, epoch, lr, eqLossFn, sample_method_X, key_loss_func, huber_delta)\u001b[0m\n\u001b[1;32m    190\u001b[0m               \u001b[0;31m#   pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 192\u001b[0;31m               \u001b[0;32mif\u001b[0m \u001b[0mtraining_stratum_losses\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    193\u001b[0m                 \u001b[0mtraining_stratum_losses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtraining_stratum_losses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mto_cpu_detach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstratum_losses_L2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mto_cpu_detach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstratum_losses_ABS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m               \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.7/bdb.py\u001b[0m in \u001b[0;36mtrace_dispatch\u001b[0;34m(self, frame, event, arg)\u001b[0m\n\u001b[1;32m     86\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;31m# None\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'line'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'call'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.7/bdb.py\u001b[0m in \u001b[0;36mdispatch_line\u001b[0;34m(self, frame)\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_here\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbreak_here\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquitting\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mraise\u001b[0m \u001b[0mBdbQuit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrace_dispatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mBdbQuit\u001b[0m: "]},{"output_type":"stream","name":"stdout","text":["time: 57.8 s (started: 2022-05-16 15:25:18 +00:00)\n"]}]},{"cell_type":"code","source":["# pie_net = MertonPiNet( NL = 3 , NN = 30 )\n","# pie_input = torch.tensor([[7.4874e-01, 3.0019e+00, 1.1477e-01, 2.2795e-03, 3.9906e-01]])\n","# pie_net(pie_input)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3qsJ5JgkADow","executionInfo":{"status":"ok","timestamp":1652688503682,"user_tz":-60,"elapsed":3,"user":{"displayName":"Hans Roggeman","userId":"10574434403170915342"}},"outputId":"132867d5-963c-4f3e-baf5-9018bad37f1d"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[0.4825, 0.5175]], grad_fn=<SoftmaxBackward0>)"]},"metadata":{},"execution_count":28},{"output_type":"stream","name":"stdout","text":["time: 24.6 ms (started: 2022-05-16 08:08:23 +00:00)\n"]}]},{"cell_type":"code","source":["q"],"metadata":{"id":"WH7eVzjqkLNH"},"execution_count":null,"outputs":[]}]}