{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Copy of crnn_merge_to_DNN.ipynb","provenance":[{"file_id":"1xbcmpyPWMK63sT6SCw4fM7jp4RynepqH","timestamp":1621464971036},{"file_id":"1ygmqkRNc3y4_CMOoFKdhyUnFVmqzAHmu","timestamp":1621268458950}],"collapsed_sections":[],"machine_shape":"hm","mount_file_id":"1xbcmpyPWMK63sT6SCw4fM7jp4RynepqH","authorship_tag":"ABX9TyPoKiqMdKGGYMlsLpThKkKF"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"mR2TvAiGQilA","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1621452850445,"user_tz":-60,"elapsed":7871,"user":{"displayName":"Hans Roggeman","photoUrl":"","userId":"10574434403170915342"}},"outputId":"d5936dc0-3277-49c5-b78f-f406eb39e441"},"source":["%pip install keras_self_attention\n","%pip install keras-tuner"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: keras_self_attention in /usr/local/lib/python3.7/dist-packages (0.49.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from keras_self_attention) (1.19.5)\n","Requirement already satisfied: Keras in /usr/local/lib/python3.7/dist-packages (from keras_self_attention) (2.4.3)\n","Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from Keras->keras_self_attention) (2.10.0)\n","Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.7/dist-packages (from Keras->keras_self_attention) (1.4.1)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from Keras->keras_self_attention) (3.13)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from h5py->Keras->keras_self_attention) (1.15.0)\n","Requirement already satisfied: keras-tuner in /usr/local/lib/python3.7/dist-packages (1.0.2)\n","Requirement already satisfied: colorama in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (0.4.4)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (1.19.5)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (1.4.1)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (0.22.2.post1)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (20.9)\n","Requirement already satisfied: tabulate in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (0.8.9)\n","Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (0.16.0)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (4.41.1)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (2.23.0)\n","Requirement already satisfied: terminaltables in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (3.1.0)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->keras-tuner) (1.0.1)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->keras-tuner) (2.4.7)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->keras-tuner) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->keras-tuner) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->keras-tuner) (2020.12.5)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->keras-tuner) (3.0.4)\n","Requirement already satisfied: pygam in /usr/local/lib/python3.7/dist-packages (0.8.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from pygam) (1.19.5)\n","Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from pygam) (0.16.0)\n","Requirement already satisfied: progressbar2 in /usr/local/lib/python3.7/dist-packages (from pygam) (3.38.0)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from pygam) (1.4.1)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from progressbar2->pygam) (1.15.0)\n","Requirement already satisfied: python-utils>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from progressbar2->pygam) (2.5.6)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"dWN1YdD7Qvc2","executionInfo":{"status":"ok","timestamp":1621452872264,"user_tz":-60,"elapsed":2006,"user":{"displayName":"Hans Roggeman","photoUrl":"","userId":"10574434403170915342"}}},"source":["import tensorflow as tf\n","from tensorflow.keras.models import Sequential, load_model, Model\n","from tensorflow.keras.layers import BatchNormalization, Dense, LeakyReLU, Dropout\n","from keras_self_attention import SeqSelfAttention, SeqWeightedAttention\n","import site\n","import pandas as pd\n","import numpy as np\n","import matplotlib\n","import os"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"nmcD3FuxQw7Q","executionInfo":{"status":"ok","timestamp":1621452872264,"user_tz":-60,"elapsed":766,"user":{"displayName":"Hans Roggeman","photoUrl":"","userId":"10574434403170915342"}}},"source":["pd.set_option('display.width', 400)\n","pd.set_option('display.max_columns', 40)"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"rfyld79IQ0j0","executionInfo":{"status":"ok","timestamp":1621452876223,"user_tz":-60,"elapsed":668,"user":{"displayName":"Hans Roggeman","photoUrl":"","userId":"10574434403170915342"}}},"source":["import tensorflow as tf\n","from tensorflow.keras.utils import to_categorical\n","import h5py as h5\n","import matplotlib.pyplot as plt\n","from tensorflow.keras.models import Model\n","import errno\n","import os\n","from collections import defaultdict\n","from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard\n","from tensorflow.summary import create_file_writer\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import confusion_matrix\n","import kerastuner as kt\n","from kerastuner import HyperModel\n","import numpy as np\n","import itertools\n","import multiprocessing\n","import tensorflow as tf\n","from tensorflow.keras.models import Sequential, load_model, Model\n","from tensorflow.keras.layers import BatchNormalization, Dense, LeakyReLU, Dropout\n","from keras_self_attention import SeqSelfAttention, SeqWeightedAttention\n","import site\n","import pandas as pd\n","import numpy as np\n","import matplotlib\n","import os\n","pd.set_option('display.width', 400)\n","pd.set_option('display.max_columns', 40)\n"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"1DZ2zSmhRDJf","executionInfo":{"status":"ok","timestamp":1621452878462,"user_tz":-60,"elapsed":812,"user":{"displayName":"Hans Roggeman","photoUrl":"","userId":"10574434403170915342"}}},"source":["def get_features_model(model_name, combined_models):\n","    for ids, models in combined_models:\n","        if models[0].name == model_name:\n","            return models[1]\n","    return None\n","\n","def get_features_from_combined_models(combined_models, X_input):\n","    data_features = []\n","    for ids, models in combined_models:\n","        data_features.append(np.array(models[1].predict(X_input), dtype='float64'))\n","    return np.concatenate(tuple(data_features), axis=1)\n"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"Nn8uaSm8Cjzv","executionInfo":{"status":"ok","timestamp":1621452885147,"user_tz":-60,"elapsed":663,"user":{"displayName":"Hans Roggeman","photoUrl":"","userId":"10574434403170915342"}}},"source":["def coShuffled_vectors(X, Y):\n","    if tf.shape(X)[0] == tf.shape(Y)[0]:\n","        test_idxs = tf.range(start=0, limit=tf.shape(X)[0], dtype=tf.int32)\n","        shuffled_test_idxs = tf.random.shuffle(test_idxs)\n","        return (tf.gather(X, shuffled_test_idxs), tf.gather(Y, shuffled_test_idxs))\n","    else:\n","        raise ValueError(f\"0-dimension has to be the same {tf.shape(X)[0]} != {tf.shape(Y)[0]}\")\n","\n","\n","def getNpArrayFromH5(hf_Data):\n","    X_train = hf_Data['Train_Data']  # Get train set\n","    X_train = np.array(X_train)\n","    Y_train = hf_Data['Label']  # Get train label\n","    Y_train = np.array(Y_train)\n","    return X_train, Y_train\n","\n","# data extraction\n","def getData(is500=True, shuffle=False, ise2e=False, include_secondary=False, validation_split=None, isColab=False):\n","    if not include_secondary:\n","        hf_Train = h5.File(\n","            f'./{\"data\" if not isColab else \"drive/MyDrive/data_papers/ncRNA\"}/{\"e2e_Train_Data\" if ise2e else \"Fold_10_Train_Data\"}_{str(500) if is500 else str(1000)}.h5', 'r')\n","        hf_Test = h5.File(\n","            f'./{\"data\" if not isColab else \"drive/MyDrive/data_papers/ncRNA\"}/{\"e2e_Test_Data\" if ise2e else \"Fold_10_Test_Data\"}_{str(500) if is500 else str(1000)}.h5', 'r')\n","    else:\n","        hf_Train = h5.File(f'./{\"data\" if not isColab else \"drive/MyDrive/data_papers/ncRNA\"}/e2e_Train_Secondary_Data_1136.h5', 'r')\n","        hf_Test = h5.File(f'./{\"data\" if not isColab else \"drive/MyDrive/data_papers/ncRNA\"}/e2e_Test_Secondary_Data_1136.h5', 'r')\n","\n","    X_train, Y_train = getNpArrayFromH5(hf_Train)\n","    X_test, Y_test = getNpArrayFromH5(hf_Test)\n","    Y_train = to_categorical(Y_train, 13)  # Process the label of tain\n","    Y_test = to_categorical(Y_test, 13)  # Process the label of te\n","\n","    if shuffle:\n","        X_train, Y_train = coShuffled_vectors(X_train, Y_train)\n","        X_test, Y_test = coShuffled_vectors(X_test, Y_test)\n","\n","    X_validation = Y_validation = None\n","    if validation_split is not None:\n","        # sklearn split shuffles anyway\n","        X_train, X_validation, Y_train, Y_validation = train_test_split(X_train, Y_train, test_size=validation_split)\n","\n","    return X_train, Y_train, X_test, Y_test, X_validation, Y_validation\n","\n","\n","def getE2eData(is500=True, shuffle=False, include_secondary=False, isColab=False):\n","    if not include_secondary:\n","        hf_Train = h5.File(\n","            f'./{\"data\" if not isColab else \"drive/MyDrive/data_papers/ncRNA\"}/e2e_Train_Data_{str(500) if is500 else str(1000)}.h5', 'r')\n","        hf_Test = h5.File(\n","            f'./{\"data\" if not isColab else \"drive/MyDrive/data_papers/ncRNA\"}/e2e_Test_Data_{str(500) if is500 else str(1000)}.h5', 'r')\n","    else:\n","        hf_Train = h5.File(f'./{\"data\" if not isColab else \"drive/MyDrive/data_papers/ncRNA\"}/e2e_Train_Secondary_Data_1136.h5', 'r')\n","        hf_Test = h5.File(f'./{\"data\" if not isColab else \"drive/MyDrive/data_papers/ncRNA\"}/e2e_Test_Secondary_Data_1136.h5', 'r')\n","\n","    X_train, Y_train = getNpArrayFromH5(hf_Train)\n","    X_test, Y_test = getNpArrayFromH5(hf_Test)\n","    Y_train = to_categorical(Y_train, 13)  # Process the label of tain\n","    Y_test = to_categorical(Y_test, 13)  # Process the label of te\n","\n","    if shuffle:\n","        X_train, Y_train = coShuffled_vectors(X_train, Y_train)\n","        X_test, Y_test = coShuffled_vectors(X_test, Y_test)\n","\n","    hf_Val = h5.File(f'./{\"data\" if not isColab else \"drive/MyDrive/data_papers/ncRNA\"}/e2e_Val_Secondary_Data_1136.h5', 'r') if include_secondary else h5.File(\n","        f'./{\"data\" if not isColab else \"drive/MyDrive/data_papers/ncRNA\"}/e2e_Val_Data_{str(500) if is500 else str(1000)}.h5', 'r')\n","    X_validation, Y_validation = getNpArrayFromH5(hf_Val)\n","    Y_validation = to_categorical(Y_validation, 13)  # Process the label of tain\n","\n","    return X_train, Y_train, X_test, Y_test, X_validation, Y_validation\n","\n","\n","def getE2eDataJustSecondary(shuffle=False,isColab=False):\n","    hf_Train = h5.File(f'./{\"data\" if not isColab else \"drive/MyDrive/data_papers/ncRNA\"}/e2e_Train_just_Secondary_Data_1000.h5', 'r')\n","    hf_Test = h5.File(f'./{\"data\" if not isColab else \"drive/MyDrive/data_papers/ncRNA\"}/e2e_Test_just_Secondary_Data_1000.h5', 'r')\n","\n","    X_train, Y_train = getNpArrayFromH5(hf_Train)\n","    X_test, Y_test = getNpArrayFromH5(hf_Test)\n","    Y_train = to_categorical(Y_train, 13)  # Process the label of tain\n","    Y_test = to_categorical(Y_test, 13)  # Process the label of te\n","\n","    if shuffle:\n","        X_train, Y_train = coShuffled_vectors(X_train, Y_train)\n","        X_test, Y_test = coShuffled_vectors(X_test, Y_test)\n","\n","    hf_Val = h5.File(f'./{\"data\" if not isColab else \"drive/MyDrive/data_papers/ncRNA\"}/e2e_Val_just_Secondary_Data_1000.h5', 'r')\n","    \n","    X_validation, Y_validation = getNpArrayFromH5(hf_Val)\n","    Y_validation = to_categorical(Y_validation, 13)  # Process the label of tain\n","\n","    return X_train, Y_train, X_test, Y_test, X_validation, Y_validation\n"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"RHCMi9z-xlo-","executionInfo":{"status":"ok","timestamp":1621458149508,"user_tz":-60,"elapsed":1922,"user":{"displayName":"Hans Roggeman","photoUrl":"","userId":"10574434403170915342"}}},"source":["def reverse_one_hot(Y_input):\n","    return np.apply_along_axis(np.argmax, 1, Y_input) + 1\n","\n","def plot_history(history):\n","    acc_keys = [k for k in history.history.keys() if k in ('accuracy', 'val_accuracy')]\n","    loss_keys = [k for k in history.history.keys() if not k in acc_keys]\n","    for k, v in history.history.items():\n","        if k in acc_keys:\n","            plt.figure(1)\n","            plt.plot(v)\n","        else:\n","            plt.figure(2)\n","            plt.plot(v)\n","    plt.figure(1)\n","    plt.title('Accuracy vs. epochs')\n","    plt.ylabel('Accuracy')\n","    plt.xlabel('Epoch')\n","    plt.legend(acc_keys, loc='lower right')\n","    plt.figure(2)\n","    plt.title('Loss vs. epochs')\n","    plt.ylabel('Loss')\n","    plt.xlabel('Epoch')\n","    plt.legend(loss_keys, loc='upper right')\n","    plt.show()\n","\n","\n","def get_layer_by_name(layers, name, return_first=True):\n","    matching_named_layers = [l for l in layers if l.name == name]\n","    if not matching_named_layers:\n","        return None\n","    return matching_named_layers[0] if return_first else matching_named_layers\n","\n","\n","def make_dir_if_not_exist(used_path):\n","    if not os.path.isdir(used_path):\n","        try:\n","            os.mkdir(used_path)\n","        except OSError as exc:\n","            if exc.errno != errno.EEXIST:\n","                raise exc\n","            else:\n","                raise ValueError(f'{used_path} directoy cannot be created because its parent directory does not exist.')\n","\n","\n","def source_model(model_func, model_name, input_shape):\n","    m = None\n","    if isinstance(model_func, tf.keras.models.Model):\n","        m = model_func\n","        m._name = model_name\n","    else:\n","        m = model_func(model_name, input_shape)\n","    return m\n","\n","\n","def compile_and_fit_model_with_tb(model_func,\n","                                  model_name,\n","                                  input_shape,\n","                                  X_train,\n","                                  Y_train,\n","                                  save_every_epoch=True,\n","                                  save_final=False,\n","                                  **kwargs):\n","    m = None\n","    if isinstance(model_func, tf.keras.models.Model):\n","        m = model_func\n","        m._name = model_name\n","    else:\n","        m = model_func(model_name, input_shape)\n","    tb_callback = TensorBoard(log_dir=f'{m.name}_logs', histogram_freq=kwargs.pop(\"histogram_freq\", 1))\n","    if save_every_epoch:\n","        tb_callback.append(ModelCheckpoint(f'{m.name}' + '_model_{epoch:03d}_{val_accuracy:0.2f}'))\n","    m.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n","    history = m.fit(X_train, Y_train, callbacks=[tb_callback], verbose=2, **kwargs)\n","    if save_final:\n","        make_dir_if_not_exist(model_name)\n","        m.save(f\"{m.name}_saved_model_after_fit\")  # Save the model\n","    return (m, history)\n","    # m.save(f\"{m.name}_Tenth_Fold_New_Model_500_8\") #Save the model\n","\n","\n","def compile_and_fit_model(model_func,\n","                          model_name,\n","                          input_shape,\n","                          X_train,\n","                          Y_train,\n","                          save_every_epoch=True,\n","                          save_final=False,\n","                          **kwargs):\n","    m = None\n","    if isinstance(model_func, tf.keras.models.Model):\n","        m = model_func\n","        m._name = model_name\n","    else:\n","        m = model_func(model_name, input_shape)\n","\n","    callbacks_used = []\n","    if save_every_epoch:\n","        callbacks_used.append(ModelCheckpoint(f'{m.name}' + '_model_{epoch:03d}_{val_accuracy:0.2f}'))\n","    m.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n","    history = m.fit(X_train, Y_train, callbacks=callbacks_used, verbose=2, **kwargs)\n","    if save_final:\n","        make_dir_if_not_exist(model_name)\n","        m.save(f\"{m.name}_saved_model_after_fit\")  # Save the model\n","    return (m, history)\n","\n","\n","def compile_model_and_fit_with_custom_loop(model_func,\n","                                           model_name,\n","                                           input_shape,\n","                                           X_train,\n","                                           Y_train,\n","                                           **kwargs):\n","    make_dir_if_not_exist(model_name)\n","    m = None\n","    if isinstance(model_func, tf.keras.models.Model):\n","        m = model_func\n","        m._name = model_name\n","    else:\n","        m = model_func(model_name, input_shape)\n","\n","    train_writer = create_file_writer(f'{m.name}_logs/train/')\n","    test_writer = create_file_writer(f'{m.name}_logs/test/')\n","    train_step = test_step = 0\n","\n","    acc_metric = tf.keras.metrics.CategoricalAccuracy()\n","    optimizer = tf.keras.optimizers.Adam()\n","    num_epochs = kwargs.get(\"epochs\", 10)\n","\n","    AUTOTUNE = tf.data.experimental.AUTOTUNE\n","    BATCH_SIZE = kwargs.get(\"batch_size\", 32)\n","    X_test, Y_test = kwargs.get(\"validation_data\", (None, None))\n","    if X_test is None:\n","        raise ValueError(\"Missing X validation data\")\n","    if Y_test is None:\n","        raise ValueError(\"Missing Y validation data\")\n","\n","    train_dataset_tf = tf.data.Dataset.from_tensor_slices((X_train, Y_train))\n","    train_dataset_tf = train_dataset_tf.batch(BATCH_SIZE)\n","    train_dataset_tf = train_dataset_tf.prefetch(AUTOTUNE)\n","\n","    test_dataset_tf = tf.data.Dataset.from_tensor_slices((X_test, Y_test))\n","    test_dataset_tf = train_dataset_tf.batch(BATCH_SIZE)\n","    test_dataset_tf = train_dataset_tf.prefetch(AUTOTUNE)\n","\n","    loss_fn = tf.keras.losses.CategoricalCrossentropy()\n","\n","    for epoch in range(num_epochs):\n","        # Iterate through training set\n","        for batch_idx, (x, y) in enumerate(train_dataset_tf):\n","            with tf.GradientTape() as tape:\n","                y_pred = m(x, training=True)\n","                loss = loss_fn(y, y_pred)\n","\n","            gradients = tape.gradient(loss, m.trainable_weights)\n","            optimizer.apply_gradients(zip(gradients, m.trainable_weights))\n","            acc_metric.update_state(y, y_pred)\n","\n","            with train_writer.as_default():\n","                tf.summary.scalar(\"Loss\", loss, step=train_step)\n","                tf.summary.scalar(\n","                    \"Accuracy\", acc_metric.result(), step=train_step,\n","                )\n","                train_step += 1\n","        # Reset accuracy in between epochs (and for testing and test)\n","        acc_metric.reset_states()\n","        # Iterate through test set\n","        for batch_idx, (x, y) in enumerate(test_dataset_tf):\n","            y_pred = m(x, training=False)\n","            loss = loss_fn(y, y_pred)\n","            acc_metric.update_state(y, y_pred)\n","            with test_writer.as_default():\n","                tf.summary.scalar(\"Loss\", loss, step=test_step)\n","                tf.summary.scalar(\n","                    \"Accuracy\", acc_metric.result(), step=test_step,\n","                )\n","                test_step += 1\n","\n","        acc_metric.reset_states()  # Reset accuracy in between epochs (and for testing and test)\n","\n","    return m\n","\n","\n","def run_mirrored_strategy(model_func, base_batch_size, nepochs, x_train, y_train, x_test, y_test, **kwargs):\n","    strategy = tf.distribute.MirroredStrategy()\n","    with strategy.scope():\n","        model = model_func()\n","        model.compile(\n","            optimizer=tf.keras.optimizers.Adam(),\n","            loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n","            metrics=tf.keras.metrics.SparseCategoricalAccuracy()\n","        )\n","    batch_size_mirr_strat = base_batch_size * strategy.num_replicas_in_sync\n","    history = model.fit(x_train, y_train, epochs=nepochs, batch_size=batch_size_mirr_strat,\n","                        validation_data=(x_test, y_test),\n","                        **kwargs)\n","    return model, history\n","\n","\n","def sparse_setdiff(a1, a2):\n","    a1a = a1.reshape(a1.shape[0], -1)\n","    a2a = a2.reshape(a2.shape[0], -1)\n","    spa2a = [np.where(x)[0].tolist() for x in a2a]\n","    spa1a = [np.where(x)[0].tolist() for x in a1a]\n","    idxs_to_keep = []\n","    for idx, sample in enumerate(spa1a):\n","        try:\n","            spa2a.index(sample)\n","        except ValueError:\n","            # not in list\n","            idxs_to_keep.append(idx)\n","    return a1[idxs_to_keep], idxs_to_keep\n","\n","def get_combined_features_from_models(\n","        to_combine,\n","        X_train, Y_train,\n","        X_test, Y_test,\n","        reverse_one_hot=False,\n","        normalize_X_func=None):\n","    \n","    models = []\n","    models_dict = {}\n","    X_trains_out = []\n","    X_test_out = []\n","    XY_dict = defaultdict(lambda: defaultdict(lambda: defaultdict(lambda: defaultdict(lambda: None))))\n","\n","    models_have_different_inputs = isinstance(Y_train,list)\n","\n","    if reverse_one_hot:\n","        if models_have_different_inputs:\n","            Y_train_new = np.apply_along_axis(np.argmax, 1, Y_train) + 1\n","            Y_test_new = np.apply_along_axis(np.argmax, 1, Y_test) + 1\n","        else:\n","            Y_train_new = [ np.apply_along_axis(np.argmax, 1, y_train) + 1 for y_train in Y_train ]  \n","            Y_test_new = [ np.apply_along_axis(np.argmax, 1, y_test) + 1 for y_test in Y_test ]              \n","    else:\n","        if models_have_different_inputs:\n","            Y_train_new = Y_train.copy()\n","            Y_test_new = Y_test.copy()\n","        else:\n","            Y_train_new = [ y_train.copy() for y_train in Y_train ] \n","            Y_test_new = [ y_test.copy() for y_test in Y_train ] \n","            \n","\n","    extraction_counter =0\n","    for model_file_name, layer_name, kwargs in to_combine:\n","        model_here = None\n","        if isinstance(model_file_name, tf.keras.models.Model):\n","            model_here = model_file_name\n","            model_file_name = model_here.name\n","        else:\n","            if model_file_name in models_dict.keys():\n","                model_here = models_dict[model_file_name]\n","            else:\n","                model_here = tf.keras.models.load_model(model_file_name,\n","                                                        **kwargs) if kwargs is not None else tf.keras.models.load_model \\\n","                    (model_file_name)\n","\n","        features_model = Model(model_here.input,\n","                               get_layer_by_name(model_here.layers, layer_name).output)\n","        \n","        if normalize_X_func is None:\n","            X_trains_out.append(np.array(features_model.predict(X_train if not models_have_different_inputs else X_train[extraction_counter]), dtype='float64'))\n","            X_test_out.append(np.array(features_model.predict(X_test if not models_have_different_inputs else X_test[extraction_counter]), dtype='float64'))\n","        else:\n","            X_trains_out.append(np.array(normalize_X_func(features_model.predict(X_train if not models_have_different_inputs else X_train[extraction_counter])), dtype='float64'))\n","            X_test_out.append(np.array(normalize_X_func(features_model.predict(X_test if not models_have_different_inputs else X_test[extraction_counter])), dtype='float64'))\n","        XY_dict[model_file_name][layer_name]['Train']['X'] = X_trains_out[-1]\n","        XY_dict[model_file_name][layer_name]['Test']['X'] = X_test_out[-1]\n","        XY_dict[model_file_name][layer_name]['Train']['Y'] = Y_train_new\n","        XY_dict[model_file_name][layer_name]['Test']['Y'] = Y_test_new\n","        models.append(((model_file_name, layer_name), (model_here, features_model)))\n","        models_dict[model_file_name] = model_here\n","        extraction_counter += 1\n","\n","    X_train_new = np.concatenate(tuple(X_trains_out), axis=1)\n","    X_test_new = np.concatenate(tuple(X_test_out), axis=1)\n","\n","    data_train = (X_train_new, Y_train_new)\n","    data_test = (X_test_new, Y_test_new)\n","\n","    return models, data_train, data_test, XY_dict\n","\n","class CNNHyperModel(HyperModel):\n","    def __init__(self, model_name, input_shape, num_classes):\n","        self.input_shape = input_shape\n","        self.num_classes = num_classes\n","        self.model_name = model_name\n","\n","    def build(self, hp):\n","        inputs = tf.keras.Input(shape=self.input_shape)\n","        x = inputs\n","\n","        for idx, i in enumerate(range(hp.Int('conv128_blocks_with_normalizations', 1, 6, default=4))):\n","            x = Conv1D(128, 3, padding='same', name=f\"conv1D_128_{idx}\")(x)\n","            if hp.Boolean(f'conv128_has_leaky_relu_{idx}', default=True):\n","                x = LeakyReLU()(x)\n","            if hp.Boolean(f'conv128_has_max_pooling_{idx}', default=True):\n","                x = MaxPooling1D()(x)\n","            if hp.Boolean(f'conv128_has_batchnorm_{idx}', default=True):\n","                x = BatchNormalization()(x)\n","            if hp.Boolean(f'conv128_has_gaussiannoise_{idx}', default=True):\n","                x = GaussianNoise(hp.Float(f'conv128_gaussiannoise_{idx}',\n","                                       min_value=1e-5,\n","                                       max_value=1e1,\n","                                       sampling='LOG',\n","                                       default=0.05\n","                                       ))(x)\n","        for idx, i in enumerate(range(hp.Int('conv256_blocks_with_normalizations', 1, 4, default=2))):\n","            x = Conv1D(256, 3, padding='same', name=f\"conv1D_256_{idx}\")(x)\n","            if hp.Boolean(f'conv256_has_leaky_relu_{idx}', default=True):\n","                x = LeakyReLU()(x)\n","            if hp.Boolean(f'conv256_has_max_pooling_{idx}', default=True):\n","                x = MaxPooling1D()(x)\n","            if hp.Boolean(f'conv256_has_batchnorm_{idx}', default=True):\n","                x = BatchNormalization()(x)\n","            if hp.Boolean(f'conv256_has_gaussiannoise_{idx}', default=True):\n","                x = GaussianNoise(hp.Float(f'conv256_gaussiannoise_{idx}',\n","                                       min_value=1e-5,\n","                                       max_value=1e1,\n","                                       sampling='LOG',\n","                                       default=0.05\n","                                       ))(x)\n","        x = Flatten(name=\"last_flatten\")(x)\n","        for idx, i in enumerate(range(hp.Int('final_dense', 1, 5, default=2))):\n","            x = Dense(units=hp.Choice(f'final_dense_num_nodes_{idx}', values=[16, 32, 64, 128], default=128),\n","                  activation=hp.Choice(f'final_dense_kernel_activation_{idx}',\n","                                       values=['exponential', 'gelu', 'elu', 'relu', 'tanh'], default='relu'),\n","                  kernel_initializer='RandomNormal',\n","                  bias_initializer='zeros',\n","                  name=f\"final_dense_{idx}\")(x)\n","            if hp.Boolean(f'final_dense_has_dropout_{idx}', default=True):\n","                x = Dropout(hp.Float(f'final_dense_dropout_{idx}',\n","                                 min_value=0.05,\n","                                 max_value=0.75,\n","                                 step=0.05,\n","                                 default=0.2\n","                                 ), name=f\"final_dense_dropout_{idx}\")(x)\n","        outputs = Dense(self.num_classes, activation='softmax', name=\"last_softmax\")(x)\n","        model = tf.keras.Model(inputs, outputs, name=self.model_name)\n","        #  m.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n","        if hp.Boolean('optimize_adam', default=True):\n","            model.compile(\n","                optimizer=tf.keras.optimizers.Adam(hp.Float('learning_rate', 1e-5, 1e-1, sampling='log')),\n","                loss='categorical_crossentropy',\n","                metrics=['accuracy'])\n","        else:\n","            model.compile(\n","                optimizer=hp.Choice('final_optimizer',\n","                                    values=['adam', 'SGD', 'RMSprop', 'Adadelta', 'Nadam', 'Adamax', 'Adagrad'],\n","                                    default='adam'),\n","                loss='categorical_crossentropy',\n","                metrics=['accuracy'])\n","        return model\n","    \n","\n","def reinitialize_weights(model):\n","    for ix, layer in enumerate(model.layers):\n","        if hasattr(model.layers[ix], 'kernel_initializer') and hasattr(model.layers[ix], 'bias_initializer'):\n","            weight_initializer = model.layers[ix].kernel_initializer\n","            bias_initializer = model.layers[ix].bias_initializer\n","    \n","            old_weights, old_biases = model.layers[ix].get_weights()\n","    \n","            model.layers[ix].set_weights([\n","                weight_initializer(shape=old_weights.shape),\n","                bias_initializer(shape=len(old_biases))])            \n","    return model\n","\n","def reverse_tensor(X):\n","    return tf.gather(X, tf.reverse(tf.range(start=0, limit=tf.shape(X)[0], dtype=tf.int32),(0,)) )\n","\n","   \n","def get_confusion_matrix_classification(model, X, Y_true):\n","    y_pred = model.predict(X)\n","    y_true = np.apply_along_axis(np.argmax, 1, Y_true)\n","    y_pred = np.apply_along_axis(np.argmax, 1, y_pred)\n","    return (confusion_matrix(y_true, y_pred), y_pred, y_true)\n","\n","def misclass_perc_to_weight(input_confusion, add_base=True, func=None):\n","    perc_misclassified = 1.0 - np.array([ input_confusion[x,x] for x in np.arange(input_confusion.shape[0]).tolist() ])/input_confusion.sum(axis=1)\n","    \n","    base_val = min(perc_misclassified[perc_misclassified>0.0])\n","    if add_base:        \n","        perc_misclassified = perc_misclassified + base_val\n","    \n","    perc_misclassified = [ x/base_val for x in perc_misclassified]\n","    \n","    return dict([ (idx, func(perc_val)) if func is not None else (idx, perc_val) for idx, perc_val in enumerate(perc_misclassified) ])\n","\n","\n","def sparse_setdiff(a1, a2):\n","    a1a = a1.reshape(a1.shape[0], -1)\n","    a2a = a2.reshape(a2.shape[0], -1)\n","    spa2a = [np.where(x)[0].tolist() for x in a2a]\n","    spa1a = [np.where(x)[0].tolist() for x in a1a]\n","    idxs_to_keep = []\n","    for idx, sample in enumerate(spa1a):\n","        try:\n","            spa2a.index(sample)\n","        except ValueError:\n","            # not in list\n","            idxs_to_keep.append(idx)\n","    return a1[idxs_to_keep], idxs_to_keep\n"],"execution_count":54,"outputs":[]},{"cell_type":"code","metadata":{"id":"3rFUtecuyVcM","executionInfo":{"status":"ok","timestamp":1621452896533,"user_tz":-60,"elapsed":643,"user":{"displayName":"Hans Roggeman","photoUrl":"","userId":"10574434403170915342"}}},"source":["class DNNFeatureMergeModel(HyperModel):\n","    \n","    def __init__(self, model_name, input_shape, num_classes):\n","        self.input_shape = input_shape\n","        self.num_classes = num_classes\n","        self.model_name = model_name\n","\n","    def build(self, hp):\n","        inputs = tf.keras.Input(shape=self.input_shape)\n","        x = inputs\n","        for idx, i in enumerate(range(hp.Int('dense_blocks_with_normalizations', 1, 10, default=1))):\n","            if hp.Boolean(f'has_batchnormalization_{idx}', default=True):\n","                x = BatchNormalization()(x)\n","            x = Dense(units= hp.Choice(f'dense_block_nunits_{idx}', values=[16,32,64,128,256,512],default=128), \n","                      activation=hp.Choice(f'dense_activation_{idx}',\n","                                       values=['selu', 'gelu', 'elu', 'relu', 'tanh', 'linear'], default='relu'),\n","                  kernel_initializer=hp.Choice(f'dense_kernel_init_{idx}',\n","                                       values=['HeNormal', 'HeUniform','VarianceScaling', 'LecunNormal','LecunUniform', 'GlorotUniform', 'GlorotNormal', 'RandomNormal', 'Ones', 'Orthogonal'], default='RandomNormal'),\n","                  bias_initializer='zeros',\n","                  name=f'dense_{idx}')(x)\n","            if hp.Boolean(f'has_leakyrelu_{idx}', default=True):\n","                x = LeakyReLU()(x)\n","            if hp.Boolean(f'has_dropout_{idx}', default=True):\n","                x = Dropout(hp.Float(f'dense_dropout_value_{idx}',\n","                                 min_value=0.0,\n","                                 max_value=0.99,\n","                                 step=0.025,\n","                                 default=0.6\n","                                 ), name=f\"dense_dropout_{idx}\")(x)\n","        outputs = Dense(self.num_classes, activation='softmax', name=\"last_softmax\")(x)\n","        model = tf.keras.Model(inputs, outputs, name=self.model_name)\n","        if hp.Boolean('optimize_adam', default=True):\n","            model.compile(\n","                optimizer=tf.keras.optimizers.Adam(hp.Float('learning_rate', 1e-7, 0.5e-1, sampling='log')),\n","                loss='categorical_crossentropy',\n","                metrics=['accuracy'])\n","        else:\n","            model.compile(\n","                optimizer=hp.Choice('final_optimizer',\n","                                    values=['adam', 'SGD', 'RMSprop', 'Adadelta', 'Nadam', 'Adamax', 'Adagrad'],\n","                                    default='adam'),\n","                loss='categorical_crossentropy',\n","                metrics=['accuracy'])\n","        return model\n","    \n","\n","class BatchSizeTuner(kt.tuners.Hyperband):\n","   def run_trial(self, trial, *args, **kwargs):\n","#     # You can add additional HyperParameters for preprocessing and custom training loops via overriding `run_trial`\n","     kwargs['batch_size'] = trial.hyperparameters.Int('batch_size', 16, 256, step=32)\n","     super(BatchSizeTuner, self).run_trial(trial, *args, **kwargs)\n"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"YXaV9H9HGBj6","executionInfo":{"status":"ok","timestamp":1621462538027,"user_tz":-60,"elapsed":628,"user":{"displayName":"Hans Roggeman","photoUrl":"","userId":"10574434403170915342"}}},"source":["def model_combination(model_name, input_shape):\n","    model = Sequential([\n","        tf.keras.Input(shape=input_shape),\n","        BatchNormalization(),\n","        Dense(256, kernel_initializer='RandomNormal', bias_initializer='zeros'),\n","        LeakyReLU(),\n","        Dropout(0.6),\n","        #GaussianNoise(0.1),\n","        Dense(128, kernel_initializer='RandomNormal', bias_initializer='zeros', kernel_regularizer = tf.keras.regularizers.l1(1e-3)),\n","        LeakyReLU(),\n","        #Dense(32, kernel_initializer='RandomNormal', bias_initializer='zeros', kernel_regularizer = tf.keras.regularizers.l1(1e-2)),\n","        #LeakyReLU(),\n","        Dropout(0.6),\n","        Dense(32, kernel_initializer='RandomNormal', bias_initializer='zeros', kernel_regularizer = tf.keras.regularizers.l1(1e-2)),\n","        LeakyReLU(),\n","        Dropout(0.5),\n","        # Dense(128, kernel_initializer='RandomNormal', bias_initializer='zeros', kernel_regularizer = tf.keras.regularizers.l1(1e-2)),\n","        # LeakyReLU(),\n","        Dense(13, activation='softmax')\n","    ], name=model_name)\n","    return model"],"execution_count":71,"outputs":[]},{"cell_type":"code","metadata":{"id":"VM12SQkLykKU","executionInfo":{"status":"ok","timestamp":1621452909926,"user_tz":-60,"elapsed":10886,"user":{"displayName":"Hans Roggeman","photoUrl":"","userId":"10574434403170915342"}}},"source":["# 'new' data \n","X_train_1000e, Y_train_1000e, X_test_1000e, Y_test_1000e, X_val_1000e, Y_val_1000e = getE2eData(is500=False,\n","                                                                                                    include_secondary=False,\n","                                                                                                    isColab=True)\n","X_train_1000e_w2nd, Y_train_1000e_w2nd, X_test_1000e_w2nd, Y_test_1000e_w2nd, X_val_1000e_w2nd, Y_val_1000e_w2nd = getE2eData(is500=False, include_secondary=True, isColab=True)\n","X_train_1000e_j2nd, Y_train_1000e_j2nd, X_test_1000e_j2nd, Y_test_1000e_j2nd, X_val_1000e_j2nd, Y_val_1000e_j2nd = getE2eDataJustSecondary(isColab=True)"],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VRzhAOuY0B33","executionInfo":{"status":"ok","timestamp":1621452911485,"user_tz":-60,"elapsed":611,"user":{"displayName":"Hans Roggeman","photoUrl":"","userId":"10574434403170915342"}},"outputId":"86f51d05-ae26-4e53-e9bd-1b074a9908cd"},"source":["print (X_train_1000e.shape)\n","print (X_train_1000e_w2nd.shape)\n","print (X_train_1000e_j2nd.shape)"],"execution_count":13,"outputs":[{"output_type":"stream","text":["(6858, 1000, 8)\n","(6858, 1136, 12)\n","(6858, 1000, 3)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"TuiFwxcoziU9","executionInfo":{"status":"ok","timestamp":1621458229596,"user_tz":-60,"elapsed":655,"user":{"displayName":"Hans Roggeman","photoUrl":"","userId":"10574434403170915342"}}},"source":["    # merge into a new train:\n","    X_new_train = np.concatenate( (X_train_1000e, X_val_1000e), axis=0 )\n","    Y_new_train = np.concatenate( (Y_train_1000e, Y_val_1000e), axis=0 )    \n","    \n","    X_new_train_j2nd = np.concatenate( (X_train_1000e_j2nd, X_val_1000e_j2nd), axis=0 )\n","    Y_new_train_j2nd = np.concatenate( (Y_train_1000e_j2nd, Y_val_1000e_j2nd), axis=0 )    \n","\n","    X_new_train_w2nd = np.concatenate( (X_train_1000e_w2nd, X_val_1000e_w2nd), axis=0 )\n","    Y_new_train_w2nd = np.concatenate( (Y_train_1000e_w2nd, Y_val_1000e_w2nd), axis=0 )    \n"],"execution_count":56,"outputs":[]},{"cell_type":"code","metadata":{"id":"KSM_vupCcQf5"},"source":["    # CNNs no secondary\n","    mCNN1_1000 = load_model(\"./drive/MyDrive/data_papers/ncRNA/CNN_baseline_May16_e2e1000_256.h5\") # CNN on 256 1st dens\n","    mCNN1_1000._name = \"cnn_merged_newdata_finalist_1\"\n","\n","    mCNN2_1000 = load_model(\"./drive/MyDrive/data_papers/ncRNA/CNN_baseline_May16_e2e.h5\")   # CNN on 128 1st dens\n","    mCNN2_1000._name = \"cnn_merged_newdata_finalist_2\"\n","    \n","    mCNN_1000 = load_model(\"./drive/MyDrive/data_papers/ncRNA/cnn_noTest_20210516_model_445_0.998\")   # CNN on 128 1st dens\n","    mCNN_1000._name = \"cnn_merged_newdata_colab_finalist\"\n","    \n","    mCNN_1000 = load_model(\"./drive/MyDrive/data_papers/ncRNA/cnn_noTest_20210516_model_445_0.998\")   # CNN on 128 1st dens\n","    mCNN_1000._name = \"cnn_merged_newdata_colab_finalist\"\n","\n","    # RNN on the same data\n","    RNN_1000 = load_model(\"./drive/MyDrive/data_papers/ncRNA/RNN_baseline_17May_180.h5\", custom_objects=SeqWeightedAttention.get_custom_objects())   # RNN on 180ep 1000 ts\n","    RNN_1000._name = \"rnn_merged_newdata_colab_finalist\"\n","\n","    # CNN w/ secondary\n","    mCNN_1000_w2nd = load_model(\"./drive/MyDrive/data_papers/ncRNA/CNN_baseline_May16_e2e_secondary.h5\", custom_objects=SeqWeightedAttention.get_custom_objects())\n","    mCNN_1000_w2nd._name = \"cnn_merged_newdata_w_secondary_finalist\"\n","\n","    # CNN secondary only\n","    mCNN_1000_j2nd = load_model(\"./drive/MyDrive/data_papers/ncRNA/cnn_j2nd_noTest_20210516_model_488_0.990\", custom_objects=SeqWeightedAttention.get_custom_objects())\n","    mCNN_1000_j2nd._name = \"cnn_merged_newdata_j_secondary_finalist\"\n","    \n","    mCNN1_1000.evaluate(X_test_1000e, Y_test_1000e)  # 96.15% \n","    mCNN2_1000.evaluate(X_test_1000e, Y_test_1000e)  # 95.80 %  \n","    mCNN_1000.evaluate(X_test_1000e, Y_test_1000e)  # 95.57% \n","    mCNN_1000_w2nd.evaluate(X_test_1000e_w2nd, Y_test_1000e_w2nd)  # 94.64 %\n","    mCNN_1000_j2nd.evaluate(X_test_1000e_j2nd, Y_test_1000e_j2nd)  # 72.96 %\n","    RNN_1000.evaluate(X_test_1000e, Y_test_1000e)  # 95.45 %"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"EZX5glv1E0w2"},"source":[" tf.keras.utils.plot_model(RNN_1000, show_shapes=True)  ## , to_file=\"C:/temp/test.png\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"yBTr_vs33xmj","executionInfo":{"status":"ok","timestamp":1621459222643,"user_tz":-60,"elapsed":329701,"user":{"displayName":"Hans Roggeman","photoUrl":"","userId":"10574434403170915342"}}},"source":["    to_combine_last_layers_no2nd_j2nd = [\n","        (mCNN1_1000, \"dense_26\", None),\n","        (mCNN2_1000, \"dense_14\", None),\n","        (mCNN_1000_j2nd,\"dense_5\", None)\n","    ]\n","\n","    combined_models_no2nd_j2nd, data_train_ll_no2nd_j2nd, data_test_ll_no2nd_j2nd, data_access_ll_no2nd_j2nd = get_combined_features_from_models(\n","        to_combine_last_layers_no2nd_j2nd,\n","        [ X_new_train, X_new_train, X_new_train_j2nd],\n","        [ Y_new_train, Y_new_train, Y_new_train_j2nd], \n","        [ X_test_1000e, X_test_1000e, X_test_1000e_j2nd],\n","        [ Y_test_1000e, Y_test_1000e, Y_test_1000e_j2nd],\n","        reverse_one_hot=False)\n","\n","    to_combine_last_layers_no2nd_j2nd_rNo2nd = [\n","        (mCNN1_1000, \"dense_26\", None),\n","        (mCNN_1000_j2nd,\"dense_5\", None),\n","        (RNN_1000,\"dense_3\", None)\n","    ]\n","\n","    combined_models_no2nd_j2nd_rNo2nd, data_train_ll_no2nd_j2nd_rNo2nd, data_test_ll_no2nd_j2nd_rNo2nd, data_access_ll_no2nd_j2nd_rNo2nd = get_combined_features_from_models(\n","        to_combine_last_layers_no2nd_j2nd_rNo2nd,\n","        [ X_new_train, X_new_train_j2nd, X_new_train],\n","        [ Y_new_train, Y_new_train_j2nd, Y_new_train], \n","        [ X_test_1000e, X_test_1000e_j2nd, X_test_1000e],\n","        [ Y_test_1000e, Y_test_1000e_j2nd, Y_test_1000e],\n","        reverse_one_hot=False)\n"],"execution_count":59,"outputs":[]},{"cell_type":"code","metadata":{"id":"f7tUUs1MSkyr","executionInfo":{"status":"ok","timestamp":1621459552468,"user_tz":-60,"elapsed":329808,"user":{"displayName":"Hans Roggeman","photoUrl":"","userId":"10574434403170915342"}}},"source":["    to_combine_penul_layers_no2nd_j2nd = [\n","        (mCNN1_1000, \"dense_25\", None),\n","        (mCNN2_1000, \"dense_13\", None),\n","        (mCNN_1000_j2nd,\"dense_4\", None)\n","    ]\n","\n","    combined_models_penul_no2nd_j2nd, data_train_ll_penul_no2nd_j2nd, data_test_ll_penul_no2nd_j2nd, data_access_ll_penul_no2nd_j2nd = get_combined_features_from_models(\n","        to_combine_penul_layers_no2nd_j2nd,\n","        [ X_new_train, X_new_train, X_new_train_j2nd],\n","        [ Y_new_train, Y_new_train, Y_new_train_j2nd], \n","        [ X_test_1000e, X_test_1000e, X_test_1000e_j2nd],\n","        [ Y_test_1000e, Y_test_1000e, Y_test_1000e_j2nd],\n","        reverse_one_hot=False)\n","\n","    to_combine_penul_layers_no2nd_j2nd_rNo2nd = [\n","        (mCNN1_1000, \"dense_25\", None),\n","        (mCNN_1000_j2nd,\"dense_4\", None),\n","        (RNN_1000,\"dense_2\", None)\n","    ]\n","\n","    combined_models_penul_no2nd_j2nd_rNo2nd, data_train_ll_penul_no2nd_j2nd_rNo2nd, data_test_ll_penul_no2nd_j2nd_rNo2nd, data_access_ll_penul_no2nd_j2nd_rNo2nd = get_combined_features_from_models(\n","        to_combine_penul_layers_no2nd_j2nd_rNo2nd,\n","        [ X_new_train, X_new_train_j2nd, X_new_train],\n","        [ Y_new_train, Y_new_train_j2nd, Y_new_train], \n","        [ X_test_1000e, X_test_1000e_j2nd, X_test_1000e],\n","        [ Y_test_1000e, Y_test_1000e_j2nd, Y_test_1000e],\n","        reverse_one_hot=False)\n"],"execution_count":60,"outputs":[]},{"cell_type":"code","metadata":{"id":"zIXl45RwsESg","executionInfo":{"status":"ok","timestamp":1621463629962,"user_tz":-60,"elapsed":634663,"user":{"displayName":"Hans Roggeman","photoUrl":"","userId":"10574434403170915342"}}},"source":["    to_combine_last_layers_no2nd_rNo2nd = [\n","        (mCNN1_1000, \"dense_26\", None),\n","        (RNN_1000,\"dense_3\", None)\n","    ]\n","\n","    combined_models_no2nd_rNo2nd, data_train_ll_no2nd_rNo2nd, data_test_ll_no2nd_rNo2nd, data_access_ll_no2nd_rNo2nd = get_combined_features_from_models(\n","        to_combine_last_layers_no2nd_rNo2nd,\n","        [ X_new_train, X_new_train],\n","        [ Y_new_train,  Y_new_train], \n","        [ X_test_1000e,  X_test_1000e],\n","        [ Y_test_1000e,  Y_test_1000e],\n","        reverse_one_hot=False)\n","    \n","    to_combine_penul_layers_no2nd_rNo2nd = [\n","        (mCNN1_1000, \"dense_25\", None),\n","        (RNN_1000,\"dense_2\", None)\n","    ]\n","\n","    combined_models_no2nd_rNo2nd_penul, data_train_penul_no2nd_rNo2nd, data_test_penul_no2nd_rNo2nd, data_access_penul_no2nd_rNo2nd = get_combined_features_from_models(\n","        to_combine_penul_layers_no2nd_rNo2nd,\n","        [ X_new_train, X_new_train],\n","        [ Y_new_train,  Y_new_train], \n","        [ X_test_1000e,  X_test_1000e],\n","        [ Y_test_1000e,  Y_test_1000e],\n","        reverse_one_hot=False)\n","\n"],"execution_count":73,"outputs":[]},{"cell_type":"code","metadata":{"id":"FNznmg7fs-Vz"},"source":["rcnn_combine_models_no2nd_rNo2nd = model_combination(\"combine_rcnns_no2nd_rNo2nd_into_dense\", data_train_ll_no2nd_rNo2nd[0][0].shape  )\n","rcnn_combine_models_no2nd_rNo2nd.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])  \n","callbacks_used_rcnn_combine_no2nd_rNo2nd = [ModelCheckpoint(f'{rcnn_combine_models_no2nd_rNo2nd.name}' + '_model_{epoch:03d}_{accuracy:0.3f}',\n","                                            save_weights_only=False,\n","                                            monitor='accuracy',\n","                                            mode='max',\n","                                            save_best_only=True),\n","                    tf.keras.callbacks.EarlyStopping(patience=10)\n","                    ]\n","rcnn_combine_models_no2nd_rNo2nd.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n","history_rcnn_combine_no2nd_rNo2nd = rcnn_combine_models_no2nd_rNo2nd.fit(data_train_ll_no2nd_rNo2nd[0], \n","                                              data_train_ll_no2nd_rNo2nd[1][0], \n","                                              callbacks=callbacks_used_rcnn_combine_no2nd_rNo2nd, \n","                                              verbose=2, \n","                                              epochs = 500, \n","                                              batch_size=64)\n","  \n","rcnn_combine_models_no2nd_rNo2nd.evaluate(data_test_ll_no2nd_rNo2nd[0],data_test_ll_no2nd_rNo2nd[1][0]) # 96.39%"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3GtnjjGRt_Yx","executionInfo":{"status":"ok","timestamp":1621464112635,"user_tz":-60,"elapsed":176153,"user":{"displayName":"Hans Roggeman","photoUrl":"","userId":"10574434403170915342"}},"outputId":"722427ce-ec04-4534-fdf0-c43def336b78"},"source":["rcnn_combine_penul_models_no2nd_rNo2nd = model_combination(\"combine_rcnns_penul_no2nd_rNo2nd_into_dense\", data_train_penul_no2nd_rNo2nd[0][0].shape  )\n","rcnn_combine_penul_models_no2nd_rNo2nd.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])  \n","callbacks_used_rcnn_combine_penul_no2nd_rNo2nd = [ModelCheckpoint(f'{rcnn_combine_penul_models_no2nd_rNo2nd.name}' + '_model_{epoch:03d}_{accuracy:0.3f}',\n","                                            save_weights_only=False,\n","                                            monitor='accuracy',\n","                                            mode='max',\n","                                            save_best_only=True),\n","                    tf.keras.callbacks.EarlyStopping(patience=10)\n","                    ]\n","rcnn_combine_penul_models_no2nd_rNo2nd.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n","history_rcnn_combine_penul_no2nd_rNo2nd = rcnn_combine_penul_models_no2nd_rNo2nd.fit(data_train_penul_no2nd_rNo2nd[0], \n","                                              data_train_penul_no2nd_rNo2nd[1][0], \n","                                              callbacks=callbacks_used_rcnn_combine_penul_no2nd_rNo2nd, \n","                                              verbose=2, \n","                                              epochs = 500, \n","                                              batch_size=64)\n","  \n","rcnn_combine_penul_models_no2nd_rNo2nd.evaluate(data_test_penul_no2nd_rNo2nd[0],data_test_penul_no2nd_rNo2nd[1][0]) # 97.20%"],"execution_count":75,"outputs":[{"output_type":"stream","text":["Epoch 1/500\n","121/121 - 1s - loss: 2.9331 - accuracy: 0.7667\n","INFO:tensorflow:Assets written to: combine_rcnns_penul_no2nd_rNo2nd_into_dense_model_001_0.767/assets\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 2/500\n","121/121 - 0s - loss: 1.3653 - accuracy: 0.9488\n","INFO:tensorflow:Assets written to: combine_rcnns_penul_no2nd_rNo2nd_into_dense_model_002_0.949/assets\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 3/500\n","121/121 - 0s - loss: 0.9618 - accuracy: 0.9651\n","INFO:tensorflow:Assets written to: combine_rcnns_penul_no2nd_rNo2nd_into_dense_model_003_0.965/assets\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 4/500\n","121/121 - 0s - loss: 0.7943 - accuracy: 0.9717\n","INFO:tensorflow:Assets written to: combine_rcnns_penul_no2nd_rNo2nd_into_dense_model_004_0.972/assets\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 5/500\n","121/121 - 0s - loss: 0.6967 - accuracy: 0.9765\n","INFO:tensorflow:Assets written to: combine_rcnns_penul_no2nd_rNo2nd_into_dense_model_005_0.977/assets\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 6/500\n","121/121 - 0s - loss: 0.6326 - accuracy: 0.9776\n","INFO:tensorflow:Assets written to: combine_rcnns_penul_no2nd_rNo2nd_into_dense_model_006_0.978/assets\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 7/500\n","121/121 - 0s - loss: 0.5761 - accuracy: 0.9820\n","INFO:tensorflow:Assets written to: combine_rcnns_penul_no2nd_rNo2nd_into_dense_model_007_0.982/assets\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 8/500\n","121/121 - 0s - loss: 0.5461 - accuracy: 0.9815\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 9/500\n","121/121 - 0s - loss: 0.5280 - accuracy: 0.9797\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 10/500\n","121/121 - 0s - loss: 0.4992 - accuracy: 0.9817\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 11/500\n","121/121 - 0s - loss: 0.4849 - accuracy: 0.9847\n","INFO:tensorflow:Assets written to: combine_rcnns_penul_no2nd_rNo2nd_into_dense_model_011_0.985/assets\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 12/500\n","121/121 - 0s - loss: 0.4856 - accuracy: 0.9833\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 13/500\n","121/121 - 0s - loss: 0.4545 - accuracy: 0.9866\n","INFO:tensorflow:Assets written to: combine_rcnns_penul_no2nd_rNo2nd_into_dense_model_013_0.987/assets\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 14/500\n","121/121 - 0s - loss: 0.4339 - accuracy: 0.9869\n","INFO:tensorflow:Assets written to: combine_rcnns_penul_no2nd_rNo2nd_into_dense_model_014_0.987/assets\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 15/500\n","121/121 - 0s - loss: 0.4395 - accuracy: 0.9843\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 16/500\n","121/121 - 0s - loss: 0.4491 - accuracy: 0.9851\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 17/500\n","121/121 - 0s - loss: 0.4268 - accuracy: 0.9835\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 18/500\n","121/121 - 0s - loss: 0.4573 - accuracy: 0.9816\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 19/500\n","121/121 - 0s - loss: 0.4169 - accuracy: 0.9879\n","INFO:tensorflow:Assets written to: combine_rcnns_penul_no2nd_rNo2nd_into_dense_model_019_0.988/assets\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 20/500\n","121/121 - 0s - loss: 0.3908 - accuracy: 0.9881\n","INFO:tensorflow:Assets written to: combine_rcnns_penul_no2nd_rNo2nd_into_dense_model_020_0.988/assets\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 21/500\n","121/121 - 0s - loss: 0.4094 - accuracy: 0.9856\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 22/500\n","121/121 - 0s - loss: 0.3887 - accuracy: 0.9861\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 23/500\n","121/121 - 0s - loss: 0.3931 - accuracy: 0.9870\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 24/500\n","121/121 - 0s - loss: 0.4038 - accuracy: 0.9841\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 25/500\n","121/121 - 0s - loss: 0.4283 - accuracy: 0.9831\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 26/500\n","121/121 - 0s - loss: 0.3910 - accuracy: 0.9863\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 27/500\n","121/121 - 0s - loss: 0.3805 - accuracy: 0.9856\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 28/500\n","121/121 - 0s - loss: 0.4245 - accuracy: 0.9850\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 29/500\n","121/121 - 0s - loss: 0.4173 - accuracy: 0.9856\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 30/500\n","121/121 - 0s - loss: 0.4030 - accuracy: 0.9861\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 31/500\n","121/121 - 0s - loss: 0.4048 - accuracy: 0.9860\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 32/500\n","121/121 - 0s - loss: 0.4241 - accuracy: 0.9819\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 33/500\n","121/121 - 0s - loss: 0.4600 - accuracy: 0.9807\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 34/500\n","121/121 - 0s - loss: 0.4660 - accuracy: 0.9812\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 35/500\n","121/121 - 0s - loss: 0.3900 - accuracy: 0.9881\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 36/500\n","121/121 - 0s - loss: 0.3614 - accuracy: 0.9895\n","INFO:tensorflow:Assets written to: combine_rcnns_penul_no2nd_rNo2nd_into_dense_model_036_0.990/assets\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 37/500\n","121/121 - 0s - loss: 0.4171 - accuracy: 0.9811\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 38/500\n","121/121 - 0s - loss: 0.4089 - accuracy: 0.9855\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 39/500\n","121/121 - 0s - loss: 0.3934 - accuracy: 0.9869\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 40/500\n","121/121 - 0s - loss: 0.4019 - accuracy: 0.9841\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 41/500\n","121/121 - 0s - loss: 0.3939 - accuracy: 0.9857\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 42/500\n","121/121 - 0s - loss: 0.3436 - accuracy: 0.9899\n","INFO:tensorflow:Assets written to: combine_rcnns_penul_no2nd_rNo2nd_into_dense_model_042_0.990/assets\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 43/500\n","121/121 - 0s - loss: 0.3097 - accuracy: 0.9914\n","INFO:tensorflow:Assets written to: combine_rcnns_penul_no2nd_rNo2nd_into_dense_model_043_0.991/assets\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 44/500\n","121/121 - 0s - loss: 0.3972 - accuracy: 0.9794\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 45/500\n","121/121 - 0s - loss: 0.5877 - accuracy: 0.9736\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 46/500\n","121/121 - 0s - loss: 0.8884 - accuracy: 0.9676\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 47/500\n","121/121 - 0s - loss: 0.9811 - accuracy: 0.9791\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 48/500\n","121/121 - 0s - loss: 0.8677 - accuracy: 0.9800\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 49/500\n","121/121 - 0s - loss: 0.6889 - accuracy: 0.9860\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 50/500\n","121/121 - 0s - loss: 0.5538 - accuracy: 0.9848\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 51/500\n","121/121 - 0s - loss: 0.4578 - accuracy: 0.9873\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 52/500\n","121/121 - 0s - loss: 0.3582 - accuracy: 0.9916\n","INFO:tensorflow:Assets written to: combine_rcnns_penul_no2nd_rNo2nd_into_dense_model_052_0.992/assets\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 53/500\n","121/121 - 0s - loss: 0.3186 - accuracy: 0.9942\n","INFO:tensorflow:Assets written to: combine_rcnns_penul_no2nd_rNo2nd_into_dense_model_053_0.994/assets\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 54/500\n","121/121 - 0s - loss: 0.3092 - accuracy: 0.9909\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 55/500\n","121/121 - 0s - loss: 0.3189 - accuracy: 0.9913\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 56/500\n","121/121 - 0s - loss: 0.2784 - accuracy: 0.9935\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 57/500\n","121/121 - 0s - loss: 0.2884 - accuracy: 0.9931\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 58/500\n","121/121 - 0s - loss: 0.2853 - accuracy: 0.9918\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 59/500\n","121/121 - 0s - loss: 0.3235 - accuracy: 0.9883\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 60/500\n","121/121 - 0s - loss: 0.3987 - accuracy: 0.9830\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 61/500\n","121/121 - 0s - loss: 0.4327 - accuracy: 0.9841\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 62/500\n","121/121 - 0s - loss: 0.5008 - accuracy: 0.9765\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 63/500\n","121/121 - 0s - loss: 0.7050 - accuracy: 0.9723\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 64/500\n","121/121 - 0s - loss: 0.9358 - accuracy: 0.9734\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 65/500\n","121/121 - 0s - loss: 0.9063 - accuracy: 0.9809\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 66/500\n","121/121 - 0s - loss: 0.7692 - accuracy: 0.9857\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 67/500\n","121/121 - 0s - loss: 0.6202 - accuracy: 0.9857\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 68/500\n","121/121 - 0s - loss: 0.5014 - accuracy: 0.9877\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 69/500\n","121/121 - 0s - loss: 0.3926 - accuracy: 0.9931\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 70/500\n","121/121 - 0s - loss: 0.3128 - accuracy: 0.9943\n","INFO:tensorflow:Assets written to: combine_rcnns_penul_no2nd_rNo2nd_into_dense_model_070_0.994/assets\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 71/500\n","121/121 - 0s - loss: 0.2908 - accuracy: 0.9946\n","INFO:tensorflow:Assets written to: combine_rcnns_penul_no2nd_rNo2nd_into_dense_model_071_0.995/assets\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 72/500\n","121/121 - 0s - loss: 0.2632 - accuracy: 0.9968\n","INFO:tensorflow:Assets written to: combine_rcnns_penul_no2nd_rNo2nd_into_dense_model_072_0.997/assets\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 73/500\n","121/121 - 0s - loss: 0.2701 - accuracy: 0.9929\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 74/500\n","121/121 - 0s - loss: 0.2693 - accuracy: 0.9936\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 75/500\n","121/121 - 0s - loss: 0.3169 - accuracy: 0.9856\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 76/500\n","121/121 - 0s - loss: 0.4647 - accuracy: 0.9780\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 77/500\n","121/121 - 0s - loss: 0.5292 - accuracy: 0.9789\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 78/500\n","121/121 - 0s - loss: 0.6408 - accuracy: 0.9752\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 79/500\n","121/121 - 0s - loss: 0.6572 - accuracy: 0.9802\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 80/500\n","121/121 - 0s - loss: 0.5854 - accuracy: 0.9824\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 81/500\n","121/121 - 0s - loss: 0.5009 - accuracy: 0.9825\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 82/500\n","121/121 - 0s - loss: 0.3890 - accuracy: 0.9916\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 83/500\n","121/121 - 0s - loss: 0.3243 - accuracy: 0.9925\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 84/500\n","121/121 - 0s - loss: 0.2909 - accuracy: 0.9922\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 85/500\n","121/121 - 0s - loss: 0.2809 - accuracy: 0.9927\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 86/500\n","121/121 - 0s - loss: 0.2627 - accuracy: 0.9929\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 87/500\n","121/121 - 0s - loss: 0.2779 - accuracy: 0.9927\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 88/500\n","121/121 - 0s - loss: 0.2479 - accuracy: 0.9949\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 89/500\n","121/121 - 0s - loss: 0.2845 - accuracy: 0.9901\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 90/500\n","121/121 - 0s - loss: 0.4212 - accuracy: 0.9750\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 91/500\n","121/121 - 0s - loss: 0.9045 - accuracy: 0.9663\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 92/500\n","121/121 - 0s - loss: 1.2887 - accuracy: 0.9724\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 93/500\n","121/121 - 0s - loss: 1.2695 - accuracy: 0.9782\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 94/500\n","121/121 - 0s - loss: 1.1149 - accuracy: 0.9861\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 95/500\n","121/121 - 0s - loss: 0.9484 - accuracy: 0.9886\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 96/500\n","121/121 - 0s - loss: 0.8109 - accuracy: 0.9890\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 97/500\n","121/121 - 0s - loss: 0.6978 - accuracy: 0.9895\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 98/500\n","121/121 - 0s - loss: 0.5656 - accuracy: 0.9916\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 99/500\n","121/121 - 0s - loss: 0.4921 - accuracy: 0.9885\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 100/500\n","121/121 - 0s - loss: 0.4145 - accuracy: 0.9903\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 101/500\n","121/121 - 0s - loss: 0.3757 - accuracy: 0.9917\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 102/500\n","121/121 - 0s - loss: 0.3241 - accuracy: 0.9946\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 103/500\n","121/121 - 0s - loss: 0.2882 - accuracy: 0.9949\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 104/500\n","121/121 - 0s - loss: 0.2662 - accuracy: 0.9960\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 105/500\n","121/121 - 0s - loss: 0.2631 - accuracy: 0.9949\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 106/500\n","121/121 - 0s - loss: 0.2547 - accuracy: 0.9949\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 107/500\n","121/121 - 0s - loss: 0.2487 - accuracy: 0.9926\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 108/500\n","121/121 - 0s - loss: 0.2613 - accuracy: 0.9924\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 109/500\n","121/121 - 0s - loss: 0.2497 - accuracy: 0.9936\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 110/500\n","121/121 - 0s - loss: 0.2817 - accuracy: 0.9898\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 111/500\n","121/121 - 0s - loss: 0.2712 - accuracy: 0.9940\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 112/500\n","121/121 - 0s - loss: 0.2553 - accuracy: 0.9927\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 113/500\n","121/121 - 0s - loss: 0.3369 - accuracy: 0.9844\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 114/500\n","121/121 - 0s - loss: 0.4219 - accuracy: 0.9829\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 115/500\n","121/121 - 0s - loss: 0.5839 - accuracy: 0.9723\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 116/500\n","121/121 - 0s - loss: 0.8792 - accuracy: 0.9693\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 117/500\n","121/121 - 0s - loss: 1.0604 - accuracy: 0.9741\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 118/500\n","121/121 - 0s - loss: 1.0312 - accuracy: 0.9819\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 119/500\n","121/121 - 0s - loss: 0.9271 - accuracy: 0.9851\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 120/500\n","121/121 - 0s - loss: 0.7952 - accuracy: 0.9872\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 121/500\n","121/121 - 0s - loss: 0.7032 - accuracy: 0.9874\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 122/500\n","121/121 - 0s - loss: 0.5998 - accuracy: 0.9869\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 123/500\n","121/121 - 0s - loss: 0.5156 - accuracy: 0.9878\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 124/500\n","121/121 - 0s - loss: 0.4326 - accuracy: 0.9881\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 125/500\n","121/121 - 0s - loss: 0.3670 - accuracy: 0.9908\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 126/500\n","121/121 - 0s - loss: 0.3056 - accuracy: 0.9925\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 127/500\n","121/121 - 0s - loss: 0.2760 - accuracy: 0.9948\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 128/500\n","121/121 - 0s - loss: 0.2555 - accuracy: 0.9957\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 129/500\n","121/121 - 0s - loss: 0.2498 - accuracy: 0.9944\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 130/500\n","121/121 - 0s - loss: 0.2521 - accuracy: 0.9938\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 131/500\n","121/121 - 0s - loss: 0.2429 - accuracy: 0.9947\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 132/500\n","121/121 - 0s - loss: 0.2642 - accuracy: 0.9925\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 133/500\n","121/121 - 0s - loss: 0.2828 - accuracy: 0.9896\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 134/500\n","121/121 - 0s - loss: 0.2695 - accuracy: 0.9927\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 135/500\n","121/121 - 0s - loss: 0.2590 - accuracy: 0.9940\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 136/500\n","121/121 - 0s - loss: 0.2461 - accuracy: 0.9942\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 137/500\n","121/121 - 0s - loss: 0.2704 - accuracy: 0.9907\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 138/500\n","121/121 - 0s - loss: 0.4172 - accuracy: 0.9780\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 139/500\n","121/121 - 0s - loss: 0.8729 - accuracy: 0.9651\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 140/500\n","121/121 - 0s - loss: 1.3165 - accuracy: 0.9723\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 141/500\n","121/121 - 0s - loss: 1.3191 - accuracy: 0.9803\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 142/500\n","121/121 - 0s - loss: 1.2082 - accuracy: 0.9855\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 143/500\n","121/121 - 0s - loss: 1.0267 - accuracy: 0.9914\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 144/500\n","121/121 - 0s - loss: 0.8462 - accuracy: 0.9918\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 145/500\n","121/121 - 0s - loss: 0.7693 - accuracy: 0.9887\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 146/500\n","121/121 - 0s - loss: 0.6710 - accuracy: 0.9870\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 147/500\n","121/121 - 0s - loss: 0.5733 - accuracy: 0.9901\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 148/500\n","121/121 - 0s - loss: 0.4603 - accuracy: 0.9924\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 149/500\n","121/121 - 0s - loss: 0.3988 - accuracy: 0.9900\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 150/500\n","121/121 - 0s - loss: 0.3409 - accuracy: 0.9943\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 151/500\n","121/121 - 0s - loss: 0.3094 - accuracy: 0.9927\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 152/500\n","121/121 - 0s - loss: 0.2892 - accuracy: 0.9943\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 153/500\n","121/121 - 0s - loss: 0.2918 - accuracy: 0.9924\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 154/500\n","121/121 - 0s - loss: 0.2881 - accuracy: 0.9924\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 155/500\n","121/121 - 0s - loss: 0.2628 - accuracy: 0.9949\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 156/500\n","121/121 - 0s - loss: 0.2665 - accuracy: 0.9904\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 157/500\n","121/121 - 0s - loss: 0.2462 - accuracy: 0.9935\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 158/500\n","121/121 - 0s - loss: 0.2489 - accuracy: 0.9933\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 159/500\n","121/121 - 0s - loss: 0.2724 - accuracy: 0.9904\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 160/500\n","121/121 - 0s - loss: 0.3347 - accuracy: 0.9877\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 161/500\n","121/121 - 0s - loss: 0.3944 - accuracy: 0.9848\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 162/500\n","121/121 - 0s - loss: 0.3984 - accuracy: 0.9861\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 163/500\n","121/121 - 0s - loss: 0.5316 - accuracy: 0.9754\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 164/500\n","121/121 - 0s - loss: 0.8438 - accuracy: 0.9703\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 165/500\n","121/121 - 0s - loss: 0.9893 - accuracy: 0.9765\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 166/500\n","121/121 - 0s - loss: 0.9207 - accuracy: 0.9830\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 167/500\n","121/121 - 0s - loss: 0.8369 - accuracy: 0.9855\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 168/500\n","121/121 - 0s - loss: 0.7722 - accuracy: 0.9847\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 169/500\n","121/121 - 0s - loss: 0.6345 - accuracy: 0.9901\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 170/500\n","121/121 - 0s - loss: 0.5384 - accuracy: 0.9878\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 171/500\n","121/121 - 0s - loss: 0.4222 - accuracy: 0.9925\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 172/500\n","121/121 - 0s - loss: 0.3414 - accuracy: 0.9935\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 173/500\n","121/121 - 0s - loss: 0.2973 - accuracy: 0.9939\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 174/500\n","121/121 - 0s - loss: 0.2710 - accuracy: 0.9956\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 175/500\n","121/121 - 0s - loss: 0.2633 - accuracy: 0.9935\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 176/500\n","121/121 - 0s - loss: 0.2658 - accuracy: 0.9951\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 177/500\n","121/121 - 0s - loss: 0.2398 - accuracy: 0.9957\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 178/500\n","121/121 - 0s - loss: 0.2404 - accuracy: 0.9939\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 179/500\n","121/121 - 0s - loss: 0.2722 - accuracy: 0.9899\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 180/500\n","121/121 - 0s - loss: 0.3427 - accuracy: 0.9864\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 181/500\n","121/121 - 0s - loss: 0.4030 - accuracy: 0.9839\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 182/500\n","121/121 - 0s - loss: 0.4100 - accuracy: 0.9857\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 183/500\n","121/121 - 0s - loss: 0.3992 - accuracy: 0.9864\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 184/500\n","121/121 - 0s - loss: 0.4232 - accuracy: 0.9820\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 185/500\n","121/121 - 0s - loss: 0.3954 - accuracy: 0.9885\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 186/500\n","121/121 - 0s - loss: 0.3747 - accuracy: 0.9877\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 187/500\n","121/121 - 0s - loss: 0.3337 - accuracy: 0.9909\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 188/500\n","121/121 - 0s - loss: 0.3154 - accuracy: 0.9905\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 189/500\n","121/121 - 0s - loss: 0.3486 - accuracy: 0.9877\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 190/500\n","121/121 - 0s - loss: 0.3837 - accuracy: 0.9846\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 191/500\n","121/121 - 0s - loss: 0.4088 - accuracy: 0.9822\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 192/500\n","121/121 - 0s - loss: 0.4697 - accuracy: 0.9815\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 193/500\n","121/121 - 0s - loss: 0.6403 - accuracy: 0.9738\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 194/500\n","121/121 - 0s - loss: 1.0652 - accuracy: 0.9680\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 195/500\n","121/121 - 0s - loss: 1.1732 - accuracy: 0.9804\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 196/500\n","121/121 - 0s - loss: 1.0638 - accuracy: 0.9859\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 197/500\n","121/121 - 0s - loss: 0.9641 - accuracy: 0.9864\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 198/500\n","121/121 - 0s - loss: 0.8717 - accuracy: 0.9859\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 199/500\n","121/121 - 0s - loss: 0.7438 - accuracy: 0.9904\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 200/500\n","121/121 - 0s - loss: 0.6017 - accuracy: 0.9920\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 201/500\n","121/121 - 0s - loss: 0.5117 - accuracy: 0.9905\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 202/500\n","121/121 - 0s - loss: 0.4245 - accuracy: 0.9925\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 203/500\n","121/121 - 0s - loss: 0.3456 - accuracy: 0.9944\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 204/500\n","121/121 - 0s - loss: 0.3044 - accuracy: 0.9944\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 205/500\n","121/121 - 0s - loss: 0.2712 - accuracy: 0.9959\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 206/500\n","121/121 - 0s - loss: 0.2585 - accuracy: 0.9948\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 207/500\n","121/121 - 0s - loss: 0.2561 - accuracy: 0.9944\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 208/500\n","121/121 - 0s - loss: 0.2762 - accuracy: 0.9917\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 209/500\n","121/121 - 0s - loss: 0.2479 - accuracy: 0.9953\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 210/500\n","121/121 - 0s - loss: 0.2546 - accuracy: 0.9918\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 211/500\n","121/121 - 0s - loss: 0.3154 - accuracy: 0.9864\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 212/500\n","121/121 - 0s - loss: 0.3286 - accuracy: 0.9907\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 213/500\n","121/121 - 0s - loss: 0.3131 - accuracy: 0.9898\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 214/500\n","121/121 - 0s - loss: 0.3048 - accuracy: 0.9901\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 215/500\n","121/121 - 0s - loss: 0.3740 - accuracy: 0.9846\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 216/500\n","121/121 - 0s - loss: 0.5156 - accuracy: 0.9763\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 217/500\n","121/121 - 0s - loss: 0.6326 - accuracy: 0.9750\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 218/500\n","121/121 - 0s - loss: 0.6900 - accuracy: 0.9798\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 219/500\n","121/121 - 0s - loss: 0.6046 - accuracy: 0.9859\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 220/500\n","121/121 - 0s - loss: 0.5191 - accuracy: 0.9859\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 221/500\n","121/121 - 0s - loss: 0.4761 - accuracy: 0.9843\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 222/500\n","121/121 - 0s - loss: 0.4363 - accuracy: 0.9869\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 223/500\n","121/121 - 0s - loss: 0.3837 - accuracy: 0.9892\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 224/500\n","121/121 - 0s - loss: 0.3180 - accuracy: 0.9914\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 225/500\n","121/121 - 0s - loss: 0.2678 - accuracy: 0.9947\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 226/500\n","121/121 - 0s - loss: 0.2425 - accuracy: 0.9943\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 227/500\n","121/121 - 0s - loss: 0.2406 - accuracy: 0.9938\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 228/500\n","121/121 - 0s - loss: 0.2425 - accuracy: 0.9957\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 229/500\n","121/121 - 0s - loss: 0.2359 - accuracy: 0.9949\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 230/500\n","121/121 - 0s - loss: 0.2342 - accuracy: 0.9953\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 231/500\n","121/121 - 0s - loss: 0.2264 - accuracy: 0.9929\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 232/500\n","121/121 - 0s - loss: 0.4473 - accuracy: 0.9750\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 233/500\n","121/121 - 0s - loss: 1.1062 - accuracy: 0.9663\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 234/500\n","121/121 - 0s - loss: 1.4042 - accuracy: 0.9773\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 235/500\n","121/121 - 0s - loss: 1.3001 - accuracy: 0.9855\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 236/500\n","121/121 - 0s - loss: 1.1893 - accuracy: 0.9859\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 237/500\n","121/121 - 0s - loss: 1.0723 - accuracy: 0.9868\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 238/500\n","121/121 - 0s - loss: 1.0031 - accuracy: 0.9872\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 239/500\n","121/121 - 0s - loss: 0.8925 - accuracy: 0.9898\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 240/500\n","121/121 - 0s - loss: 0.7757 - accuracy: 0.9908\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 241/500\n","121/121 - 0s - loss: 0.6811 - accuracy: 0.9911\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 242/500\n","121/121 - 0s - loss: 0.5851 - accuracy: 0.9913\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 243/500\n","121/121 - 0s - loss: 0.4960 - accuracy: 0.9911\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 244/500\n","121/121 - 0s - loss: 0.4107 - accuracy: 0.9920\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 245/500\n","121/121 - 0s - loss: 0.3507 - accuracy: 0.9933\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 246/500\n","121/121 - 0s - loss: 0.3146 - accuracy: 0.9948\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 247/500\n","121/121 - 0s - loss: 0.2788 - accuracy: 0.9946\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 248/500\n","121/121 - 0s - loss: 0.2819 - accuracy: 0.9936\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 249/500\n","121/121 - 0s - loss: 0.2639 - accuracy: 0.9949\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 250/500\n","121/121 - 0s - loss: 0.2396 - accuracy: 0.9936\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 251/500\n","121/121 - 0s - loss: 0.2580 - accuracy: 0.9925\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 252/500\n","121/121 - 0s - loss: 0.2660 - accuracy: 0.9931\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 253/500\n","121/121 - 0s - loss: 0.2410 - accuracy: 0.9957\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 254/500\n","121/121 - 0s - loss: 0.2401 - accuracy: 0.9943\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 255/500\n","121/121 - 0s - loss: 0.2416 - accuracy: 0.9947\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 256/500\n","121/121 - 0s - loss: 0.2943 - accuracy: 0.9881\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 257/500\n","121/121 - 0s - loss: 0.3481 - accuracy: 0.9846\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 258/500\n","121/121 - 0s - loss: 0.4944 - accuracy: 0.9772\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 259/500\n","121/121 - 0s - loss: 0.6308 - accuracy: 0.9760\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 260/500\n","121/121 - 0s - loss: 0.7470 - accuracy: 0.9776\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 261/500\n","121/121 - 0s - loss: 0.7838 - accuracy: 0.9798\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 262/500\n","121/121 - 0s - loss: 0.7492 - accuracy: 0.9847\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 263/500\n","121/121 - 0s - loss: 0.7062 - accuracy: 0.9842\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 264/500\n","121/121 - 0s - loss: 0.6424 - accuracy: 0.9841\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 265/500\n","121/121 - 0s - loss: 0.5378 - accuracy: 0.9879\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 266/500\n","121/121 - 0s - loss: 0.4408 - accuracy: 0.9908\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 267/500\n","121/121 - 0s - loss: 0.3642 - accuracy: 0.9912\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 268/500\n","121/121 - 0s - loss: 0.3156 - accuracy: 0.9926\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 269/500\n","121/121 - 0s - loss: 0.2740 - accuracy: 0.9942\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 270/500\n","121/121 - 0s - loss: 0.2488 - accuracy: 0.9959\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 271/500\n","121/121 - 0s - loss: 0.2451 - accuracy: 0.9942\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 272/500\n","121/121 - 0s - loss: 0.2267 - accuracy: 0.9955\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 273/500\n","121/121 - 0s - loss: 0.2270 - accuracy: 0.9951\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 274/500\n","121/121 - 0s - loss: 0.2368 - accuracy: 0.9920\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 275/500\n","121/121 - 0s - loss: 0.3374 - accuracy: 0.9846\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 276/500\n","121/121 - 0s - loss: 0.5221 - accuracy: 0.9768\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 277/500\n","121/121 - 0s - loss: 0.8259 - accuracy: 0.9701\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 278/500\n","121/121 - 0s - loss: 0.9816 - accuracy: 0.9773\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 279/500\n","121/121 - 0s - loss: 0.8829 - accuracy: 0.9842\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 280/500\n","121/121 - 0s - loss: 0.7885 - accuracy: 0.9864\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 281/500\n","121/121 - 0s - loss: 0.6800 - accuracy: 0.9870\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 282/500\n","121/121 - 0s - loss: 0.6085 - accuracy: 0.9873\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 283/500\n","121/121 - 0s - loss: 0.5120 - accuracy: 0.9892\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 284/500\n","121/121 - 0s - loss: 0.4306 - accuracy: 0.9881\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 285/500\n","121/121 - 0s - loss: 0.3576 - accuracy: 0.9922\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 286/500\n","121/121 - 0s - loss: 0.3269 - accuracy: 0.9921\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 287/500\n","121/121 - 0s - loss: 0.2902 - accuracy: 0.9935\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 288/500\n","121/121 - 0s - loss: 0.2563 - accuracy: 0.9943\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 289/500\n","121/121 - 0s - loss: 0.2323 - accuracy: 0.9964\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 290/500\n","121/121 - 0s - loss: 0.2303 - accuracy: 0.9955\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 291/500\n","121/121 - 0s - loss: 0.2379 - accuracy: 0.9939\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 292/500\n","121/121 - 0s - loss: 0.2301 - accuracy: 0.9940\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 293/500\n","121/121 - 0s - loss: 0.2631 - accuracy: 0.9898\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 294/500\n","121/121 - 0s - loss: 0.3085 - accuracy: 0.9886\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 295/500\n","121/121 - 0s - loss: 0.3278 - accuracy: 0.9872\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 296/500\n","121/121 - 0s - loss: 0.4180 - accuracy: 0.9784\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 297/500\n","121/121 - 0s - loss: 0.6603 - accuracy: 0.9725\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 298/500\n","121/121 - 0s - loss: 0.7875 - accuracy: 0.9764\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 299/500\n","121/121 - 0s - loss: 0.7654 - accuracy: 0.9817\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 300/500\n","121/121 - 0s - loss: 0.7618 - accuracy: 0.9829\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 301/500\n","121/121 - 0s - loss: 0.6974 - accuracy: 0.9839\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 302/500\n","121/121 - 0s - loss: 0.6143 - accuracy: 0.9879\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 303/500\n","121/121 - 0s - loss: 0.5417 - accuracy: 0.9866\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 304/500\n","121/121 - 0s - loss: 0.4653 - accuracy: 0.9877\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 305/500\n","121/121 - 0s - loss: 0.3947 - accuracy: 0.9901\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 306/500\n","121/121 - 0s - loss: 0.3349 - accuracy: 0.9917\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 307/500\n","121/121 - 0s - loss: 0.2913 - accuracy: 0.9931\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 308/500\n","121/121 - 0s - loss: 0.2671 - accuracy: 0.9944\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 309/500\n","121/121 - 0s - loss: 0.2633 - accuracy: 0.9920\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 310/500\n","121/121 - 0s - loss: 0.2437 - accuracy: 0.9943\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 311/500\n","121/121 - 0s - loss: 0.2422 - accuracy: 0.9931\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 312/500\n","121/121 - 0s - loss: 0.2276 - accuracy: 0.9935\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 313/500\n","121/121 - 0s - loss: 0.2199 - accuracy: 0.9951\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 314/500\n","121/121 - 0s - loss: 0.2298 - accuracy: 0.9949\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 315/500\n","121/121 - 0s - loss: 0.2301 - accuracy: 0.9944\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 316/500\n","121/121 - 0s - loss: 0.2566 - accuracy: 0.9912\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 317/500\n","121/121 - 0s - loss: 0.3233 - accuracy: 0.9854\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 318/500\n","121/121 - 0s - loss: 0.5310 - accuracy: 0.9736\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 319/500\n","121/121 - 0s - loss: 1.1520 - accuracy: 0.9690\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 320/500\n","121/121 - 0s - loss: 1.3489 - accuracy: 0.9804\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 321/500\n","121/121 - 0s - loss: 1.2428 - accuracy: 0.9847\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 322/500\n","121/121 - 0s - loss: 1.2066 - accuracy: 0.9863\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 323/500\n","121/121 - 0s - loss: 1.1543 - accuracy: 0.9872\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 324/500\n","121/121 - 0s - loss: 0.9994 - accuracy: 0.9907\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 325/500\n","121/121 - 0s - loss: 0.9141 - accuracy: 0.9908\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 326/500\n","121/121 - 0s - loss: 0.7895 - accuracy: 0.9924\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 327/500\n","121/121 - 0s - loss: 0.6695 - accuracy: 0.9924\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 328/500\n","121/121 - 0s - loss: 0.5982 - accuracy: 0.9905\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 329/500\n","121/121 - 0s - loss: 0.5295 - accuracy: 0.9891\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 330/500\n","121/121 - 0s - loss: 0.4687 - accuracy: 0.9918\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 331/500\n","121/121 - 0s - loss: 0.3845 - accuracy: 0.9931\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 332/500\n","121/121 - 0s - loss: 0.3270 - accuracy: 0.9912\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 333/500\n","121/121 - 0s - loss: 0.3016 - accuracy: 0.9940\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 334/500\n","121/121 - 0s - loss: 0.2784 - accuracy: 0.9949\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 335/500\n","121/121 - 0s - loss: 0.2559 - accuracy: 0.9962\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 336/500\n","121/121 - 0s - loss: 0.2474 - accuracy: 0.9957\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 337/500\n","121/121 - 0s - loss: 0.2449 - accuracy: 0.9930\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 338/500\n","121/121 - 0s - loss: 0.2522 - accuracy: 0.9938\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 339/500\n","121/121 - 0s - loss: 0.2367 - accuracy: 0.9933\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 340/500\n","121/121 - 0s - loss: 0.2293 - accuracy: 0.9952\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 341/500\n","121/121 - 0s - loss: 0.2449 - accuracy: 0.9931\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 342/500\n","121/121 - 0s - loss: 0.2294 - accuracy: 0.9940\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 343/500\n","121/121 - 0s - loss: 0.2282 - accuracy: 0.9956\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 344/500\n","121/121 - 0s - loss: 0.2440 - accuracy: 0.9920\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 345/500\n","121/121 - 0s - loss: 0.2695 - accuracy: 0.9926\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 346/500\n","121/121 - 0s - loss: 0.3759 - accuracy: 0.9794\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 347/500\n","121/121 - 0s - loss: 0.7242 - accuracy: 0.9728\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 348/500\n","121/121 - 0s - loss: 1.0411 - accuracy: 0.9715\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 349/500\n","121/121 - 0s - loss: 1.1091 - accuracy: 0.9808\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 350/500\n","121/121 - 0s - loss: 1.0466 - accuracy: 0.9850\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 351/500\n","121/121 - 0s - loss: 0.9644 - accuracy: 0.9852\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 352/500\n","121/121 - 0s - loss: 0.8535 - accuracy: 0.9877\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 353/500\n","121/121 - 0s - loss: 0.7521 - accuracy: 0.9895\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 354/500\n","121/121 - 0s - loss: 0.6189 - accuracy: 0.9922\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 355/500\n","121/121 - 0s - loss: 0.5264 - accuracy: 0.9922\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 356/500\n","121/121 - 0s - loss: 0.4757 - accuracy: 0.9896\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 357/500\n","121/121 - 0s - loss: 0.4179 - accuracy: 0.9912\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 358/500\n","121/121 - 0s - loss: 0.3452 - accuracy: 0.9931\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 359/500\n","121/121 - 0s - loss: 0.2961 - accuracy: 0.9931\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 360/500\n","121/121 - 0s - loss: 0.2732 - accuracy: 0.9922\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 361/500\n","121/121 - 0s - loss: 0.2491 - accuracy: 0.9959\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 362/500\n","121/121 - 0s - loss: 0.2354 - accuracy: 0.9942\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 363/500\n","121/121 - 0s - loss: 0.2229 - accuracy: 0.9960\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 364/500\n","121/121 - 0s - loss: 0.2135 - accuracy: 0.9959\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 365/500\n","121/121 - 0s - loss: 0.2216 - accuracy: 0.9942\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 366/500\n","121/121 - 0s - loss: 0.2517 - accuracy: 0.9916\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 367/500\n","121/121 - 0s - loss: 0.2512 - accuracy: 0.9942\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 368/500\n","121/121 - 0s - loss: 0.2551 - accuracy: 0.9907\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 369/500\n","121/121 - 0s - loss: 0.3248 - accuracy: 0.9869\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 370/500\n","121/121 - 0s - loss: 0.4613 - accuracy: 0.9763\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 371/500\n","121/121 - 0s - loss: 0.8170 - accuracy: 0.9695\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 372/500\n","121/121 - 0s - loss: 1.0037 - accuracy: 0.9777\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 373/500\n","121/121 - 0s - loss: 1.0076 - accuracy: 0.9838\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 374/500\n","121/121 - 0s - loss: 1.0843 - accuracy: 0.9809\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 375/500\n","121/121 - 0s - loss: 0.9052 - accuracy: 0.9904\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 376/500\n","121/121 - 0s - loss: 0.8263 - accuracy: 0.9877\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 377/500\n","121/121 - 0s - loss: 0.7123 - accuracy: 0.9896\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 378/500\n","121/121 - 0s - loss: 0.6051 - accuracy: 0.9904\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 379/500\n","121/121 - 0s - loss: 0.4849 - accuracy: 0.9918\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 380/500\n","121/121 - 0s - loss: 0.3977 - accuracy: 0.9900\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 381/500\n","121/121 - 0s - loss: 0.3884 - accuracy: 0.9886\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 382/500\n","121/121 - 0s - loss: 0.3396 - accuracy: 0.9920\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 383/500\n","121/121 - 0s - loss: 0.2819 - accuracy: 0.9944\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 384/500\n","121/121 - 0s - loss: 0.2574 - accuracy: 0.9947\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 385/500\n","121/121 - 0s - loss: 0.2426 - accuracy: 0.9956\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 386/500\n","121/121 - 0s - loss: 0.2233 - accuracy: 0.9961\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 387/500\n","121/121 - 0s - loss: 0.2222 - accuracy: 0.9951\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 388/500\n","121/121 - 0s - loss: 0.2248 - accuracy: 0.9951\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 389/500\n","121/121 - 0s - loss: 0.2167 - accuracy: 0.9962\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 390/500\n","121/121 - 0s - loss: 0.2205 - accuracy: 0.9949\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 391/500\n","121/121 - 0s - loss: 0.2324 - accuracy: 0.9921\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 392/500\n","121/121 - 0s - loss: 0.2798 - accuracy: 0.9890\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 393/500\n","121/121 - 0s - loss: 0.4550 - accuracy: 0.9768\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 394/500\n","121/121 - 0s - loss: 0.6357 - accuracy: 0.9746\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 395/500\n","121/121 - 0s - loss: 0.7885 - accuracy: 0.9782\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 396/500\n","121/121 - 0s - loss: 0.7723 - accuracy: 0.9829\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 397/500\n","121/121 - 0s - loss: 0.7155 - accuracy: 0.9842\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 398/500\n","121/121 - 0s - loss: 0.6900 - accuracy: 0.9830\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 399/500\n","121/121 - 0s - loss: 0.6567 - accuracy: 0.9844\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 400/500\n","121/121 - 0s - loss: 0.6177 - accuracy: 0.9842\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 401/500\n","121/121 - 0s - loss: 0.5656 - accuracy: 0.9868\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 402/500\n","121/121 - 0s - loss: 0.5174 - accuracy: 0.9863\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 403/500\n","121/121 - 0s - loss: 0.4229 - accuracy: 0.9894\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 404/500\n","121/121 - 0s - loss: 0.3304 - accuracy: 0.9934\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 405/500\n","121/121 - 0s - loss: 0.2882 - accuracy: 0.9926\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 406/500\n","121/121 - 0s - loss: 0.2550 - accuracy: 0.9948\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 407/500\n","121/121 - 0s - loss: 0.2409 - accuracy: 0.9933\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 408/500\n","121/121 - 0s - loss: 0.2209 - accuracy: 0.9959\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 409/500\n","121/121 - 0s - loss: 0.2072 - accuracy: 0.9966\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 410/500\n","121/121 - 0s - loss: 0.2298 - accuracy: 0.9936\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 411/500\n","121/121 - 0s - loss: 0.2234 - accuracy: 0.9948\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 412/500\n","121/121 - 0s - loss: 0.2134 - accuracy: 0.9944\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 413/500\n","121/121 - 0s - loss: 0.2405 - accuracy: 0.9918\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 414/500\n","121/121 - 0s - loss: 0.2843 - accuracy: 0.9877\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 415/500\n","121/121 - 0s - loss: 0.3709 - accuracy: 0.9819\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 416/500\n","121/121 - 0s - loss: 0.4941 - accuracy: 0.9741\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 417/500\n","121/121 - 0s - loss: 1.0328 - accuracy: 0.9669\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 418/500\n","121/121 - 0s - loss: 1.2304 - accuracy: 0.9817\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 419/500\n","121/121 - 0s - loss: 1.1370 - accuracy: 0.9860\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 420/500\n","121/121 - 0s - loss: 1.0708 - accuracy: 0.9856\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 421/500\n","121/121 - 0s - loss: 0.9270 - accuracy: 0.9908\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 422/500\n","121/121 - 0s - loss: 0.8067 - accuracy: 0.9905\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 423/500\n","121/121 - 0s - loss: 0.7210 - accuracy: 0.9901\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 424/500\n","121/121 - 0s - loss: 0.6337 - accuracy: 0.9909\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 425/500\n","121/121 - 0s - loss: 0.5113 - accuracy: 0.9933\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 426/500\n","121/121 - 0s - loss: 0.4096 - accuracy: 0.9948\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 427/500\n","121/121 - 0s - loss: 0.3484 - accuracy: 0.9922\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 428/500\n","121/121 - 0s - loss: 0.3519 - accuracy: 0.9901\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 429/500\n","121/121 - 0s - loss: 0.3051 - accuracy: 0.9946\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 430/500\n","121/121 - 0s - loss: 0.2652 - accuracy: 0.9940\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 431/500\n","121/121 - 0s - loss: 0.2432 - accuracy: 0.9956\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 432/500\n","121/121 - 0s - loss: 0.2227 - accuracy: 0.9953\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 433/500\n","121/121 - 0s - loss: 0.2269 - accuracy: 0.9948\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 434/500\n","121/121 - 0s - loss: 0.2175 - accuracy: 0.9962\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 435/500\n","121/121 - 0s - loss: 0.2170 - accuracy: 0.9952\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 436/500\n","121/121 - 0s - loss: 0.2393 - accuracy: 0.9927\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 437/500\n","121/121 - 0s - loss: 0.2944 - accuracy: 0.9886\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 438/500\n","121/121 - 0s - loss: 0.4038 - accuracy: 0.9822\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 439/500\n","121/121 - 0s - loss: 0.5474 - accuracy: 0.9776\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 440/500\n","121/121 - 0s - loss: 0.7901 - accuracy: 0.9723\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 441/500\n","121/121 - 0s - loss: 0.9129 - accuracy: 0.9768\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 442/500\n","121/121 - 0s - loss: 0.8831 - accuracy: 0.9819\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 443/500\n","121/121 - 0s - loss: 0.8001 - accuracy: 0.9855\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 444/500\n","121/121 - 0s - loss: 0.7456 - accuracy: 0.9860\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 445/500\n","121/121 - 0s - loss: 0.6548 - accuracy: 0.9866\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 446/500\n","121/121 - 0s - loss: 0.5523 - accuracy: 0.9920\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 447/500\n","121/121 - 0s - loss: 0.4424 - accuracy: 0.9926\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 448/500\n","121/121 - 0s - loss: 0.3699 - accuracy: 0.9913\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 449/500\n","121/121 - 0s - loss: 0.3210 - accuracy: 0.9930\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 450/500\n","121/121 - 0s - loss: 0.2826 - accuracy: 0.9940\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 451/500\n","121/121 - 0s - loss: 0.2419 - accuracy: 0.9959\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 452/500\n","121/121 - 0s - loss: 0.2280 - accuracy: 0.9952\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 453/500\n","121/121 - 0s - loss: 0.2190 - accuracy: 0.9960\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 454/500\n","121/121 - 0s - loss: 0.2124 - accuracy: 0.9966\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 455/500\n","121/121 - 0s - loss: 0.2208 - accuracy: 0.9959\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 456/500\n","121/121 - 0s - loss: 0.2120 - accuracy: 0.9956\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 457/500\n","121/121 - 0s - loss: 0.2314 - accuracy: 0.9948\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 458/500\n","121/121 - 0s - loss: 0.2093 - accuracy: 0.9957\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 459/500\n","121/121 - 0s - loss: 0.2304 - accuracy: 0.9927\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 460/500\n","121/121 - 0s - loss: 0.3074 - accuracy: 0.9851\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 461/500\n","121/121 - 0s - loss: 0.4993 - accuracy: 0.9782\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 462/500\n","121/121 - 0s - loss: 0.7751 - accuracy: 0.9710\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 463/500\n","121/121 - 0s - loss: 1.1787 - accuracy: 0.9729\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 464/500\n","121/121 - 0s - loss: 1.1117 - accuracy: 0.9850\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 465/500\n","121/121 - 0s - loss: 0.9917 - accuracy: 0.9879\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 466/500\n","121/121 - 0s - loss: 0.8577 - accuracy: 0.9901\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 467/500\n","121/121 - 0s - loss: 0.7622 - accuracy: 0.9873\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 468/500\n","121/121 - 0s - loss: 0.6864 - accuracy: 0.9899\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 469/500\n","121/121 - 0s - loss: 0.6071 - accuracy: 0.9894\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 470/500\n","121/121 - 0s - loss: 0.5245 - accuracy: 0.9895\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 471/500\n","121/121 - 0s - loss: 0.4454 - accuracy: 0.9905\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 472/500\n","121/121 - 0s - loss: 0.3697 - accuracy: 0.9921\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 473/500\n","121/121 - 0s - loss: 0.3384 - accuracy: 0.9917\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 474/500\n","121/121 - 0s - loss: 0.2744 - accuracy: 0.9952\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 475/500\n","121/121 - 0s - loss: 0.2586 - accuracy: 0.9935\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 476/500\n","121/121 - 0s - loss: 0.2454 - accuracy: 0.9952\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 477/500\n","121/121 - 0s - loss: 0.2225 - accuracy: 0.9969\n","INFO:tensorflow:Assets written to: combine_rcnns_penul_no2nd_rNo2nd_into_dense_model_477_0.997/assets\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 478/500\n","121/121 - 0s - loss: 0.2195 - accuracy: 0.9949\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 479/500\n","121/121 - 0s - loss: 0.2177 - accuracy: 0.9952\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 480/500\n","121/121 - 0s - loss: 0.2211 - accuracy: 0.9939\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 481/500\n","121/121 - 0s - loss: 0.2257 - accuracy: 0.9927\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 482/500\n","121/121 - 0s - loss: 0.2597 - accuracy: 0.9907\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 483/500\n","121/121 - 0s - loss: 0.2738 - accuracy: 0.9938\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 484/500\n","121/121 - 0s - loss: 0.2331 - accuracy: 0.9938\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 485/500\n","121/121 - 0s - loss: 0.2967 - accuracy: 0.9865\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 486/500\n","121/121 - 0s - loss: 0.4395 - accuracy: 0.9771\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 487/500\n","121/121 - 0s - loss: 1.0123 - accuracy: 0.9642\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 488/500\n","121/121 - 0s - loss: 1.3168 - accuracy: 0.9815\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 489/500\n","121/121 - 0s - loss: 1.2381 - accuracy: 0.9843\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 490/500\n","121/121 - 0s - loss: 1.1828 - accuracy: 0.9874\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 491/500\n","121/121 - 0s - loss: 1.0367 - accuracy: 0.9891\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 492/500\n","121/121 - 0s - loss: 0.9113 - accuracy: 0.9901\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 493/500\n","121/121 - 0s - loss: 0.8232 - accuracy: 0.9890\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 494/500\n","121/121 - 0s - loss: 0.7527 - accuracy: 0.9898\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 495/500\n","121/121 - 0s - loss: 0.6658 - accuracy: 0.9905\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 496/500\n","121/121 - 0s - loss: 0.5599 - accuracy: 0.9925\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 497/500\n","121/121 - 0s - loss: 0.4679 - accuracy: 0.9925\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 498/500\n","121/121 - 0s - loss: 0.3829 - accuracy: 0.9936\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 499/500\n","121/121 - 0s - loss: 0.3169 - accuracy: 0.9939\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 500/500\n","121/121 - 0s - loss: 0.2781 - accuracy: 0.9951\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","27/27 [==============================] - 0s 2ms/step - loss: 0.3775 - accuracy: 0.9720\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["[0.3774701952934265, 0.9720279574394226]"]},"metadata":{"tags":[]},"execution_count":75}]},{"cell_type":"code","metadata":{"id":"2rmtDF-jGHoq"},"source":["cnn_combine_model = model_combination(\"combine_cnns_no2nd_j2nd_into_dense\", data_train_ll_no2nd_j2nd[0][0].shape  )\n","cnn_combine_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])  \n","callbacks_used_cnn_combine = [ModelCheckpoint(f'{cnn_combine_model.name}' + '_model_{epoch:03d}_{accuracy:0.3f}',\n","                                            save_weights_only=False,\n","                                            monitor='accuracy',\n","                                            mode='max',\n","                                            save_best_only=True),\n","                    tf.keras.callbacks.EarlyStopping(patience=10)\n","                    ]\n","cnn_combine_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n","history_cnn_combine = cnn_combine_model.fit(data_train_ll_no2nd_j2nd[0], \n","                                              data_train_ll_no2nd_j2nd[1][0], \n","                                              callbacks=callbacks_used_cnn_combine, \n","                                              verbose=2, \n","                                              epochs = 500, \n","                                              batch_size=64)\n","  \n","cnn_combine_model.evaluate(data_test_ll_no2nd_j2nd[0],data_test_ll_no2nd_j2nd[1][0]) # 96.85%\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"cw5iYRtPeRHK"},"source":["rcnn_combine_model = model_combination(\"combine_rcnns_no2nd_j2nd_rNo2nd_into_dense\", data_train_ll_no2nd_j2nd_rNo2nd[0][0].shape  )\n","rcnn_combine_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])  \n","callbacks_used_rcnn_combine = [ModelCheckpoint(f'{rcnn_combine_model.name}' + '_model_{epoch:03d}_{accuracy:0.3f}',\n","                                            save_weights_only=False,\n","                                            monitor='accuracy',\n","                                            mode='max',\n","                                            save_best_only=True),\n","                    tf.keras.callbacks.EarlyStopping(patience=10)\n","                    ]\n","rcnn_combine_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n","history_rcnn_combine = rcnn_combine_model.fit(data_train_ll_no2nd_j2nd_rNo2nd[0], \n","                                              data_train_ll_no2nd_j2nd_rNo2nd[1][0], \n","                                              callbacks=callbacks_used_rcnn_combine, \n","                                              verbose=2, \n","                                              epochs = 500, \n","                                              batch_size=64)\n","  \n","rcnn_combine_model.evaluate(data_test_ll_no2nd_j2nd_rNo2nd[0],data_test_ll_no2nd_j2nd_rNo2nd[1][0])  # 96.39%\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3TAUWcoueV7N"},"source":["cnn_penul_combine_model = model_combination(\"combine_cnns_penul_no2nd_j2nd_into_dense\", data_train_ll_no2nd_j2nd[0][0].shape  )\n","cnn_penul_combine_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])  \n","callbacks_used_cnn_combine_penul = [ModelCheckpoint(f'{cnn_penul_combine_model.name}' + '_model_{epoch:03d}_{accuracy:0.3f}',\n","                                            save_weights_only=False,\n","                                            monitor='accuracy',\n","                                            mode='max',\n","                                            save_best_only=True),\n","                    tf.keras.callbacks.EarlyStopping(patience=10)\n","                    ]\n","cnn_penul_combine_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n","history_cnn_penul_combine = cnn_penul_combine_model.fit(data_train_ll_no2nd_j2nd[0], \n","                                              data_train_ll_no2nd_j2nd[1][0], \n","                                              callbacks=callbacks_used_cnn_combine_penul, \n","                                              verbose=2, \n","                                              epochs = 500, \n","                                              batch_size=64)\n","  \n","cnn_penul_combine_model.evaluate(data_test_ll_no2nd_j2nd[0],data_test_ll_no2nd_j2nd[1][0]) # 96.39%"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ierH9hNbL5s6"},"source":["rcnn_penul_combine_model = model_combination(\"combine_rcnns_penul_no2nd_j2nd_rNo2nd_into_dense\", data_train_ll_penul_no2nd_j2nd_rNo2nd[0][0].shape  )\n","rcnn_penul_combine_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])  \n","callbacks_used_rcnn_combine_penul = [ModelCheckpoint(f'{rcnn_penul_combine_model.name}' + '_model_{epoch:03d}_{accuracy:0.3f}',\n","                                            save_weights_only=False,\n","                                            monitor='accuracy',\n","                                            mode='max',\n","                                            save_best_only=True),\n","                    tf.keras.callbacks.EarlyStopping(patience=10)\n","                    ]\n","rcnn_penul_combine_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n","history_rcnn_penul_combine = rcnn_penul_combine_model.fit(data_train_ll_penul_no2nd_j2nd_rNo2nd[0], \n","                                              data_train_ll_penul_no2nd_j2nd_rNo2nd[1][0], \n","                                              callbacks=callbacks_used_rcnn_combine_penul, \n","                                              verbose=2, \n","                                              epochs = 500, \n","                                              batch_size=64)\n","  \n","rcnn_penul_combine_model.evaluate(data_test_ll_penul_no2nd_j2nd_rNo2nd[0],data_test_ll_penul_no2nd_j2nd_rNo2nd[1][0]) # 97.32%\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0LkXb0FnHpGF","executionInfo":{"status":"ok","timestamp":1621464175493,"user_tz":-60,"elapsed":978,"user":{"displayName":"Hans Roggeman","photoUrl":"","userId":"10574434403170915342"}},"outputId":"31478fe0-70cb-433b-829a-6d4f1373a3ed"},"source":["cnn_combine_model.evaluate(data_test_ll_no2nd_j2nd[0],data_test_ll_no2nd_j2nd[1][0]) # 96.85%\n","rcnn_combine_model.evaluate(data_test_ll_no2nd_j2nd_rNo2nd[0],data_test_ll_no2nd_j2nd_rNo2nd[1][0]) # 96.39%\n","cnn_penul_combine_model.evaluate(data_test_ll_no2nd_j2nd[0],data_test_ll_no2nd_j2nd[1][0]) # 96.39%\n","rcnn_penul_combine_model.evaluate(data_test_ll_penul_no2nd_j2nd_rNo2nd[0],data_test_ll_penul_no2nd_j2nd_rNo2nd[1][0]) # 97.32%\n","rcnn_combine_models_no2nd_rNo2nd.evaluate(data_test_ll_no2nd_rNo2nd[0],data_test_ll_no2nd_rNo2nd[1][0]) # 96.39%\n","rcnn_combine_penul_models_no2nd_rNo2nd.evaluate(data_test_penul_no2nd_rNo2nd[0],data_test_penul_no2nd_rNo2nd[1][0]) # 97.20%"],"execution_count":76,"outputs":[{"output_type":"stream","text":["27/27 [==============================] - 0s 2ms/step - loss: 1.2021 - accuracy: 0.9685\n","27/27 [==============================] - 0s 2ms/step - loss: 0.4793 - accuracy: 0.9639\n","27/27 [==============================] - 0s 2ms/step - loss: 1.0965 - accuracy: 0.9639\n","27/27 [==============================] - 0s 2ms/step - loss: 1.4012 - accuracy: 0.9732\n","27/27 [==============================] - 0s 2ms/step - loss: 0.9990 - accuracy: 0.9639\n","27/27 [==============================] - 0s 2ms/step - loss: 0.3775 - accuracy: 0.9720\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["[0.3774701952934265, 0.9720279574394226]"]},"metadata":{"tags":[]},"execution_count":76}]},{"cell_type":"code","metadata":{"id":"JWoc0J2H0Bxt","executionInfo":{"status":"ok","timestamp":1621464559697,"user_tz":-60,"elapsed":614,"user":{"displayName":"Hans Roggeman","photoUrl":"","userId":"10574434403170915342"}}},"source":["cnn_combine_model.save(\"merge_model_a.h5\")\n","rcnn_combine_model.save(\"merge_model_b.h5\")\n","cnn_penul_combine_model.save(\"merge_model_c.h5\")\n","rcnn_penul_combine_model.save(\"merge_model_d.h5\")\n","rcnn_combine_models_no2nd_rNo2nd.save(\"merge_model_e.h5\")\n","rcnn_combine_penul_models_no2nd_rNo2nd.save(\"merge_model_f.h5\")"],"execution_count":78,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":16},"id":"CvKlUyHl0f0S","executionInfo":{"status":"ok","timestamp":1621464738895,"user_tz":-60,"elapsed":618,"user":{"displayName":"Hans Roggeman","photoUrl":"","userId":"10574434403170915342"}},"outputId":"1b058c17-ba24-4388-d5f9-d90ccfa19c16"},"source":["from google.colab import files\n","files.download(\"/content/merge_model_a.h5\")\n","files.download(\"/content/merge_model_b.h5\")\n","files.download(\"/content/merge_model_c.h5\")\n","files.download(\"/content/merge_model_d.h5\")\n","files.download(\"/content/merge_model_e.h5\")\n","files.download(\"/content/merge_model_f.h5\")"],"execution_count":80,"outputs":[{"output_type":"display_data","data":{"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"application/javascript":["download(\"download_df625db8-7f04-476b-9972-30274ec21b28\", \"merge_model_a.h5\", 629600)"],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"application/javascript":["download(\"download_05c62471-1abd-47cb-bc94-40d2a24787a4\", \"merge_model_b.h5\", 629576)"],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"application/javascript":["download(\"download_19ce778d-5bcd-4566-856a-d5fea6ec1c8a\", \"merge_model_c.h5\", 629944)"],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"application/javascript":["download(\"download_4181905c-a56a-4f80-a668-79d5a014d2da\", \"merge_model_d.h5\", 1105616)"],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"application/javascript":["download(\"download_2f5e4574-6765-4b0e-af6a-f398ef5c34d1\", \"merge_model_e.h5\", 589424)"],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"application/javascript":["download(\"download_e71453fc-c848-451a-a6ff-1ef30a1fca7c\", \"merge_model_f.h5\", 906424)"],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"EGiH8Wwl339i","executionInfo":{"status":"ok","timestamp":1621464448381,"user_tz":-60,"elapsed":638,"user":{"displayName":"Hans Roggeman","photoUrl":"","userId":"10574434403170915342"}}},"source":["# hypermodel_lastlayers_merge_1 = DNNFeatureMergeModel(model_name=\"combine_last_layers_no2nd_j2nd\", input_shape=(data_train_ll_no2nd_j2nd[0].shape[1],), num_classes=data_train_ll_no2nd_j2nd[1][0].shape[-1] )\n","hypermodel_lastlayers_merge_1 = DNNFeatureMergeModel(model_name=\"combine_best_into_DNN\", input_shape=(data_test_ll_penul_no2nd_j2nd_rNo2nd[0].shape[1],), num_classes=data_test_ll_penul_no2nd_j2nd_rNo2nd[1][0].shape[-1] )\n","\n","# tuner = BatchSizeTuner(\n","#     hypermodel_lastlayers_merge_1,\n","#     max_epochs=4,\n","#     objective='loss',\n","#     executions_per_trial=4,\n","#     hyperband_iterations=6,\n","#     seed=123,\n","#     directory=f'{hypermodel_lastlayers_merge_1.model_name}_hyperband'\n","# )\n","\n","# tuner.search(data_train_ll_no2nd_j2nd[0], data_train_ll_no2nd_j2nd[1][0],\n","#              epochs=50,\n","#              callbacks=[tf.keras.callbacks.EarlyStopping(patience=2)])\n","\n","tuner = BatchSizeTuner(\n","    hypermodel_lastlayers_merge_1,\n","    max_epochs=4,\n","    objective='loss',\n","    executions_per_trial=4,\n","    hyperband_iterations=6,\n","    seed=123,\n","    directory=f'{hypermodel_lastlayers_merge_1.model_name}_hyperband'\n",")\n","\n","tuner.search(data_train_ll_no2nd_j2nd_rNo2nd[0], data_train_ll_no2nd_j2nd_rNo2nd[1][0],\n","             epochs=50,\n","             callbacks=[tf.keras.callbacks.EarlyStopping(patience=2)])"],"execution_count":77,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2EogtPah4JLc","executionInfo":{"status":"ok","timestamp":1621456085272,"user_tz":-60,"elapsed":596167,"user":{"displayName":"Hans Roggeman","photoUrl":"","userId":"10574434403170915342"}},"outputId":"785aedac-6af8-4039-9a73-b6bc3f3f6594"},"source":[""],"execution_count":25,"outputs":[{"output_type":"stream","text":["Trial 60 Complete [00h 00m 07s]\n","loss: 1.4409853219985962\n","\n","Best loss So Far: 0.003907026839442551\n","Total elapsed time: 00h 09m 55s\n","INFO:tensorflow:Oracle triggered exit\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Aaw6v-2q4fiT"},"source":["# Show a summary of the search\n","tuner.results_summary()\n","# Retrieve the best model.\n","tuner.get_best_models()\n","\n","best_model = tuner.get_best_models(num_models=1)[0]\n","# best_model.save(\"hypermodel_merge_3lastlayers_m1.h5\")\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1-pmEiMW6EPY","executionInfo":{"status":"ok","timestamp":1621456418572,"user_tz":-60,"elapsed":1303,"user":{"displayName":"Hans Roggeman","photoUrl":"","userId":"10574434403170915342"}},"outputId":"0fdcf7a1-2694-4986-ae57-6939c3192fa9"},"source":["predY = np.apply_along_axis(np.argmax, 1, best_model.predict(data_test_ll_no2nd_j2nd_rNo2nd[0]))\n","trueY = np.apply_along_axis(np.argmax, 1, data_test_ll_no2nd_j2nd_rNo2nd[1][0])\n","np.sum(predY==trueY)/predY.shape[-1"],"execution_count":28,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n","WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Xfok3o8ZbxDH"},"source":["best_models = tuner.get_best_models(num_models=50)\n","for model in best_models:\n","  model.evaluate(data_test_ll_no2nd_j2nd_rNo2nd[0], data_test_ll_no2nd_j2nd_rNo2nd[1][0])\n","\n"],"execution_count":null,"outputs":[]}]}